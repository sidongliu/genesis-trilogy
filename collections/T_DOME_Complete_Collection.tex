% ============================================================================
% T-DOME: Thermodynamic Dynamics of Observer-Memory Entanglement
% Complete Collected Volume
% ============================================================================

\documentclass[12pt,a4paper,openany]{book}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amsfonts,amsthm}
\usepackage{physics}
\usepackage{graphicx}
\usepackage[hidelinks]{hyperref}
\usepackage{geometry}
\usepackage{fancyhdr}
\usepackage{array}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{caption}
\usepackage{float}

\geometry{a4paper, margin=1in, headheight=14pt}

\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{corollary}[theorem]{Corollary}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE,RO]{\thepage}
\fancyhead[RE]{\textit{Thermodynamic Dynamics of Observer-Memory Entanglement}}
\fancyhead[LO]{\textit{\leftmark}}
\renewcommand{\headrulewidth}{0.4pt}

\title{
  \vspace{-2cm}
  {\Huge\textbf{Thermodynamic Dynamics of\\Observer-Memory Entanglement}}\\[1cm]
  {\Large\textit{Memory, Ego, and Self-Referential Calibration\\
  in Persistent Far-from-Equilibrium Systems}}\\[2cm]
  {\large Complete Collected Volume}\\[0.5cm]
  {\normalsize Papers I, II, and III}
}

\author{
  \textbf{Sidong Liu, PhD}\\[0.5em]
  iBioStratix Ltd\\[0.3em]
  \texttt{sidongliu@hotmail.com}
}

\date{February 2026}

\begin{document}

\frontmatter
\maketitle

\newpage
\thispagestyle{empty}
\vspace*{\fill}
\begin{center}
\textbf{Publication Record}\\[2em]
\begin{tabular}{ll}
Paper I & DOI: 10.5281/zenodo.18574342 \\
Paper II & DOI: 10.5281/zenodo.18579703 \\
Paper III & DOI: 10.5281/zenodo.18591771 \\
\end{tabular}
\\[3em]
\textit{This collected volume compiles previously published works\\
for archival and reference purposes.}
\\[2em]
\copyright{} 2026 Sidong Liu. All rights reserved.
\end{center}
\vspace*{\fill}

\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}

This volume develops the theory of persistent agency under thermodynamic constraints.  The central question is: what minimal internal structure must an open quantum system possess in order to maintain itself far from equilibrium in a changing environment?

The answer is organised as an irreversible logical chain across three papers:

\begin{enumerate}
\item \textbf{Paper~I (Memory):} We prove a Markovian Ceiling---under open-loop Markovian dynamics the survival functional satisfies $\mathcal{S} \leq 0$---and show that non-Markovian memory (system--environment correlations carried forward in time) is necessary for sustained far-from-equilibrium persistence.  Memory, however, creates the Memory Catastrophe: unbounded history under finite resources leads to thermodynamic collapse.

\item \textbf{Paper~II (Ego):} We prove a Computational Ceiling---symmetric processing of a Clifford algebra $Cl(V,q)$ leads to computational paralysis at a finite critical time---and show that the resolution requires spontaneous symmetry breaking of the agent's internal reference frame.  The broken phase (the ``ego'') introduces four systematic bias terms and, under environmental drift, leads to the Delusion Trap: an exponential divergence of prediction error invisible from within the agent's own frame.

\item \textbf{Paper~III (Loop):} We show that the Fisher information of the agent's own prediction-residual stream provides a detectable drift signal (growing quadratically with accumulated drift), derive a Self-Referential Cram\'{e}r--Rao bound on drift estimation, and establish a Lyapunov tracking bound for the natural-gradient calibration loop.  The thermodynamic cost of the complete self-referential architecture is calculated explicitly.
\end{enumerate}

Each resolution creates the precondition for the next crisis: memory enables overload, compression enables bias, and bias demands calibration.  Together, the three papers establish a Four-Part Structure Proposition: within the class of agents satisfying the standing assumptions, a sufficient architecture for persistence comprises (1)~an external observable geometry, (2)~an internal control algebra, (3)~a self-monitoring Lyapunov function, and (4)~biased non-Markovian memory.

The framework builds on the Holographic Alaya-Field Framework (HAFF), which establishes that geometry emerges from observable algebras, and Q-RAIF, which establishes the algebraic constraints on persistent subsystems.  T-DOME completes the programme by characterising the \emph{observer}: the internal architecture that makes persistence possible.

\bigskip
\noindent\textbf{Keywords}: non-Markovian dynamics, open quantum systems, memory kernel, spontaneous symmetry breaking, bounded rationality, Fisher information, information geometry, self-referential calibration, Lyapunov stability, thermodynamic cost

\tableofcontents

\mainmatter


% ============================================================================
% PAPER I
% ============================================================================
\chapter{Non-Markovian Memory and the Thermodynamic Necessity of Temporal Accumulation}
\label{chap:paperI}

\begin{center}
\textit{Paper I --- ``The Seed''}\\[0.5em]
Originally published: Zenodo, DOI: 10.5281/zenodo.18574342
\end{center}

\bigskip

\section*{Abstract}
We investigate the thermodynamic constraints on open quantum systems
that must persist far from equilibrium in stochastic environments.
Working within the framework of stochastic thermodynamics and
information thermodynamics (Sagawa--Ueda), we define a
\emph{survival functional} $\mathcal{S} := \Delta F - W$
measuring the difference between the non-equilibrium free energy
gained and the work invested by an agent.

We prove a \textbf{Markovian Ceiling}: for any open-loop
Markovian (GKSL) dynamics with no measurement or feedback,
$\mathcal{S} \leq 0$---the agent cannot thermodynamically
``profit.''
We then derive an exact identity---valid for
\emph{arbitrary} (possibly correlated) initial states under
autonomous evolution in the weak-coupling limit---expressing
the survival functional in terms of the change in
system--environment mutual information and bath displacement:
$\beta\,\mathcal{S} = -\Delta I(S{:}E)
- \Delta D_{\mathrm{KL}}(\rho_E \| \rho_E^{\mathrm{th}})$.
Pre-existing correlations $I(S{:}E;\, 0) > 0$, built during
prior interaction epochs, serve as a consumable thermodynamic
resource; their consumption during non-Markovian backflow
intervals yields $\mathcal{S} > 0$, bounded by the initial
correlation budget.

This establishes \textbf{memory as a thermodynamic necessity}
for sustained far-from-equilibrium persistence.
The memory kernel induces a causal partial order on system
trajectories that, when restricted to the classical sector
selected by decoherence (quantum Darwinism), is consistent
with the accessibility ordering of the Holographic Alaya-Field
Framework (HAFF).
A worked example---a spin-boson model with Lorentz--Drude
spectral density---illustrates how non-Markovian backflow
enables free-energy extraction unavailable to memoryless systems.

Finally, using the entropy rate and predictive information from
computational mechanics, we quantify the intrinsic cost of memory
and identify the \textbf{Memory Catastrophe}: unbounded memory
under finite energy leads to thermodynamic collapse, motivating
the symmetry-breaking mechanism of Paper~II\@.

\medskip
\noindent\textbf{Keywords}: non-Markovian dynamics, open quantum systems,
Nakajima--Zwanzig equation, memory kernel, thermodynamic arrow of time,
information backflow, entropy production, stochastic thermodynamics


% ============================================================
\section{Introduction}
\label{I-sec:intro}

% ------------------------------------------------------------
\subsection{Context: The Problem of Persistence}

A quantum system coupled to a thermal environment generically
relaxes toward equilibrium. This is the content of the
\emph{zeroth crisis}: absent special structure, every open
subsystem is eventually erased by thermal noise~\cite{BreuerPetruccione2002}.

Yet the physical world contains persistent far-from-equilibrium
structures---from molecular machines to living organisms---that
maintain themselves against the entropic tide for timescales
vastly exceeding their intrinsic relaxation times. What
structural feature of their dynamics makes this possible?

The standard answer invokes free-energy input: a persistent system
is one that continuously imports low-entropy energy and exports
high-entropy waste~\cite{Schrodinger1944}. This is correct but
incomplete. Two systems receiving \emph{identical} free-energy
flux from \emph{identical} environments may exhibit vastly
different persistence characteristics. The distinguishing factor,
we argue, is \emph{memory}---the capacity to condition present
dynamics on past environmental states.

% ------------------------------------------------------------
\subsection{Position within the Series}

This paper is the first of three constituting the
\textbf{T-DOME} (Thermodynamic Dynamics of Observer-Memory
Entanglement) framework, the third pillar of a three-paper
program.

\begin{center}
\small
\setlength{\tabcolsep}{4pt}%
\begin{tabular}{@{}lp{3.2cm}cp{3.4cm}c@{}}
\toprule
\textbf{Framework} & \textbf{Question} & & \textbf{Result} & \textbf{Status} \\
\midrule
HAFF~\cite{Liu2026HAFF_A,Liu2026HAFF_B}
  & How does geometry emerge?
  & Ocean
  & Algebra $\to$ Geometry
  & Complete \\[3pt]
Q-RAIF~\cite{Liu2026QRAIF_A,Liu2026QRAIF_B}
  & What algebra must an observer have?
  & Fish
  & $Cl(V,q) \hookrightarrow Cl(1,3)$
  & Complete \\[3pt]
\textbf{T-DOME I} (this work)
  & Why must agents carry memory?
  & Seed
  & Markovian ceiling; memory as necessity
  & \textbf{This paper} \\[3pt]
T-DOME II
  & Why must agents break symmetry?
  & Ego
  & Reference-frame selection
  & Planned \\[3pt]
T-DOME III
  & How does self-calibration arise?
  & Loop
  & Fisher self-referential bound
  & Planned \\
\bottomrule
\end{tabular}
\end{center}

The three T-DOME papers form an irreversible logical chain.
Each resolves a survival crisis created by its predecessor:
\begin{enumerate}
\item \textbf{Paper I (The Seed):} Without memory, a system
  is trapped in the \emph{Markovian present}---no accumulation,
  no temporal arrow, inevitable thermal death.
  Memory breaks this trap but floods the system with unbounded
  historical data.
\item \textbf{Paper II (The Ego):} Unbounded memory under finite
  computational resources causes processing collapse.
  Spontaneous symmetry breaking of the reference frame
  (establishing a ``self'') resolves the overload but introduces
  systematic bias.
\item \textbf{Paper III (The Loop):} Uncorrected bias diverges from a
  changing environment. A self-referential calibration loop
  (monitoring one's own prediction error) resolves the bias
  but requires the system to ``observe its own observation''---closing
  the self-calibration loop.
\end{enumerate}

\noindent
The present paper addresses only the first link in this chain.

% ------------------------------------------------------------
\subsection{Relation to HAFF Paper F}

HAFF Paper F~\cite{Liu2026HAFF_F} establishes the arrow of time
as the direction of \emph{accessibility propagation}:
informational redundancy $\mathcal{R}(\hat{O})$ generically expands,
inducing a partial order $\prec$ on observable algebras.
That analysis is purely algebraic---it characterizes temporal
asymmetry without invoking dynamics.

The present paper complements Paper F by identifying the
\emph{dynamical} origin of temporal asymmetry: the non-Markovian
memory kernel $\mathcal{K}(t,s)$. We show (Section~\ref{I-sec:arrow})
that the partial order induced by the kernel's temporal support
embeds into the HAFF accessibility ordering as a sub-structure.
The two descriptions are dual faces of the same phenomenon:
Paper F provides the algebraic skeleton; Paper I provides the
dynamical muscle.

% ------------------------------------------------------------
\subsection{Scope and Disclaimers}

\begin{enumerate}
\item This work does \emph{not} claim that non-Markovian dynamics
  is sufficient for persistence. Memory is identified as
  \emph{necessary} under the conditions specified; sufficiency
  requires additional structure (Papers II and III).
\item We do \emph{not} claim that all non-Markovian systems
  outperform all Markovian systems. The theorem establishes that
  the supremum of survival efficiency over non-Markovian dynamics
  strictly exceeds the Markovian supremum.
\item We do \emph{not} derive the specific form of the memory
  kernel from first principles. The kernel is treated as a
  structural feature of the system-environment coupling.
\item The term ``agent'' is used in the control-theoretic sense
  (a subsystem that acts on its environment to maintain a target
  state) and carries no implication of consciousness, intention,
  or subjective experience.
\item A broader structural analogy with classical philosophical
  concepts of temporal persistence exists but is outside the
  scope of this paper.
\end{enumerate}

% ============================================================
\section{Mathematical Preliminaries}
\label{I-sec:prelim}

% ------------------------------------------------------------
\subsection{Open Quantum Systems: The Markovian Baseline}

Consider a bipartite Hilbert space
$\mathcal{H} = \mathcal{H}_R \otimes \mathcal{H}_E$,
where $R$ denotes the ``agent'' (reduced system) and $E$ the
environment. The total Hamiltonian is
\begin{equation}
\label{I-eq:H_total}
H = H_R \otimes \mathbb{1}_E
  + \mathbb{1}_R \otimes H_E
  + \lambda\, H_{\mathrm{int}},
\end{equation}
where $\lambda$ parametrizes the coupling strength.

Under the Born--Markov and secular approximations, the reduced
dynamics of $\rho_R(t) = \mathrm{Tr}_E[\rho(t)]$ is governed by
the Gorini--Kossakowski--Sudarshan--Lindblad (GKSL) master
equation~\cite{Lindblad1976,GKS1976}:
\begin{equation}
\label{I-eq:GKSL}
\dot{\rho}_R(t)
= -i[H_{\mathrm{eff}},\, \rho_R(t)]
  + \sum_k \gamma_k \left(
    L_k \rho_R(t) L_k^\dagger
    - \tfrac{1}{2}\{L_k^\dagger L_k,\, \rho_R(t)\}
  \right),
\end{equation}
with $\gamma_k \geq 0$ and Lindblad operators $\{L_k\}$.

\begin{remark}[Markovian = Memoryless]
\label{I-rem:markov}
The GKSL equation is \emph{time-local}: $\dot{\rho}_R(t)$ depends
only on $\rho_R(t)$, never on $\rho_R(s)$ for $s < t$.
Physically, this corresponds to an environment with vanishing
correlation time ($\tau_E \to 0$): the bath ``forgets'' its
interaction with the system instantaneously.
The semigroup property $\Lambda(t+s) = \Lambda(t)\Lambda(s)$
ensures complete positivity at all times but precludes any
information backflow from environment to system~\cite{RivasHuelgaPlenio2014}.
\end{remark}

% ------------------------------------------------------------
\subsection{Beyond Markov: The Nakajima--Zwanzig Equation}

When the environmental correlation time $\tau_E$ is non-negligible,
the Born--Markov approximation fails. The exact reduced dynamics
is captured by the Nakajima--Zwanzig (NZ) integro-differential
equation~\cite{Nakajima1958,Zwanzig1960}:
\begin{equation}
\label{I-eq:NZ}
\dot{\rho}_R(t)
= -i[H_{\mathrm{eff}},\, \rho_R(t)]
  + \int_0^t ds\; \mathcal{K}(t,s)\, \rho_R(s),
\end{equation}
where $\mathcal{K}(t,s)$ is the \textbf{memory kernel}---a
superoperator encoding the influence of the system's entire
history on its present dynamics.

\begin{definition}[Memory Kernel]
\label{I-def:kernel}
The memory kernel $\mathcal{K}: [0,\infty)^2 \to
\mathcal{L}(\mathcal{B}(\mathcal{H}_R))$ is the superoperator
satisfying~\eqref{I-eq:NZ}. It encodes two types of information:
\begin{enumerate}
\item \textbf{Environmental structure:} the spectral density,
  correlation functions, and non-equilibrium features of the bath;
\item \textbf{Temporal reach:} the effective support
  $\tau_{\mathrm{mem}} := \inf\{\tau : \|\mathcal{K}(t,s)\| < \epsilon
  \;\forall\; t - s > \tau\}$, the ``memory depth.''
\end{enumerate}
The Markovian limit corresponds to
$\mathcal{K}(t,s) \to \mathcal{K}_0\, \delta(t-s)$,
recovering the GKSL generator.
\end{definition}

\begin{remark}[Information Backflow]
\label{I-rem:backflow}
Non-Markovian dynamics admits \emph{information backflow}:
the distinguishability of two initial states, as measured by
trace distance $D(\rho_1(t), \rho_2(t))$, can temporarily
increase~\cite{BreuerLainePiilo2009}. This is the operational
signature of memory---the environment returns previously
absorbed information to the system.
\end{remark}

% ------------------------------------------------------------
\subsection{Thermodynamic Framework}
\label{I-subsec:thermo}

We adopt the framework of stochastic thermodynamics for open
quantum systems~\cite{EspositoLindenbergVandenBroeck2010}.
The following conventions are fixed throughout.

\begin{definition}[Thermodynamic Setup]
\label{I-def:thermo_setup}
\leavevmode
\begin{enumerate}
\item \textbf{Hamiltonian decomposition.}
  The system Hamiltonian is
  $H_S(t) = H_R + H_{\mathrm{ctrl}}(t)$,
  where $H_R$ is the \emph{fixed} bare Hamiltonian and
  $H_{\mathrm{ctrl}}(t)$ is the agent's time-dependent
  control protocol.
  The bath Hamiltonian $H_E$ and coupling $H_{\mathrm{int}}$
  are as in~\eqref{I-eq:H_total}.

\item \textbf{Reference state.}
  The thermal equilibrium state of the bare Hamiltonian is
  \begin{equation}
  \label{I-eq:rho_eq}
  \rho_{\mathrm{eq}} := \frac{e^{-\beta H_R}}{Z_R},
  \qquad Z_R := \tr(e^{-\beta H_R}),
  \qquad \beta := (k_B T)^{-1}.
  \end{equation}
  Since $H_R$ is time-independent, $\rho_{\mathrm{eq}}$ is a
  well-defined, fixed reference throughout the protocol.

\item \textbf{Non-equilibrium free energy.}
  For any state $\rho$ of the reduced system,
  \begin{equation}
  \label{I-eq:F_neq}
  F(\rho) := \tr(\rho\, H_R) + \beta^{-1}\tr(\rho\ln\rho)
  = \langle H_R \rangle_\rho - \beta^{-1} S(\rho),
  \end{equation}
  where $S(\rho) = -\tr(\rho\ln\rho)$ is the von~Neumann entropy.
  The equilibrium value is $F_{\mathrm{eq}} = -\beta^{-1}\ln Z_R$.

\item \textbf{Free energy--relative entropy identity.}
  \begin{equation}
  \label{I-eq:DKL_F}
  D_{\mathrm{KL}}(\rho \| \rho_{\mathrm{eq}})
  = \beta\bigl(F(\rho) - F_{\mathrm{eq}}\bigr) \geq 0.
  \end{equation}
  Thus $D_{\mathrm{KL}}$ measures the free-energy surplus in
  units of $k_B T$.

\item \textbf{Work.}
  The work performed on the system by the control protocol
  over $[0,\tau]$ is
  \begin{equation}
  \label{I-eq:work}
  W[0,\tau] := \int_0^\tau
  \tr\!\left(\rho(t)\,
  \frac{\partial H_{\mathrm{ctrl}}}{\partial t}\right) dt.
  \end{equation}

\item \textbf{Entropy-production functional.}
  The \emph{generalised entropy production} over $[0,\tau]$ is
  \begin{equation}
  \label{I-eq:Sigma}
  \Sigma[0,\tau] := \beta\bigl(W[0,\tau] - \Delta F\bigr),
  \end{equation}
  where $\Delta F = F(\rho(\tau)) - F(\rho(0))$.
  For uncorrelated (product) initial states,
  $\Sigma \geq 0$ recovers the standard second-law bound.
  For initially correlated states, $\Sigma$ can be
  \emph{negative}, reflecting the consumption of
  pre-existing correlations
  (see Remark~\ref{I-rem:battery}).
\end{enumerate}
\end{definition}

\begin{remark}[Why $H_R$ is fixed]
\label{I-rem:H_fixed}
The bare Hamiltonian $H_R$ defines the system's energy scale and
hence the reference state $\rho_{\mathrm{eq}}$.
The agent acts on the world through $H_{\mathrm{ctrl}}(t)$,
which may be time-dependent.
This separation ensures that $\rho_{\mathrm{eq}}$ is
well-defined and time-independent, avoiding the ambiguity
that arises when the full $H_S(t)$ is used to define the
thermal reference.
\end{remark}

\begin{definition}[Standing Assumptions]
\label{I-def:assumptions}
The following minimal assumptions are in force throughout
Sections~\ref{I-sec:advantage}--\ref{I-sec:example} unless
stated otherwise.
Every main result
(Lemma~\ref{I-lem:info_thermo},
Theorem~\ref{I-thm:advantage},
Corollary~\ref{I-cor:three_regimes})
relies \emph{only} on items
\textup{(A1)--(A5)} below.
\begin{enumerate}
\item[\textup{(A1)}]
  \textbf{Finite-dimensional bipartite system.}
  $\mathcal{H} = \mathcal{H}_S \otimes \mathcal{H}_E$,
  with total Hamiltonian~\eqref{I-eq:H_total}
  and global unitary evolution
  $U(t) = \mathcal{T}\exp(-i\int_0^t H(s)\,ds)$.

\item[\textup{(A2)}]
  \textbf{Weak coupling.}
  The system--environment interaction satisfies
  $\lambda \ll 1$ in~\eqref{I-eq:H_total}, so that
  $\Delta\langle H_{\mathrm{int}} \rangle
  = O(\lambda)$~\cite{BreuerPetruccione2002}.
  Energy conservation is then
  $\Delta\langle H_R\rangle
  + \Delta\langle H_{\mathrm{ctrl}}\rangle
  + \Delta\langle H_E\rangle \approx 0$
  up to controlled $O(\lambda)$ corrections.

\item[\textup{(A3)}]
  \textbf{Fixed environmental reference.}
  $\rho_E^{\mathrm{th}} := e^{-\beta H_E}/Z_E$
  is a fixed \emph{bookkeeping} Gibbs state at inverse
  temperature $\beta$.
  The \emph{actual} initial bath state $\rho_E(0)$
  need not coincide with $\rho_E^{\mathrm{th}}$;
  when $\rho_E(0) \neq \rho_E^{\mathrm{th}}$, the quantity
  $D_{\mathrm{KL}}(\rho_E(t)\|\rho_E^{\mathrm{th}})$
  tracks the nonequilibrium free energy stored in the bath
  relative to this reference.
  The bath Hamiltonian $H_E$ is time-independent.

\item[\textup{(A4)}]
  \textbf{Arbitrary initial state.}
  The total initial state $\rho_{SE}(0)$ is \emph{not}
  required to be a product state.
  In particular, initial system--environment correlations
  $I(S{:}E;\,0) > 0$ and initial bath displacement
  $D_{\mathrm{KL}}(\rho_E(0)\|\rho_E^{\mathrm{th}}) > 0$
  are both permitted.
\item[\textup{(A5)}]
  \textbf{Regularity.}
  All quantum states appearing in the thermodynamic
  identities are assumed to have full rank (or are
  restricted to their support), so that all relative
  entropies $D_{\mathrm{KL}}(\rho\|\sigma)$ are finite.
\end{enumerate}
\end{definition}

\begin{remark}[Bookkeeping conventions]
\label{I-rem:bookkeeping}
The heat absorbed by the environment is
$Q := \Delta\langle H_E \rangle
= \mathrm{Tr}[\rho_E(\tau) H_E]
  - \mathrm{Tr}[\rho_E(0) H_E]$
(matching
Esposito \emph{et al.}~\cite{EspositoLindenbergVandenBroeck2010}).
We define $\Sigma := \beta(W - \Delta F)$ as a
\emph{generalised entropy-balance functional};
for correlated initial conditions $\Sigma$ need not be
nonnegative
(see Remark~\ref{I-rem:battery}).
\end{remark}

% ------------------------------------------------------------
\subsection{The Survival Functional}
\label{I-subsec:survival}

We now define the central quantity of this paper.

\begin{definition}[Survival Functional]
\label{I-def:survival}
For a reduced system $R$ evolving under dynamics $\Lambda$
over $[0,\tau]$, the \textbf{survival functional} is
\begin{equation}
\label{I-eq:survival}
\mathcal{S}[\Lambda, \tau]
:= \Delta F - W[0,\tau]
= \bigl[F(\rho(\tau)) - F(\rho(0))\bigr] - W[0,\tau].
\end{equation}
Equivalently, using~\eqref{I-eq:Sigma},
\begin{equation}
\label{I-eq:survival_Sigma}
\beta\,\mathcal{S}[\Lambda,\tau] = -\Sigma[0,\tau].
\end{equation}
\end{definition}

\noindent\textit{Note on nomenclature.}
We retain the term ``survival functional'' to emphasize
the biological interpretation of persistence far from
equilibrium; mathematically, $\mathcal{S}$ is strictly a
\emph{generalized entropy-balance functional} derived from
the first and second laws.

\begin{remark}[Interpretation]
\label{I-rem:survival_interp}
The survival functional has a transparent physical meaning:
\begin{itemize}
\item $\mathcal{S} > 0$: the system gained more free energy than
  was invested by the external protocol---a \emph{thermodynamic
  profit}. The agent has extracted usable work from environmental
  correlations.
\item $\mathcal{S} = 0$: the agent breaks even (reversible limit,
  $\Sigma = 0$).
\item $\mathcal{S} < 0$: the agent paid more than it gained
  (the generic irreversible case).
\end{itemize}
Under the standard second law ($\Sigma \geq 0$),
$\mathcal{S} \leq 0$ always.
As we show in Sections~\ref{I-sec:ceiling} and~\ref{I-sec:advantage},
achieving $\mathcal{S} > 0$ requires \emph{information}---and
the memory kernel provides exactly this.
\end{remark}

\begin{remark}[Connection to Information Thermodynamics]
\label{I-rem:connection_SU}
In the Sagawa--Ueda framework~\cite{SagawaUeda2010,SagawaUeda2012},
a system under feedback control satisfies the generalized second law
\begin{equation}
\label{I-eq:sagawa_ueda}
\Sigma \geq -I_{\mathrm{feedback}},
\end{equation}
where $I_{\mathrm{feedback}} \geq 0$ is the mutual information
gained through measurement of the system.
This permits $\Sigma < 0$ (and hence $\mathcal{S} > 0$) at
the expense of information.
The core thesis of this paper is that a non-Markovian memory
kernel provides \emph{implicit} feedback: the system's history
encodes correlations with the environment that play the same
thermodynamic role as explicit measurement outcomes.
\end{remark}

% ============================================================
\section{The Markovian Ceiling}
\label{I-sec:ceiling}

We now establish the fundamental thermodynamic limitation
of memoryless agents.
The result is elementary given the framework of
Section~\ref{I-subsec:thermo}, but its consequences are far-reaching:
under \emph{open-loop} control---where the agent's protocol
$H_{\mathrm{ctrl}}(t)$ is fixed in advance and receives no
information from the bath---the survival functional can never
be positive.

\subsection{Spohn's Inequality}

Throughout this section we assume that the GKSL generator
$\mathcal{L}$ is a \emph{thermal Lindbladian}: it is obtained
from the weak-coupling (Davies) limit of a system coupled to a
single thermal bath at inverse temperature $\beta$, and satisfies
\textbf{quantum detailed balance} (the KMS
condition)~\cite{Spohn1978,BreuerPetruccione2002}.
Under this assumption, the unique stationary state is the Gibbs
state $\rho_{\mathrm{ss}} = \rho_{\mathrm{eq}}$
of~\eqref{I-eq:rho_eq}, and the generator is self-adjoint with
respect to the KMS inner product.
This ensures that the entropy production rate below is
well-defined and non-negative.

\begin{definition}[Markovian Semigroup]
\label{I-def:markov_semigroup}
Throughout this paper, ``Markovian'' dynamics refers
strictly to a \textbf{dynamical semigroup} generated by a
time-independent GKSL generator $\mathcal{L}$ with
non-negative rates.
While time-dependent CP-divisible
maps~\cite{RivasHuelgaPlenio2014} are often called
Markovian in broader contexts, the ceiling theorem
(Theorem~\ref{I-thm:ceiling}) targets the semigroup case
$\Lambda(t) = e^{\mathcal{L}t}$, where no memory effects
or temporal correlations can be exploited.
\end{definition}

\begin{lemma}[Spohn~\cite{Spohn1978}]
\label{I-lem:spohn}
For any GKSL dynamical semigroup $\Lambda_t = e^{\mathcal{L}t}$
satisfying quantum detailed balance with unique invariant state
$\rho_{\mathrm{eq}}$, the entropy production
rate
\begin{equation}
\label{I-eq:spohn_sigma}
\sigma(t) := -\tr\!\bigl(\mathcal{L}[\rho(t)]\,
(\ln\rho(t) - \ln\rho_{\mathrm{eq}})\bigr)
\end{equation}
satisfies $\sigma(t) \geq 0$, with equality if and only if
$\rho(t) = \rho_{\mathrm{eq}}$.
\end{lemma}

\begin{proof}
This follows from the contractivity of CPTP maps under quantum
relative entropy~\cite{Spohn1978,BreuerPetruccione2002}:
$D_{\mathrm{KL}}(\Lambda_t\rho \| \Lambda_t\rho_{\mathrm{eq}})
\leq D_{\mathrm{KL}}(\rho \| \rho_{\mathrm{eq}})$
for all $t \geq 0$.
Differentiating at $t = 0$ yields $\sigma(t) \geq 0$.
\end{proof}

\subsection{The Markovian Ceiling Theorem}

\begin{definition}[Open-loop Markovian control class
$\mathcal{C}_{\mathrm{M}}$]
\label{I-def:control_class}
A protocol $H_{\mathrm{ctrl}}(t)$ belongs to the
\textbf{open-loop Markovian control class}
$\mathcal{C}_{\mathrm{M}}$ if and only if:
\begin{enumerate}
\item[\textup{(C1)}] $H_{\mathrm{ctrl}}(t)$ is a
  \emph{predetermined} function of $t$ alone, fixed before the
  protocol begins.
\item[\textup{(C2)}] No measurement of the system or
  environment is performed during $[0,\tau]$, and
  $H_{\mathrm{ctrl}}(t)$ receives no feedback from measurement
  outcomes.
\item[\textup{(C3)}] $H_{\mathrm{ctrl}}(t)$ is statistically
  independent of the bath realization
  $\{\xi_E(s) : s \in [0,\tau]\}$.
\end{enumerate}
Protocols involving adaptive measurement-based feedback
(Sagawa--Ueda~\cite{SagawaUeda2010}) are \emph{excluded} from
$\mathcal{C}_{\mathrm{M}}$.
\end{definition}

\begin{theorem}[Markovian Ceiling]
\label{I-thm:ceiling}
Let $\Lambda^{\mathrm{M}}$ denote GKSL dynamics~\eqref{I-eq:GKSL}
satisfying quantum detailed balance
(Lemma~\ref{I-lem:spohn}), coupled to a stationary thermal bath at
inverse temperature $\beta$, under a control protocol
$H_{\mathrm{ctrl}}(t) \in \mathcal{C}_{\mathrm{M}}$
(Definition~\ref{I-def:control_class}).
Then the survival functional satisfies
\begin{equation}
\label{I-eq:ceiling}
\mathcal{S}[\Lambda^{\mathrm{M}}, \tau] \leq 0
\qquad\text{for all } \tau \geq 0.
\end{equation}
Equality holds in the quasi-static limit ($\Sigma \to 0$),
where the protocol varies slowly enough that the state
remains close to the instantaneous Gibbs state
$\rho_{\mathrm{eq}}(t)$ at all times.
\end{theorem}

\begin{proof}
The proof proceeds in two steps.

\noindent\textbf{Step 1: Free-energy balance.}
Differentiating~\eqref{I-eq:DKL_F}, the relative entropy
evolves as
\begin{equation}
\label{I-eq:balance}
\frac{d}{dt}\, D_{\mathrm{KL}}(\rho(t) \| \rho_{\mathrm{eq}})
= \beta\,\dot{W}(t) - \sigma(t),
\end{equation}
where $\dot{W}(t) = \tr(\rho(t)\,\partial_t H_{\mathrm{ctrl}})$
is the instantaneous power and $\sigma(t)$ is Spohn's entropy
production rate~\eqref{I-eq:spohn_sigma}.
Integrating over $[0,\tau]$:
\begin{equation}
\label{I-eq:balance_int}
\Delta D_{\mathrm{KL}} = \beta\, W[0,\tau]
  - \underbrace{\int_0^\tau \sigma(t)\, dt}_{\displaystyle
    = \Sigma \;\geq\; 0}.
\end{equation}

\noindent\textbf{Step 2: Applying Spohn.}
By Lemma~\ref{I-lem:spohn}, $\sigma(t) \geq 0$ for all $t$,
so $\Sigma \geq 0$.
From~\eqref{I-eq:balance_int}:
\begin{equation}
\Delta D_{\mathrm{KL}} \leq \beta\, W[0,\tau].
\end{equation}
Converting via~\eqref{I-eq:DKL_F}:
$\Delta F \leq W[0,\tau]$,
whence $\mathcal{S} = \Delta F - W \leq 0$.

The ceiling $\mathcal{S} = 0$ is achieved in the reversible
limit where the protocol is infinitely slow and $\sigma(t) \to 0$
pointwise.
\end{proof}

\begin{remark}[The ``Open-Loop'' Qualifier]
\label{I-rem:open_loop}
The restriction to the control class
$\mathcal{C}_{\mathrm{M}}$
(Definition~\ref{I-def:control_class}) is essential.
If the agent can perform \emph{measurements} on the bath and
condition its protocol on the outcomes---i.e., violate
condition~\textup{(C2)}---the Sagawa--Ueda
generalized second law~\eqref{I-eq:sagawa_ueda} permits
$\Sigma < 0$ (and hence $\mathcal{S} > 0$) at the expense
of mutual information.
The Markovian ceiling is therefore not a universal bound on
all Markovian agents, but on agents whose protocols satisfy
\textup{(C1)--(C3)}.

This qualifier is precisely the point:
the memory kernel of non-Markovian dynamics provides implicit
access to bath correlations, playing the role of implicit
measurement---the subject of Section~\ref{I-sec:advantage}.
\end{remark}

\begin{corollary}[Temporal Blindness]
\label{I-cor:blindness}
Under the Born--Markov approximation, the bath correlation
function is replaced by its white-noise limit
$C(t,s) \to C_0\,\delta(t-s)$, and the GKSL dissipator depends
only on the spectral density $J(\omega)$ evaluated at the
system's Bohr frequencies.
The agent interacts with the environment's
\emph{power spectrum} but is structurally blind to its
\emph{temporal correlations}---the off-diagonal elements
$C(t,s)$ for $t \neq s$.

Consequently, the spectral gap
$\lambda_{\min} \propto \sum_k J(\omega_k)$ of the Liouvillian
sets the rate of irreversible decay.
Maintaining $D_{\mathrm{KL}} > 0$ requires continuous work at
rate $\dot{W} \geq \beta^{-1}\sigma(t) > 0$, and the integrated
cost always meets or exceeds the integrated gain.
\end{corollary}

\begin{remark}[Dissipative vs.\ Self-Nourishing Structures]
\label{I-rem:ceiling_physics}
The Markovian ceiling partitions far-from-equilibrium structures
into two classes:
\begin{itemize}
\item \textbf{Dissipative structures} ($\mathcal{S} \leq 0$):
  sustained by continuous external free-energy input.
  Every unit of order is paid for in full.
  (Prigogine's sense~\cite{Schrodinger1944}.)
\item \textbf{Self-nourishing structures} ($\mathcal{S} > 0$):
  extract structured advantage from environmental correlations,
  gaining more free energy than they consume.
  These require information flow, and hence memory.
\end{itemize}
The ceiling is not a limitation of the agent's control
strategy but a \emph{structural consequence} of temporal
blindness: without memory, the environment's temporal
correlations are thermodynamically invisible.
\end{remark}

% ============================================================
\section{The Non-Markovian Advantage}
\label{I-sec:advantage}

Having established that open-loop Markovian agents are
thermodynamically capped at $\mathcal{S} \leq 0$, we now
demonstrate how non-Markovian dynamics breaks this ceiling.
The mechanism is grounded entirely in standard quantities:
the quantum mutual information $I(S{:}E)$ between system
and environment serves as a consumable thermodynamic resource.
Non-Markovian backflow intervals are precisely those during
which pre-existing correlations are consumed, enabling the
system to extract free energy beyond what open-loop work
provides.

\subsection{System--Environment Mutual Information}

We work with the total system--environment state
$\rho_{SE}(t)$, evolving unitarily under the total
Hamiltonian~\eqref{I-eq:H_total}.
The quantum mutual information
\begin{equation}
\label{I-eq:mutual_info}
I(S{:}E;\, t) := S(\rho_S(t)) + S(\rho_E(t))
  - S(\rho_{SE}(t))
= D_{\mathrm{KL}}\!\bigl(\rho_{SE}(t) \,\big\|\,
  \rho_S(t) \otimes \rho_E(t)\bigr)
\geq 0
\end{equation}
quantifies the total correlations (classical and quantum)
between the system $S$ and the environment $E$ at time $t$.

\begin{remark}[Role of Initial Correlations]
\label{I-rem:initial_corr}
Under the Born approximation, the initial state is taken as a
product $\rho_{SE}(0) = \rho_S(0) \otimes \rho_E^{\mathrm{th}}$,
so $I(S{:}E;\, 0) = 0$.
For a system that has already been interacting with its
environment (the physically generic situation for a
``persistent agent''), the effective initial state at any
restart time $t_0 > 0$ is \emph{not} a product state:
the preceding evolution has established correlations
$I(S{:}E;\, t_0) > 0$.
These pre-existing correlations---the system's ``memory''
of past interactions---are the thermodynamic resource
that the memory kernel can exploit.
\end{remark}

\subsection{The Information--Thermodynamic Identity}

The following identity is the central technical tool of this
section.
It holds for \textbf{any} initial state---product or
correlated---and relies only on unitarity and the definitions
of mutual information and relative entropy.

\begin{remark}[Relative-entropy chain rule]
\label{I-rem:chain_rule}
We repeatedly use the identity
\begin{equation}
\label{I-eq:chain_general}
D_{\mathrm{KL}}\!\bigl(\rho_{SE}\,\big\|\,
  \rho_S\otimes\sigma_E\bigr)
= I(S{:}E)_{\rho_{SE}}
  + D_{\mathrm{KL}}(\rho_E\|\sigma_E),
\end{equation}
valid for \emph{arbitrary} (possibly correlated)
$\rho_{SE}$ and any full-rank reference state
$\sigma_E$.\footnote{This follows from the definition of
quantum relative entropy and
$\ln(\rho_S\otimes\sigma_E)
= \ln\rho_S\otimes\mathbb{1}_E
  +\mathbb{1}_S\otimes\ln\sigma_E$.
See, e.g., M.~M.~Wilde, \emph{Quantum Information
Theory}, 2nd ed., Cambridge University Press (2017),
Sec.~11; and M.~A.~Nielsen and I.~L.~Chuang,
\emph{Quantum Computation and Quantum Information},
Cambridge University Press (2000), Ch.~11.}
Importantly, this is a \emph{pure algebraic identity} and
does not assume product initial conditions.
\end{remark}

\begin{lemma}[Information--Thermodynamic Identity]
\label{I-lem:info_thermo}
Let $\rho_{SE}(t)$ evolve unitarily under the total
Hamiltonian.
Then, for \textbf{any} initial state $\rho_{SE}(0)$
(product or correlated):
\begin{equation}
\label{I-eq:info_thermo}
\Delta I(S{:}E)
+ \Delta D_{\mathrm{KL}}\!\bigl(\rho_E \,\big\|\,
  \rho_E^{\mathrm{th}}\bigr)
= \Delta S_S + \beta\,\Delta\langle H_E \rangle,
\end{equation}
where $\Delta S_S = S(\rho_S(\tau)) - S(\rho_S(0))$ is the
change in the system's von~Neumann entropy and
$\Delta\langle H_E \rangle
= \mathrm{Tr}[\rho_E(\tau)\, H_E]
  - \mathrm{Tr}[\rho_E(0)\, H_E]$
is the energy absorbed by the environment.
\end{lemma}

\begin{proof}
Applying the chain rule~\eqref{I-eq:chain_general}
(Remark~\ref{I-rem:chain_rule}) with
$\sigma_E = \rho_E^{\mathrm{th}}$:
\begin{equation}
\label{I-eq:chain_step}
D_{\mathrm{KL}}\!\bigl(\rho_{SE}(t) \,\big\|\,
  \rho_S(t) \otimes \rho_E^{\mathrm{th}}\bigr)
= I(S{:}E;\, t)
  + D_{\mathrm{KL}}\!\bigl(\rho_E(t) \,\big\|\,
    \rho_E^{\mathrm{th}}\bigr).
\end{equation}
Expanding the left side using
$\ln\rho_E^{\mathrm{th}} = -\beta H_E - \ln Z_E$:
\begin{equation}
\label{I-eq:phi_expand}
D_{\mathrm{KL}}\!\bigl(\rho_{SE}(t) \,\big\|\,
  \rho_S(t) \otimes \rho_E^{\mathrm{th}}\bigr)
= -S(\rho_{SE}(t)) + S(\rho_S(t))
  + \beta\langle H_E \rangle_t + \ln Z_E.
\end{equation}
Since the total evolution is unitary,
$S(\rho_{SE}(t)) = S(\rho_{SE}(0))$ for all $t$.
Taking the difference between times $\tau$ and $0$ cancels
both $S(\rho_{SE})$ and $\ln Z_E$, yielding
\begin{equation}
\Delta\!\left[I(S{:}E)
  + D_{\mathrm{KL}}(\rho_E \| \rho_E^{\mathrm{th}})\right]
= \Delta S_S + \beta\,\Delta\langle H_E \rangle.
\end{equation}
\end{proof}

\begin{remark}[No assumption on the initial state]
\label{I-rem:no_product_lemma}
The proof of Lemma~\ref{I-lem:info_thermo} uses \emph{only}
unitarity ($\Delta S(\rho_{SE}) = 0$) and the algebraic
structure of the KL divergence.
No assumption is made about the initial state $\rho_{SE}(0)$,
the coupling strength, or the character (Markovian or
non-Markovian) of the reduced dynamics.
When the initial state is a product state with the environment
in thermal equilibrium, all initial-time terms vanish and the
identity reduces to the Esposito
decomposition~\cite{EspositoLindenbergVandenBroeck2010}:
$\Sigma = I(S{:}E;\,\tau)
+ D_{\mathrm{KL}}(\rho_E(\tau) \| \rho_E^{\mathrm{th}})$.
\end{remark}

\subsection{The Survival Identity}

We now connect the information--thermodynamic
identity~\eqref{I-eq:info_thermo} to the survival
functional $\mathcal{S}$ defined in
Section~\ref{I-subsec:survival}.

\begin{theorem}[Survival Functional: General Form]
\label{I-thm:advantage}
Under Assumptions \textup{(A1)--(A5)} of
Definition~\ref{I-def:assumptions},
let $\rho_{SE}(t)$ evolve unitarily from an \emph{arbitrary}
(possibly correlated) initial state $\rho_{SE}(0)$.
The survival functional
satisfies
\begin{equation}
\label{I-eq:advantage}
\boxed{\;
\beta\,\mathcal{S}[\Lambda,\tau]
= -\Delta I(S{:}E)
  - \Delta D_{\mathrm{KL}}\!\bigl(\rho_E \,\big\|\,
    \rho_E^{\mathrm{th}}\bigr)
  - \beta\,\Delta\langle H_{\mathrm{ctrl}} \rangle,
\;}
\end{equation}
where $\Delta\langle H_{\mathrm{ctrl}} \rangle
= \mathrm{Tr}[\rho_S(\tau)\, H_{\mathrm{ctrl}}(\tau)]
  - \mathrm{Tr}[\rho_S(0)\, H_{\mathrm{ctrl}}(0)]$
is the change in the control-field energy.

For \textbf{autonomous evolution}
($H_{\mathrm{ctrl}} = 0$ throughout $[0,\tau]$),
the control term vanishes:
\begin{equation}
\label{I-eq:advantage_auto}
\beta\,\mathcal{S}[\Lambda,\tau]
= -\Delta I(S{:}E)
  - \Delta D_{\mathrm{KL}}\!\bigl(\rho_E \,\big\|\,
    \rho_E^{\mathrm{th}}\bigr).
\end{equation}
\end{theorem}

\begin{proof}
The proof uses three ingredients: the definition of
$\mathcal{S}$, the first law, and
Lemma~\ref{I-lem:info_thermo}.

\noindent\textbf{Step 1 (First law in weak coupling).}
Since $H_{\mathrm{ctrl}}(t)$ is the only time-dependent
component of $H$, the work satisfies
$W = \Delta\langle H \rangle
\approx \Delta\langle H_R \rangle
  + \Delta\langle H_{\mathrm{ctrl}} \rangle
  + \Delta\langle H_E \rangle$
by Assumption~\textup{(A2)}.

\noindent\textbf{Step 2 (Connecting $\Sigma$ to the
identity).}
From Definition~\ref{I-def:survival} and~\eqref{I-eq:Sigma},
using $\Delta F = \Delta\langle H_R \rangle
- \beta^{-1}\Delta S_S$:
\begin{align}
\Sigma &= \beta(W - \Delta F)
= \beta\bigl(W - \Delta\langle H_R \rangle\bigr)
  + \Delta S_S \nonumber \\
&= \beta\bigl(\Delta\langle H_{\mathrm{ctrl}} \rangle
  + \Delta\langle H_E \rangle\bigr) + \Delta S_S
\nonumber \\
&= \bigl(\Delta S_S
  + \beta\,\Delta\langle H_E \rangle\bigr)
  + \beta\,\Delta\langle H_{\mathrm{ctrl}} \rangle.
\label{I-eq:Sigma_decomp}
\end{align}
By Lemma~\ref{I-lem:info_thermo}, the parenthesized term
equals
$\Delta I(S{:}E)
+ \Delta D_{\mathrm{KL}}(\rho_E \| \rho_E^{\mathrm{th}})$.
Hence
\begin{equation}
\label{I-eq:Sigma_general}
\Sigma = \Delta I(S{:}E)
  + \Delta D_{\mathrm{KL}}\!\bigl(\rho_E \,\big\|\,
    \rho_E^{\mathrm{th}}\bigr)
  + \beta\,\Delta\langle H_{\mathrm{ctrl}} \rangle.
\end{equation}

\noindent\textbf{Step 3 (Survival functional).}
$\beta\,\mathcal{S} = -\Sigma$ by~\eqref{I-eq:survival_Sigma},
yielding~\eqref{I-eq:advantage}.
For $H_{\mathrm{ctrl}} = 0$:
$\Delta\langle H_{\mathrm{ctrl}} \rangle = 0$,
recovering~\eqref{I-eq:advantage_auto}.
\end{proof}

\begin{remark}[Nature of the result]
\label{I-rem:identity_not_bound}
Equation~\eqref{I-eq:advantage} is an exact
\emph{accounting identity}, not an inequality or
optimality bound.
It establishes that any thermodynamic profit
($\mathcal{S} > 0$) in the autonomous regime must be
perfectly balanced by the consumption of
system--environment correlations ($\Delta I < 0$) or
the relaxation of the bath
($\Delta D_{\mathrm{KL}} < 0$).
The ``non-Markovian advantage'' arises because memory
kernels allow access to regimes where
$\Delta I(S{:}E)$ is negative and dominant---a channel
that memoryless (Born--Markov) dynamics resets to zero
at every time step
(Remark~\ref{I-rem:born_kills}).
\end{remark}

\begin{remark}[Scope of the theorem]
\label{I-rem:no_product}
Theorem~\ref{I-thm:advantage} holds for \emph{any} initial
state $\rho_{SE}(0)$---product or correlated.
The proof requires only
Assumptions~\textup{(A1)--(A5)} of
Definition~\ref{I-def:assumptions} and the definitions of
$\mathcal{S}$, $I(S{:}E)$, and $D_{\mathrm{KL}}$.
No assumption about the reduced dynamics (Markovian,
non-Markovian, or otherwise) is needed.
This generality is essential: a persistent agent that has
already been interacting with its environment necessarily
carries correlations ($I(S{:}E;\,0) > 0$), and it is
precisely these correlations that constitute the thermodynamic
resource for survival.
\end{remark}

\subsection{Three Regimes of Survival}

We specialize to the autonomous case
($H_{\mathrm{ctrl}} = 0$), which is the natural setting for
the ``memory as a resource'' argument: the agent benefits from
pre-existing correlations without external driving.

\begin{corollary}[Three Regimes]
\label{I-cor:three_regimes}
Under autonomous evolution, identity~\eqref{I-eq:advantage_auto}
identifies three regimes:
\begin{enumerate}
\item \textbf{Product initial state}
  ($I(S{:}E;\, 0) = 0$,
  $D_{\mathrm{KL}}(\rho_E(0) \| \rho_E^{\mathrm{th}}) = 0$):
  Both $\Delta I$ and $\Delta D_{\mathrm{KL}}$ are increases
  from zero to non-negative final values, so
  \[
  \beta\,\mathcal{S}
  = -\bigl(I(S{:}E;\,\tau)
  + D_{\mathrm{KL}}(\rho_E(\tau) \| \rho_E^{\mathrm{th}})\bigr)
  \leq 0.
  \]
  This recovers the Markovian ceiling
  (Theorem~\ref{I-thm:ceiling}), now with a precise accounting
  of \emph{where} the entropy goes: into system--environment
  correlations and bath displacement.

\item \textbf{Correlated initial state}
  ($I(S{:}E;\, 0) > 0$):
  If the dynamics \emph{consumes} pre-existing correlations
  ($\Delta I < 0$, i.e., $I(S{:}E;\, \tau) < I(S{:}E;\, 0)$),
  the first term contributes \emph{positively} to
  $\mathcal{S}$.
  Provided
  \begin{equation}
  \label{I-eq:ceiling_breach}
  |\Delta I(S{:}E)| > \Delta D_{\mathrm{KL}}\!\bigl(\rho_E
  \,\big\|\, \rho_E^{\mathrm{th}}\bigr),
  \end{equation}
  the survival functional is strictly positive:
  $\mathcal{S} > 0$.
  The agent has converted pre-existing correlations into
  usable free energy.

\item \textbf{Upper bound:}
  Since $I(S{:}E;\, \tau) \geq 0$ and
  $D_{\mathrm{KL}}(\rho_E(\tau) \| \rho_E^{\mathrm{th}})
  \geq 0$, the maximum survival gain is bounded by
  \begin{equation}
  \label{I-eq:S_upper}
  \beta\,\mathcal{S}
  \leq I(S{:}E;\, 0)
    + D_{\mathrm{KL}}\!\bigl(\rho_E(0) \,\big\|\,
      \rho_E^{\mathrm{th}}\bigr).
  \end{equation}
  The thermodynamic profit cannot exceed the total initial
  ``resource budget''---the pre-existing correlations plus
  the initial displacement of the bath from equilibrium.
\end{enumerate}
\end{corollary}

\subsection{The Correlation Battery}

The three regimes of Corollary~\ref{I-cor:three_regimes} raise a
natural question: \emph{where do the initial correlations
$I(S{:}E;\, 0) > 0$ come from?}

\begin{remark}[The Correlation Battery]
\label{I-rem:battery}
The answer is: from \textbf{prior interaction epochs}.
A persistent agent does not begin its existence in a product
state.
Over any interaction interval, unitary evolution generically
builds system--environment correlations ($\Delta I > 0$),
at a thermodynamic cost ($\mathcal{S} < 0$ during this
phase by Corollary~\ref{I-cor:three_regimes}(i)).
The non-Markovian agent's advantage is that these correlations
\emph{persist} and can be consumed during later intervals
($\Delta I < 0$, $\mathcal{S} > 0$).

The process is analogous to a \textbf{battery}:
\begin{itemize}
\item \textbf{Charging phase}
  (correlation building, $\Delta I > 0$):
  the agent ``pays'' free energy to build
  system--environment correlations.
  $\mathcal{S} < 0$.
\item \textbf{Discharging phase}
  (correlation consumption, $\Delta I < 0$):
  the agent extracts free energy from the stored
  correlations.
  $\mathcal{S} > 0$.
\end{itemize}
A Markovian agent cannot operate this battery.
The Born approximation resets $I(S{:}E) = 0$ at every
infinitesimal time step, destroying the stored correlations
before they can be used.
The semigroup property $\Lambda(t+s) = \Lambda(t)\Lambda(s)$
is precisely the statement that no inter-epoch correlations
survive.
The memory kernel $\mathcal{K}(t,s)$ is what allows the
non-Markovian agent to carry charge across epochs.

Crucially, global thermodynamics remains respected.
For any full cycle starting from an uncorrelated thermal
state ($I(S{:}E;\,0) = 0$,
$D_{\mathrm{KL}}(\rho_E(0)\|\rho_E^{\mathrm{th}}) = 0$),
the total survival functional satisfies
\begin{equation}
\label{I-eq:battery_closure}
\beta\,\mathcal{S}[0, t]
= -\Sigma[0, t] \;\leq\; 0
\qquad\text{(second law).}
\end{equation}
The local positivity $\mathcal{S}[t^*, t] > 0$ during the
discharging phase is strictly funded by the free energy
dissipated during the earlier charging phase
(see Proposition~\ref{I-prop:full_cycle} for the formal
decomposition).
\end{remark}

\begin{proposition}[Full-cycle closure]
\label{I-prop:full_cycle}
Under the conditions of
Theorem~\textup{\ref{I-thm:advantage}} with autonomous evolution
($H_{\mathrm{ctrl}} = 0$), partition $[0,\tau]$ at any
intermediate time $t^*$ into a charging phase $[0,t^*]$ and
a discharging phase $[t^*,\tau]$.
\begin{enumerate}
\item[\textup{(i)}]
  \textbf{Charging} (product initial state, $I(S{:}E;\,0) = 0$).
  By Corollary~\textup{\ref{I-cor:three_regimes}(i)},
  \begin{equation}
  \label{I-eq:charge}
  \beta\,\mathcal{S}[0,t^*]
  = -I(S{:}E;\,t^*)
    - D_{\mathrm{KL}}\!\bigl(\rho_E(t^*) \,\big\|\,
      \rho_E^{\mathrm{th}}\bigr)
  \;\leq\; 0.
  \end{equation}
\item[\textup{(ii)}]
  \textbf{Discharging} (correlated initial state at $t^*$).
  Applying~\eqref{I-eq:advantage_auto} to $[t^*,\tau]$:
  \begin{equation}
  \label{I-eq:discharge}
  \beta\,\mathcal{S}[t^*,\tau]
  = -\bigl(I(S{:}E;\,\tau) - I(S{:}E;\,t^*)\bigr)
    - \bigl(D_{\mathrm{KL}}(\rho_E(\tau)\|\rho_E^{\mathrm{th}})
      - D_{\mathrm{KL}}(\rho_E(t^*)\|\rho_E^{\mathrm{th}})\bigr),
  \end{equation}
  which is positive whenever the decrease in correlations
  dominates the change in bath displacement
  (Corollary~\textup{\ref{I-cor:three_regimes}(ii)}).
\item[\textup{(iii)}]
  \textbf{Full cycle.}
  Since $\mathcal{S}$ is additive over concatenated intervals,
  $\beta\,\mathcal{S}[0,\tau]
  = \beta\,\mathcal{S}[0,t^*]
    + \beta\,\mathcal{S}[t^*,\tau]$.
  Equivalently, applying~\eqref{I-eq:advantage_auto} directly to
  $[0,\tau]$ with $I(S{:}E;\,0) = 0$:
  \begin{equation}
  \label{I-eq:full_cycle}
  \beta\,\mathcal{S}[0,\tau]
  = -I(S{:}E;\,\tau)
    - D_{\mathrm{KL}}\!\bigl(\rho_E(\tau) \,\big\|\,
      \rho_E^{\mathrm{th}}\bigr)
  \;\leq\; 0.
  \end{equation}
\end{enumerate}
The net thermodynamic profit over the full cycle is
non-positive---the ``interest'' paid during charging
meets or exceeds the ``dividend'' collected during
discharging.
But the \emph{local} positivity of $\mathcal{S}$ during
discharge~\eqref{I-eq:discharge} is what enables the agent
to survive through intervals that would kill a memoryless
system.
\end{proposition}

\begin{proof}
The survival functional is additive over concatenated
intervals:
\[
\mathcal{S}[0,\tau]
= \underbrace{(\Delta F[0,t^*] - W[0,t^*])}_{\mathcal{S}[0,t^*]}
  +\; \underbrace{(\Delta F[t^*,\tau] - W[t^*,\tau])}_{\mathcal{S}[t^*,\tau]},
\]
since both $\Delta F$ and $W$ decompose additively.
Items (i) and (iii) then follow from
Theorem~\ref{I-thm:advantage} (autonomous case) applied to
$[0,t^*]$ and $[0,\tau]$ respectively, each starting from
a product state.
Item (ii) follows from Theorem~\ref{I-thm:advantage} applied
to $[t^*,\tau]$ with correlated initial state
$\rho_{SE}(t^*)$.
Inequality~\eqref{I-eq:full_cycle} holds because
$I(S{:}E;\,\tau) \geq 0$ and
$D_{\mathrm{KL}}(\rho_E(\tau)\|\rho_E^{\mathrm{th}}) \geq 0$.
\end{proof}

\subsection{Connection to Non-Markovianity Measures}

\begin{remark}[The Born Approximation Destroys the Resource]
\label{I-rem:born_kills}
Under the Born (product-state) approximation, every
infinitesimal time step begins from
$\rho_{SE} \approx \rho_S \otimes \rho_E^{\mathrm{th}}$,
enforcing $I(S{:}E) = 0$ at all times.
Corollary~\ref{I-cor:three_regimes}(i) then guarantees
$\mathcal{S} \leq 0$ for \emph{every} finite interval.
The Born approximation does not merely simplify the
dynamics---it \emph{eliminates the thermodynamic resource}
(system--environment correlations) that would otherwise be
available.
\end{remark}

\begin{remark}[Connection to BLP Non-Markovianity]
\label{I-rem:BLP}
The Breuer--Laine--Piilo (BLP) measure of
non-Markovianity~\cite{BreuerLainePiilo2009} is defined via
the temporary increase of trace distance between pairs of
initial states:
$\mathcal{N}_{\mathrm{BLP}} := \max_{\rho_{1,2}}
\int_{\dot{D}>0} \frac{d}{dt}
D(\rho_1(t),\rho_2(t))\, dt$.
The intervals where trace distance increases are precisely the
``discharging'' intervals of
Remark~\ref{I-rem:battery}~\cite{RivasHuelgaPlenio2014}:
correlations previously deposited in the bath flow back to the
system, restoring distinguishability.
The BLP measure thus witnesses the thermodynamic resource
that drives $\mathcal{S} > 0$ in
Corollary~\ref{I-cor:three_regimes}(ii).
\end{remark}

\begin{remark}[Consistency with the Sagawa--Ueda Framework]
\label{I-rem:SU_consistency}
In the Sagawa--Ueda framework~\cite{SagawaUeda2010,SagawaUeda2012},
measurement-based feedback permits
$\Sigma \geq -I_{\mathrm{feedback}}$, where
$I_{\mathrm{feedback}}$ is the mutual information gained
through measurement.
The memory kernel plays an analogous role:
the pre-existing correlations $I(S{:}E;\, 0)$ are the
non-Markovian analogue of $I_{\mathrm{feedback}}$.
The total system (agent + bath) still satisfies
$\Sigma_{\mathrm{total}} \geq 0$; the apparent ``profit'' for
the agent is paid for by the correlations consumed from the
system--environment entanglement.
The bound~\eqref{I-eq:S_upper} is the non-Markovian analogue of
the Sagawa--Ueda bound $\beta\,\mathcal{S} \leq
I_{\mathrm{feedback}}$.
\end{remark}

\subsection{Mechanism: The Surfer Analogy}

The physical mechanism admits an intuitive picture.

\begin{itemize}
\item \textbf{The Markovian Agent (The Stone):}
A stone thrown into the ocean sinks.
It interacts with the water only at the instant of contact,
dissipates its kinetic energy, and thermalizes
($\mathcal{S} \leq 0$).
Each collision builds system--environment correlations that are
immediately discarded (Born approximation), so
$I(S{:}E) = 0$ at all times.
The wave structure is invisible to it.

\item \textbf{The Non-Markovian Agent (The Surfer):}
A surfer carries \emph{memory} of past wave patterns---encoded
in the correlations $I(S{:}E;\, t_0) > 0$ built up over
previous interactions (the ``charging phase'' of
Remark~\ref{I-rem:battery}).
During backflow intervals ($\Delta I < 0$), the surfer
\emph{spends} these stored correlations to extract free energy
from the wave itself.
The surfer remains far from equilibrium not by fighting the
environment, but by converting temporal correlations into
thermodynamic profit.
\end{itemize}

\begin{remark}[Thermodynamic Rectification]
\label{I-rem:rectification}
The ``surfing'' mechanism is \textbf{thermodynamic
rectification}: the memory kernel $\mathcal{K}(t,s)$ functions
as a temporal filter that enables the system to accumulate
correlations during one phase and consume them during another.
Formally, the kernel enables access to the resource
$I(S{:}E;\, 0)$ accumulated during previous interaction
epochs---converting the environment's temporal correlations
into the system's structural persistence via the
$\Delta I$ term in Theorem~\ref{I-thm:advantage}.
\end{remark}

\begin{remark}[Memory as Implicit Maxwell's Demon]
\label{I-rem:demon}
The memory kernel functions as an \emph{implicit Maxwell's demon}.
A Markovian system interacts with each environmental fluctuation
exactly once, at the moment of contact; the Born approximation
resets $I(S{:}E) = 0$ after each step.
A non-Markovian system retains a trace of past fluctuations
(via $\mathcal{K}(t,s)$ with $s < t$) and can exploit
correlations between past and present environmental states.
This is not a violation of the second law but an instance of
the Sagawa--Ueda generalization: the demon's cost is paid in
the currency of memory maintenance (Landauer erasure), a point
we quantify in Section~\ref{I-sec:cost}.
The total budget for ``demonic profit'' is capped by the
bound~\eqref{I-eq:S_upper}.
\end{remark}

% ============================================================
\section{Emergent Temporal Arrow}
\label{I-sec:arrow}

We have shown that survival requires memory.
This requirement yields a corollary: the emergence of a
thermodynamic arrow of time.
In this framework, time is not an external parameter;
rather, \emph{the direction of time is the direction of memory
accumulation}.

We formalize this by defining a dynamical partial order induced
by the memory kernel and connecting it to the algebraic
accessibility structure of HAFF Paper~F~\cite{Liu2026HAFF_F}.

\subsection{The Causal Memory Order}

A non-Markovian memory kernel $\mathcal{K}(t,s)$ defines a
causal link between a past state at $s$ and the present dynamics
at $t$.
We define a partial order based on the effective support of this
influence.

\begin{definition}[Causal Memory Order]
\label{I-def:memory_order}
Let $\mathcal{T} = \{\rho(t) \mid t \in \mathbb{R}^+\}$ be
a state trajectory.
We define the binary relation $\prec_K$ on $\mathcal{T}$ by
\begin{equation}
\label{I-eq:memory_order}
\rho(s) \prec_K \rho(t) \quad \iff \quad
\exists\, \tau \in [s, t] \text{ such that }
\| \mathcal{K}(t, \tau)[\rho(s)] \| > \epsilon,
\end{equation}
where $\epsilon > 0$ is a physical distinguishability threshold
set by the thermal noise floor
$\epsilon \sim e^{-\beta\, \Delta E_{\min}}$.
Physically, $\rho(s) \prec_K \rho(t)$ means ``the dynamics at
$t$ retains operationally distinguishable information about the
state at $s$.''
\end{definition}

For a Markovian agent, $\mathcal{K}(t,s) \propto \delta(t-s)$,
so $\rho(s) \nprec_K \rho(t)$ for any $s < t$.
The Markovian agent has no dynamical past---it lives in an
eternal ``now.''
A non-Markovian agent carries its history within its dynamics;
the depth of the order $\prec_K$ is set by the memory time
$\tau_{\mathrm{mem}}$ (Definition~\ref{I-def:kernel}).

\subsection{Unidirectionality from Survival Optimization}

Why does the order $\prec_K$ point ``forward''?
While the microscopic laws are time-reversible, the
\emph{survival imperative} (maximizing $\mathcal{S}$) creates
a statistical irreversibility.

\begin{proposition}[Fisher Information Accretion]
\label{I-prop:fisher_accretion}
Let $\mathcal{I}_F(\theta;\, \rho(t))$ denote the Fisher
information contained in the system state $\rho(t)$ regarding
a parameter $\theta$ encoded in the environment at time $s < t$.
For an agent whose dynamics maximize the survival
functional~\eqref{I-eq:survival}, the time-averaged Fisher
information satisfies
\begin{equation}
\label{I-eq:fisher_accretion}
\overline{\frac{d}{dt}\,
\mathcal{I}_F(\theta;\, \rho(t))} \geq 0,
\end{equation}
where the overbar denotes a time average over scales larger
than the bath correlation time $\tau_B$.
\end{proposition}

\begin{proof}
By Theorem~\ref{I-thm:advantage}, the survival functional is
maximized when $I(S{:}E;\,0)$ is large and can be consumed
($\Delta I < 0$) during subsequent evolution.
Maintaining a large correlation budget $I(S{:}E)$ requires
the system state to retain correlations with environmental
degrees of freedom; this is precisely the content of
$\mathcal{I}_F(\theta;\, \rho(t)) > 0$.
An agent that discards useful correlations (decreasing
$\mathcal{I}_F$) without thermodynamic necessity depletes the
resource $I(S{:}E)$ and hence its survival functional.
Since the environment's correlations decay on a timescale
$\tau_B$, the agent must continuously build new correlations
to replace decaying ones.
The net effect is a time-averaged accretion of Fisher
information, whose gradient defines the dynamical arrow of time.
\end{proof}

\subsection{The Bridge to HAFF}

We now connect this dynamical picture to the algebraic picture of
HAFF Paper~F~\cite{Liu2026HAFF_F}, where the arrow of time was
defined by the expansion of the redundancy subalgebra
$\mathcal{R}$.

The connection requires care: quantum information cannot be
cloned (the no-cloning theorem), so the ``redundancy expansion''
of HAFF must be interpreted through the lens of
\emph{quantum Darwinism}~\cite{Zurek2009}.
In this framework, the environment acquires not copies of the
quantum state $\rho(s)$ itself, but rather \emph{coarse-grained
classical records} of pointer-state outcomes---precisely the
information that survives decoherence and can be redundantly
encoded in many environmental fragments.

\begin{proposition}[Dynamical--Algebraic Correspondence]
\label{I-prop:HAFF_bridge}
Let $\prec_K$ be the causal memory order
(Definition~\ref{I-def:memory_order}) and let
$\prec_{\mathrm{HAFF}}$ be the accessibility order of
HAFF Paper~F, defined by the inclusion of redundancy
subalgebras $\mathcal{R}$.
Under the additional assumption that the system--environment
interaction produces decoherence in a preferred pointer
basis~\cite{Zurek2009}, there exists a coarse-graining map
$\Phi: \rho(t) \mapsto \hat{p}(t)$ (projecting onto the
diagonal in the pointer basis) such that:
\begin{equation}
\label{I-eq:HAFF_bridge}
\rho(s) \prec_K \rho(t)
\quad\Longrightarrow\quad
\mathcal{R}(\Phi[\rho(s)])
\subseteq \mathcal{R}(\Phi[\rho(t)]).
\end{equation}
That is, the dynamical partial order maps into the algebraic
accessibility order when restricted to the classical sector
selected by decoherence.
\end{proposition}

\begin{proof}
The argument has three steps.

\noindent\textbf{Step 1 (Dynamical side):}
$\rho(s) \prec_K \rho(t)$ implies that the memory kernel
$\mathcal{K}$ transduces information about the state at $s$
into the dynamics at $t$, via system--environment correlations
built up over $[s,t]$.

\noindent\textbf{Step 2 (Quantum Darwinism):}
The system--environment interaction selects pointer states
$\{|i\rangle\}$ that are robust under
decoherence~\cite{Zurek2009}.
The diagonal populations
$p_i(t) = \langle i | \rho(t) | i \rangle$
constitute \emph{classical} information.
Quantum Darwinism~\cite{Zurek2009} establishes that this
classical information---and \emph{only} this information---is
redundantly imprinted in many environmental fragments $E_k$
through the decoherence interaction.
Each fragment that acquires a record of
$\hat{p}(t) = \{p_i(t)\}$ contributes to the growth of the
redundancy subalgebra $\mathcal{R}$.
Crucially, no quantum cloning is involved: the no-cloning
theorem forbids copying of arbitrary quantum states, but does
not constrain the classical pointer-state probabilities, which
are freely duplicable.
The expansion of $\mathcal{R}$ reflects the proliferation of
these classical records, not the copying of quantum coherences.

\noindent\textbf{Step 3 (Correspondence):}
The coarse-graining map $\Phi$ projects onto the
\emph{commuting} subalgebra generated by the pointer
observables $\{|i\rangle\langle i|\}$.
The resulting probability distributions $\hat{p}(t)$ are
classical and lie in a simplex.
If $\rho(s) \prec_K \rho(t)$, then the dynamics at $t$
retains information about the state at $s$
(Definition~\ref{I-def:memory_order}); in the pointer basis,
this means $\hat{p}(s)$ is statistically reconstructible
from the environmental records available at $t$.
Since each environmental fragment carrying a record of
$\hat{p}$ contributes to the HAFF redundancy subalgebra
$\mathcal{R}$, and the number of such fragments grows
monotonically with the accumulation of decoherence records,
the inclusion
$\mathcal{R}(\Phi[\rho(s)]) \subseteq
\mathcal{R}(\Phi[\rho(t)])$ follows.
\end{proof}

\begin{remark}[Scope of the Correspondence]
\label{I-rem:scope}
Proposition~\ref{I-prop:HAFF_bridge} is a \emph{consistency
result}, not a derivation of HAFF from T-DOME or vice versa.
It shows that the dynamical arrow (memory accumulation) and the
algebraic arrow (redundancy expansion) are compatible when
restricted to the decoherence-selected classical sector.
The quantum coherences---which are not redundantly
recorded---lie outside this correspondence and are handled by
the full non-Markovian dynamics.
\end{remark}

\begin{remark}[Dynamical and Algebraic Time]
\label{I-rem:dual_time}
The correspondence links two independently motivated notions of
temporal direction:
\begin{center}
\begin{tabular}{@{}lll@{}}
\toprule
& \textbf{Paper F (HAFF)} & \textbf{Paper I (T-DOME)} \\
\midrule
Nature & Algebraic & Dynamical \\
Mechanism & Redundancy expansion
  & Information backflow from memory \\
Formalism & Partial order on $\mathcal{A}_{\mathbf{c}}$
  & Partial order $\prec_K$ on $\rho_R(t)$ \\
Asymmetry source & Phase-space measure
  & Bath correlation structure \\
Domain & Classical (pointer) sector
  & Full quantum dynamics \\
\bottomrule
\end{tabular}
\end{center}
Paper~F provides the structural \emph{skeleton} of temporal
asymmetry; Paper~I provides the dynamical \emph{muscle}.
\end{remark}

\begin{remark}[The Seed and the Tree]
\label{I-rem:seed_tree}
The correspondence justifies the title of this paper.
In HAFF, the geometry of spacetime is the static ``tree.''
In T-DOME, the memory kernel is the ``seed'' containing the
generative algorithm for growth.
Time is not the space in which the tree grows;
time is the \emph{act of growing} itself.
\end{remark}

% ============================================================
\section{Worked Example: The Quantum Predictive Agent}
\label{I-sec:example}

To illustrate the Markovian ceiling and the memory advantage
\emph{quantitatively}, we employ the archetypal open quantum
system model: the spin-boson model with Lorentz--Drude spectral
density, which admits an exact analytic solution for the
decoherence dynamics~\cite{BreuerPetruccione2002}.

\subsection{Model Setup}

The total Hamiltonian is $H = H_S + H_B + H_I$.
The agent is a two-level system with energy gap $\omega_0$:
$H_S = \tfrac{\omega_0}{2}\sigma_z$.
The environment is a bosonic bath:
$H_B = \sum_k \omega_k b_k^\dagger b_k$.
The interaction is of the pure-dephasing form
$H_I = \sigma_z \otimes \sum_k (g_k\, b_k
+ g_k^*\, b_k^\dagger)$.

The spectral density
$J(\omega) = \sum_k |g_k|^2 \delta(\omega - \omega_k)$
characterizes the environment. We choose the Lorentz--Drude form:
\begin{equation}
\label{I-eq:lorentz_drude}
J(\omega) = \frac{2\lambda\, \gamma\, \omega}
  {\omega^2 + \gamma^2},
\end{equation}
where $\lambda$ is the reorganization energy and $\gamma$ is the
bath memory rate (inverse correlation time
$\tau_B = 1/\gamma$).
We place the system in the low-temperature regime
$\beta\omega_0 \gg 1$ (i.e., $k_BT \ll \omega_0$).
The bath correlation function in the $T \to 0$ limit is
$C(t) = \lambda\gamma\, e^{-\gamma|t|}$, so the parameter
$\gamma$ directly controls the bath memory depth.
For $\beta\omega_0 \geq 10$ the finite-temperature corrections
to all quantities below are of order
$O(e^{-\beta\omega_0}) \lesssim 5 \times 10^{-5}$ and
are neglected throughout.\footnote{All plots and numerical values
use the standard $T \to 0$ analytic expression for the
decoherence function~\eqref{I-eq:decoherence}
(see Breuer and Petruccione~\cite{BreuerPetruccione2002},
Sec.~12.3, for the Lorentz--Drude pure-dephasing solution),
which provides an accurate proxy in the low-temperature
regime;
$\beta$ is a well-defined bookkeeping parameter and
$\beta^{-1}$ a finite energy scale.}

\subsection{Exact Decoherence Function}

For the pure-dephasing spin-boson model in the
$T \to 0$ limit,
the off-diagonal element of the reduced density matrix
$\rho_{01}(t) = \rho_{01}(0)\, p(t)$ is governed by the
\textbf{decoherence function}~\cite{BreuerPetruccione2002}:
\begin{equation}
\label{I-eq:decoherence}
p(t) = e^{-\gamma t / 2}\left[
  \cos(\Omega t) + \frac{\gamma}{2\Omega}\,\sin(\Omega t)
\right],
\end{equation}
where $\Omega := \frac{1}{2}\sqrt{4\lambda\gamma - \gamma^2}$.
This solution is exact for the Lorentz--Drude spectral density.

\begin{remark}[Non-Markovian Regime]
\label{I-rem:NM_regime}
The character of the dynamics is controlled by the discriminant
$\Delta := 4\lambda\gamma - \gamma^2 = \gamma(4\lambda - \gamma)$:
\begin{itemize}
\item $\gamma > 4\lambda$ ($\Delta < 0$):
  $\Omega$ is imaginary, $p(t)$ decays monotonically.
  The dynamics is Markovian (no backflow).
\item $\gamma = 4\lambda$ ($\Delta = 0$):
  Critical damping. $p(t) = (1 + \gamma t/2)\, e^{-\gamma t/2}$.
\item $\gamma < 4\lambda$ ($\Delta > 0$):
  $\Omega$ is real and positive.
  $p(t)$ oscillates with envelope $e^{-\gamma t/2}$.
  The dynamics is \emph{non-Markovian}: intervals where
  $|p(t)|$ increases correspond to information
  backflow~\cite{BreuerLainePiilo2009}.
\end{itemize}
The non-Markovian regime $\gamma < 4\lambda$ is thus the regime
of structured, long-memory baths.
\end{remark}

\subsection{Quantitative Evaluation}

We now evaluate the survival functional explicitly.
For the pure-dephasing model, populations are conserved
($p_0(t) = p_0(0)$, $p_1(t) = p_1(0)$), and the non-equilibrium
free energy depends only on the coherence:
\begin{equation}
\label{I-eq:F_qubit}
F(\rho(t)) - F(\rho_{\mathrm{eq}})
= \beta^{-1}\, D_{\mathrm{KL}}(\rho(t) \| \rho_{\mathrm{eq}}).
\end{equation}
For a qubit with initial state
$\rho(0) = \tfrac{1}{2}(\mathbb{1} + \vec{r}\cdot\vec{\sigma})$
and $r_z = 0$ (maximal coherence in the $x$--$y$ plane),
the relative entropy reduces to
$D_{\mathrm{KL}}(\rho(t) \| \rho_{\mathrm{eq}})
\approx |p(t)|^2\, |\rho_{01}(0)|^2$
to leading order in the coherence (see,
e.g.,~\cite{BreuerPetruccione2002}).
Since there is no external driving ($H_{\mathrm{ctrl}} = 0$,
$W = 0$), the survival functional is simply
\begin{equation}
\label{I-eq:S_qubit}
\beta\,\mathcal{S}(t)
= D_{\mathrm{KL}}(\rho(t) \| \rho_{\mathrm{eq}})
  - D_{\mathrm{KL}}(\rho(0) \| \rho_{\mathrm{eq}})
\propto |p(t)|^2 - 1.
\end{equation}
The proportionality in~\eqref{I-eq:S_qubit} is specific to
the \textbf{pure-dephasing model} with the chosen maximally
coherent initial state ($r_z = 0$) and measurement in the
pointer basis ($\sigma_z$).
Under these conditions, the exact
solution~\cite{BreuerPetruccione2002} ensures that population
terms vanish from the free energy
($\Delta\langle H_S \rangle = 0$), leaving only the
coherence contribution:
$\beta\,\mathcal{S} = -\Delta S_S$ depends only on the
coherence trajectory $|p(t)|$.
The proxy $|p(t)|^2$ thus rigorously captures the sign and
monotone behaviour of $\beta\,\mathcal{S}$; the exact
numerical prefactor depends on the initial state and
on $\beta$, but the qualitative conclusion---$\mathcal{S} > 0$
during backflow intervals---is robust and does not depend on
the proxy normalization.

For a Markovian evolution, $|p(t)|$ decreases monotonically,
so $|p(t)|^2 - 1 \leq 0$ for all $t$: $\mathcal{S} \leq 0$
always (consistent with Theorem~\ref{I-thm:ceiling}).
For non-Markovian evolution with $\gamma < 4\lambda$, the
oscillations in $p(t)$ produce intervals where $|p(t)|$
\emph{increases after a previous decrease}, i.e., the system
\emph{re-coheres}.

\textbf{Concrete parameters.}
Set $\omega_0 = 1$ (energy units), $\lambda = 1$,
$\gamma = 0.5$ (deep non-Markovian regime: $\gamma / 4\lambda = 0.125 \ll 1$).
Then:
\begin{equation}
\Omega = \tfrac{1}{2}\sqrt{4 \cdot 1 \cdot 0.5 - 0.25}
= \tfrac{1}{2}\sqrt{1.75} \approx 0.661.
\end{equation}

The decoherence function~\eqref{I-eq:decoherence} first reaches
$p(t^*) = 0$ at $t^* \approx 2.00/\Omega \approx 3.03$
(in units of $\omega_0^{-1}$), where the system has fully
decohered.
Subsequently, the environment \emph{returns} coherence:
$|p(t)|$ increases, reaching a local maximum
$|p(t_1)| \approx 0.31$ at $t_1 \approx 4.75/\omega_0$.

Over the backflow interval $[t^*, t_1]$,
for the pure-dephasing qubit with the chosen initial state
($r_z = 0$, maximal coherence) and in the autonomous setting
($H_{\mathrm{ctrl}} = 0$, $W = 0$),
the survival proxy~\eqref{I-eq:S_qubit} gives
\begin{equation}
\label{I-eq:S_numeric}
\beta\,\mathcal{S}[t^*, t_1]
\propto |p(t_1)|^2 - |p(t^*)|^2
\approx 0.093 - 0 = 0.093 > 0.
\end{equation}
Equivalently,
$\mathcal{S} \approx 0.093\,\beta^{-1}$
in the bookkeeping units set by $\beta$.
The agent has gained a dimensionless survival advantage
$\beta\,\mathcal{S} \approx +0.093$
\emph{with zero work input}
(autonomous evolution, $H_{\mathrm{ctrl}} = 0$),
solely by exploiting the non-Markovian backflow.
Figure~\ref{I-fig:survival} illustrates the contrast between
Markovian and non-Markovian evolution.

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]{fig_survival.pdf}
\caption{%
Pure-dephasing spin-boson model
(Section~\ref{I-sec:example}) with Lorentz--Drude spectral
density~\eqref{I-eq:lorentz_drude}.
\textbf{Parameters:}
$\omega_0 = 1$ (energy unit),
$\lambda = 1$ (reorganization energy).
\textbf{Units:}
all times in $\omega_0^{-1}$;
energies in $\hbar\omega_0$.
\textbf{Regime:}
low temperature ($\beta\omega_0 \gg 1$);
the standard $T \to 0$ analytic
expression~\eqref{I-eq:decoherence}~\cite{BreuerPetruccione2002}
is used as an accurate proxy.
\textbf{(a)}~Decoherence amplitude $|p(t)|$
(eq.~\eqref{I-eq:decoherence}).
Blue: non-Markovian
($\gamma = 0.5$, $\gamma/4\lambda = 0.125$).
Orange: Markovian
($\gamma = 5.0$, $\gamma/4\lambda = 1.25$).
Dashed: exponential envelope $e^{-\gamma t/2}$.
Green bands indicate backflow
(Remark~\ref{I-rem:NM_regime}:
$d|p|/dt > 0$, $\Gamma(t) < 0$
per~\eqref{I-eq:Gamma_inst}).
\textbf{(b)}~Survival proxy
$|p(t)|^2 \propto \beta\,\mathcal{S}$
(eq.~\eqref{I-eq:S_qubit}).
At the first revival
($t_1 = \pi/\Omega \approx 4.75\,\omega_0^{-1}$),
the non-Markovian agent achieves
$\beta\,\mathcal{S}[t^*,t_1] \approx +0.093$
(eq.~\eqref{I-eq:S_numeric}), consistent with the
closed-form prediction~\eqref{I-eq:revival_exact},
funded by the consumption of pre-existing
correlations
(Proposition~\ref{I-prop:full_cycle}).
The Markovian agent decays monotonically:
$\mathcal{S} \leq 0$ always
(Theorem~\ref{I-thm:ceiling}).%
}
\label{I-fig:survival}
\end{figure}

\textbf{Consistency with
Theorem~\ref{I-thm:advantage} and
Proposition~\ref{I-prop:full_cycle}.}
Since this is autonomous evolution ($H_{\mathrm{ctrl}} = 0$),
identity~\eqref{I-eq:advantage_auto} applies exactly:
$\beta\,\mathcal{S} = -\Delta I(S{:}E)
- \Delta D_{\mathrm{KL}}(\rho_E \| \rho_E^{\mathrm{th}})$.
The example realizes the \emph{correlation battery}
of Remark~\ref{I-rem:battery}, with the charge--discharge
decomposition of
Proposition~\ref{I-prop:full_cycle}:
\begin{itemize}
\item \textbf{Charging} ($[0, t^*]$, eq.~\eqref{I-eq:charge}):
  the system decoheres, building correlations
  $I(S{:}E;\, t^*) > 0$ at the cost of
  $\mathcal{S} < 0$.
\item \textbf{Discharging} ($[t^*, t_1]$,
  eq.~\eqref{I-eq:discharge}):
  the correlations are consumed
  ($\Delta I < 0$ over this interval),
  returning $\beta\,\mathcal{S} \approx +0.093 > 0$.
\end{itemize}
The bound~\eqref{I-eq:S_upper} is satisfied:
$\beta\,\mathcal{S}[t^*, t_1] = 0.093
\leq I(S{:}E;\, t^*)$.
Full-cycle closure~\eqref{I-eq:full_cycle} is confirmed:
$\beta\,\mathcal{S}[0, t_1] < 0$.

\textbf{Instantaneous decoherence rate.}
The rate of coherence loss is
\begin{equation}
\label{I-eq:Gamma_inst}
\Gamma(t) := -\frac{d}{dt}\ln|p(t)|
= \frac{\gamma}{2}
  - \frac{\Omega\sin(\Omega t)
    + \tfrac{\gamma}{2}\cos(\Omega t)}
  {\cos(\Omega t)
    + \tfrac{\gamma}{2\Omega}\sin(\Omega t)}\,.
\end{equation}
In the Markovian limit $\gamma \gg 4\lambda$,
$\Gamma(t) \to \gamma/2 > 0$ for all $t$
(monotone decoherence).
In the non-Markovian regime $\gamma < 4\lambda$,
$\Gamma(t)$ oscillates and becomes \emph{negative}
during the backflow intervals where $|p(t)|$ increases.
These are precisely the intervals where
$\mathcal{S} > 0$.

\textbf{Closed-form revival amplitude.}
The decoherence function~\eqref{I-eq:decoherence} can be
written as $p(t) = R\, e^{-\gamma t/2}\cos(\Omega t - \phi)$,
where $R = \sqrt{1 + (\gamma/2\Omega)^2}$ and
$\phi = \arctan(\gamma/2\Omega)$, with $R\cos\phi = 1$.
The extrema of $|p(t)|$ occur at $t_n = n\pi/\Omega$
($n = 0, 1, 2, \ldots$), and the first revival peak
after the first zero is at $t_1 = \pi/\Omega$.
Its amplitude is \emph{exactly}
\begin{equation}
\label{I-eq:revival_exact}
|p(t_1)| = e^{-\gamma\pi/(2\Omega)},
\qquad
\beta\,\mathcal{S}[t^*, t_1]
\approx |p(t_1)|^2
= e^{-\gamma\pi/\Omega}.
\end{equation}
This is the paper's central computable prediction: the
survival gain at first backflow is determined by a single
dimensionless ratio $\gamma/\Omega$.

\begin{remark}[Parameter Survey]
\label{I-rem:parameter_survey}
Table~\ref{I-tab:survey} demonstrates the transition from
the Markovian regime ($\mathcal{S} \leq 0$) to the
non-Markovian regime ($\mathcal{S} > 0$) as the bath
memory rate $\gamma$ decreases below the critical value
$4\lambda$.
All entries use $\omega_0 = 1$, $\lambda = 1$,
$W = 0$ (autonomous evolution), with revival amplitudes
computed from~\eqref{I-eq:revival_exact}.
\begin{center}
\begin{tabular}{@{}cccccc@{}}
\toprule
$\gamma$ & $\gamma/4\lambda$ & Regime
& $|p(t_1)|$ & $\beta\,\mathcal{S}(t_1)$
& $\Gamma_{\min}$ \\
\midrule
$20.0$ & $5.0$ & Markov & --- & $\leq 0$ & $>0$ \\
$4.0$ & $1.0$ & Critical & --- & $\leq 0$ & $= 0$ \\
$2.0$ & $0.50$ & Non-Markov & $0.043$
  & $+0.002$ & $< 0$ \\
$1.0$ & $0.25$ & Non-Markov & $0.163$
  & $+0.027$ & $< 0$ \\
$0.5$ & $0.125$ & Deep NM & $0.305$
  & $+0.093$ & $< 0$ \\
$0.1$ & $0.025$ & Deep NM & $0.605$
  & $+0.37\phantom{0}$ & $< 0$ \\
\bottomrule
\end{tabular}
\end{center}
\captionsetup{hypcap=false}%
\captionof{table}{%
Survival functional at first backflow revival
as a function of the bath memory rate $\gamma$,
for the pure-dephasing spin-boson model
with Lorentz--Drude spectral density.
$|p(t_1)|$ is computed
from~\eqref{I-eq:revival_exact};
$\Gamma_{\min}$ is the sign of the minimum of the
instantaneous decoherence rate~\eqref{I-eq:Gamma_inst}.
The transition $\mathcal{S} \leq 0 \to \mathcal{S} > 0$
occurs precisely at the non-Markovian threshold
$\gamma = 4\lambda$.
For $\gamma = 0.1$ (deep non-Markovian),
the agent achieves $\beta\,\mathcal{S} \approx +0.37$
per backflow cycle in the autonomous setting
($H_{\mathrm{ctrl}} = 0$).%
}
\label{I-tab:survey}
\end{remark}

\begin{remark}[The Two Regimes: Summary]
\label{I-rem:two_regimes}
\begin{center}
\begin{tabular}{@{}lll@{}}
\toprule
& \textbf{Markovian ($\gamma = 20$)}
& \textbf{Non-Markovian ($\gamma = 0.5$)} \\
\midrule
$\gamma / 4\lambda$ & $5.0$ (overdamped)
  & $0.125$ (underdamped) \\
$\tau_B$ & $0.05\,\omega_0^{-1}$
  & $2.0\,\omega_0^{-1}$ \\
$p(t)$ & Monotone decay
  & Oscillatory with envelope \\
$|p(t_1)|$ at first revival & $0$ (no revival)
  & $\approx 0.31$ \\
$\beta\,\mathcal{S}$ at revival & $\leq 0$
  & $\approx +0.093$ \\
$\Gamma(t)$ & $> 0$ always
  & Oscillates, $< 0$ during backflow \\
Interpretation & Stone (sinks)
  & Surfer (rides backflow) \\
\bottomrule
\end{tabular}
\end{center}
The non-Markovian agent achieves
$\beta\,\mathcal{S} \approx +0.093$
per backflow cycle (autonomous, $H_{\mathrm{ctrl}} = 0$),
while the Markovian agent can only lose free energy.
As the coupling deepens ($\gamma/4\lambda \to 0$), the
revival amplitude grows and
$\mathcal{S}$ increases
(Table~\ref{I-tab:survey}), bounded above by
$\beta\,\mathcal{S} \leq I(S{:}E;\, t^*)$
(Corollary~\ref{I-cor:three_regimes}(iii)).
\end{remark}

% ============================================================
\section{The Cost of Memory}
\label{I-sec:cost}

We have shown that memory allows an agent to breach the
Markovian ceiling.
However, every advantage carries a thermodynamic shadow.
We now quantify the cost of memory and identify the survival
crisis that sets the stage for Paper~II\@.

\subsection{The Landauer Debt}

To exploit the memory kernel $\mathcal{K}(t,s)$, the physical
substrate of the agent must maintain correlations with its own
past.
This is equivalent to storing information.
By Landauer's principle, erasing or overwriting this information
dissipates heat; if the agent does not erase, it must pay an
entropic cost to store.

\begin{proposition}[Landauer Cost of Memory]
\label{I-prop:cost}
Let $\mathcal{I}_{\mathrm{stored}}(\tau_{\mathrm{mem}})$ be the
mutual information between the agent's state trajectory over
$[t - \tau_{\mathrm{mem}},\, t]$ and its current control
protocol $H_{\mathrm{ctrl}}(t)$.
The free-energy cost of maintaining this memory satisfies
\begin{equation}
\label{I-eq:landauer}
\Delta F_{\mathrm{mem}}
\geq k_B T \ln 2 \cdot
\mathcal{I}_{\mathrm{stored}}(\tau_{\mathrm{mem}}).
\end{equation}
\end{proposition}

\subsection{The Memory Catastrophe}

The crisis arises from the scaling of
$\mathcal{I}_{\mathrm{stored}}$ with time.
To quantify this, we borrow two quantities from computational
mechanics~\cite{CrutchfieldYoung1989,ShaliziCrutchfield2001}:

\begin{definition}[Entropy Rate and Predictive Information]
\label{I-def:entropy_rate}
Let $\{X_t\}$ be the stochastic process describing the
environment's influence on the agent (e.g., the sequence of
bath correlation values).
\begin{enumerate}
\item The \textbf{entropy rate} of the environment is
  \begin{equation}
  \label{I-eq:entropy_rate}
  h_\mu := \lim_{n \to \infty}
  H(X_n \mid X_{n-1}, \ldots, X_1),
  \end{equation}
  measuring the intrinsic unpredictability per time step.
\item The \textbf{predictive information} (excess entropy) is
  \begin{equation}
  \label{I-eq:pred_info}
  I_{\mathrm{pred}} := I(\overleftarrow{X};\,
  \overrightarrow{X})
  = \sum_{k=1}^{\infty}
  \bigl[H(X_k) - h_\mu\bigr],
  \end{equation}
  where $\overleftarrow{X}$ and $\overrightarrow{X}$ denote
  the past and future half-chains.
  This is the total amount of information about the future
  that is encoded in the past---the \emph{useful} memory.
\end{enumerate}
\end{definition}

For an environment with finite predictive information
($I_{\mathrm{pred}} < \infty$), an optimal agent needs only
finite memory to capture all exploitable correlations.
However, for environments with \emph{divergent} predictive
information (e.g., processes with long-range temporal
correlations, $1/f$ noise, or non-stationary statistics),
the required memory grows without bound.

\begin{proposition}[The Memory Catastrophe]
\label{I-thm:catastrophe}
\textbf{Assumptions.}
Let the environment be a \emph{stationary, mixing} stochastic
process with positive entropy rate $h_\mu > 0$
\cite{CrutchfieldYoung1989,ShaliziCrutchfield2001}.
Consider an agent that maintains a memory kernel
$\mathcal{K}(t,s)$ with support on $[t - \tau_{\mathrm{mem}},\, t]$.
Let $\dot{W}_{\mathrm{budget}}$ be the agent's available
free-energy flux (constant).
\begin{enumerate}
\item The minimum memory required to exploit correlations up
  to depth $\tau_{\mathrm{mem}}$ satisfies
  \begin{equation}
  \label{I-eq:mem_lower_bound}
  \mathcal{I}_{\mathrm{stored}}(\tau_{\mathrm{mem}})
  \geq \min\!\big(I_{\mathrm{pred}},\;
  h_\mu\, \tau_{\mathrm{mem}}\big).
  \end{equation}
\item The Landauer cost of maintaining this memory is
  \begin{equation}
  \label{I-eq:mem_cost_rate}
  \dot{W}_{\mathrm{mem}} \geq
  k_B T \ln 2 \cdot h_\mu,
  \end{equation}
  since the agent must erase (or overwrite) at least $h_\mu$
  bits per unit time to prevent memory overflow.
\item There exists a critical time
  $t_{\mathrm{crit}}$ beyond which the memory maintenance cost
  exceeds the survival gain:
  \begin{equation}
  \label{I-eq:catastrophe}
  t > t_{\mathrm{crit}}
  \quad\Longrightarrow\quad
  \dot{W}_{\mathrm{mem}}(t) > \dot{W}_{\mathrm{budget}},
  \end{equation}
  unless the agent compresses its memory.
\end{enumerate}
The agent dies not from entropy (disorder) but from
\emph{hypermnesia}: the thermodynamic cost of perfect memory
exceeds the benefit it provides.
\end{proposition}

\begin{proof}
Part~(1): an agent exploiting temporal correlations to depth
$\tau_{\mathrm{mem}}$ must store at least the mutual information
between the past $\tau_{\mathrm{mem}}$ time steps and the
present.
For a stationary ergodic process, this mutual information is
bounded below by $\min(I_{\mathrm{pred}},\,
h_\mu\, \tau_{\mathrm{mem}})$~\cite{CrutchfieldYoung1989,
BialekNemenmanTishby2001}.

Part~(2): each time step, the agent receives $\sim h_\mu$
bits of genuinely new information.
To maintain a fixed-capacity memory, it must erase at least
this many bits, incurring Landauer cost
$k_B T \ln 2 \cdot h_\mu$ per time step.

Part~(3): if $I_{\mathrm{pred}} = \infty$ (as for environments
with long-range correlations), the stored information grows
as $\mathcal{I}_{\mathrm{stored}} \sim h_\mu\,
\tau_{\mathrm{mem}}$.
Combined with part~(2), the memory cost grows linearly in the
effective memory depth.
For any finite budget $\dot{W}_{\mathrm{budget}}$, there exists
$t_{\mathrm{crit}}$ such that the cost exceeds the budget.
\end{proof}

\subsection{Resolution: The Necessity of Forgetting}

To survive beyond $t_{\mathrm{crit}}$, the agent must introduce
a \emph{lossy compression} scheme: it must discard the vast
majority of stored correlations and retain only the
thermodynamically salient features.

\begin{itemize}
\item \textbf{Compression requires a criterion.}
  To decide what to keep and what to erase, the agent needs a
  \emph{relevance function}---a mapping from stored correlations
  to survival value.
  This is a reference frame that ranks information by its
  contribution to $\mathcal{S}$.

\item \textbf{A reference frame requires symmetry breaking.}
  An ``unbiased'' agent that treats all correlations as equally
  valuable cannot compress: it must keep everything.
  The act of preferring one subset of information over another
  is a spontaneous breaking of the informational symmetry.
  This is the thermodynamic definition of a ``perspective''---or,
  more precisely, a \emph{privileged basis}.
\end{itemize}

\begin{remark}[The Origin of Paper II]
\label{I-rem:paper_II}
\emergencystretch=1em
Proposition~\ref{I-thm:catastrophe} reveals the \emph{poison} embedded
in Paper~I's medicine.
Memory enables survival beyond the Markovian ceiling, but
unbounded memory under finite energy resources leads to
\emph{computational explosion}: the agent must process an
ever-growing archive with bounded free energy.

This is the precise thermodynamic origin of the crisis
addressed in Paper~II\@.
The resolution---spontaneous symmetry breaking of the
agent's reference frame---is not an additional hypothesis
but a \emph{thermodynamic necessity}: the agent must
compress its infinite history into a finite, biased
representation.
The ``self'' (a privileged computational basis) emerges as
the minimal structure that makes memory computationally
tractable.

In the structural parallel noted in HAFF
Essay~C~\cite{Liu2026HAFF_C}: the accumulation mechanism of
Paper~I provides the raw material for survival, but without the
discriminative compression of Paper~II, the system collapses
under the weight of its own stored correlations.
\end{remark}

% ============================================================
\section{Numerical Demonstration}
\label{I-sec:numerical}

The preceding sections establish analytic bounds and a
worked example in the spin-boson model.  We now provide a numerical illustration showing that the
Markovian ceiling signature predicted by
Theorem~\ref{I-thm:ceiling} and the memory advantage of
Theorem~\ref{I-thm:advantage} are reproduced in a minimal
partially observed environment.
Full code and parameters are provided for reproducibility.

% ------------------------------------------------------------
\subsection{Model}
\label{I-subsec:demo_model}

\paragraph{Environment.}
A two-hidden-state HMM with aliased observations.
The hidden state $s_t \in \{0,1\}$ evolves as a persistent
Markov chain with $\Pr(s_{t+1} = s_t) = 1 - \varepsilon$;
the parameter $\varepsilon \in [10^{-3}, 10^{-1}]$ controls
the correlation length $\ell \sim 1/\varepsilon$.
Observations $o_t \in \{A, B\}$ are aliased:
$\Pr(o_t = A \mid s_t = 0) = 0.5 + \delta$,
$\Pr(o_t = A \mid s_t = 1) = 0.5 - \delta$,
with $\delta = 0.05$ (mutual information
$I(O; S) \approx 0.007$~bits).
Reward: $r_t = 1$ if $a_t = s_t$, $0$ otherwise.

\paragraph{Agents.}
All agents use the true model parameters and compute
exact Bayesian posteriors; the only difference is how many
observations each agent retains.
\begin{itemize}
\item \textbf{Markov-$k$} ($k \in \{1,2,4,8\}$): runs
  an exact Bayes filter over the most recent $k$
  observations (sliding window, uniform prior at each
  window start); acts by MAP.
\item \textbf{Memory (Bayes filter)}: maintains the full
  belief state $b_t = \Pr(s_t = 1 \mid o_{1:t})$ via the
  exact predict--update cycle over all past observations;
  acts by MAP.
\end{itemize}

\paragraph{Parameters.}
\begin{center}
\small
\begin{tabular}{@{}lcl@{}}
\toprule
\textbf{Quantity} & \textbf{Value} & \textbf{Role} \\
\midrule
$T$ & $100{,}000$ & horizon per trial \\
Seeds & 10 & independent replications \\
$\delta$ & 0.05 & observation asymmetry \\
$k$ & $\{1, 2, 4, 8\}$ & Markov window sizes \\
$\varepsilon$ & logspace($10^{-3}$, $10^{-1}$, 15)
  & transition noise grid \\
Burn-in & $5{,}000$ & discarded steps \\
\bottomrule
\end{tabular}
\end{center}

% ------------------------------------------------------------
\subsection{Results}
\label{I-subsec:demo_results}

Figure~\ref{I-fig:markov_ceiling} shows the two key signatures.

\paragraph{Result 1: Markov ceiling
(Figure~\ref{I-fig:markov_ceiling}a).}
The average reward $\bar{R}$ of the Bayes filter (memory
agent) increases monotonically with correlation length
$\ell = 1/\varepsilon$, while each Markov-$k$ agent
saturates at a distinct ceiling.  The ceilings are
ordered: $k = 1$ (lowest) through $k = 8$ (highest),
and all fall below the memory agent for
$\ell \gtrsim 20$.  This is consistent with the qualitative prediction of
Theorem~\ref{I-thm:ceiling}: finite-order Markov
representations have a performance upper bound that
the memory-carrying agent surpasses.

\paragraph{Result 2: Memory advantage
(Figure~\ref{I-fig:markov_ceiling}b).}
The gap $\Delta\bar{R} = \bar{R}_{\mathrm{mem}}
- \bar{R}_{\mathrm{Markov}\text{-}k}$ increases
monotonically with $\ell$, and is larger for smaller $k$.
Shaded bands show 95\% confidence intervals across
10 seeds.  The Markov-1 and Markov-2 curves nearly
overlap at small $\ell$, reflecting the fact that
short observation windows provide negligible additional
information in this aliasing regime---a consistency
check, not a deficiency.

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]%
  {fig_paper1_markov_ceiling.pdf}
\caption{%
\textbf{Markov ceiling and memory advantage.}
$T = 100{,}000$, 10 seeds, 95\% CI bands.
\textbf{(a)}~Average reward $\bar{R}$ vs correlation
length $\ell = 1/\varepsilon$.  The Bayes filter
(blue, bold) rises monotonically; Markov-$k$ agents
saturate at $k$-dependent ceilings.
\textbf{(b)}~Performance gap
$\Delta\bar{R} = \bar{R}_{\mathrm{mem}}
- \bar{R}_{\mathrm{Markov}\text{-}k}$
increases with $\ell$; smaller $k$ yields a larger gap.}
\label{I-fig:markov_ceiling}
\end{figure}

% ------------------------------------------------------------
\subsection{Scope of This Demonstration}
\label{I-subsec:demo_scope}

These simulations illustrate the ceiling phenomenon
predicted by Theorem~\ref{I-thm:ceiling} under the stated
model class; they do not constitute a proof beyond this
class.

\medskip
This demonstration \textbf{does} show:
\begin{enumerate}
\item A reproducible regime in which finite-order Markov
  agents exhibit a performance ceiling while a
  memory-carrying (Bayes filter) agent improves---the
  Markov ceiling signature predicted by
  Theorem~\ref{I-thm:ceiling}.
\item The memory advantage (Theorem~\ref{I-thm:advantage})
  manifests as a monotonically growing gap that widens
  with correlation length and tightens with window size.
\end{enumerate}

\noindent
This demonstration does \textbf{not} show:
\begin{enumerate}
\item Universality across environments, observation models,
  or agent architectures.  The model uses a two-state
  HMM with binary aliased observations.
\item Tight constants or the functional form of the
  ceiling boundary $\ell_c(k)$.
\item That the Bayes filter is optimal among all possible
  memory-carrying agents.
\end{enumerate}

\paragraph{Reproducibility.}
The complete simulation is a self-contained Python script
(\texttt{paper1\_markov\_ceiling\_demo.py}, ${\sim}\,560$
lines, requiring only NumPy and Matplotlib) with fixed
random seeds.  All figures in this section can be
reproduced by executing the script.  The following files
are included in the supplementary archive:
\begin{itemize}
\item \texttt{paper1\_markov\_ceiling\_demo.py} --- simulation script
\item \texttt{fig\_paper1\_markov\_ceiling.pdf} --- Figure~\ref{I-fig:markov_ceiling}
\item \texttt{markov\_ceiling\_data.csv} --- raw sweep data
\item \texttt{markov\_ceiling\_boundary.csv} --- extracted
  ceiling boundaries $\ell_c(k)$
\end{itemize}

% ============================================================
\section{Discussion}
\label{I-sec:discussion}

\subsection{Summary of Results}

\begin{center}
\small
\setlength{\tabcolsep}{4pt}%
\begin{tabular}{@{}lp{7.5cm}c@{}}
\toprule
\textbf{Result} & \textbf{Statement} & \textbf{Sec.} \\
\midrule
Markovian Ceiling &
  $\mathcal{S} \leq 0$ for open-loop GKSL (no feedback)
  & \ref{I-sec:ceiling} \\[3pt]
Memory Advantage &
  $\beta\mathcal{S} = -\Delta I
  - \Delta D_{\mathrm{KL}}
  - \beta\Delta\langle H_{\mathrm{ctrl}}\rangle$;\;
  $\mathcal{S} > 0$ when correlations consumed
  (any initial state)
  & \ref{I-sec:advantage} \\[3pt]
Quantitative demo &
  Spin-boson: $\beta\mathcal{S} \approx +0.093 > 0$
  at first backflow revival (Fig.~\ref{I-fig:survival},
  Table~\ref{I-tab:survey})
  & \ref{I-sec:example} \\[3pt]
Temporal Arrow &
  $\prec_K \to \prec_{\mathrm{HAFF}}$ via quantum
  Darwinism
  & \ref{I-sec:arrow} \\[3pt]
Memory Catastrophe &
  $\dot{W}_{\mathrm{mem}} \geq k_BT\ln 2 \cdot h_\mu$;\;
  exceeds budget at $t_{\mathrm{crit}}$
  & \ref{I-sec:cost} \\[3pt]
Numerical demo &
  Markov ceiling reproduced in HMM
  (Fig.~\ref{I-fig:markov_ceiling})
  & \ref{I-sec:numerical} \\
\bottomrule
\end{tabular}
\end{center}

\subsection{What This Paper Does and Does Not Show}

\textbf{This paper shows:}
\begin{enumerate}
\item Under open-loop GKSL dynamics (no measurement or feedback),
  the survival functional $\mathcal{S} \leq 0$
  (Theorem~\ref{I-thm:ceiling}).
\item For any initial state (product or correlated), the
  survival functional satisfies the exact identity
  $\beta\,\mathcal{S} = -\Delta I(S{:}E)
  - \Delta D_{\mathrm{KL}}(\rho_E \| \rho_E^{\mathrm{th}})
  - \beta\,\Delta\langle H_{\mathrm{ctrl}}\rangle$
  (Theorem~\ref{I-thm:advantage}).
  Under autonomous evolution, when pre-existing
  system--environment correlations are consumed
  ($\Delta I < 0$), $\mathcal{S} > 0$ is achievable,
  bounded by the initial correlation budget
  (Corollary~\ref{I-cor:three_regimes}).
\item A quantitative spin-boson example illustrates:
  $\beta\,\mathcal{S} \approx +0.093 > 0$ at the first
  non-Markovian revival (Section~\ref{I-sec:example}).
\item The causal memory order $\prec_K$ is consistent with the
  HAFF accessibility order when restricted to the classical
  (pointer-state) sector
  (Proposition~\ref{I-prop:HAFF_bridge}).
\item The thermodynamic cost of memory, quantified by the
  environment's entropy rate $h_\mu$, creates a survival
  crisis for agents with finite energy budgets
  (Proposition~\ref{I-thm:catastrophe}).
\item A minimal computational demonstration reproduces the
  Markov ceiling and memory advantage signatures in a
  two-state HMM with aliased observations
  (Section~\ref{I-sec:numerical},
  Figure~\ref{I-fig:markov_ceiling}).
\end{enumerate}

\textbf{This paper does not show:}
\begin{enumerate}
\item That non-Markovian dynamics is \emph{sufficient} for
  persistence (it is necessary but not sufficient;
  Paper~II addresses the additional requirements).
\item That \emph{all} non-Markovian systems outperform all
  Markovian systems (the comparison is between suprema under
  specified constraints).
\item That Markovian agents with explicit measurement-feedback
  are bounded by the ceiling (the Sagawa--Ueda framework shows
  they are not; Remark~\ref{I-rem:open_loop}).
\item That the specific form of the optimal memory kernel can be
  derived from first principles without specifying the
  environment.
\item That memory implies or requires consciousness.
\end{enumerate}

% ============================================================
% REFERENCES
% ============================================================

% ============================================================================
% PAPER II
% ============================================================================
\chapter{Spontaneous Symmetry Breaking of Reference Frames as a Computational Cost Minimization Strategy}
\label{chap:paperII}

\begin{center}
\textit{Paper II --- ``The Ego''}\\[0.5em]
Originally published: Zenodo, DOI: 10.5281/zenodo.18579703
\end{center}

\bigskip

\section*{Abstract}
We investigate the computational constraints on persistent
open quantum systems that carry non-Markovian memory
(Paper~I~\cite{Liu2026TDOME_I}).
Paper~I established that memory is a thermodynamic necessity
for survival beyond the Markovian ceiling, but revealed a
secondary crisis: the \emph{Memory Catastrophe}, in which
the Landauer cost of maintaining unbounded history exceeds
any finite free-energy budget.

We prove a \textbf{Computational Ceiling}: any agent that
processes its memory \emph{symmetrically}---treating all
components of its internal Clifford algebra $Cl(V,q)$ as
equally relevant---reaches computational paralysis at a
finite critical time $t_{\mathrm{par}}$.

We then show that the resolution requires
\textbf{spontaneous symmetry breaking} of the agent's
internal reference frame: the selection of a privileged basis
(a gauge fixing of the automorphism group
$G = \mathrm{Aut}(Cl(V,q))$) that compresses the memory
kernel into a tractable, low-dimensional representation.
The optimal compression is governed by a survival-weighted
rate-distortion bound; under generic conditions, the agent
retains $k^{*} = \mathcal{C}_{\mathrm{budget}}/h_\mu$
components and discards the rest.

This establishes \textbf{reference-frame selection as the
survival-optimal strategy under bounded rationality}:
the ``self'' (a privileged computational basis) is not an
additional hypothesis but the minimal structure that makes
memory computationally tractable.

The broken phase introduces four systematic bias terms---basis
selection, frame drag, objective centering, and model
incompleteness---that are generic consequences
of gauge fixing under assumptions~(B1)--(B5).
We show that under environmental drift, a fixed reference
frame leads to the \textbf{Delusion Trap}: an exponential
divergence of prediction error that the agent cannot detect
from within its own frame, establishing the crisis that
Paper~III must resolve.


% ============================================================
\section{Introduction}
\label{II-sec:intro}

% ------------------------------------------------------------
\subsection{Context: The Problem of Overload}
\label{II-subsec:overload}

Paper~I of this series~\cite{Liu2026TDOME_I} established that
non-Markovian memory is a thermodynamic necessity for
persistent far-from-equilibrium systems: under open-loop
Markovian (GKSL) dynamics, the survival functional satisfies
$\mathcal{S} \leq 0$ (the Markovian Ceiling), while agents
carrying memory kernels can achieve $\mathcal{S} > 0$ by
consuming stored system--environment correlations.

This result, however, carries a price.
The \emph{Memory Catastrophe} (Paper~I, Proposition~10)
shows that the Landauer cost of maintaining a memory archive
of depth $\tau_{\mathrm{mem}}$ grows at a rate
\begin{equation}
\label{II-eq:mem_cost_recall}
\dot{W}_{\mathrm{mem}}
\geq k_B T \ln 2 \cdot h_\mu,
\end{equation}
where $h_\mu$ is the entropy rate of the environmental
process~\cite{CrutchfieldYoung1989,ShaliziCrutchfield2001}.
For any finite free-energy budget $\dot{W}_{\mathrm{budget}}$,
there exists a critical time $t_{\mathrm{crit}}$ beyond which
$\dot{W}_{\mathrm{mem}} > \dot{W}_{\mathrm{budget}}$:
the agent's memory consumes more resources than are available.

But thermodynamic cost is only half the crisis.
Even if unlimited free energy were available for memory
maintenance, the agent must still \emph{process} the stored
correlations---evaluate the survival functional as a function
of its ever-growing archive---using finite computational
resources. This is the problem that the present paper
addresses.

% ------------------------------------------------------------
\subsection{Position within the Series}
\label{II-subsec:series_position}

This paper is the second of three constituting the
\textbf{T-DOME} (Thermodynamic Dynamics of Observer-Memory
Entanglement) framework, the third pillar of a three-paper
program.

\begin{center}
\small
\setlength{\tabcolsep}{4pt}%
\begin{tabular}{@{}lp{3.2cm}cp{3.4cm}c@{}}
\toprule
\textbf{Framework} & \textbf{Question} & & \textbf{Result}
  & \textbf{Status} \\
\midrule
HAFF~\cite{Liu2026HAFF_A,Liu2026HAFF_B}
  & How does geometry emerge?
  & Ocean
  & Algebra $\to$ Geometry
  & Complete \\[3pt]
Q-RAIF~\cite{Liu2026QRAIF_A,Liu2026QRAIF_B}
  & What algebra must an observer have?
  & Fish
  & $Cl(V,q) \hookrightarrow Cl(1,3)$
  & Complete \\[3pt]
T-DOME~I~\cite{Liu2026TDOME_I}
  & Why must agents carry memory?
  & Seed
  & Markovian ceiling; memory as necessity
  & Complete \\[3pt]
\textbf{T-DOME~II} (this work)
  & Why must agents break symmetry?
  & Ego
  & Reference-frame selection under bounded computation
  & \textbf{This paper} \\[3pt]
T-DOME~III
  & How does self-calibration arise?
  & Loop
  & Fisher self-referential bound
  & Planned \\
\bottomrule
\end{tabular}
\end{center}

The three T-DOME papers form an irreversible logical chain.
Each resolves a survival crisis created by its predecessor:
\begin{enumerate}
\item \textbf{Paper~I (The Seed):} Without memory, a system
  is trapped in the \emph{Markovian present}---no accumulation,
  no temporal arrow, inevitable thermal death.
  Memory breaks this trap but floods the system with unbounded
  historical data.
\item \textbf{Paper~II (The Ego, this work):} Unbounded memory
  under finite computational resources causes processing
  collapse. Spontaneous symmetry breaking of the reference
  frame (establishing a ``self'') resolves the overload but
  introduces systematic bias.
\item \textbf{Paper~III (The Loop):} Uncorrected bias diverges
  from a changing environment. A self-referential calibration
  loop (monitoring one's own prediction error) resolves the
  bias but requires the system to ``observe its own
  observation''---closing the self-calibration loop.
\end{enumerate}

% ------------------------------------------------------------
\subsection{Relation to Q-RAIF}
\label{II-subsec:qraif}

Q-RAIF Paper~B~\cite{Liu2026QRAIF_B} established that any
persistent open quantum subsystem maintaining a
non-equilibrium steady state (NESS) requires an internal
control algebra isomorphic to a Clifford algebra $Cl(V,q)$.
Paper~C~\cite{Liu2026QRAIF_C} showed that this algebra must
embed in the environmental observable algebra via a
realizability homomorphism
$\phi: Cl(V,q) \hookrightarrow Cl(1,3)$.

The Clifford algebra $Cl(V,q)$, however, admits a non-trivial
\emph{automorphism group} $G = \mathrm{Aut}(Cl(V,q))$.
In the absence of external constraints, all elements of $G$
yield physically equivalent representations---the choice of
basis within the algebra is a \emph{gauge freedom}.
This gauge freedom is the mathematical substrate of the
symmetry that the present paper breaks.

The ``ego'' is not a new algebraic structure imposed from
outside the Q-RAIF framework; it is a \emph{gauge fixing}
of the already-present internal symmetry, driven by
computational optimality under bounded resources.

% ------------------------------------------------------------
\subsection{Relation to HAFF Paper~G}
\label{II-subsec:haff_g}

HAFF Paper~G established \emph{architectural
incompleteness}: the observable-algebra framework cannot
self-ground~\cite{Liu2026HAFF_G}.
The present paper provides a partial operational resolution:
under bounded computation, an agent satisfying~(B1)--(B5)
is driven to choose a computational basis (break symmetry)
precisely \emph{because} the framework is incomplete.
The ego is an operational response to incompleteness, not a
metaphysical addition.

% ------------------------------------------------------------
\subsection{Scope and Disclaimers}
\label{II-subsec:scope}

To prevent interpretational overreach, we state at the
outset what this paper does \emph{not} claim:
\begin{enumerate}
\item We do not claim that symmetry breaking is
  \emph{sufficient} for persistence.
  Paper~III addresses the additional requirements.
\item We do not claim that the specific form of the
  privileged basis is unique---only that \emph{some} basis
  selection is necessary under bounded computation.
\item The term ``ego'' or ``self'' is used in the
  control-theoretic sense: a fixed reference frame within
  the agent's internal algebra. It carries no implication
  of consciousness or subjective experience.
\item A broader structural analogy with classical philosophical
  concepts of selfhood exists but is outside the scope of
  this paper.
\end{enumerate}

\paragraph{Related work.}
The idea that bounded agents must compress their
representations has roots in Simon's bounded
rationality~\cite{Simon1955}, Shannon's
rate-distortion theory~\cite{Shannon1959,CoverThomas2006},
and Sims's rational inattention~\cite{Sims2003}, which
models finite-capacity decision-makers as solving a
rate-distortion problem---precisely the economic
counterpart of our $\mathcal{C}_{\mathrm{budget}}$
formalism.
The information bottleneck~\cite{Tishby2000}
formalises relevance-weighted compression and has been
applied to neural coding and deep
learning.
The role of decoherence in selecting preferred bases
(pointer states) is well established via quantum
Darwinism~\cite{Zurek2009}; our contribution is to
show that the same selection arises as a \emph{computational}
necessity, independent of the decoherence mechanism.
Measures of non-Markovianity and their thermodynamic
consequences are reviewed
in~\cite{RivasHuelgaPlenio2014,BreuerPetruccione2002};
the connection to survival was established in Paper~I.

\paragraph{Summary of contributions.}
This paper establishes three main results:
\begin{enumerate}
\item \textbf{Computational Ceiling scaling law}
  (Theorem~\ref{II-thm:comp_ceiling}): symmetric processing
  of a $Cl(V,q)$ memory kernel requires rate
  $\mathcal{R} \geq h_\mu \cdot D$, leading to paralysis
  at a finite $\tau_{\mathrm{par}}$.
\item \textbf{Survival-weighted rate-distortion bound}
  (Theorem~\ref{II-thm:compression}): the optimal gauge-fixed
  representation retains
  $k^* = \lfloor\mathcal{C}_{\mathrm{budget}}/h_\mu\rfloor$
  components.
\item \textbf{Delusion dynamics}
  (Theorem~\ref{II-thm:delusion}): a fixed reference frame
  decouples from a drifting environment on the logarithmic
  timescale $t_{\mathrm{del}}
  = \Lambda^{-1}\ln(\pi/4\theta_0)$.
\end{enumerate}

% ============================================================
\section{Mathematical Preliminaries}
\label{II-sec:prelim}

% ------------------------------------------------------------
\subsection{Inherited Framework from Paper~I}
\label{II-subsec:inherited}

We briefly recall the key objects from
Paper~I~\cite{Liu2026TDOME_I} that the present work builds
upon.  The reader is referred to Paper~I for full definitions
and proofs.

\paragraph{Survival functional.}
For an open quantum system $S$ coupled to an environment $E$
at inverse temperature $\beta$, with dynamics $\Lambda$ and
external control protocol $H_{\mathrm{ctrl}}(t)$, the
survival functional is
\begin{equation}
\label{II-eq:survival_recall}
\mathcal{S}[\Lambda, \tau]
:= \Delta F - W[0,\tau],
\end{equation}
where $\Delta F = F(\rho(\tau)) - F(\rho(0))$ is the change
in non-equilibrium free energy and
$W = \int_0^\tau \tr(\rho(t)\,\dot{H}_{\mathrm{ctrl}}(t))\,dt$
is the work performed by the external protocol.

\paragraph{Markovian Ceiling.}
Under open-loop GKSL dynamics with no feedback
(control class $\mathcal{C}_{\mathrm{M}}$, Paper~I,
Definition~6):
\begin{equation}
\label{II-eq:ceiling_recall}
\mathcal{S}[\Lambda^{\mathrm{M}}, \tau] \leq 0
\qquad\text{for all } \tau \geq 0.
\end{equation}

\paragraph{Non-Markovian advantage identity.}
For arbitrary initial states:
\begin{equation}
\label{II-eq:advantage_recall}
\beta\,\mathcal{S}
= -\Delta I(S{:}E)
  - \Delta D_{\mathrm{KL}}(\rho_E \| \rho_E^{\mathrm{th}})
  - \beta\,\Delta\langle H_{\mathrm{ctrl}} \rangle.
\end{equation}

\paragraph{Memory Catastrophe.}
The Landauer cost of maintaining a memory archive of depth
$\tau_{\mathrm{mem}}$ satisfies
$\dot{W}_{\mathrm{mem}} \geq k_BT\ln 2 \cdot h_\mu$
(Paper~I, Proposition~10),
where $h_\mu$ is the \emph{per-component} entropy rate of the
environmental process~\cite{CrutchfieldYoung1989}, defined by
\begin{equation}
\label{II-eq:entropy_rate}
h_\mu
:= \lim_{T\to\infty}\frac{1}{T}\,H(X_{0:T}),
\end{equation}
measuring the asymptotic information (in bits per unit time)
generated by a single algebraic component of the memory
kernel (we work in units where the sampling interval equals
the environmental correlation time
$\tau_E$)\footnote{For a continuous-valued process sampled at
resolution $b$ bits, $h_\mu$ includes the quantisation cost:
$h_\mu = h_\mu^{(\mathrm{diff})} + b\,f_s$, where
$h_\mu^{(\mathrm{diff})}$ is the differential entropy rate
and $f_s$ the sampling frequency.  All budget inequalities in
this paper hold with $h_\mu$ so defined.}---and the stored
mutual
information grows as
$\mathfrak{i}_{\mathrm{stored}}(\tau_{\mathrm{mem}})
\geq \min(I_{\mathrm{pred}},\; h_\mu \,\tau_{\mathrm{mem}})$,
with $I_{\mathrm{pred}}$ the \emph{predictive information}
(excess entropy)~\cite{BialekNemenmanTishby2001,ShaliziCrutchfield2001},
defined as the mutual information between past and future
of the environmental process:
\begin{equation}
\label{II-eq:I_pred}
I_{\mathrm{pred}}
:= I\!\left(\overleftarrow{X};\, \overrightarrow{X}\right)
= H(\overrightarrow{X})
  - H(\overrightarrow{X} \mid \overleftarrow{X}),
\end{equation}
where $\overleftarrow{X}$ and $\overrightarrow{X}$ denote
the semi-infinite past and future, respectively.
For a stationary process,
$I_{\mathrm{pred}}$ relates to $h_\mu$ via the entropy-rate
decomposition
$H(X_{1:T}) = I_{\mathrm{pred}} + h_\mu\,T + o(1)$
as $T \to \infty$~\cite{CrutchfieldYoung1989}.

% ------------------------------------------------------------
\subsection{The Agent's Internal Algebra}
\label{II-subsec:algebra}

Following Q-RAIF~\cite{Liu2026QRAIF_B,Liu2026QRAIF_C},
the agent's internal control algebra is a Clifford algebra
$\mathcal{O}_{\mathrm{int}} = Cl(V,q)$
for a real vector space $V$ equipped with a non-degenerate
quadratic form $q$.
The algebra satisfies the fundamental relation
$v^2 = q(v)\,\mathbf{1}$ for all $v \in V$.

The \emph{automorphism group}
\begin{equation}
\label{II-eq:gauge_group}
G := \mathrm{Aut}(Cl(V,q))
\end{equation}
is the group of algebra automorphisms that preserve the
grading and quadratic form.\footnote{\label{II-fn:gauge_group}%
We use $G$ as an effective symmetry group acting
transitively on admissible frames.
The detailed Lie-algebraic structure of $G$ is not required
for our results; only the existence of a non-trivial
symmetry that must be broken (assumption~(B5)).
In concrete models, one may replace $G$ by its image
under the adjoint representation---typically
$O(V,q)$ or a pin/spin subgroup.}
For $Cl(1,3)$, $G$ contains the spin group
$\mathrm{Spin}(1,3) \cong SL(2,\mathbb{C})$
as a subgroup---a six-real-dimensional Lie group.

In the absence of computational constraints, all
$g \in G$ yield physically equivalent descriptions of
the agent's internal state.
The choice of basis within $Cl(V,q)$ is a \emph{gauge
freedom}---the symmetry that will be broken.

The realizability embedding
$\phi: Cl(V,q) \hookrightarrow Cl(1,3)$
(Q-RAIF Paper~C) constrains the physically accessible
reference frames: only gauge choices compatible with
$\mathrm{Im}(\phi) \subset Cl(1,3)$ are realizable.

\paragraph{Dimensional convention.}
Two distinct notions of dimension appear throughout:
\begin{center}
\small
\begin{tabular}{@{}lll@{}}
\toprule
Symbol & Meaning & Scaling \\
\midrule
$n := \dim V$ & number of generators
  (degrees of freedom) & --- \\
$D := \dim Cl(V,q) = 2^n$ & full multivector space
  (algebra basis size) & exponential in $n$ \\
\bottomrule
\end{tabular}
\end{center}
The Computational Ceiling (Section~\ref{II-sec:ceiling})
scales with~$D$, not~$n$; the distinction matters
whenever one compares generator-level and
algebra-level quantities.

% ------------------------------------------------------------
\subsection{Rate-Distortion Theory}
\label{II-subsec:RD}

We require the classical rate-distortion framework
of Shannon~\cite{Shannon1959}.

\begin{definition}[Rate-distortion function]
\label{II-def:RD}
Let $X$ be a random source with distribution $p(x)$,
$\hat{X}$ a reconstruction, and
$d: \mathcal{X} \times \hat{\mathcal{X}} \to [0,\infty)$
a distortion measure.
The \emph{rate-distortion function} is
\begin{equation}
\label{II-eq:RD}
R(D) := \min_{\substack{p(\hat{x}|x):\\
  \mathbb{E}[d(X,\hat{X})] \leq D}} I(X; \hat{X}),
\end{equation}
the minimum mutual information between source and
reconstruction that achieves average distortion at most $D$.
\end{definition}

$R(D)$ is a convex, non-increasing function of $D$ with
$R(0) = H(X)$ (lossless) and
$R(D_{\max}) = 0$ (maximum distortion).
It provides the fundamental limit on lossy
compression~\cite{CoverThomas2006}.
The \emph{information bottleneck} method of
Tishby et al.~\cite{Tishby2000} generalises this framework
to the case where the relevant variable is not the source
itself but a downstream prediction target---precisely the
situation in our survival-weighted compression problem
(Section~\ref{II-subsec:RD_bound}).

% ------------------------------------------------------------
\subsection{Bounded Rationality}
\label{II-subsec:bounded}

Following Simon~\cite{Simon1955}, we model computational
limitations as a hard constraint on the agent's information
processing rate.

\begin{definition}[Computational budget]
\label{II-def:budget}
The agent's \emph{computational budget}
$\mathcal{C}_{\mathrm{budget}}$ (measured in bits per unit
time) is the maximum rate at which the agent can evaluate
functions of its stored correlations.
We assume $\mathcal{C}_{\mathrm{budget}} < \infty$.
\end{definition}

Physically, finiteness of $\mathcal{C}_{\mathrm{budget}}$
reflects the finite number of degrees of freedom in the
agent's physical substrate: finite Hilbert space dimension,
finite memory register size, and finite energy available for
computation (Landauer's
principle~\cite{Landauer1961,Bennett1982}).

% ------------------------------------------------------------
\subsection{Fiber Bundle Formalism}
\label{II-subsec:fiber}

The geometric setting for reference-frame selection is a
principal fiber bundle.

\begin{definition}[Gauge bundle]
\label{II-def:bundle}
The \emph{gauge bundle} is the principal $G$-bundle
\begin{equation}
\label{II-eq:bundle}
\pi: P \to M, \qquad G = \mathrm{Aut}(Cl(V,q)),
\end{equation}
where:
\begin{itemize}
\item $M$ is the base space of \emph{effective memory
  kernels}---equivalently, the space of induced
  sufficient-statistic processes accessible to the agent
  (a finite-dimensional manifold that admits local
  parametrisation by the environmental spectral-density
  couplings);
\item $G$ is the structure group acting transitively on
  admissible frames (see
  footnote~\ref{II-fn:gauge_group} for the effective
  subgroup);
\item the fiber $\pi^{-1}(\kappa)$ over a kernel
  $\kappa \in M$ is the $G$-orbit of equivalent algebraic
  representations (frames) for describing~$\kappa$
  in $Cl(V,q)$;
\item a \emph{section} $\sigma: M \to P$ constitutes a
  global gauge-fixing policy---a systematic choice
  of reference frame for every kernel configuration.
\end{itemize}
\end{definition}

A \emph{connection} on $P$ specifies how the reference frame
is parallel-transported as the agent's state evolves.
The curvature of this connection measures the extent to
which the reference frame ``twists'' along different paths
through state space.

% ------------------------------------------------------------
\subsection{Standing Assumptions}
\label{II-subsec:standing}

\begin{definition}[Standing Assumptions]
\label{II-def:assumptions_B}
Throughout this paper, the following conditions are assumed:
\begin{enumerate}
\item[\textup{(B1)}] \textbf{Inherited framework.}
  All assumptions (A1)--(A5) of
  Paper~I~\cite{Liu2026TDOME_I} remain in force
  (open quantum system coupled to a thermal bath,
  well-defined free energy, non-equilibrium initial state,
  finite-dimensional system Hilbert space,
  and weak-coupling or controlled-coupling regime).
  Additionally, the agent possesses an internal control
  algebra $\mathcal{O}_{\mathrm{int}} = Cl(V,q)$
  with realizability embedding
  $\phi: Cl(V,q) \hookrightarrow Cl(1,3)$
  (Q-RAIF~\cite{Liu2026QRAIF_C}).
\item[\textup{(B2)}] \textbf{Finite computational budget.}
  The agent's information processing rate satisfies
  $\mathcal{C}_{\mathrm{budget}} < \infty$
  (Definition~\ref{II-def:budget}).
\item[\textup{(B3)}] \textbf{Non-trivial environment.}
  The entropy rate satisfies $h_\mu > 0$ and the
  memory depth satisfies $\tau_{\mathrm{mem}} > 0$.
  In Sections~\ref{II-sec:breaking}--\ref{II-sec:cost} we
  additionally require that the Computational Ceiling
  is binding:
  $\tau_{\mathrm{mem}} > \tau_{\mathrm{par}}$
  (Theorem~\ref{II-thm:comp_ceiling}), i.e., the symmetric
  phase is computationally intractable.
\item[\textup{(B4)}] \textbf{Survival imperative.}
  The agent's dynamics must maintain
  $\mathcal{S} \geq \mathcal{S}_{\min}$
  over survival horizons
  $T \gg \tau_{\mathrm{mem}}$.
  This is a persistence constraint, not an optimization
  objective.
\item[\textup{(B5)}] \textbf{Gauge symmetry of bare
  algebra.}
  The automorphism group $G = \mathrm{Aut}(Cl(V,q))$
  is non-trivial ($G \neq \{e\}$).
  In the absence of computational constraints, all
  $g \in G$ yield physically equivalent descriptions.
\end{enumerate}
\end{definition}

% ============================================================
\section{The Computational Ceiling}
\label{II-sec:ceiling}

We now establish the fundamental computational limitation of
symmetric agents---those that treat all components of their
internal algebra as equally relevant.
The result is the computational analogue of Paper~I's
Markovian Ceiling: where that theorem showed that
\emph{memoryless} dynamics cannot achieve
$\mathcal{S} > 0$, the present theorem shows that
\emph{unbiased processing} of memory leads to computational
paralysis.

% ------------------------------------------------------------
\subsection{The Information Processing Inequality
for Bounded Agents}
\label{II-subsec:processing}

\paragraph{Accounting convention.}
To ensure dimensional consistency throughout, we distinguish
two quantities:
\begin{itemize}
\item $\mathcal{C}_{\mathrm{budget}}$: the agent's processing
  \emph{rate} (bits per unit time).
\item $\mathcal{I}_{\mathrm{proc}}(\tau)$: the total
  information (bits) that must be processed per evaluation
  cycle when the memory archive has depth $\tau$.
\end{itemize}
The agent must complete one evaluation cycle per
environmental correlation time $\tau_E$.
The \emph{processing rate} required for a memory depth
$\tau$ is
\begin{equation}
\label{II-eq:rate_def}
\mathcal{R}_{\mathrm{proc}}(\tau)
:= \frac{\mathcal{I}_{\mathrm{proc}}(\tau)}
        {\tau_E}.
\end{equation}
Paralysis occurs when
$\mathcal{R}_{\mathrm{proc}}(\tau_{\mathrm{mem}})
> \mathcal{C}_{\mathrm{budget}}$.
Hereafter we measure time in units of $\tau_E$
(i.e., set $\tau_E = 1$), so that rates and per-cycle
information quantities are numerically equal.

\begin{definition}[Symmetric processing]
\label{II-def:symmetric}
An agent processes its memory \emph{symmetrically} if both
its cost functional $\mathcal{C}[\cdot]$ and its distortion
measure $D(\cdot)$ are $G$-invariant:
$\mathcal{C}[g \cdot \mathcal{K}]
= \mathcal{C}[\mathcal{K}]$ and
$D(g \cdot \mathcal{F}) = D(\mathcal{F})$
for every $g \in G = \mathrm{Aut}(Cl(V,q))$.
In operational terms: for every stored correlation $c_i$ in the
memory kernel $\mathcal{K}(t,s)$ and every $g \in G$, the
cost of evaluating $c_i$ equals the cost of evaluating
$g \cdot c_i$, and no basis direction is
\emph{a priori} preferred for survival evaluation.
\end{definition}

\begin{remark}[Operational meaning of processing rate]
\label{II-rem:proc_rate}
We define the processing rate
$\mathcal{R}_{\mathrm{proc}}$ as an
\emph{information-throughput} measure: the number of
algebraic components that must be updated per unit time,
multiplied by the innovation rate $h_\mu$ per component.
It captures the \emph{bandwidth} cost of maintaining an
internal representation, not the algorithmic gate
complexity of individual operations.
\end{remark}

\begin{theorem}[Computational Ceiling]
\label{II-thm:comp_ceiling}
Let an agent satisfy assumptions~\textup{(B1)--(B5)} with
memory depth $\tau_{\mathrm{mem}}$ and per-component entropy
rate $h_\mu > 0$.
Assume the environment is \textbf{unstructured} in the
following two senses:
\textup{(i)}~the effective activated dimension satisfies
$D_{\mathrm{eff}} \approx D$ (all grades of $Cl(V,q)$
carry non-negligible correlations), and
\textup{(ii)}~the predictive information is not concentrated
on a known sub-algebra (the agent possesses no
\emph{a priori} knowledge of the environmental symmetry
group and cannot exploit group-theoretic shortcuts such as
irreducible representations or Schur
decompositions).\footnote{%
If the agent knows the environmental symmetry group $H$,
symmetric processing can be restricted to the isotypic
components of $H$, reducing the effective dimension to
$D_{\mathrm{eff}} \leq D$.
The ceiling applies to the \emph{generic} (worst-case)
scenario.
All subsequent results hold \emph{a fortiori}
when $D$ is replaced by $D_{\mathrm{eff}}$.}
Within the class of \emph{symmetric representations}
that retain all $D$ components with equal fidelity
(permitting no privileged subspace)---thereby precluding
structured compression techniques such as sparse coding
or Johnson--Lindenstrauss
embeddings~\cite{JohnsonLindenstrauss1984}, as these
inherently implement a form of symmetry
breaking---the minimum processing rate satisfies
\begin{equation}
\label{II-eq:comp_ceiling}
\mathcal{R}_{\mathrm{proc}}^{\mathrm{sym}}
\;\geq\; h_\mu \cdot D,
\qquad D := \dim Cl(V,q) = 2^n,
\end{equation}
where $n = \dim V$ is the number of generators.
This rate scales \emph{linearly} in the algebra dimension
$D$ and \emph{exponentially} in~$n$.

For any finite $\mathcal{C}_{\mathrm{budget}}$, the maximum
memory depth that can be processed before correlations
expire is
\begin{equation}
\label{II-eq:t_par}
\tau_{\mathrm{par}}
:= \frac{\mathcal{C}_{\mathrm{budget}}}
        {h_\mu \cdot D}.
\end{equation}
Here $\tau_{\mathrm{par}}$ is measured in units of
$\tau_E$ (environmental correlation times), not seconds;
cf.\ the accounting convention at the start of this section.

For $\tau_{\mathrm{mem}} > \tau_{\mathrm{par}}$, the agent's
evaluation cycle cannot complete within one correlation time:
\begin{equation}
\label{II-eq:paralysis}
\mathcal{I}_{\mathrm{proc}}(\tau_{\mathrm{mem}})
= h_\mu \cdot \tau_{\mathrm{mem}} \cdot D
> \mathcal{C}_{\mathrm{budget}}.
\end{equation}
Stored correlations go stale before they can be used.
\end{theorem}

\begin{proof}
Under symmetric processing, the agent maintains $D$
parallel correlation channels---one for each independent
algebraic component of $Cl(V,q)$.
The environment generates innovations at rate $h_\mu$ bits
per unit time in each channel
(Remark~\ref{II-rem:proc_rate}).
Over a memory depth $\tau_{\mathrm{mem}}$, the total
information load is therefore
$\mathcal{I}_{\mathrm{proc}}(\tau_{\mathrm{mem}})
= D \cdot h_\mu \cdot \tau_{\mathrm{mem}}$
bits~\cite{CoverThomas2006}, and the required
\emph{rate} is
$\mathcal{R}_{\mathrm{proc}}^{\mathrm{sym}}
= D \cdot h_\mu$ bits per unit time.

The agent must complete one evaluation cycle within
$\tau_E$ (one environmental correlation time); otherwise
the oldest correlations expire before use.
Setting
$\mathcal{R}_{\mathrm{proc}}^{\mathrm{sym}}
= \mathcal{C}_{\mathrm{budget}}$
and solving for $\tau_{\mathrm{mem}}$ gives
$\tau_{\mathrm{par}}$~\eqref{II-eq:t_par}.
\end{proof}

\begin{corollary}[The Symmetry Tax]
\label{II-cor:symmetry_tax}
Maintaining full gauge invariance imposes a multiplicative
overhead of $D = 2^n$ on all computational operations
relative to a fixed-basis agent that processes only $k$
components.
The overhead ratio is $D/k$, which for
$Cl(1,3)$ ($D = 16$, $k = 2$) is $8\times$, and grows
exponentially with the number of generators $n$.
\end{corollary}

\begin{remark}[Effective vs.\ full dimension]
\label{II-rem:D_eff}
The ceiling uses $D = \dim Cl(V,q) = 2^n$, the full
multivector dimension.
In practice, the environment may couple to only a subset of
grades (e.g., grade-1 generators), yielding an effective
dimension $D_{\mathrm{eff}} \leq D$.
For a \emph{structured} environment where the agent knows
which grades are active, the ceiling can be tightened to
$\mathcal{R}_{\mathrm{proc}} \gtrsim h_\mu
\cdot D_{\mathrm{eff}}$.
The unstructured assumption~(B3) represents the worst case;
all subsequent results hold \emph{a fortiori} when
$D$ is replaced by $D_{\mathrm{eff}}$.
\end{remark}

% ------------------------------------------------------------
\subsection{Processing Collapse}
\label{II-subsec:collapse}

\begin{proposition}[Processing Collapse]
\label{II-prop:collapse}
Under~\textup{(B1)--(B5)}, an agent that maintains full
gauge symmetry reaches computational paralysis at time
$\tau_{\mathrm{par}}$~\eqref{II-eq:t_par}.
Beyond $\tau_{\mathrm{par}}$, the agent's processing latency
$\delta t_{\mathrm{proc}}$ exceeds the environmental
correlation time $\tau_E$:
\begin{equation}
\label{II-eq:latency}
\delta t_{\mathrm{proc}}(\tau_{\mathrm{mem}})
= \frac{D \cdot \tau_{\mathrm{mem}}}
       {\mathcal{C}_{\mathrm{budget}} / h_\mu}
> 1
\qquad\text{(in units of $\tau_E$)}.
\end{equation}
Every stored correlation becomes stale before it can be
evaluated, rendering the entire memory archive operationally
useless.
\end{proposition}

\begin{remark}[Comparison with Paper~I's Memory Catastrophe]
\label{II-rem:comparison}
Paper~I's Memory Catastrophe is \emph{thermodynamic}:
the \emph{cost of storing} memory exceeds the energy budget.
The Computational Ceiling is \emph{informational}: the
\emph{cost of processing} memory exceeds the computational
budget.
The two crises are complementary---an agent with unlimited
energy but finite computation is still paralyzed, and vice
versa.
The resolution of both crises is the same: compression
through symmetry breaking.
\end{remark}

% ============================================================
\section{The Symmetry Breaking Resolution}
\label{II-sec:breaking}

% ------------------------------------------------------------
\subsection{Reference Frame as Gauge Fixing}
\label{II-subsec:frame}

\begin{definition}[Reference frame]
\label{II-def:frame}
A \emph{reference frame} $\mathcal{F}$ is a section
$\sigma: M \to P$ of the gauge bundle
(Definition~\ref{II-def:bundle}).
Choosing $\sigma$ is equivalent to selecting a preferred
orthonormal basis $\{e_1, \ldots, e_n\}$ of the generating
vector space $V$ at each point in state space~$M$, thereby
fixing the gauge freedom of $Cl(V,q)$.
\end{definition}

\begin{definition}[Projected memory kernel]
\label{II-def:projected}
Given a reference frame $\mathcal{F}$, let
$V_{\mathrm{fg}}(\mathcal{F}) \subset Cl(V,q)$ be the
$k^*$-dimensional \emph{foreground subspace} selected by
the rate-distortion optimization
(Theorem~\ref{II-thm:compression}).
Let $\Pi_{\mathcal{F}}$ denote the orthogonal projection
onto $V_{\mathrm{fg}}(\mathcal{F})$ with respect to the
trace inner product
$\langle A, B \rangle := \tr(A^\dagger B)$.
The \emph{projected memory kernel} is
\begin{equation}
\label{II-eq:projected_kernel}
\mathcal{K}_{\mathcal{F}}(t,s)
:= \Pi_{\mathcal{F}}\,\mathcal{K}(t,s)\,
   \Pi_{\mathcal{F}}.
\end{equation}
The complementary projection
$\Pi_{\mathcal{F}}^{\perp}
= \mathbf{1} - \Pi_{\mathcal{F}}$ defines the
\emph{background subspace} $V_{\mathrm{bg}}(\mathcal{F})$.
The decomposition
$Cl(V,q) = V_{\mathrm{fg}} \oplus V_{\mathrm{bg}}$
is determined by $\mathcal{F}$, not by any \emph{a priori}
ordering of basis vectors.
\end{definition}

% ------------------------------------------------------------
\subsection{The Rate-Distortion Bound}
\label{II-subsec:RD_bound}

We now apply rate-distortion theory to the problem of
optimal memory compression under the survival constraint.

\paragraph{Processing rate of a frame.}
If the agent retains $k$ algebraic components (the foreground
subspace $V_{\mathrm{fg}}$), each generating $h_\mu$ bits
per unit time, the processing rate of frame $\mathcal{F}$ is
\begin{equation}
\label{II-eq:R_frame}
R_{\mathcal{F}}(k) \;=\; k \cdot h_\mu
\qquad\text{(bits per unit time)}.
\end{equation}
The budget constraint $R_{\mathcal{F}} \leq
\mathcal{C}_{\mathrm{budget}}$ thus bounds the number of
maintainable components.

\begin{definition}[Survival distortion]
\label{II-def:survival_distortion}
The \emph{survival distortion} of a reference frame
$\mathcal{F}$ is
\begin{equation}
\label{II-eq:distortion}
D(\mathcal{F})
:= \mathbb{E}_{\xi}\!\left[
  \ell\!\bigl(\mathcal{S}_{\mathrm{full}}(\xi)
  - \mathcal{S}_{\mathcal{F}}(\xi)\bigr)
\right],
\end{equation}
where $\xi$ denotes environmental realizations,
$\ell: \mathbb{R} \to [0,\infty)$ is a convex,
non-decreasing loss function (we use squared error
$\ell(x) = x^2$ throughout),
$\mathcal{S}_{\mathrm{full}}(\xi)$ is the survival
functional evaluated using the full memory kernel
$\mathcal{K}(t,s)$, and $\mathcal{S}_{\mathcal{F}}(\xi)$
is evaluated using the projected kernel
$\mathcal{K}_{\mathcal{F}}(t,s)$.
\end{definition}

\begin{remark}[Information-theoretic objects]
\label{II-rem:info_objects}
Strictly speaking, rate-distortion theory and mutual
information apply to stochastic processes, not to
superoperator kernels directly.
Throughout
Sections~\ref{II-sec:breaking}--\ref{II-sec:cost},
$I(\mathcal{K}_{\mathcal{F}};\,\mathcal{K})$ is shorthand
for $I(\hat{X};\,X)$, where
$X = \{c_i(t)\}_{i=1}^{D}$ is the sufficient-statistic
record process induced by the full kernel $\mathcal{K}$
acting on the agent's internal coordinates, and
$\hat{X} = \{c_i(t)\}_{i \in V_{\mathrm{fg}}}$ is the
projected record induced by
$\mathcal{K}_{\mathcal{F}}$.
The distortion measure~\eqref{II-eq:distortion} acts on the
survival functional $\mathcal{S}$ evaluated on these
records.
\end{remark}

\begin{theorem}[Optimal Compression under Survival Constraint]
\label{II-thm:compression}
Let an agent with computational budget
$\mathcal{C}_{\mathrm{budget}}$ and per-component entropy
rate $h_\mu$ choose a reference frame $\mathcal{F}$ that
minimizes the survival distortion~\eqref{II-eq:distortion}
subject to $R_{\mathcal{F}} \leq
\mathcal{C}_{\mathrm{budget}}$~\eqref{II-eq:R_frame}.
Then:
\begin{enumerate}
\item[\textup{(a)}] Assuming that $D(\mathcal{F})$ is
  non-increasing in the available rate $R_{\mathcal{F}}$
  (retaining more components cannot worsen survival
  distortion), the set of optimal reference frames
  $\mathfrak{F}^*
  := \operatorname*{arg\,min}_{\mathcal{F}}
  D(\mathcal{F})$
  subject to the budget constraint is non-empty, and
  any $\mathcal{F}^* \in \mathfrak{F}^*$ saturates the
  budget:
  $R_{\mathcal{F}^*} = \mathcal{C}_{\mathrm{budget}}$
  (the set $\mathfrak{F}^*$ may contain multiple
  elements; see Theorem~\ref{II-thm:SSB}(c)).
\item[\textup{(b)}] The compressed representation retains
  \begin{equation}
  \label{II-eq:k_star}
  k^* = \left\lfloor
    \frac{\mathcal{C}_{\mathrm{budget}}}{h_\mu}
  \right\rfloor
  \end{equation}
  effective algebraic components
  (the maximum integer number of components whose processing
  rate $k^* \cdot h_\mu$ fits within the budget;
  in practice the floor function ensures
  $k^* \in \mathbb{Z}_{\geq 1}$).
\item[\textup{(c)}] The fraction of algebraic structure
  discarded (in component count) is
  \begin{equation}
  \label{II-eq:discard_fraction}
  1 - \frac{k^*}{D},
  \end{equation}
  For $Cl(1,3)$ ($D = 16$) with a budget allowing
  $k^* = 2$, the discarded fraction is $1 - 2/16 = 87.5\%$.
  For $k^* = 1$, it exceeds $93\%$.
  In the regime $k^* \ll D$, the fraction approaches
  $1 - 1/D$ and grows with algebra dimension.
\end{enumerate}
\end{theorem}

\begin{proof}
The survival functional $\mathcal{S}$ is a function of the
full density operator $\rho(t)$, which in turn depends on
the full memory kernel $\mathcal{K}(t,s)$.
The agent's task is to evaluate $\mathcal{S}$ using only
$k$ components of $\mathcal{K}$, chosen to minimize the
mean-squared error in $\mathcal{S}$.

Strictly, rate-distortion theory applies to
\emph{random processes}, not to superoperator kernels
directly.
The bridge is the \emph{induced record process}: the
memory kernel $\mathcal{K}(t,s)$, acting on the agent's
internal coordinates, generates a $D$-component time series
of sufficient statistics $\{c_i(t)\}_{i=1}^{D}$ whose
entropy rate per component is~$h_\mu$.
Rate-distortion is applied to this record
stream~(Section~\ref{II-subsec:RD};
cf.\ Tishby et al.~\cite{Tishby2000}),
with source $X = \{c_i(t)\}$ (the full record),
reconstruction
$\hat{X} = \{c_i(t)\}_{i \in V_{\mathrm{fg}}}$
(the projected record), and distortion measure
$d = |\mathcal{S}_{\mathrm{full}}
- \mathcal{S}_{\mathcal{F}}|^2$.

By Shannon's rate-distortion theorem~\cite{Shannon1959},
the minimum rate required to achieve distortion $\delta$ is
$R(\delta)$, a convex non-increasing function.
The budget constraint~\eqref{II-eq:R_frame} limits the
processing rate to $R_{\mathcal{F}} = k \cdot h_\mu
\leq \mathcal{C}_{\mathrm{budget}}$.
The optimal frame $\mathcal{F}^*$ saturates this bound.

For part~(b): by~\eqref{II-eq:R_frame}, tracking $k$ components
costs $k \cdot h_\mu$ bits per unit time.
The maximum integer $k$ satisfying
$k \cdot h_\mu \leq \mathcal{C}_{\mathrm{budget}}$ is
$k^* = \lfloor \mathcal{C}_{\mathrm{budget}} / h_\mu
\rfloor$.

The discard fraction~(c) follows by counting:
$k^*$ of $D$ components are retained.
For $Cl(1,3)$ ($D = 16$, $k^* = 2$), the discarded fraction
is $87.5\%$; for higher-dimensional algebras it exceeds
$99\%$.
\end{proof}

% ------------------------------------------------------------
\subsection{Spontaneous Symmetry Breaking}
\label{II-subsec:SSB}

\begin{theorem}[Necessity of Symmetry Breaking]
\label{II-thm:SSB}
Under assumptions~\textup{(B1)--(B5)}, with the
Computational Ceiling binding
($\tau_{\mathrm{mem}} > \tau_{\mathrm{par}}$, both
measured in units of~$\tau_E$), and
assuming \emph{non-degeneracy}: the survival
distortion~\eqref{II-eq:distortion} satisfies
$D(\mathcal{F}) \neq D(\mathcal{F}')$ for almost all
pairs $\mathcal{F} \neq \mathcal{F}'$ in the space of
frames\footnote{%
Non-degeneracy is generically satisfied when the
environment's pointer basis~\cite{Zurek2009} assigns
different survival values to different algebraic
components, breaking the continuous symmetry of the
distortion landscape.
In degenerate cases, a finite set of local minima may
coexist---multiple ``ego attractors''---analogous to
the discrete magnetization directions in a
crystal-field anisotropic ferromagnet.},
the agent's survival-optimal strategy requires:
\begin{enumerate}
\item[\textup{(a)}] \textbf{Gauge fixing}: selection of a
  section $\sigma$ of the gauge bundle
  (Definition~\ref{II-def:bundle}), breaking the
  $G$-symmetry of the bare algebra.
\item[\textup{(b)}] \textbf{Privileged decomposition}:
  partition of the algebra into foreground and background
  subspaces,
  $Cl(V,q) = V_{\mathrm{fg}} \oplus V_{\mathrm{bg}}$,
  with
  $\dim V_{\mathrm{fg}} = k^* \ll \dim V_{\mathrm{bg}}$.
\item[\textup{(c)}] \textbf{Non-uniqueness}: the gauge
  fixing is generically \emph{not} unique.
  Different initial conditions, environmental histories,
  or stochastic fluctuations lead to different choices of
  $\sigma$, just as different initial conditions in a
  ferromagnet lead to different magnetization directions.
\end{enumerate}
The symmetry breaking is \emph{spontaneous} in the precise
physical sense: the underlying algebra $Cl(V,q)$ retains
its full $G$-symmetry, but the agent's operational
representation necessarily breaks it.
\end{theorem}

\begin{proof}
By Theorem~\ref{II-thm:comp_ceiling}, symmetric processing
leads to paralysis at $\tau_{\mathrm{par}}$.
By assumption~(B4) (survival imperative), the agent must
maintain $\mathcal{S} \geq \mathcal{S}_{\min}$ beyond
$\tau_{\mathrm{par}}$.
This requires evaluating $\mathcal{S}$ within the
computational budget $\mathcal{C}_{\mathrm{budget}}$, which
by Theorem~\ref{II-thm:compression} requires projecting onto
$k^* < \dim Cl(V,q)$ components.

Such a projection \emph{is} a gauge fixing: it selects
$k^*$ basis vectors $\{e_1, \ldots, e_{k^*}\}$ from the
generating space $V$, thereby breaking the
$G$-invariance that treats all bases equivalently.

Part~(b) follows from the definition of the projected kernel
(Definition~\ref{II-def:projected}).
Part~(c) follows from the non-degeneracy assumption:
the rate-distortion optimization
(Theorem~\ref{II-thm:compression}) generically admits
finitely many local minima.
Different initial conditions or environmental histories
select different minima, analogous to the
spontaneous magnetization of a ferromagnet below $T_c$.
The breaking is \emph{spontaneous}: the algebra retains
$G$-symmetry, but any operational solution breaks it.
\end{proof}

% ------------------------------------------------------------
\subsection{The Four Bias Terms}
\label{II-subsec:bias}

\begin{proposition}[Structure of the Broken Phase]
\label{II-prop:bias}
When gauge symmetry is broken by a reference frame
$\mathcal{F}$, the agent's operational representation
acquires four systematic deviations from the symmetric
phase:
\begin{enumerate}
\item[\textup{(i)}] \textbf{Basis selection bias}
  ($\mathcal{B}_{\mathrm{select}}$):
  The choice of $\{e_1, \ldots, e_{k^*}\}$ privileges
  certain algebraic components over others.
  Information aligned with the chosen basis is processed
  efficiently; misaligned information is discarded or
  distorted.
  \emph{Observable consequence:} systematic blindness to
  off-basis environmental perturbations (orthogonal
  masking).
\item[\textup{(ii)}] \textbf{Frame drag}
  ($\mathcal{B}_{\mathrm{frame}}$):
  The connection on the gauge bundle
  (Section~\ref{II-subsec:fiber}) induces a systematic
  preference for states near the current gauge choice.
  The agent's predictions are biased toward confirming
  its existing frame.
  \emph{Observable consequence:} hysteresis in belief
  updating; the agent's model lags behind rapid
  environmental shifts.
\item[\textup{(iii)}] \textbf{Objective centering}
  ($\mathcal{B}_{\mathrm{center}}$):
  The survival functional $\mathcal{S}$, when evaluated
  in the projected basis, becomes centered on the agent's
  own state rather than a global optimum.
  The agent optimizes \emph{locally} within its frame.
  \emph{Observable consequence:} inability to detect
  global survival optima located in the background
  subspace.
\item[\textup{(iv)}] \textbf{Model incompleteness}
  ($\mathcal{B}_{\mathrm{inc}}$):
  The compression from $Cl(V,q)$ to $V_{\mathrm{fg}}$
  is lossy.
  The discarded components $V_{\mathrm{bg}}$ contain
  correlations that are invisible to the agent but
  physically real.
  \emph{Observable consequence:} systematic
  underestimation of total thermodynamic uncertainty
  (overconfidence).
\end{enumerate}
\end{proposition}

\begin{proof}
(i)~follows directly from the definition of the projection
$\Pi_{\mathcal{F}}$: components orthogonal to the selected
basis are annihilated.

(ii)~The parallel transport of the gauge connection
preserves the agent's basis choice along its trajectory.
Under perturbation, the connection's holonomy creates a
restoring ``force'' toward the established frame---a
systematic confirmation bias.

(iii)~In the projected representation,
$\mathcal{S}_{\mathcal{F}}$ is a function of the
$k^*$-dimensional foreground state only.
The gradient $\nabla \mathcal{S}_{\mathcal{F}}$ lies
entirely in $V_{\mathrm{fg}}$, so the agent's
optimization is blind to directions in
$V_{\mathrm{bg}}$.
This is equivalent to centering the objective function
on the agent's own representational subspace.

(iv)~By Theorem~\ref{II-thm:compression}(c), a fraction
$\geq 1 - k^*/\dim Cl(V,q)$ of information is discarded.
The discarded components exist physically (they contribute
to $\mathcal{S}_{\mathrm{full}}$) but are invisible to the
agent's evaluation of $\mathcal{S}_{\mathcal{F}}$.
\end{proof}

\begin{table}[H]
\centering
\small
\setlength{\tabcolsep}{3pt}
\begin{tabular}{@{}lp{3.5cm}p{4.2cm}l@{}}
\toprule
\textbf{Bias} & \textbf{Origin}
  & \textbf{Observable consequence}
  & \textbf{Determines} \\
\midrule
$\mathcal{B}_{\mathrm{select}}$ (selection)
  & projection $\Pi_{\mathcal{F}}$
  & Systematic blindness to off-basis
    perturbations (orthogonal masking)
  & \emph{what} is seen \\[4pt]
$\mathcal{B}_{\mathrm{frame}}$ (frame drag)
  & bundle connection / holonomy
  & Hysteresis in belief updating;
    model lags behind rapid drift
  & \emph{duration} \\[4pt]
$\mathcal{B}_{\mathrm{center}}$ (centering)
  & $\nabla\mathcal{S} \in V_{\mathrm{fg}}$
  & Local frame-relative optima;
    global background optima invisible
  & \emph{target} \\[4pt]
$\mathcal{B}_{\mathrm{inc}}$ (incompleteness)
  & lossy compression $k^* \ll D$
  & Underestimation of thermodynamic
    uncertainty (structural overconfidence)
  & \emph{blind spot} \\
\bottomrule
\end{tabular}
\caption{The four bias terms of the broken phase.
  All four are generic consequences of gauge fixing
  under assumptions~(B1)--(B5).}
\label{II-tab:bias}
\end{table}

\begin{remark}[Nature of the bias terms]
\label{II-rem:bias_nature}
The four bias terms (Table~\ref{II-tab:bias}) are not
pathologies---they are \emph{generic} consequences of gauge
fixing under bounded computation.
Any agent satisfying~(B1)--(B5) acquires all four.
\end{remark}

% ============================================================
\section{Emergent Structure: The Architecture of Ego}
\label{II-sec:architecture}

We consolidate the gauge-fixed compressed representation
into a single mathematical object.
Throughout this section, ``ego'' is used purely as shorthand
for a gauge-fixed compressed representation; no claims about
phenomenal consciousness, subjective experience, or qualia
are intended or implied.

\begin{definition}[Ego]
\label{II-def:ego}
The \emph{ego} of an agent satisfying~\textup{(B1)--(B5)}
is the pair
\begin{equation}
\label{II-eq:ego}
\mathfrak{E}
:= \bigl(\mathcal{F}^*,\;
   V_{\mathrm{fg}}^*\bigr),
\end{equation}
where $\mathcal{F}^* \in \mathfrak{F}^*$
(Theorem~\ref{II-thm:compression}) is the chosen gauge
(providing the coordinate system) and
$V_{\mathrm{fg}}^*
:= V_{\mathrm{fg}}(\mathcal{F}^*)$ is the
$k^*$-dimensional foreground subspace selected by
the rate-distortion bound (providing the compression).
The projected memory kernel
$\mathcal{K}_{\mathfrak{E}}
:= \Pi_{V_{\mathrm{fg}}^*}\,\mathcal{K}\,
\Pi_{V_{\mathrm{fg}}^*}$
is induced by this pair.
All bias terms, distortion bounds, and delusion dynamics
are functions of~$\mathfrak{E}$.
\end{definition}

% ------------------------------------------------------------
\subsection{The Ego as a Fiber Bundle Section}
\label{II-subsec:section}

The reference frame $\mathcal{F}$, understood as a section
$\sigma: M \to P$, is the mathematical object we call the
\emph{ego}.
It has three key properties:

\paragraph{Smoothness.}
The section $\sigma$ varies continuously with the agent's
state $\rho \in M$.
Small changes in $\rho$ produce small changes in the
preferred basis---the ego is not a discrete switch but a
smooth deformation of perspective.

\paragraph{Holonomy.}
If the agent's state traces a closed loop
$\gamma: [0,1] \to M$ with $\gamma(0) = \gamma(1) = \rho_0$,
the parallel-transported frame need not return to its
initial value:
\begin{equation}
\label{II-eq:holonomy}
\sigma(\gamma(1))
= \mathrm{Hol}(\gamma) \cdot \sigma(\gamma(0)),
\end{equation}
where $\mathrm{Hol}(\gamma) \in G$ is the holonomy of the
connection around $\gamma$.
Non-trivial holonomy means the agent can ``learn''---its
reference frame shifts after a complete cycle of experience.

\paragraph{Topological obstruction.}
In general, a \emph{global} section $\sigma: M \to P$ may
not exist.
The obstruction is measured by the characteristic classes of
the bundle $P$.
When a global section does not exist, the ego must have
``singularities''---states where the preferred basis is
undefined or discontinuous.
This connects to the crisis of Paper~III: the delusion trap
can be understood as the agent approaching a topological
obstruction of its own reference frame.

% ------------------------------------------------------------
\subsection{The Effective Survival Functional}
\label{II-subsec:effective}

\begin{proposition}[Survival decomposition]
\label{II-prop:decomp}
In the broken phase, the survival functional decomposes as
\begin{equation}
\label{II-eq:decomp}
\mathcal{S}
= \mathcal{S}_{\mathrm{vis}}(\mathcal{F})
  + \mathcal{S}_{\mathrm{hid}}(\mathcal{F}),
\end{equation}
where:
\begin{itemize}
\item $\mathcal{S}_{\mathrm{vis}}(\mathcal{F})$
  is the contribution from the foreground subspace
  $V_{\mathrm{fg}}$, computable within the agent's
  reference frame;
\item $\mathcal{S}_{\mathrm{hid}}(\mathcal{F})$
  is the contribution from the background subspace
  $V_{\mathrm{bg}}$, invisible to the agent.
\end{itemize}
The agent maximizes $\mathcal{S}_{\mathrm{vis}}$ while
being structurally blind to
$\mathcal{S}_{\mathrm{hid}}$.
\end{proposition}

\begin{proof}
The survival functional $\mathcal{S} = \Delta F - W$ depends
on $\rho(t)$, which is a function of the full memory kernel
$\mathcal{K}(t,s)$.
Decomposing
$\mathcal{K} = \Pi_{\mathcal{F}}\,\mathcal{K}\,
\Pi_{\mathcal{F}}
+ \Pi_{\mathcal{F}}^{\perp}\,\mathcal{K}\,
\Pi_{\mathcal{F}}^{\perp}
+ \text{cross terms}$,
the leading contributions are
$\mathcal{S}_{\mathrm{vis}} := \mathcal{S}[
\Pi_{\mathcal{F}}\,\mathcal{K}\,\Pi_{\mathcal{F}}]$
and
$\mathcal{S}_{\mathrm{hid}} := \mathcal{S} -
\mathcal{S}_{\mathrm{vis}}$
(collecting background and cross terms).
The agent computes only
$\mathcal{S}_{\mathrm{vis}}$, as the projected kernel
$\mathcal{K}_{\mathcal{F}}$ discards all background
components.
\end{proof}

% ------------------------------------------------------------
\subsection{The Computational Speedup}
\label{II-subsec:speedup}

\begin{proposition}[Ego dividend]
\label{II-prop:speedup}
After symmetry breaking, the computational cost of
processing memory drops from
$\mathcal{C}_{\mathrm{proc}} \sim h_\mu \cdot
\tau_{\mathrm{mem}} \cdot D$
(symmetric case, $D = \dim Cl(V,q)$) to
\begin{equation}
\label{II-eq:speedup}
\mathcal{C}_{\mathrm{proc}}^{(\mathcal{F})}
\sim h_\mu \cdot \tau_{\mathrm{mem}}
     \cdot k^*.
\end{equation}
The speedup factor is
\begin{equation}
\label{II-eq:speedup_factor}
\frac{D}{k^*} = \frac{2^n}{k^*}.
\end{equation}
\end{proposition}

This is the computational advantage of reference-frame
selection.
For $Cl(1,3)$ ($D = 16$) with $k^* = 2$, the speedup is
$8\times$.
For higher-dimensional algebras, the speedup grows
exponentially in $n$.

% ------------------------------------------------------------
\subsection{The Ego-Entropy Trade-off}
\label{II-subsec:tradeoff}

\begin{theorem}[Ego-Entropy Trade-off]
\label{II-thm:tradeoff}
Let $X = \{c_i(t)\}_{i=1}^{D}$ denote the full stochastic
record process induced by the memory kernel $\mathcal{K}$
on the agent's internal coordinates, and let
$\hat{X} = \{c_i(t)\}_{i \in V_{\mathrm{fg}}}$ denote the
projected record retained by the ego.
The mutual information between compressed and full records,
denoted $I(\mathcal{K}_{\mathcal{F}};\,\mathcal{K})
\equiv I(\hat{X};\,X)$, satisfies
\begin{equation}
\label{II-eq:I_retained}
I(\hat{X};\,X) \;\leq\; H(\hat{X})
\;\leq\; k^* \cdot h_\mu \cdot \tau_{\mathrm{mem}}.
\end{equation}
Under the additional assumption that
$I_{\mathrm{pred}}$~\eqref{II-eq:I_pred} is approximately
uniformly distributed across the $D$ algebraic components
in the symmetric phase\footnote{%
This ``uniformity assumption'' is the information-theoretic
counterpart of the unstructured-environment condition in
Theorem~\ref{II-thm:comp_ceiling}.
When some components carry disproportionately more predictive
information, the bound tightens or loosens depending on the
alignment between $V_{\mathrm{fg}}$ and the high-information
subspace.},
the information discarded by the ego is bounded below
(up to $O(1)$ constants under uniformity):
\begin{equation}
\label{II-eq:I_discarded}
I_{\mathrm{discarded}}
:= H(X) - I(\hat{X};\,X)
\gtrsim \left(1 - \frac{k^*}{D}\right)
\cdot I_{\mathrm{pred}}.
\end{equation}
\end{theorem}

\begin{proof}
By the data processing inequality,
$I(\hat{X};\,X) \leq H(\hat{X})$.
The projected record $\hat{X}$ has $k^*$ components,
each carrying at most $h_\mu$ bits per unit time over a
window of $\tau_{\mathrm{mem}}$, giving
$H(\hat{X}) \leq k^* \cdot h_\mu \cdot
\tau_{\mathrm{mem}}$~\cite{CoverThomas2006}.
This yields~\eqref{II-eq:I_retained}.
The total predictive information in the full record is
$I_{\mathrm{pred}}$~\eqref{II-eq:I_pred}.
Under the uniformity assumption, each of the $D$ components
carries $\sim I_{\mathrm{pred}}/D$, so the $k^*$ retained
components account for $\sim (k^*/D)\,I_{\mathrm{pred}}$.
The discarded fraction follows by subtraction.
\end{proof}

\begin{remark}[The price of selfhood]
\label{II-rem:price}
Equation~\eqref{II-eq:I_discarded} quantifies the
\emph{information cost of having an ego}: the agent
sacrifices at least a fraction
$1 - k^*/\dim Cl(V,q)$ of all predictive information
about its environment in exchange for computational
tractability.
This is not a deficiency---it is a \emph{design
constraint} forced by bounded resources.
The ego is the optimal lossy compression under survival
weighting.
\end{remark}

% ============================================================
\section{Worked Example: Qubit in a Two-Channel Bath}
\label{II-sec:example}

% ------------------------------------------------------------
\subsection{Model Setup}
\label{II-subsec:model}

We extend Paper~I's spin-boson model to demonstrate
symmetry breaking explicitly.
Consider a qubit ($\dim \mathcal{H}_S = 2$) with internal
algebra $Cl(0,2) \cong \mathbb{H}$ (the quaternions,
$\dim = 4$).

\paragraph{Symbol mapping.}
The general framework of Sections~\ref{II-sec:ceiling}--\ref{II-sec:architecture}
specialises as follows:
\begin{center}
\small
\begin{tabular}{@{}lll@{}}
\toprule
General & This example & Value \\
\midrule
$Cl(V,q)$ & $Cl(0,2) \cong \mathbb{H}$
  & $D = 4$ \\
$G = \mathrm{Aut}(Cl(V,q))$ & $SO(3)$
  & acting on $\{\mathbf{i},\mathbf{j},\mathbf{k}\}$\\
$\mathcal{C}_{\mathrm{budget}}$ & $2\,h_\mu$
  & bits/time \\
$k^*$ (Thm.~\ref{II-thm:compression})
  & $\lfloor 2h_\mu / h_\mu \rfloor = 2$
  & components \\
$V_{\mathrm{fg}}$ & $\mathrm{span}\{1,\mathbf{k}\}$
  & dephasing subspace \\
$V_{\mathrm{bg}}$ & $\mathrm{span}\{\mathbf{i},\mathbf{j}\}$
  & dissipative subspace \\
$\tau_{\mathrm{par}}$ (Thm.~\ref{II-thm:comp_ceiling})
  & $2h_\mu / (4h_\mu) = 0.5$
  & $\omega_0^{-1}$ \\
\bottomrule
\end{tabular}
\end{center}
The qubit is coupled to a bosonic environment through
\emph{two} independent channels:
\begin{itemize}
\item A \emph{dephasing channel} via $\sigma_z$, with
  spectral density
  \begin{equation}
  \label{II-eq:J_z}
  J_z(\omega)
  = \frac{2\lambda_z\,\gamma_z\,\omega}
         {\omega^2 + \gamma_z^2}
  \qquad\text{(Lorentz--Drude)},
  \end{equation}
  producing a memory kernel $\mathcal{K}_z(t,s)$ with
  non-Markovian backflow.
\item A \emph{dissipative channel} via $\sigma_x$, with
  spectral density
  \begin{equation}
  \label{II-eq:J_x}
  J_x(\omega)
  = \frac{2\lambda_x\,\gamma_x\,\omega}
         {\omega^2 + \gamma_x^2}
  \qquad\text{(Lorentz--Drude)},
  \end{equation}
  producing a memory kernel $\mathcal{K}_x(t,s)$.
\end{itemize}

The full memory kernel is
$\mathcal{K}(t,s)
= \mathcal{K}_z(t,s) \oplus \mathcal{K}_x(t,s)$,
and the quaternionic algebra
$\mathbb{H} = \mathrm{span}\{1, \mathbf{i}, \mathbf{j},
\mathbf{k}\}$
has automorphism group
$G = \mathrm{Aut}(\mathbb{H}) \cong SO(3)$
(rotations of the pure quaternion subspace).

\paragraph{Parameters.}
We set $\omega_0 = 1$ (energy unit),
$\lambda_z = 1$, $\gamma_z = 0.5$ (underdamped, strong
non-Markovian effects in the dephasing channel),
$\lambda_x = 0.3$, $\gamma_x = 5.0$ (overdamped,
approximately Markovian in the dissipative channel),
and the low-temperature regime $\beta\omega_0 \gg 1$.

\paragraph{Computational budget.}
The agent has
$\mathcal{C}_{\mathrm{budget}} = 2\,h_\mu$
bits per unit time---sufficient to track two components
of $\mathbb{H}$ but not all four.

\paragraph{Parameter-to-theorem mapping.}
Table~\ref{II-tab:params} collects the example parameters and
confirms that the Computational Ceiling binds.

\begin{table}[t]
\centering
\small
\begin{tabular}{@{}lcll@{}}
\toprule
\textbf{Quantity} & \textbf{Symbol} & \textbf{Value}
  & \textbf{Theorem check} \\
\midrule
Full dimension & $D$ & $4$ &
  Thm.~\ref{II-thm:comp_ceiling} \\
Entropy rate & $h_\mu$ & $1.0$ (normalised) &
  per-component rate \\
Budget & $\mathcal{C}_{\mathrm{budget}}$ & $2\,h_\mu$
  & Def.~\ref{II-def:budget} \\
\midrule
Ceiling check & $h_\mu D$ vs $\mathcal{C}_{\rm budget}$
  & $4 > 2$ & \textbf{ceiling binds} \\
Optimal $k$ & $k^*$ & $\lfloor 2/1 \rfloor = 2$
  & Thm.~\ref{II-thm:compression}(b) \\
Discard fraction & $1 - k^*/D$ & $1/2 = 50\%$
  & Thm.~\ref{II-thm:tradeoff} \\
Paralysis time & $\tau_{\mathrm{par}}$ & $2/(4) = 0.5$
  & Eq.~\eqref{II-eq:t_par} \\
\bottomrule
\end{tabular}
\caption{Parameter mapping for the two-channel qubit
example.  The ceiling check confirms that symmetry
breaking is necessary; the budget is exactly saturated
after breaking ($R_{\mathcal{F}} = k^* h_\mu
= \mathcal{C}_{\mathrm{budget}}$).}
\label{II-tab:params}
\end{table}

% ------------------------------------------------------------
\subsection{The Unbroken Phase: Paralysis}
\label{II-subsec:unbroken}

In the symmetric phase, the agent tracks all four
quaternionic components
$\{1, \mathbf{i}, \mathbf{j}, \mathbf{k}\}$
simultaneously.
The computational cost is
\begin{equation}
\label{II-eq:cost_full}
\mathcal{C}_{\mathrm{proc}}
= h_\mu \cdot \tau_{\mathrm{mem}} \cdot D
= 4\,h_\mu \cdot \tau_{\mathrm{mem}},
\qquad D := \dim Cl(0,2) = 4.
\end{equation}
The paralysis time is
\begin{equation}
\label{II-eq:t_par_example}
\tau_{\mathrm{par}}
= \frac{\mathcal{C}_{\mathrm{budget}}}
       {h_\mu \cdot D}
= \frac{2\,h_\mu}{4\,h_\mu} = 0.5
\qquad\text{(in units of $\omega_0^{-1}$)}.
\end{equation}
Beyond $\tau_{\mathrm{mem}} = 0.5\,\omega_0^{-1}$,
the agent cannot process both channels
simultaneously---it is paralyzed.

% ------------------------------------------------------------
\subsection{Symmetry Breaking: Choosing $\sigma_z$}
\label{II-subsec:choosing}

The agent breaks the $SO(3)$ symmetry of $\mathbb{H}$
by selecting $\sigma_z$ as the privileged basis direction,
retaining the $\{1, \mathbf{k}\}$ subspace (the dephasing
channel) as foreground and discarding
$\{\mathbf{i}, \mathbf{j}\}$ (the dissipative channel)
as background:
\begin{equation}
\label{II-eq:decomp_example}
\mathbb{H}
= \underbrace{\mathrm{span}\{1, \mathbf{k}\}}_{%
  V_{\mathrm{fg}}\; (k^* = 2)}
\oplus
\underbrace{\mathrm{span}\{\mathbf{i}, \mathbf{j}\}}_{%
  V_{\mathrm{bg}}}.
\end{equation}

\paragraph{Why $\sigma_z$?}
The dephasing channel ($\lambda_z = 1$, $\gamma_z = 0.5$)
is strongly non-Markovian and carries the dominant
survival-relevant information (the backflow revivals that
enable $\mathcal{S} > 0$, as demonstrated in Paper~I).
The dissipative channel ($\lambda_x = 0.3$, $\gamma_x = 5.0$)
is approximately Markovian and contributes primarily to
decoherence---its survival value is negative.

This choice coincides with the \emph{pointer basis}
selected by environmental decoherence (quantum
Darwinism~\cite{Zurek2009}): the $\sigma_z$ eigenstates
are the states that survive decoherence and become
redundantly encoded in the environment.
The ego ``accepts the suggestion'' of decoherence,
aligning its computational resources with the
environmentally stable basis.

% ------------------------------------------------------------
\subsection{The Broken Phase: Effective Processing}
\label{II-subsec:broken}

In the broken phase, the projected memory kernel
$\mathcal{K}_{\mathcal{F}} = \mathcal{K}_z$ retains only
the dephasing-channel dynamics.
The computational cost drops to
\begin{equation}
\label{II-eq:cost_broken}
\mathcal{C}_{\mathrm{proc}}^{(\mathcal{F})}
= h_\mu \cdot \tau_{\mathrm{mem}} \cdot k^*
= 2\,h_\mu \cdot \tau_{\mathrm{mem}},
\end{equation}
exactly half the symmetric cost~\eqref{II-eq:cost_full}.
The agent can now process memory up to depth
$\tau_{\mathrm{mem}} = 1\,\omega_0^{-1}$ before reaching
its budget---twice the paralysis time.

The survival functional in the broken phase is
\begin{equation}
\label{II-eq:S_broken}
\mathcal{S}_{\mathrm{vis}}(\mathcal{F})
= \mathcal{S}[\mathcal{K}_z],
\end{equation}
which, as shown in Paper~I, achieves
$\beta\,\mathcal{S}_{\mathrm{vis}} \approx +0.093$ at
the first backflow revival.

The hidden component
$\mathcal{S}_{\mathrm{hid}} = \mathcal{S}[\mathcal{K}_x]$
is the survival contribution from the dissipative channel,
which the agent can no longer evaluate.
For the chosen parameters,
$|\mathcal{S}_{\mathrm{hid}}|
\ll |\mathcal{S}_{\mathrm{vis}}|$
(the dissipative channel contributes primarily negative
survival value), so the distortion is small.

% ------------------------------------------------------------
\subsection{Quantitative Evaluation}
\label{II-subsec:quantitative}

We now evaluate the ego dividend explicitly.
Each channel's decoherence function follows from the exact
$T \to 0$ solution of the Lorentz--Drude pure-dephasing
model~\cite{BreuerPetruccione2002,Liu2026TDOME_I}:
\begin{equation}
\label{II-eq:decoherence_II}
p_\alpha(t) = e^{-\gamma_\alpha t/2}\!\left[
  \cos(\Omega_\alpha t)
  + \frac{\gamma_\alpha}{2\Omega_\alpha}\,
    \sin(\Omega_\alpha t)
\right],
\quad
\Omega_\alpha
:= \tfrac{1}{2}\sqrt{4\lambda_\alpha\gamma_\alpha
   - \gamma_\alpha^2},
\end{equation}
for $\alpha \in \{z, x\}$.
When $4\lambda_\alpha\gamma_\alpha < \gamma_\alpha^2$
(the overdamped regime), $\Omega_\alpha$ becomes imaginary
and the trigonometric functions are replaced by hyperbolic
functions (monotonic decay, no backflow).

For our parameters:
\begin{itemize}
\item \textbf{$z$-channel} ($\lambda_z = 1$,
  $\gamma_z = 0.5$):
  $\Omega_z = \frac{1}{2}\sqrt{1.75} \approx 0.661$.
  Underdamped; $|p_z(t)|$ exhibits oscillatory backflow.
\item \textbf{$x$-channel} ($\lambda_x = 0.3$,
  $\gamma_x = 5.0$):
  Discriminant $4\lambda_x\gamma_x - \gamma_x^2
  = 6 - 25 = -19 < 0$.
  Overdamped; $|p_x(t)|$ decays monotonically with no
  backflow.
\end{itemize}

The survival proxy from Paper~I,
$\beta\,\mathcal{S} \propto |p(t)|^2 - 1$
(valid for the pure-dephasing model with maximally coherent
initial state and pointer-basis measurement), applies to
each channel independently.
Backflow intervals---where $d|p_\alpha|/dt > 0$---produce
$\mathcal{S} > 0$ over those subintervals (Paper~I,
Theorem~2).

\textbf{Key result.}
For the $z$-channel with $\gamma_z = 0.5$, the first
backflow interval begins at
$t^* \approx 2.9\,\omega_0^{-1}$---well after the
paralysis time $\tau_{\mathrm{par}} = 0.5\,\omega_0^{-1}$.
The symmetric agent, paralyzed at $\tau_{\mathrm{par}}$,
can harvest \emph{zero} backflow.
The ego agent, tracking only the $z$-channel, can process
memory to depth $1\,\omega_0^{-1}$ and exploits \emph{all
three} backflow revivals visible in
Figure~\ref{II-fig:ego}(a).

The cumulative backflow harvested by the ego agent
(Figure~\ref{II-fig:ego}(b)) totals approximately $0.10$
(in dimensionless $\beta\,\mathcal{S}$ units) over
$t \in [0, 15\,\omega_0^{-1}]$.
The symmetric agent harvests exactly zero.
This infinite ratio is the \emph{ego dividend}: the entire
non-Markovian survival advantage is accessible only to the
agent that has broken symmetry.

Crucially, visual inspection of Figure~\ref{II-fig:ego}(a)
reveals a timeline of tragedy for the symmetric agent.
The paralysis time $\tau_{\mathrm{par}} = 0.5$ occurs
\emph{before} the onset of the first backflow interval
($t^* \approx 2.9$).
The symmetric agent is computationally dead before the
environment offers its first gift.
The ratio of survival profit is not merely large; it is
singular.
In this framework, to remain symmetric is to starve in the
midst of plenty.

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]{fig_ego.pdf}
\caption{%
Two-channel qubit model (Section~\ref{II-sec:example}) with
Lorentz--Drude spectral density.
\textbf{Parameters:}
$\omega_0 = 1$ (energy unit);
$\lambda_z = 1$, $\gamma_z = 0.5$ (dephasing, non-Markovian);
$\lambda_x = 0.3$, $\gamma_x = 5.0$ (dissipative,
$\sim$Markovian);
$\mathcal{C}_{\mathrm{budget}} = 2\,h_\mu$.
\textbf{Units:} time in $\omega_0^{-1}$.
\textbf{Regime:} low temperature ($\beta\omega_0 \gg 1$);
using the standard $T \to 0$ analytic
expression~\eqref{II-eq:decoherence_II}~%
\cite{BreuerPetruccione2002}.
\textbf{(a)}~Decoherence amplitudes $|p_z(t)|$ (blue,
non-Markovian, with backflow in green bands) and
$|p_x(t)|$ (orange, monotonic decay).
Red dashed: paralysis time $\tau_{\mathrm{par}} = 0.5$.
\textbf{(b)}~Cumulative backflow harvested.
Blue: ego agent (broken $\to \sigma_z$) exploits all three
revival intervals.
Red dashed: symmetric agent, paralyzed at
$\tau_{\mathrm{par}}$, harvests zero---all backflow occurs
after paralysis onset.
The growing gap is the \emph{ego dividend}.}
\label{II-fig:ego}
\end{figure}

\paragraph{Consistency check.}
We verify the Computational Ceiling
(Theorem~\ref{II-thm:comp_ceiling}) directly:
$\mathcal{R}_{\mathrm{proc}}^{\mathrm{sym}}
= h_\mu \cdot D = 4\,h_\mu
> \mathcal{C}_{\mathrm{budget}} = 2\,h_\mu$,
confirming that the ceiling binds and symmetry breaking is
required.
After breaking ($k^* = 2$),
$R_{\mathcal{F}} = 2\,h_\mu
= \mathcal{C}_{\mathrm{budget}}$:
the budget is exactly saturated, as predicted by
Theorem~\ref{II-thm:compression}(a).

% ------------------------------------------------------------
\subsection{The Pointer-State Connection}
\label{II-subsec:pointer}

The optimal basis choice coincides with the einselection
(environment-induced superselection) basis of decoherence
theory~\cite{Zurek2009}.
This is not a coincidence: the pointer states are precisely
those that generate the most redundant records in the
environment---i.e., the most predictive correlations.
The rate-distortion optimization
(Theorem~\ref{II-thm:compression}) selects the components
with the highest survival value per bit, which are
generically the pointer-state components.

\begin{remark}[Decoherence as symmetry-breaking catalyst]
\label{II-rem:decoherence}
The environment does not \emph{force} a specific gauge
fixing; it merely breaks the degeneracy among possible
fixings by making some bases more informationally
efficient than others.
The agent's bounded computation does the rest: once
the degeneracy is broken, the survival imperative~(B4)
selects the pointer-aligned frame as optimal.
This is the precise sense in which decoherence ``catalyzes''
the spontaneous symmetry breaking of the ego.
\end{remark}

% ============================================================
\section{The Cost of Ego}
\label{II-sec:cost}

The ego resolves the computational crisis of
Section~\ref{II-sec:ceiling}, but it introduces a new
vulnerability. A fixed reference frame is a \emph{static}
gauge choice in a \emph{dynamic} environment.
If the environment changes, the ego becomes progressively
maladaptive.

\paragraph{Drift layer.}
Environmental change can occur at multiple levels:
parameter drift ($\lambda_\alpha(t)$, $\gamma_\alpha(t)$),
spectral-density deformation ($J(\omega, t)$), or
full process-distribution shift ($P_t(X)$).
For analytical tractability, we model drift at the
\emph{spectral-density parameter level} throughout this
section; the results generalise monotonically to deeper
levels (faster drift $\Rightarrow$ shorter
$t_{\mathrm{del}}$).

% ------------------------------------------------------------
\subsection{The Rigidity Trap}
\label{II-subsec:rigidity}

\begin{proposition}[Frame Rigidity under Drift]
\label{II-prop:rigidity}
Let the environment undergo slow drift: the spectral density
parameters change as
$\lambda_\alpha(t) = \lambda_\alpha^{(0)}
+ \varepsilon\,f_\alpha(t)$
for $\alpha \in \{z, x\}$, with drift rate
$\varepsilon > 0$.
The optimal reference frame $\mathcal{F}^*(t)$ (the
instantaneous minimizer of survival distortion)
rotates continuously in the gauge group~$G$.

If the agent's reference frame $\mathcal{F}$ is held fixed
(no recalibration), the mismatch between $\mathcal{F}$
and $\mathcal{F}^*(t)$ grows as
\begin{equation}
\label{II-eq:mismatch}
\delta(t)
:= d_G\bigl(\mathcal{F},\, \mathcal{F}^*(t)\bigr)
\sim \varepsilon \int_0^t \bigl|\dot{f}(s)\bigr|\,ds,
\end{equation}
where $d_G$ is the geodesic distance in the gauge group.
\end{proposition}

\begin{proof}
The instantaneous optimal frame $\mathcal{F}^*(t)$ is a
continuous function of the spectral density parameters
$\{\lambda_\alpha(t), \gamma_\alpha(t)\}$.
Under the drift $\lambda_\alpha(t)
= \lambda_\alpha^{(0)} + \varepsilon\,f_\alpha(t)$,
the chain rule gives
$\dot{\mathcal{F}}^*(t)
= \varepsilon\,\sum_\alpha
(\partial \mathcal{F}^*/\partial\lambda_\alpha)\,
\dot{f}_\alpha(t)$.
Integrating and taking the norm in $G$ gives
the bound~\eqref{II-eq:mismatch}.
\end{proof}

% ------------------------------------------------------------
\subsection{Stylized Drift Model}
\label{II-subsec:drift_model}

To quantify the collapse of a fixed frame, we introduce
a minimal drift model that makes the exponential divergence
and the logarithmic delusion time algebraically explicit.

\begin{definition}[Rotating optimal frame]
\label{II-def:drift}
Let the mismatch angle $\theta(t)$ between the agent's
fixed frame $\mathcal{F}$ and the instantaneous optimal
frame $\mathcal{F}^*(t)$ evolve as
\begin{equation}
\label{II-eq:theta}
\theta(t) = \theta_0\,e^{\Lambda t}
\qquad\text{(chaotic drift)},
\end{equation}
where $\theta_0 \in (0, \pi/4)$ is the initial misalignment
(so that $t_{\mathrm{del}} > 0$) and
$\Lambda > 0$ is the environmental Lyapunov exponent
(the rate at which nearby environmental trajectories
diverge in spectral-density space).
Operationally, $\Lambda$ is determined by the drift rate
$\varepsilon$ and the adaptation timescale
$\tau_{\mathrm{adapt}}$ of the spectral-density
parameters via the scaling
\begin{equation}
\label{II-eq:Lambda_scaling}
\Lambda \;\sim\; \frac{\varepsilon}
  {\tau_{\mathrm{adapt}}}\,;
\end{equation}
cf.~\eqref{II-eq:mismatch}.
For slow linear drift ($\theta(t) = \varepsilon\,t$,
$\Lambda \to 0$), the crossover time is
$t_{\mathrm{del}} = \pi/(4\varepsilon)$
(Remark~\ref{II-rem:linear_drift}).

The visible and hidden survival components decompose
geometrically:
\begin{equation}
\label{II-eq:vis_hid_theta}
\mathcal{S}_{\mathrm{vis}}(t)
= \mathcal{S}_{\mathrm{tot}}\,\cos^2\theta(t),
\qquad
\mathcal{S}_{\mathrm{hid}}(t)
= \mathcal{S}_{\mathrm{tot}}\,\sin^2\theta(t),
\end{equation}
where $\mathcal{S}_{\mathrm{tot}}$ is the full survival
functional (invariant under frame rotation).
\end{definition}

% ------------------------------------------------------------
\subsection{The Prediction Error Divergence}
\label{II-subsec:divergence}

\begin{proposition}[Divergence of Hidden Survival]
\label{II-prop:divergence}
Under the drift model~\eqref{II-eq:theta}--\eqref{II-eq:vis_hid_theta},
the hidden survival component grows as
\begin{equation}
\label{II-eq:divergence}
\bigl|\mathcal{S}_{\mathrm{hid}}(t)\bigr|
= |\mathcal{S}_{\mathrm{tot}}|\,\sin^2\!\bigl(\theta_0\,
  e^{\Lambda t}\bigr).
\end{equation}
For small angles ($\theta_0 e^{\Lambda t} \ll 1$):
$|\mathcal{S}_{\mathrm{hid}}| \approx
|\mathcal{S}_{\mathrm{tot}}|\,\theta_0^2\,e^{2\Lambda t}$
(exponential growth).
\end{proposition}

\begin{proof}
Direct substitution of~\eqref{II-eq:theta}
into~\eqref{II-eq:vis_hid_theta}.
The small-angle expansion
$\sin^2\theta \approx \theta^2$ gives the exponential
form.
\end{proof}

% ------------------------------------------------------------
\subsection{The Delusion Trap}
\label{II-subsec:delusion}

\begin{theorem}[The Delusion Trap]
\label{II-thm:delusion}
Under~\textup{(B1)--(B5)} with the drift
model~\eqref{II-eq:theta} and initial misalignment
$\theta_0 \in (0,\,\pi/4)$, an agent with a fixed
reference frame $\mathcal{F}$ reaches a critical
\textbf{delusion time}
\begin{equation}
\label{II-eq:t_delusion}
t_{\mathrm{del}}
= \frac{1}{\Lambda}\,
\ln\!\left(\frac{\pi/4}{\theta_0}\right),
\end{equation}
beyond which:
\begin{enumerate}
\item[\textup{(a)}]
  $|\mathcal{S}_{\mathrm{hid}}(t)|
  > |\mathcal{S}_{\mathrm{vis}}(t)|$:
  the invisible component dominates the survival functional.
\item[\textup{(b)}]
  The agent's update direction becomes
  \emph{anti-correlated} with the true optimal direction:
  the inner product of survival gradients
  (with respect to the agent's control variables
  $u \in V_{\mathrm{fg}}$) satisfies
  \begin{equation}
  \label{II-eq:anti_correlation}
  \bigl\langle \nabla_u\mathcal{S}_{\mathrm{vis}},\;
    \nabla_u\mathcal{S}_{\mathrm{full}}
  \bigr\rangle < 0.
  \end{equation}
  Updating $u$ to maximise $\mathcal{S}_{\mathrm{vis}}$
  actually \emph{decreases}
  $\mathcal{S}_{\mathrm{full}}$.
\item[\textup{(c)}]
  The agent cannot detect this failure from within its
  own reference frame, because all four bias terms
  ($\mathcal{B}_{\mathrm{select}}$,
  $\mathcal{B}_{\mathrm{frame}}$,
  $\mathcal{B}_{\mathrm{center}}$,
  $\mathcal{B}_{\mathrm{inc}}$)
  operate within $V_{\mathrm{fg}}$ and cannot register
  changes in $V_{\mathrm{bg}}$.
\end{enumerate}
\end{theorem}

\begin{proof}
Part~(a):
The crossover $|\mathcal{S}_{\mathrm{hid}}|
= |\mathcal{S}_{\mathrm{vis}}|$ occurs when
$\sin^2\theta = \cos^2\theta$, i.e.,
$\theta(t_{\mathrm{del}}) = \pi/4$.
Substituting~\eqref{II-eq:theta}:
$\theta_0\,e^{\Lambda\,t_{\mathrm{del}}} = \pi/4$,
which gives~\eqref{II-eq:t_delusion}.
The logarithmic dependence on $1/\theta_0$ means that
even a very small initial misalignment ($\theta_0 \sim 10^{-3}$)
delays the trap only by $\sim 7/\Lambda$---a modest
multiple of the environmental Lyapunov time.

Part~(b):
Beyond $t_{\mathrm{del}}$, the gradient
$\nabla\mathcal{S}_{\mathrm{full}}$ points primarily
into $V_{\mathrm{bg}}$ (the hidden sector now carrying
$> 50\%$ of survival weight), while
$\nabla\mathcal{S}_{\mathrm{vis}}$ remains confined to
$V_{\mathrm{fg}}$.
Since the foreground and background subspaces are
orthogonal by construction, the angle between the two
gradients exceeds $\pi/2$, yielding anti-correlation.

Part~(c):
The bias terms
$\mathcal{B}_{\mathrm{select}}$ through
$\mathcal{B}_{\mathrm{inc}}$
(Proposition~\ref{II-prop:bias}) are defined
\emph{within} $V_{\mathrm{fg}}$.
The agent's performance metric
$\mathcal{S}_{\mathrm{vis}} =
\mathcal{S}_{\mathrm{tot}}\cos^2\theta$
decreases only at second order in $\theta$,
so it remains positive and shows no anomaly until
$\theta$ is already $O(1)$.
The growing signal in $V_{\mathrm{bg}}$ maps to the null
space of $\Pi_{\mathcal{F}}$ and is strictly invisible.
\end{proof}

\begin{remark}[Linear drift limit]
\label{II-rem:linear_drift}
For slow linear drift ($\theta(t) = \varepsilon\,t$,
$\Lambda \to 0$), the crossover occurs at
$t_{\mathrm{del}} = \pi/(4\varepsilon)$.
With $\varepsilon = 0.01\,\omega_0$,
$t_{\mathrm{del}} \approx 79\,\omega_0^{-1}$---long
enough for the agent to accumulate a false sense of
security, yet short on environmental timescales.
\end{remark}

\begin{remark}[Why dithering does not help]
\label{II-rem:dithering}
One might ask whether the agent could escape the delusion
trap by randomly ``probing'' the background subspace
$V_{\mathrm{bg}}$---temporarily rotating its frame to
sample hidden components.
This fails for two reasons.
First, each probe costs
$\sim h_\mu \cdot D$ bits of
computation (the Symmetry Tax, Corollary~\ref{II-cor:symmetry_tax}),
directly competing with the budget allocated to foreground
processing.
Second---and more fundamentally---the agent has no
\emph{gradient signal} to indicate \emph{when} or
\emph{where} to probe.
As long as $|\mathcal{S}_{\mathrm{hid}}|
< |\mathcal{S}_{\mathrm{vis}}|$ (pre-delusion), the
in-frame performance metric $\mathcal{S}_{\mathrm{vis}}$
shows no anomaly.
The exponential divergence~\eqref{II-eq:divergence} is
invisible until it dominates---at which point it is too late.
Systematic correction requires monitoring the \emph{rate of
change} of prediction error, which is a second-order
operation: the subject of Paper~III.
\end{remark}

\begin{remark}[The ego as medicine and poison]
\label{II-rem:medicine_poison}
The ego cures computational paralysis
(Theorem~\ref{II-thm:comp_ceiling}) but creates the delusion
trap (Theorem~\ref{II-thm:delusion}).
It is simultaneously the \emph{medicine} for Paper~I's
crisis and the \emph{poison} that generates Paper~III's
crisis.
This duality is a structural consequence of the irreversible
logic chain: each resolution creates the conditions for the
next crisis.
\end{remark}

% ------------------------------------------------------------
\subsection{The Origin of Paper~III}
\label{II-subsec:paper3}

To escape the delusion trap, the agent needs a mechanism
to monitor the quality of its own reference frame---to
``observe its own observation.''
This requires a \emph{second-order control loop}: a
meta-controller that adjusts the gauge fixing $\sigma$ in
response to accumulated prediction errors.

The key difficulty is that the prediction errors the agent
can measure ($\mathcal{S}_{\mathrm{vis}} -
\mathcal{S}_{\mathrm{vis}}^{\mathrm{predicted}}$) all
lie within $V_{\mathrm{fg}}$.
To detect frame drift, the agent must compare these
in-frame errors to an estimate of out-of-frame
contributions---a self-referential operation that requires
\emph{Fisher information about the agent's own parameters}.

This is the subject of Paper~III: the Fisher information
geometry of self-referential calibration, and the
thermodynamic cost of the loop that closes the chain
\emph{Chaos $\to$ Time $\to$ Self $\to$ Calibration}.

% ============================================================
\section{Numerical Demonstration}
\label{II-sec:numerical}

The preceding sections establish analytic bounds and a
worked example with a qubit in a two-channel bath.
We now provide a numerical illustration showing that the
core symmetry-breaking signature---attention entropy collapse
under budget constraints---and the resulting selection
advantage are reproduced in a minimal multi-dimensional
system.
Full code and parameters are provided for reproducibility.

% ------------------------------------------------------------
\subsection{Model}
\label{II-subsec:demo_model}

\paragraph{Environment.}
A $D$-dimensional linear prediction task with sparse
rotating support:
$y(t) = \mathbf{w}^*(t)^\top \mathbf{x}(t) + \xi(t)$,
$\mathbf{x}(t) \sim \mathcal{N}(\mathbf{0}, \mathbf{I}_D)$,
$\xi \sim \mathcal{N}(0, \sigma^2)$.
Only $m \ll D$ dimensions carry nonzero weight at any time;
the active support rotates every $\tau_{\mathrm{switch}}$
steps, modelling environmental drift.

\paragraph{Hard budget constraint.}
Per step, the agent may update only $k$ coordinates of its
weight vector (a hard processing budget), mirroring the
bounded computation assumption~(B2).

\paragraph{Agents.}
\begin{itemize}
\item \textbf{Budgeted selector (SSB)}: selects the top-$k$
  dimensions by importance score---an exponential moving
  average of the signed per-coordinate gradient.  Signed
  accumulation ensures that noise dimensions (zero expected
  signal) cancel over time while signal dimensions persist,
  enabling reliable discrimination without access to the true
  support.
\item \textbf{Random-$k$ baseline}: selects $k$ dimensions
  uniformly at random each step.  This provides a
  budget-fair comparison: identical mechanism, no symmetry
  breaking.
\end{itemize}

\noindent
The choice of \emph{signed} gradient EMA (rather than
squared-gradient magnitude) is structurally motivated:
for noise dimensions $\mathbb{E}[r\,x_i] = 0$, so the
signed accumulation cancels over time; for signal
dimensions $\mathbb{E}[r\,x_i] \neq 0$, so a consistent
directional bias persists.  The signed EMA thus acts as a
\emph{directional coherence filter} that discriminates
signal from noise without access to the true support---a
minimal realisation of the ``reference-frame bias'' that
emerges from symmetry breaking.

\paragraph{Parameters.}
\begin{center}
\small
\begin{tabular}{@{}lcl@{}}
\toprule
\textbf{Quantity} & \textbf{Value} & \textbf{Role} \\
\midrule
$D$ & 64 & ambient dimension \\
$m$ & 8  & signal dimensions (sparse support) \\
$T$ & $10{,}000$ & horizon per trial \\
Seeds & 10 & independent replications \\
$\sigma$ & 0.3 & observation noise std \\
$\eta$ & 0.02 & SGD learning rate \\
$\lambda$ & 0.995 & weight decay per step \\
$k$ & 2, 4, 6, 8, 10, 12, 16, 20, 24, 32, 48, 64
  & budget grid \\
$\tau_{\mathrm{switch}}$ & $\{500, 1000, 2000\}$
  & support rotation period \\
\bottomrule
\end{tabular}
\end{center}

\paragraph{Attention entropy.}
Let $n_i$ be the number of updates coordinate $i$ receives
in a measurement window of the last $1{,}000$ steps.
The normalised update frequency
$p_i = n_i / \sum_j n_j$ defines the attention entropy:
\begin{equation}
\label{II-eq:H_attn}
H_{\mathrm{attn}} = -\sum_{i=1}^{D} p_i \ln p_i.
\end{equation}
Under symmetric processing (no SSB), $p_i = 1/D$ and
$H_{\mathrm{attn}} = \ln D$.  Under budget-constrained
selection, $H_{\mathrm{attn}}$ collapses away from $\ln D$,
serving as an order parameter for symmetry breaking.

\paragraph{Oracle metric.}
Neither agent has access to $\mathbf{w}^*(t)$.
Performance is evaluated externally using the
weight-space mean-squared error
$\mathrm{MSE} = \|\hat{\mathbf{w}} - \mathbf{w}^*\|^2$,
averaged over post-burn-in steps.

% ------------------------------------------------------------
\subsection{Results}
\label{II-subsec:demo_results}

Figure~\ref{II-fig:kstar_scaling} shows the two key signatures.

\paragraph{Result 1: Attention entropy collapse
(Figure~\ref{II-fig:kstar_scaling}a).}
Under fixed support (no rotation), the attention entropy
$H_{\mathrm{attn}}$ exhibits a sharp collapse away from
$\ln D = \ln 64 \approx 4.16$ and increases monotonically
with $k$, consistent with a budget-induced concentration
of update mass onto signal-carrying dimensions.
For budgets near and below the signal scale ($k \leq m$),
$H_{\mathrm{attn}}$ remains $O(\ln m)$, consistent with
confinement to the signal subspace.
We use the collapse of $H_{\mathrm{attn}}$ away from
$\ln D$ as the order parameter of symmetry breaking;
a strict plateau at $\ln m$ is not expected under the
present re-selection dynamics and finite-window estimator.

\paragraph{Result 2: Selection advantage
(Figure~\ref{II-fig:kstar_scaling}b).}
Under rotating support, the mean-squared error gap
$\Delta\mathrm{MSE} = \mathrm{MSE}_{\mathrm{rnd}}
- \mathrm{MSE}_{\mathrm{sel}}$ is positive for
$k \lesssim 3m$ and peaks at tight budgets ($k = 2$)
where the selection advantage is strongest.
For $k \gg m$ the gap turns slightly negative
(the selector's commitment to stale dimensions costs
more than the random baseline's diversification),
before returning to zero at $k = D$.
The three $\tau_{\mathrm{switch}}$ curves are ordered:
slower drift (larger $\tau$) yields a larger peak gap,
with the ordering most visible at small $k$.

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]%
  {fig_paper2_kstar_scaling.pdf}
\caption{%
\textbf{Budget-induced symmetry breaking.}
$D = 64$, $m = 8$, $T = 10{,}000$, 10 seeds, 95\% CI bands.
\textbf{(a)}~Attention entropy $H_{\mathrm{attn}}$ vs
budget $k$ (fixed support).  The empirical curve (blue)
collapses from $\ln D \approx 4.16$ toward an
$O(\ln m)$ floor as budget tightens.
For $k \leq m$, $H_{\mathrm{attn}}$ remains below
$\ln m \approx 2.08$ (green dashed), consistent with
confinement to the signal subspace.
\textbf{(b)}~Selection advantage
$\Delta\mathrm{MSE} = \mathrm{MSE}_{\mathrm{rnd}}
- \mathrm{MSE}_{\mathrm{sel}}$ vs budget $k$ under
rotating support.  The gap is positive for $k \lesssim 3m$
(selection helps), turns slightly negative at large $k$
(commitment cost exceeds diversification), and returns
to zero at $k = D$.  Slower drift ($\tau = 2000$)
yields a larger peak advantage.}
\label{II-fig:kstar_scaling}
\end{figure}

% ------------------------------------------------------------
\subsection{Scope of This Demonstration}
\label{II-subsec:demo_scope}

These simulations illustrate the symmetry-breaking
phenomenon predicted by Theorem~\ref{II-thm:SSB} under
the stated model class; they do not constitute a proof
beyond this class.

\medskip
This demonstration \textbf{does} show:
\begin{enumerate}
\item Under hard budget constraints, attention entropy
  collapses sharply away from $\ln D$ and remains
  $O(\ln m)$ for $k \leq m$---the agent confines its
  updates to the signal subspace.
  This is the computational analogue of spontaneous
  symmetry breaking (Theorem~\ref{II-thm:SSB}).
\item A budgeted selector that exploits importance-weighted
  selection systematically outperforms a budget-fair
  random baseline, consistent with a survival advantage
  in the broken phase
  (cf.~Proposition~\ref{II-prop:speedup}).
\item The advantage scales with both budget tightness
  (smaller $k$) and environmental stability (larger
  $\tau_{\mathrm{switch}}$).
\end{enumerate}

\noindent
In summary, this demonstration validates the
\emph{existence} and \emph{measurability} of
budget-induced symmetry breaking in a minimal linear
setting; it does not claim universality across
architectures or environment classes.

\medskip
This demonstration does \textbf{not} show:
\begin{enumerate}
\item That $H_{\mathrm{attn}}$ reaches a strict plateau
  at $\ln m$ for all $k \leq m$.  Under the adaptive
  re-selection dynamics used here, the selector cycles
  within the signal subspace, producing
  $H_{\mathrm{attn}}$ values near but not locked to
  $\ln m$.  The relevant signature is the collapse
  \emph{away from} $\ln D$, not convergence to a
  specific lower bound.
\item That the specific form of the importance score
  (signed gradient EMA) is optimal.  It is one
  realisation of the selection mechanism.
\item That the results generalise to all environment
  classes.  The model uses Gaussian features, linear
  regression, and sparse rotating support.
\item That the delusion--correction cycle is addressed.
  This is the subject of Paper~III.
\end{enumerate}

\paragraph{Reproducibility.}
The complete simulation is a self-contained Python script
(\texttt{paper2\_kstar\_scaling\_demo.py}, ${\sim}\,540$
lines, requiring only NumPy and Matplotlib) with fixed
random seeds.  All figures in this section can be
reproduced by executing the script.  The following files
are included in the supplementary archive:
\begin{itemize}
\item \texttt{paper2\_kstar\_scaling\_demo.py} --- simulation script
\item \texttt{fig\_paper2\_kstar\_scaling.pdf} --- Figure~\ref{II-fig:kstar_scaling}
\item \texttt{kstar\_scaling\_data.csv} --- raw performance gap data
\end{itemize}

% ============================================================
\section{Discussion}
\label{II-sec:discussion}

% ------------------------------------------------------------
\subsection{Summary of Results}
\label{II-subsec:summary}

\begin{center}
\small
\setlength{\tabcolsep}{4pt}%
\begin{tabular}{@{}lp{6cm}c@{}}
\toprule
\textbf{Result} & \textbf{Statement} & \textbf{Sec.} \\
\midrule
Computational Ceiling
  & Symmetric processing cost exceeds
    $\mathcal{C}_{\mathrm{budget}}$ at
    $\tau_{\mathrm{par}}$
  & \ref{II-sec:ceiling} \\[3pt]
Rate-Distortion Bound
  & Optimal compression retains
    $k^* = \mathcal{C}_{\mathrm{budget}}/h_\mu$
    components
  & \ref{II-subsec:RD_bound} \\[3pt]
Necessity of SSB
  & Under bounded computation, survival requires gauge fixing
  & \ref{II-subsec:SSB} \\[3pt]
Four Bias Terms
  & Broken phase acquires $\mathcal{B}_{\mathrm{select}}$,
    $\mathcal{B}_{\mathrm{frame}}$,
    $\mathcal{B}_{\mathrm{center}}$,
    $\mathcal{B}_{\mathrm{inc}}$
  & \ref{II-subsec:bias} \\[3pt]
Survival Decomposition
  & $\mathcal{S} = \mathcal{S}_{\mathrm{vis}} +
    \mathcal{S}_{\mathrm{hid}}$
  & \ref{II-subsec:effective} \\[3pt]
Ego-Entropy Trade-off
  & $\gtrsim 1 - k^*/\dim Cl(V,q)$ of
    $I_{\mathrm{pred}}$ discarded (uniformity assumption)
  & \ref{II-subsec:tradeoff} \\[3pt]
Delusion Trap
  & Fixed frame diverges from optimal under environmental
    drift; agent cannot self-detect
  & \ref{II-subsec:delusion} \\[3pt]
Numerical demo
  & Budget-induced SSB and selection advantage
    (Fig.~\ref{II-fig:kstar_scaling})
  & \ref{II-sec:numerical} \\
\bottomrule
\end{tabular}
\end{center}

% ------------------------------------------------------------
\subsection{What This Paper Does and Does Not Show}
\label{II-subsec:claims}

This paper \textbf{does} show:
\begin{enumerate}
\item Under bounded computation~(B2) and non-trivial
  environment~(B3), symmetric processing of memory leads
  to computational paralysis (Theorem~\ref{II-thm:comp_ceiling}).
\item The survival-optimal response is spontaneous symmetry
  breaking of the internal reference frame
  (Theorem~\ref{II-thm:SSB}), governed by a rate-distortion
  bound (Theorem~\ref{II-thm:compression}).
\item The broken phase acquires four generic bias
  terms under~(B1)--(B5) (Proposition~\ref{II-prop:bias}).
\item Under environmental drift, a fixed frame leads to
  exponential divergence of prediction error---the
  Delusion Trap (Theorem~\ref{II-thm:delusion}).
\item A minimal computational demonstration reproduces
  the budget-induced symmetry-breaking signature (attention
  entropy collapse away from $\ln D$) and selection
  advantage over a budget-fair random baseline
  (Section~\ref{II-sec:numerical},
  Figure~\ref{II-fig:kstar_scaling}).
\end{enumerate}

\medskip
This paper does \textbf{not} show:
\begin{enumerate}
\item That the privileged basis is uniquely determined by
  computational constraints. The basis is constrained but
  not unique---different histories lead to different gauge
  fixings, as in a ferromagnet.
\item That symmetry breaking is sufficient for persistence.
  It is the survival-optimal strategy under bounded computation;
  sufficiency
  requires the self-referential calibration of Paper~III.
\item That the ``ego'' implies or requires consciousness,
  subjective experience, or phenomenal awareness.
  The term is used strictly in the control-theoretic sense.
\item That this framework constitutes a theory of
  consciousness. It is a theory of computational optimality
  under thermodynamic constraints.
\item That the four bias terms exhaust the phenomenology of
  self-reference. They are the minimal structural
  consequences of gauge fixing in a Clifford algebra.
\item That the rate-distortion bound is achievable by any
  specific physical implementation. It is an
  information-theoretic lower bound.
\item That the Delusion Trap is inescapable. Paper~III will
  show it can be mitigated by self-referential calibration.
\item That the framework constitutes or implies a
  philosophical or metaphysical claim about the nature
  of selfhood.
\item That this framework applies to all possible physical
  systems. It applies to systems
  satisfying~(B1)--(B5)---persistent agents with finite
  computation in non-trivial environments.
\item That the Clifford algebra is the only possible
  algebraic setting. It is the minimal setting inherited
  from Q-RAIF. Other algebras may yield analogous results.
\end{enumerate}

% ============================================================
% REFERENCES
% ============================================================

% ============================================================================
% PAPER III
% ============================================================================
\chapter{Fisher Information Geometry and the Thermodynamic Cost of Self-Referential Calibration}
\label{chap:paperIII}

\begin{center}
\textit{Paper III --- ``The Loop''}\\[0.5em]
Originally published: Zenodo, DOI: 10.5281/zenodo.18591771
\end{center}

\bigskip

\section*{Abstract}
Papers~I and~II of the T-DOME
series~\cite{Liu2026TDOME_I,Liu2026TDOME_II} established
that persistent agents must carry non-Markovian memory
(Paper~I) and must spontaneously break the gauge symmetry of
their internal Clifford algebra $Cl(V,q)$ to form a
compressed reference frame---the ``ego''
$\mathfrak{E} = (\mathcal{F}^*,\,V_{\mathrm{fg}}^*)$
(Paper~II).
Paper~II concluded with the \textbf{Delusion Trap}: under
environmental drift, a fixed reference frame decouples from
the optimal gauge on the logarithmic timescale
$t_{\mathrm{del}}
= \Lambda^{-1}\ln(\pi/4\theta_0)$,
and the agent cannot detect this failure from within its own
foreground subspace $V_{\mathrm{fg}}$.

In this final work we derive the theory of
\textbf{self-referential calibration}.
We show that while the agent cannot observe the background
subspace $V_{\mathrm{bg}}$ directly, it can measure the
\textbf{Fisher information} of its own prediction-residual
stream with respect to its frame parameters~$\sigma$.
We prove three main results:
\begin{enumerate}
\item \textbf{Drift Detectability}
  (Theorem~\ref{III-thm:detectability}):
  environmental drift generates a quadratically growing
  signal in the self-referential Fisher information
  $\mathcal{I}_F(\sigma)$, detectable before the
  Delusion Trap closes.
\item \textbf{Self-Referential Cram\'{e}r--Rao Bound}
  (Theorem~\ref{III-thm:SRCR}):
  the agent's drift-estimation error is bounded below by
  $1/(n_{\mathrm{eff}}\,\mathcal{I}_F + \mathcal{I}_{\mathrm{ego}})$,
  where $\mathcal{I}_{\mathrm{ego}}$ quantifies the
  rigidity of the ego prior.
\item \textbf{Thermodynamic Cost of the Loop}
  (Theorem~\ref{III-thm:loop_cost}):
  the minimum dissipation rate for self-referential
  calibration is
  $\dot{W}_{\mathrm{loop}}
  \geq k_BT\,\ln 2\,[h_\mu\,k^*
  + \mathcal{C}_{\mathrm{meta}}]
  + \mathcal{L}^2/\tau_{\mathrm{recalib}}^2$,
  where $\mathcal{L}$ is the thermodynamic length of the
  frame update and $\tau_{\mathrm{recalib}}$ is the
  recalibration time.
\end{enumerate}
The calibration loop satisfies a Lyapunov tracking bound
(Theorem~\ref{III-thm:loop_stability}),
keeping the mismatch within a neighbourhood whose size is
set by the ratio of environmental drift speed to adaptation
rate.
We identify this loop as the minimal physical realisation of
\emph{reflexivity}---estimating drift from residual
statistics and correcting the frame via Lyapunov-monitored
natural gradient descent.
Combining with Papers~I and~II, we state a
\textbf{Four-Part Structure Proposition}
(Proposition~\ref{III-prop:four_part}):
within the class of agents satisfying~(C1)--(C5),
a sufficient architecture for persistence under drift
requires
(1)~an external observable geometry,
(2)~an internal control algebra,
(3)~a self-monitoring Lyapunov function, and
(4)~biased non-Markovian memory.


% ============================================================
\section{Introduction}
\label{III-sec:intro}

% ------------------------------------------------------------
\subsection{Context: The Delusion Trap}
\label{III-subsec:delusion_context}

Paper~II of this series~\cite{Liu2026TDOME_II} established
that persistent agents under bounded computation must
spontaneously break the gauge symmetry of their internal
algebra $Cl(V,q)$, selecting a privileged reference frame
$\mathcal{F}^*$ that compresses the memory kernel into a
tractable $k^*$-dimensional foreground subspace
$V_{\mathrm{fg}}$.
This gauge fixing---the ``ego''
$\mathfrak{E} := (\mathcal{F}^*,\,V_{\mathrm{fg}}^*)$---is
not an additional hypothesis but the survival-optimal strategy
under bounded rationality.

However, Paper~II's final theorem revealed a fatal
consequence.
Under environmental drift (spectral-density parameters
changing at rate~$\varepsilon$), the mismatch angle between
the agent's fixed frame and the instantaneous optimal frame
grows as
$\theta(t) = \theta_0\,e^{\Lambda t}$
(Paper~II, Definition~27),
where $\Lambda \sim \varepsilon/\tau_{\mathrm{adapt}}$
is the environmental Lyapunov exponent.
Beyond the \emph{delusion time}
\begin{equation}
\label{III-eq:t_del_recall}
t_{\mathrm{del}}
= \frac{1}{\Lambda}\,
\ln\!\left(\frac{\pi/4}{\theta_0}\right),
\end{equation}
three catastrophic failures occur simultaneously
(Paper~II, Theorem~29):
\begin{enumerate}
\item The hidden survival component dominates:
  $|\mathcal{S}_{\mathrm{hid}}|
  > |\mathcal{S}_{\mathrm{vis}}|$.
\item The agent's update direction anti-correlates with
  the true survival gradient:
  $\langle \nabla_u\mathcal{S}_{\mathrm{vis}},\,
  \nabla_u\mathcal{S}_{\mathrm{full}}\rangle
  < 0$.
\item All four bias terms
  ($\mathcal{B}_{\mathrm{select}}$,
  $\mathcal{B}_{\mathrm{frame}}$,
  $\mathcal{B}_{\mathrm{center}}$,
  $\mathcal{B}_{\mathrm{inc}}$)
  operate within $V_{\mathrm{fg}}$ and cannot register
  changes in the background $V_{\mathrm{bg}}$.
\end{enumerate}

Paper~II further showed
(Remark~31)
that ``dithering''---randomly probing the background
subspace---fails because the agent has no gradient signal to
indicate \emph{when} or \emph{where} to probe.
The exponential divergence in $V_{\mathrm{bg}}$ is invisible
until it dominates, at which point it is too late.

\emph{The present paper provides the escape.}

% ------------------------------------------------------------
\subsection{Position within Papers~I--III}
\label{III-subsec:sequence}

This paper is the third and final of the T-DOME framework,
closing the three-paper sequence.

\begin{center}
\small
\setlength{\tabcolsep}{4pt}%
\begin{tabular}{@{}lp{3.5cm}p{4.2cm}c@{}}
\toprule
\textbf{Framework} & \textbf{Question} & \textbf{Result}
  & \textbf{Status} \\
\midrule
HAFF~\cite{Liu2026HAFF_A,Liu2026HAFF_B}
  & How does geometry emerge?
  & Algebra $\to$ Geometry
  & Complete \\[3pt]
Q-RAIF~\cite{Liu2026QRAIF_A,Liu2026QRAIF_B}
  & What algebra must an observer have?
  & $Cl(V,q) \hookrightarrow Cl(1,3)$
  & Complete \\[3pt]
T-DOME~I~\cite{Liu2026TDOME_I}
  & Why must agents carry memory?
  & Markovian ceiling; memory as necessity
  & Complete \\[3pt]
T-DOME~II~\cite{Liu2026TDOME_II}
  & Why must agents break symmetry?
  & Reference-frame selection under bounded computation
  & Complete \\[3pt]
\textbf{T-DOME~III} (this work)
  & How does self-calibration arise?
  & Fisher self-referential bound;
    thermodynamic cost of reflexivity
  & \textbf{This paper} \\
\bottomrule
\end{tabular}
\end{center}

The three T-DOME papers form an irreversible logical chain:
\begin{enumerate}
\item \textbf{Paper~I:} Without memory, a system
  is trapped in the Markovian present.
  Memory breaks this trap but floods the system with
  unbounded historical data.
\item \textbf{Paper~II:} Unbounded memory under
  finite computational resources causes processing collapse.
  Spontaneous symmetry breaking resolves the overload but
  introduces systematic bias.
\item \textbf{Paper~III (this work):} Uncorrected
  bias diverges from a changing environment.
  A self-referential calibration loop---monitoring the
  Fisher information of one's own prediction stream---resolves
  the bias but requires a second-order control structure and
  an irreducible thermodynamic cost.
\end{enumerate}

Each resolution creates the precondition for the next
crisis: memory enables overload, compression enables bias,
and bias demands calibration.
Only the complete closure
\emph{Paper~I $+$ Paper~II $+$ Paper~III}
allows a system to persist under the Second Law in a
drifting environment.

% ------------------------------------------------------------
\subsection{The Information-Geometric Insight}
\label{III-subsec:insight}

The key observation that resolves the Delusion Trap is
subtle:
\emph{while the agent cannot observe $V_{\mathrm{bg}}$
directly, it can observe the statistical properties of its
own prediction residuals in $V_{\mathrm{fg}}$.}

The prediction residual
$e(t) := \mathcal{S}_{\mathrm{vis}}(t)
- \mathcal{S}_{\mathrm{vis}}^{(\mathrm{pred})}(t)$
lies in $V_{\mathrm{fg}}$ by construction.
Its \emph{value} carries no information about the background.
But its \emph{distribution}---the probability law
$p(e\,|\,\sigma)$, parametrised by the gauge-fixing
parameter~$\sigma$---does depend on~$\sigma$, because the
projection $\Pi_{\mathcal{F}}(\sigma)$ determines which
environmental correlations are captured and which are
discarded.

When the frame $\sigma$ drifts away from the optimal
$\sigma^*$, the residual distribution shifts.
The \emph{Fisher information metric}
\begin{equation}
\label{III-eq:fisher_preview}
g_{ij}(\sigma)
= \mathbb{E}_\sigma\!\left[
  \frac{\partial \log p(e\,|\,\sigma)}
       {\partial \sigma^i}\,
  \frac{\partial \log p(e\,|\,\sigma)}
       {\partial \sigma^j}
\right]
\end{equation}
measures the sensitivity of this distribution to changes
in~$\sigma$.
A spike in $g_{ij}$---a ``stress'' in the agent's
internal geometry---is the signal that the reference frame
is becoming stale.

This is the mathematical realisation of the
``second-order operation'' demanded by
Paper~II, Section~7.5: the agent does not need to see the
truth (the full $Cl(V,q)$), but only the \emph{rate of
change of its own prediction error} as a function of its
frame parameters.
Fisher information is precisely this quantity.

% ------------------------------------------------------------
\subsection{Relation to Architectural Incompleteness}
\label{III-subsec:haff_g}

The architectural incompleteness
result~\cite{Liu2026HAFF_G} established
\emph{architectural incompleteness}: the observable-algebra
framework cannot self-ground.
Paper~II provided a partial operational response (the ego as
gauge fixing under bounded computation).
The present paper provides the final operational response:
the self-referential calibration loop cannot \emph{eliminate}
architectural incompleteness, but it can \emph{track}
the consequences of incompleteness in real time.
The Lyapunov function $V(\sigma)$ monitors the distance
between the agent's frame and the optimal frame without
requiring access to the ``complete'' description---it
operates entirely within the agent's own predictive
statistics.

% ------------------------------------------------------------
\subsection{Scope and Disclaimers}
\label{III-subsec:scope}

\begin{enumerate}
\item \emph{Reflexivity} refers throughout to
  second-order control: the ability of a system to
  monitor and adjust its own monitoring process.
  It carries \emph{no} implication of phenomenal
  consciousness, subjective experience, or qualia.
\item The self-referential calibration loop does not
  \emph{eliminate} the ego's bias; it tracks and
  compensates for drift in the bias.
  The four bias terms of Paper~II persist in the
  calibrated phase.
\item The thermodynamic cost bounds are
  information-theoretic lower bounds, not claims about
  specific physical implementations.
\item The framework applies to systems
  satisfying~(C1)--(C5) (Section~\ref{III-subsec:standing_C}).
  It is not a universal theory of agency.
\end{enumerate}

\paragraph{Related work.}
The Fisher information metric on statistical manifolds was
introduced by Rao~\cite{Rao1945} and shown to be unique
by \v{C}encov~\cite{Cencov1982}.
The natural gradient and information geometry were developed
by Amari~\cite{Amari1998,AmariNagaoka2000}.
Thermodynamic length and optimal finite-time transformations
were established by
Crooks~\cite{Crooks2007} and
Sivak--Crooks~\cite{SivakCrooks2012}.
The connection between Fisher information and entropy
production was formalised by Ito~\cite{Ito2018} and
Barato--Seifert~\cite{BaratoSeifert2015}.
Second-order cybernetics originates with
Ashby~\cite{Ashby1956} and
von Foerster~\cite{vonFoerster2003}.
Adaptive control and self-tuning regulators are treated
in~\cite{AstromWittenmark1995}.
The Bayesian Cram\'{e}r--Rao bound (van Trees inequality)
is from~\cite{vanTrees1968}.

\paragraph{Summary of contributions.}
This paper establishes three main results:
\begin{enumerate}
\item \textbf{Drift Detectability}
  (Theorem~\ref{III-thm:detectability}):
  the self-referential Fisher information of the
  prediction-residual stream grows quadratically with
  accumulated drift, providing a detectable signal
  before the Delusion Trap closes.
\item \textbf{Self-Referential Cram\'{e}r--Rao Bound}
  (Theorem~\ref{III-thm:SRCR}):
  drift-estimation precision is bounded by the sum of
  data Fisher information and ego rigidity.
\item \textbf{Thermodynamic Cost}
  (Theorem~\ref{III-thm:loop_cost}):
  the self-calibration loop requires a minimum
  dissipation rate with three distinct components
  (sensing, computing, actuating).
\end{enumerate}

% ============================================================
\section{Mathematical Preliminaries}
\label{III-sec:prelim}

% ------------------------------------------------------------
\subsection{Inherited Framework from Papers~I and~II}
\label{III-subsec:inherited}

We briefly recall the key objects; the reader is referred to
Papers~I and~II for full definitions and proofs.

\paragraph{From Paper~I~\cite{Liu2026TDOME_I}.}
\begin{itemize}
\item \textbf{Survival functional.}
  $\mathcal{S}[\Lambda,\tau]
  := \Delta F - W[0,\tau]$~(Paper~I,
  Eq.~(9)).
\item \textbf{Markovian Ceiling.}
  $\mathcal{S}[\Lambda^{\mathrm{M}},\tau] \leq 0$ for all
  $\tau \geq 0$.
\item \textbf{Memory kernel.}
  $\mathcal{K}(t,s)$: the non-Markovian superoperator
  encoding system--environment correlations.
\item \textbf{Entropy rate.}
  $h_\mu := \lim_{T\to\infty}T^{-1}H(X_{0:T})$ (bits per
  unit time per algebraic component).
\item \textbf{Predictive information.}
  $I_{\mathrm{pred}}
  := I(\overleftarrow{X};\,\overrightarrow{X})$.
\end{itemize}

\paragraph{From Paper~II~\cite{Liu2026TDOME_II}.}
\begin{itemize}
\item \textbf{Internal algebra.}
  $\mathcal{O}_{\mathrm{int}} = Cl(V,q)$, $D = \dim Cl(V,q) = 2^n$,
  gauge group $G = \mathrm{Aut}(Cl(V,q))$.
\item \textbf{Gauge bundle.}
  $\pi: P \to M$, structure group $G$; a section
  $\sigma: M \to P$ is a reference frame.
\item \textbf{Ego.}
  $\mathfrak{E} := (\mathcal{F}^*,\,V_{\mathrm{fg}}^*)$
  with $k^* = \lfloor \mathcal{C}_{\mathrm{budget}}/
  h_\mu \rfloor$ foreground components.
\item \textbf{Projected kernel.}
  $\mathcal{K}_{\mathcal{F}}(t,s)
  = \Pi_{\mathcal{F}}\,\mathcal{K}(t,s)\,
  \Pi_{\mathcal{F}}$.
\item \textbf{Survival decomposition.}
  $\mathcal{S} = \mathcal{S}_{\mathrm{vis}}(\mathcal{F})
  + \mathcal{S}_{\mathrm{hid}}(\mathcal{F})$.
\item \textbf{Four bias terms.}
  $\mathcal{B}_{\mathrm{select}}$,
  $\mathcal{B}_{\mathrm{frame}}$,
  $\mathcal{B}_{\mathrm{center}}$,
  $\mathcal{B}_{\mathrm{inc}}$
  (Paper~II, Proposition~18, Table~2).
\item \textbf{Delusion Trap.}
  $t_{\mathrm{del}}
  = \Lambda^{-1}\ln(\pi/4\theta_0)$
  (Paper~II, Theorem~29).
\item \textbf{Information-objects convention.}
  $I(\mathcal{K}_{\mathcal{F}};\,\mathcal{K})
  \equiv I(\hat{X};\,X)$ on induced record processes
  (Paper~II, Remark~15).
\end{itemize}

% ------------------------------------------------------------
\subsection{Fisher Information Metric}
\label{III-subsec:fisher}

\begin{definition}[Fisher information matrix]
\label{III-def:fisher}
Let $\{p(x\,|\,\theta) : \theta \in \Theta
\subset \mathbb{R}^d\}$ be a parametric family of
probability densities satisfying standard regularity
conditions (interchange of differentiation and integration).
The \emph{Fisher information matrix} is
\begin{equation}
\label{III-eq:fisher_def}
g_{ij}(\theta)
:= \mathbb{E}_\theta\!\left[
  \frac{\partial \log p(x\,|\,\theta)}
       {\partial \theta^i}\,
  \frac{\partial \log p(x\,|\,\theta)}
       {\partial \theta^j}
\right]
= -\mathbb{E}_\theta\!\left[
  \frac{\partial^2 \log p(x\,|\,\theta)}
       {\partial \theta^i\,\partial \theta^j}
\right].
\end{equation}
The pair $(\Theta,\,g)$ is a Riemannian manifold called the
\emph{statistical manifold}.
\end{definition}

\begin{remark}[Uniqueness]
\label{III-rem:cencov}
By \v{C}encov's theorem~\cite{Cencov1982}, the Fisher--Rao
metric $g^{\mathrm{FR}}$ is, up to a positive scalar
multiple, the unique Riemannian metric on the space of
probability distributions that is invariant under all
Markov morphisms (sufficient-statistic embeddings).
This uniqueness guarantees that the Fisher metric is the
\emph{canonical} choice for measuring drift on the
statistical manifold of the agent's predictive model---it is
not a design choice but a mathematical necessity.
\end{remark}

\begin{proposition}[Cram\'{e}r--Rao bound]
\label{III-prop:CR}
For any unbiased estimator $\hat{\theta}$ of $\theta$ based
on $n$ independent observations:
\begin{equation}
\label{III-eq:CR}
\mathrm{Cov}(\hat{\theta})
\;\succeq\; \frac{1}{n}\,\bigl[g(\theta)\bigr]^{-1}
\end{equation}
in the L\"{o}wner order.
The scalar case reads
$\mathrm{Var}(\hat{\theta})
\geq 1/\bigl(n\,g(\theta)\bigr)$.
\end{proposition}

\begin{remark}[Effective independence]
\label{III-rem:effective_independence}
Throughout this paper, references to ``independent
observations'' in the context of continuous-time residual
streams should be read as \emph{effective independence}
after thinning by the environmental decorrelation
time~$\tau_E$, yielding an effective sample size
$n_{\mathrm{eff}} \approx T/\tau_E$.
In particular, the sample count $n$ in~\eqref{III-eq:CR}
becomes $n_{\mathrm{eff}}$ in the self-referential
setting of Section~\ref{III-subsec:SRCR}.
\end{remark}

\begin{remark}[Fisher metric and KL divergence]
\label{III-rem:fisher_KL}
The Fisher metric arises as the Hessian of the
Kullback--Leibler divergence~\cite{CoverThomas2006}:
\begin{equation}
\label{III-eq:fisher_KL}
D_{\mathrm{KL}}\bigl(p_\theta \,\|\, p_{\theta+d\theta}\bigr)
= \tfrac{1}{2}\,g_{ij}(\theta)\,d\theta^i\,d\theta^j
  + O\!\left(|d\theta|^3\right).
\end{equation}
This identifies the Fisher metric as the infinitesimal
measure of statistical distinguishability.
\end{remark}

% ------------------------------------------------------------
\subsection{Information Geometry}
\label{III-subsec:info_geom}

Following Amari~\cite{Amari1985,AmariNagaoka2000}, the
statistical manifold $(\Theta,\,g)$ carries additional
geometric structure beyond the Riemannian metric.

\paragraph{$\alpha$-connections.}
For each $\alpha \in [-1,\,1]$, Amari defines an affine
connection $\nabla^{(\alpha)}$ on $\Theta$.
The cases $\alpha = 1$ (exponential connection,
$\nabla^{(e)}$) and $\alpha = -1$ (mixture connection,
$\nabla^{(m)}$) are \emph{dual} with respect to $g$:
$\partial_k\,g(X,Y)
= g(\nabla_k^{(e)}X,\,Y)
+ g(X,\,\nabla_k^{(m)}Y)$.
For exponential families, $\nabla^{(e)}$ is flat in natural
parameters and $\nabla^{(m)}$ is flat in expectation
parameters---the \emph{dually flat structure}.
The case $\alpha = 0$ recovers the Levi-Civita connection of
the Fisher metric.

\paragraph{Natural gradient.}
Standard gradient descent in parameter space ignores the
curvature of the statistical manifold.
The \emph{natural gradient}~\cite{Amari1998}
\begin{equation}
\label{III-eq:natural_gradient}
\dot{\theta}
= -\eta\,g^{-1}(\theta)\,\nabla_\theta L(\theta),
\end{equation}
where $\eta > 0$ is the learning rate and $L(\theta)$ is a
loss function, provides the steepest descent direction in the
Fisher metric.
It is reparametrisation-invariant and Fisher-efficient
(achieves the Cram\'{e}r--Rao bound asymptotically).

\paragraph{Pythagorean theorem.}
In a dually flat space, the KL divergence satisfies
a generalised Pythagorean relation:
$D_{\mathrm{KL}}(p\,\|\,r)
= D_{\mathrm{KL}}(p\,\|\,q)
+ D_{\mathrm{KL}}(q\,\|\,r)$
when $q$ is the $m$-projection of $p$ onto a
submanifold containing $r$.
This decomposition will be applied to separate the
foreground-recoverable and background-irrecoverable
components of drift.

% ------------------------------------------------------------
\subsection{Thermodynamic Length}
\label{III-subsec:thermo_length}

\begin{definition}[Thermodynamic length]
\label{III-def:thermo_length}
Let $\lambda(t)$ for $t \in [0,\tau]$ be a path through
control parameter space, and let $\zeta_{ij}(\lambda)$ be the
\emph{friction tensor} (the time-integrated equilibrium
force--force correlation function at~$\lambda$).
The \emph{thermodynamic length} of the
path~\cite{Crooks2007} is
\begin{equation}
\label{III-eq:thermo_length}
\mathcal{L}
:= \int_0^\tau
\sqrt{\zeta_{ij}(\lambda)\,
  \dot{\lambda}^i\,\dot{\lambda}^j}\;dt.
\end{equation}
\end{definition}

\begin{proposition}[Sivak--Crooks bound]
\label{III-prop:sivak_crooks}
The excess (dissipated) work during a finite-time
transformation of duration $\tau$ satisfies~\cite{SivakCrooks2012}
\begin{equation}
\label{III-eq:sivak_crooks}
W_{\mathrm{ex}} \;\geq\; \frac{\mathcal{L}^2}{\tau}.
\end{equation}
The minimum is achieved by the geodesic of the friction
tensor $\zeta$.
In the linear-response regime, the friction tensor is
related to the Fisher metric of the equilibrium distribution
at $\lambda$ by
$\zeta_{ij}(\lambda)
\sim \tau_{\mathrm{relax}}\,g_{ij}^{\mathrm{Fisher}}(\lambda)$,
where $\tau_{\mathrm{relax}}$ is the relaxation time.
\end{proposition}

% ------------------------------------------------------------
\subsection{Second-Order Cybernetics}
\label{III-subsec:cybernetics}

Von Foerster~\cite{vonFoerster2003} distinguished two levels
of control:
\begin{itemize}
\item \textbf{First-order cybernetics}: feedback control of
  observed systems.
  The controller adjusts its actions based on the output of
  a sensor.
  Paper~II's ego is a first-order structure: it processes
  environmental data within a fixed frame.
\item \textbf{Second-order cybernetics}: feedback control of
  the \emph{observing} system itself.
  The controller adjusts the \emph{sensor}---or equivalently,
  the reference frame within which the sensor operates.
  This is what Paper~III provides.
\end{itemize}

Ashby's Law of Requisite Variety~\cite{Ashby1956} provides a
lower bound on the complexity of the meta-controller:
\begin{equation}
\label{III-eq:requisite_variety}
\dim\!\left(\text{meta-controller state space}\right)
\;\geq\; \dim\!\left(\text{environmental drift subspace}\right).
\end{equation}
The meta-observer must have at least as many adjustable
parameters as there are independent modes of environmental
drift.

In adaptive control
theory~\cite{AstromWittenmark1995}, the analogous result is
the \emph{persistent excitation} condition: parameter
estimates converge if and only if the input signal is
``rich enough'' to excite all modes of the system.
In our framework, persistent excitation corresponds to
$h_\mu > 0$---the environment must continue to generate
novelty for the self-calibration loop to function.

\begin{remark}[Operational content]
\label{III-rem:cybernetics_operational}
The second-order cybernetic structure in this paper is
\emph{not} a philosophical metaphor.
It has concrete operational content: the natural gradient
update~\eqref{III-eq:natural_gradient} is a specific algorithm
that takes as input the Fisher information of the residual
stream and produces as output an update to the frame
parameter~$\sigma$.
This algorithm can be implemented by any physical system
capable of accumulating second-moment statistics of its own
prediction errors over a window of length~$T \geq \tau_E$.
\end{remark}

% ------------------------------------------------------------
\subsection{Standing Assumptions}
\label{III-subsec:standing_C}

\begin{definition}[Standing Assumptions]
\label{III-def:assumptions_C}
Throughout this paper, the following conditions are assumed:
\begin{enumerate}
\item[\textup{(C1)}] \textbf{Inherited framework.}
  All assumptions (B1)--(B5) of
  Paper~II~\cite{Liu2026TDOME_II} remain in force.
  This transitively includes (A1)--(A5) of
  Paper~I~\cite{Liu2026TDOME_I}
  (open quantum system, thermal bath, well-defined free
  energy, finite Hilbert space, weak coupling) and the
  realizability embedding
  $\phi: Cl(V,q) \hookrightarrow Cl(1,3)$
  (Q-RAIF~\cite{Liu2026QRAIF_C}).
  We invoke this embedding strictly as a structural
  inheritance from the earlier papers; no new physical
  claims about $Cl(1,3)$ spacetime are introduced here.
  Additionally, the Delusion Trap is active:
  $\tau_{\mathrm{mem}} > \tau_{\mathrm{par}}$ and
  $\Lambda > 0$.
\item[\textup{(C2)}] \textbf{Environmental drift.}
  The instantaneous optimal frame
  $\mathcal{F}^*(t)$ rotates continuously in~$G$ at
  a rate characterised by the Lyapunov exponent
  $\Lambda > 0$~(Paper~II, Eq.~(37)).
\item[\textup{(C3)}] \textbf{Finite meta-observer budget.}
  The self-calibration loop has a computational budget
  $\mathcal{C}_{\mathrm{meta}} < \infty$ (bits per unit
  time), distinct from the ego's processing budget
  $\mathcal{C}_{\mathrm{budget}}$.
\item[\textup{(C4)}] \textbf{Regularity.}
  The agent's predictive family
  $\{p(e\,|\,\sigma)
  : \sigma \in G/H\}$ satisfies standard Fisher
  information regularity: full rank, finite Fisher matrix,
  and interchange of differentiation and integration.
  This extends (A5) from Paper~I.
\item[\textup{(C5)}] \textbf{Persistent excitation.}
  The environmental entropy rate satisfies
  $h_\mu > 0$ for all~$t$.
  The environment generates new information indefinitely;
  no ``frozen'' regimes occur.
\end{enumerate}
\end{definition}

% ============================================================
\section{The Drift Detection Problem}
\label{III-sec:detection}

% ------------------------------------------------------------
\subsection{Why First-Order Control Fails}
\label{III-subsec:first_order}

\begin{theorem}[First-Order Insufficiency]
\label{III-thm:first_order}
Under assumptions~\textup{(C1)--(C5)}, decompose the
prediction residual as
$e(t) = e_{\mathrm{drift}}(t) + \xi(t)$,
where $e_{\mathrm{drift}}$ is the deterministic
drift-induced component (second-order in $\theta$)
and $\xi(t)$ is the innovation noise, whose distribution
is symmetric on $V_{\mathrm{fg}}$ under~\textup{(C5)}.
No first-order controller---one that updates
$\dot{\sigma} = f(e(t))$ based on the instantaneous
residual without computing statistical properties of the
error stream---can uniformly reduce the drift.
Specifically: for any deterministic update function~$f$,
there exists a measurable event
$\mathcal{E} \subset V_{\mathrm{fg}}$ with
$\mathbb{P}(\mathcal{E})
\geq 1/2 - O(\mathrm{SNR})$
under the symmetric innovation distribution~$p(\xi)$,
such that for all $\xi \in \mathcal{E}$ the update
direction satisfies
$\langle \dot{\sigma},\,\dot{\sigma}^*\rangle \leq 0$,
where $\mathrm{SNR} \sim \theta^4/h_\mu$.
\end{theorem}

\begin{proof}
\emph{Probability space.}
The probability is taken over the innovation sequence
$\{\xi(t)\}_{t \geq 0}$ under the symmetric distribution
induced by the bath coupling~(C5).
All expectations below are over~$p(\xi)$.

\emph{Signal-to-noise separation.}
The prediction error $e(t)$ lies in $V_{\mathrm{fg}}$ by
construction.
Frame drift manifests as a rotation of the optimal frame
$\mathcal{F}^*(t)$ in the gauge group $G$, shifting
survival weight from $V_{\mathrm{fg}}$ to
$V_{\mathrm{bg}}$.
In $V_{\mathrm{fg}}$, the drift signal enters only at
second order in the mismatch angle~$\theta$
(Paper~II, proof of Theorem~29, part~(c)):
$\mathcal{S}_{\mathrm{vis}}
= \mathcal{S}_{\mathrm{tot}}\cos^2\theta$,
so
$e_{\mathrm{drift}}
\sim \theta^2\,\mathcal{S}_{\mathrm{tot}}$.
The noise $\xi(t)$ scales as $h_\mu^{1/2}$.
For $\theta \ll 1$, the single-sample signal-to-noise
ratio is
$\mathrm{SNR} \sim \theta^4/h_\mu \ll 1$.

\emph{Symmetry argument.}
Since $p(\xi)$ is symmetric on $V_{\mathrm{fg}}$,
for any deterministic $f$:
\begin{itemize}
\item If $f$ is odd (e.g., linear gain),
  $\mathbb{E}[f(e_{\mathrm{drift}} + \xi)]
  \approx f(e_{\mathrm{drift}})$,
  but the instantaneous sign of $f$ is determined by $\xi$
  with probability $\tfrac{1}{2} - O(\mathrm{SNR})$.
\item If $f$ is even,
  $f(e)$ carries no information about the
  \emph{sign} of $\dot{\sigma}^*$, so
  $\langle f(e),\,\dot{\sigma}^*\rangle$ vanishes in
  expectation.
\end{itemize}
In either case, the probability that the update direction
anti-correlates with the true drift direction is at
least~$1/2 - O(\mathrm{SNR})$.
Systematic drift detection requires accumulating
second-order statistics of the residual stream over
multiple samples---a second-order operation.
\end{proof}

% ------------------------------------------------------------
\subsection{The Agent's Statistical Manifold}
\label{III-subsec:stat_manifold}

The agent's prediction-residual stream
$\{e(t)\}_{t \geq 0}$ defines a stochastic process whose
distribution depends on the gauge-fixing
parameter~$\sigma$.
We model this dependence as a parametric family.

\begin{definition}[Predictive family]
\label{III-def:predictive_family}
The \emph{predictive family} of the agent is the set
\begin{equation}
\label{III-eq:predictive_family}
\mathcal{P}
:= \bigl\{p(e\,|\,\sigma)
  : \sigma \in \mathcal{M}_G\bigr\},
\end{equation}
where $\mathcal{M}_G := G/H$ is the space of gauge-fixing
orbits ($H$ is the stabiliser of the foreground subspace),
$e$ denotes the prediction-residual time series over a
window of length~$T$, and $p(e\,|\,\sigma)$ is the
likelihood of the observed residuals given the gauge
parameter~$\sigma$.
\end{definition}

The key insight is that $p(e\,|\,\sigma)$ depends
on~$\sigma$ even though $e(t) \in V_{\mathrm{fg}}$,
because the projection $\Pi_{\mathcal{F}}(\sigma)$
determines which environmental correlations are captured.
When $\sigma$ drifts from the optimal $\sigma^*$:
\begin{itemize}
\item The variance of the residuals increases (the
  discarded background components contribute unmodelled
  noise).
\item The temporal correlations of the residuals change
  (the projected kernel $\mathcal{K}_{\mathcal{F}}$ no
  longer captures the dominant environmental modes).
\item Higher-order statistics (kurtosis, spectral shape)
  shift systematically.
\end{itemize}
These distributional changes are invisible to the
raw error $e(t)$ but detectable by the Fisher metric
of $\mathcal{P}$.

% ------------------------------------------------------------
\subsection{Self-Referential Fisher Information}
\label{III-subsec:self_ref_fisher}

\begin{definition}[Self-referential Fisher information]
\label{III-def:self_ref_fisher}
The \emph{self-referential Fisher information} of the agent
at gauge parameter $\sigma$ is
\begin{equation}
\label{III-eq:self_ref_fisher}
\mathcal{I}_F(\sigma)
:= g_{ij}(\sigma)\,\delta\sigma^i\,\delta\sigma^j,
\end{equation}
where $g_{ij}(\sigma)$ is the Fisher information matrix of
the predictive family $\mathcal{P}$
(Definition~\ref{III-def:predictive_family}) evaluated at
$\sigma$, and $\delta\sigma$ is the frame perturbation
direction.
In the scalar case (single drift mode),
$\mathcal{I}_F(\sigma)
= \mathbb{E}_\sigma\!\bigl[
  (\partial_\sigma \log p(e\,|\,\sigma))^2\bigr]$.
\end{definition}

\begin{remark}[What the agent ``measures'']
\label{III-rem:what_measured}
Computing $\mathcal{I}_F(\sigma)$ does not require access
to $V_{\mathrm{bg}}$ or to the ``true'' environment.
It requires only: (i)~the agent's own prediction residuals
$\{e(t)\}$ (which lie in $V_{\mathrm{fg}}$), and
(ii)~the ability to evaluate the score function
$\partial_\sigma \log p(e\,|\,\sigma)$---the sensitivity of
its own predictive model to frame perturbations.
This is a computation entirely within the agent's internal
algebra, using only quantities already available from the
ego's processing pipeline.
\end{remark}

\begin{theorem}[Drift Detectability]
\label{III-thm:detectability}
Under assumptions~\textup{(C1)--(C5)}, suppose the frame
is freshly calibrated at time $t_0$
($\theta(t_0) = 0$).  Then the self-referential
Fisher information of the prediction-residual stream
satisfies, for small accumulated drift
($\Lambda\,\Delta t \ll 1$):
\begin{equation}
\label{III-eq:detectability}
\mathcal{I}_F(\sigma;\,\{e_t\}_{t_0}^{t_0+\Delta t})
\;\geq\; \kappa\,\Lambda^2\,(\Delta t)^2\,
\mathcal{I}_F^{\mathrm{env}},
\end{equation}
where:
\begin{itemize}
\item $\kappa := \inf_{\sigma \in \mathcal{N}}
  (\partial\theta / \partial\sigma)^2 > 0$ is the
  \emph{coupling efficiency}, where $\mathcal{N}$ is a
  compact neighbourhood of the calibrated point
  $\sigma^*$ on which the gauge chart is non-singular
  (existence guaranteed by~\textup{(C4)}; see proof);
\item $\Lambda$ is the environmental Lyapunov exponent
  \textup{(Paper~II, Eq.~(37))};
\item $\Delta t$ is the observation window;
\item $\mathcal{I}_F^{\mathrm{env}}
  := \mathbb{E}_{p(\cdot|\theta)}
  [(\partial_\theta \log p)^2]$ is the per-component
  environmental Fisher information, measuring the
  baseline sensitivity of the decoherence functions to the
  mismatch angle~$\theta$.
\end{itemize}

The self-referential Fisher information grows
\emph{quadratically} with accumulated drift time.
\end{theorem}

\begin{proof}
\emph{Step~1: chain rule.}
The frame parameter $\sigma$ determines the mismatch angle
$\theta = \theta(\sigma)$ via the gauge map
$G/H \to [0,\pi/2]$.
The chain rule for Fisher information gives
\begin{equation}
\label{III-eq:chain_rule_IF}
\mathcal{I}_F(\sigma)
\;=\; \left(\frac{\partial\theta}{\partial\sigma}\right)^2
\,\mathcal{I}_F(\theta),
\end{equation}
where $\mathcal{I}_F(\theta)
:= \mathbb{E}[(\partial_\theta \log p(e|\theta))^2]$
is the Fisher information of the residual stream with
respect to the mismatch angle.
By~(C4) (full-rank Fisher matrix), the Jacobian
$\partial\theta/\partial\sigma$ is bounded away from zero
on any compact neighbourhood $\mathcal{N}$ of the
calibrated point;
we define the coupling efficiency
$\kappa := \inf_{\sigma \in \mathcal{N}}
(\partial\theta/\partial\sigma)^2 > 0$.
This constant depends on the foreground
dimension~$k^*$, the Jacobian norms of the gauge-orbit
map $G/H \to [0,\pi/2]$, and the regularity constants
in~(C4); it is computable for any concrete model
(see Remark~\ref{III-rem:kappa_qubit} for the qubit case).

\emph{Step~2: small-drift expansion.}
Under freshly calibrated initial conditions
($\theta(t_0) = 0$),
the mismatch angle grows as
$\theta(\Delta t) = \Lambda\,\Delta t + O((\Delta t)^2)$
(Paper~II, Eq.~(35), linearised about $\theta = 0$).
The visible survival functional satisfies
$\mathcal{S}_{\mathrm{vis}}
= \mathcal{S}_{\mathrm{tot}}\cos^2\theta
\approx \mathcal{S}_{\mathrm{tot}}\,(1 - \theta^2)$
for $\theta \ll 1$.
Thus the residual distribution
$p(e\,|\,\theta)$ shifts from its baseline
$p(e\,|\,0)$ by a score proportional to $\theta^2$:
$\partial_\theta \log p \sim 2\theta
\cdot (\partial_\theta \log p)|_{\theta=\theta^*}$,
and consequently
\begin{equation}
\label{III-eq:IF_theta_lower}
\mathcal{I}_F(\theta)
\;\geq\; (\Lambda\,\Delta t)^2\,
\mathcal{I}_F^{\mathrm{env}},
\end{equation}
where the inequality retains only the leading $O(\theta^2)$
term and drops $O(\theta^4)$ corrections.

\emph{Step~3: assembly.}
Substituting~\eqref{III-eq:IF_theta_lower}
into~\eqref{III-eq:chain_rule_IF}:
\[
\mathcal{I}_F(\sigma)
\;\geq\; \kappa\,\Lambda^2\,(\Delta t)^2\,
\mathcal{I}_F^{\mathrm{env}}.
\qedhere
\]
\end{proof}

\begin{remark}[Coupling efficiency in the qubit example]
\label{III-rem:kappa_qubit}
For the single-qubit model of Section~\ref{III-sec:example},
the gauge orbit is parametrised directly by $\theta$
(rotation in the $xz$-plane of the Bloch sphere), so
$\partial\theta/\partial\sigma = 1$ and $\kappa = 1$.
More generally, $\kappa$ depends on the dimensionality
of the gauge group and the curvature of the orbit
$G/H$ at the current frame.
\end{remark}

\begin{corollary}[Detection before delusion]
\label{III-cor:detection_window}
Under~\textup{(C1)--(C5)}, there exists a detection
time $\Delta t_{\mathrm{detect}}$ satisfying
\begin{equation}
\label{III-eq:detection_window}
\Delta t_{\mathrm{detect}}
\;=\; \frac{1}{\Lambda}
\sqrt{\frac{\mathcal{I}_F^{\mathrm{min}}}
  {\kappa\,\mathcal{I}_F^{\mathrm{env}}}}
\;<\; t_{\mathrm{del}},
\end{equation}
where $\mathcal{I}_F^{\mathrm{min}}$ is the minimum Fisher
information required to exceed the noise floor
(determined by $h_\mu$ and the observation window length).
The detection window opens \emph{before} the Delusion Trap
closes, provided the meta-observer budget
$\mathcal{C}_{\mathrm{meta}}$ is sufficient to compute
$\mathcal{I}_F$.
\end{corollary}

\begin{proof}
The detection time
$\Delta t_{\mathrm{detect}} \propto \Lambda^{-1}$
(from~\eqref{III-eq:detectability}), while
$t_{\mathrm{del}} = \Lambda^{-1}\ln(\pi/4\theta_0)$
(from~\eqref{III-eq:t_del_recall}).
Since $\ln(\pi/4\theta_0) > 1$ for $\theta_0 < \pi/4e$
and the constant $\kappa\,\mathcal{I}_F^{\mathrm{env}}$
is finite under~(C4), the square root in
$\Delta t_{\mathrm{detect}}$ can be made smaller than
the logarithm in $t_{\mathrm{del}}$ for sufficiently
sensitive meta-observers (large
$\mathcal{I}_F^{\mathrm{env}}$).
\end{proof}

% ============================================================
\section{The Self-Referential Bound}
\label{III-sec:SRCR}

% ------------------------------------------------------------
\subsection{The Bayesian Framework}
\label{III-subsec:bayesian}

The agent's ego structure (Paper~II) provides a
\emph{prior belief} about the correct gauge parameter:
the current frame $\sigma_0$ is the ego's
``preferred'' value.
We encode this as a prior distribution
$\pi_{\mathrm{ego}}(\sigma)$, concentrated around
$\sigma_0$.

\begin{definition}[Ego rigidity]
\label{III-def:ego_rigidity}
The \emph{ego rigidity} is the prior Fisher information
\begin{equation}
\label{III-eq:ego_rigidity}
\mathcal{I}_{\mathrm{ego}}
:= \int_{\mathcal{M}_G}
\left(\frac{\partial \log \pi_{\mathrm{ego}}(\sigma)}
  {\partial \sigma}\right)^{\!2}
\pi_{\mathrm{ego}}(\sigma)\,d\sigma.
\end{equation}
High $\mathcal{I}_{\mathrm{ego}}$ corresponds to a
sharply peaked prior (rigid ego); low
$\mathcal{I}_{\mathrm{ego}}$ to a diffuse prior (flexible
ego).
The four bias terms of Paper~II contribute to
$\mathcal{I}_{\mathrm{ego}}$:
$\mathcal{B}_{\mathrm{select}}$ and
$\mathcal{B}_{\mathrm{frame}}$ sharpen the prior
around the current basis and connection,
while $\mathcal{B}_{\mathrm{center}}$ centres the prior
on the agent's own state.
\end{definition}

% ------------------------------------------------------------
\subsection{The Self-Referential Cram\'{e}r--Rao Bound}
\label{III-subsec:SRCR}

\begin{theorem}[Self-Referential Cram\'{e}r--Rao Bound]
\label{III-thm:SRCR}
Under assumptions~\textup{(C1)--(C5)}, let
$\delta\hat{\sigma}$ be any estimator of the frame drift
$\delta\sigma := \sigma^*(t) - \sigma$, based on a
residual record of duration~$T$.
Define the \emph{effective sample size}
$n_{\mathrm{eff}} := T/\tau_E$, where $\tau_E$ is the
decorrelation time of the residual process~$\{e(t)\}$
(the time beyond which consecutive residuals carry
approximately independent information about~$\sigma$).
Then the van Trees inequality~\cite{vanTrees1968} gives
\begin{equation}
\label{III-eq:SRCR}
\mathbb{E}\!\left[
  \bigl|\delta\hat{\sigma} - \delta\sigma\bigr|^2
\right]
\;\geq\; \frac{1}{n_{\mathrm{eff}}\,\mathcal{I}_F(\sigma)
  + \mathcal{I}_{\mathrm{ego}}}.
\end{equation}
\end{theorem}

\begin{proof}
This is a direct application of the van Trees
(Bayesian Cram\'{e}r--Rao)
inequality~\cite{vanTrees1968}.
The total information about the drift parameter $\delta\sigma$
consists of two contributions:
\begin{itemize}
\item $n_{\mathrm{eff}}\,\mathcal{I}_F(\sigma)$: the data
  Fisher information.  In continuous time, the residual
  process is correlated with decorrelation time $\tau_E$
  set by the bath memory kernel.
  Over a window of duration~$T$, the process yields
  $n_{\mathrm{eff}} \approx T/\tau_E$ effectively
  independent samples, each carrying
  $\mathcal{I}_F(\sigma)$ bits of information
  about $\delta\sigma$.
\item $\mathcal{I}_{\mathrm{ego}}$: the prior Fisher
  information from the ego's preference for $\sigma_0$
  (Definition~\ref{III-def:ego_rigidity}).
\end{itemize}
The van Trees inequality states that the Bayesian
mean-squared error is bounded below by the inverse of the
total information.
\end{proof}

\begin{remark}[The ego as help and hindrance]
\label{III-rem:ego_dual}
The ego rigidity $\mathcal{I}_{\mathrm{ego}}$ acts as
both help and hindrance:
\begin{itemize}
\item \textbf{Help}: when the ego is well-aligned
  ($\sigma_0 \approx \sigma^*$), the prior tightens the
  bound, reducing estimation variance.
\item \textbf{Hindrance}: when the ego is misaligned
  ($|\sigma_0 - \sigma^*|$ large), the prior pulls the
  estimate toward the wrong value, creating a
  \emph{confirmation bias} that resists recalibration.
\end{itemize}
The optimal Bayesian estimator balances data and prior:
\begin{equation}
\label{III-eq:optimal_estimator}
\hat{\sigma}_{\mathrm{opt}}
= \frac{n_{\mathrm{eff}}\,\mathcal{I}_F\,\hat{\sigma}_{\mathrm{MLE}}
  + \mathcal{I}_{\mathrm{ego}}\,\sigma_0}
  {n_{\mathrm{eff}}\,\mathcal{I}_F + \mathcal{I}_{\mathrm{ego}}},
\end{equation}
a weighted average of the maximum-likelihood estimate
$\hat{\sigma}_{\mathrm{MLE}}$ and the ego's prior belief
$\sigma_0$, with weights proportional to their respective
Fisher informations.
As $n_{\mathrm{eff}}\,\mathcal{I}_F \gg \mathcal{I}_{\mathrm{ego}}$
(enough data to overwhelm the ego), the estimator converges
to the MLE.
\end{remark}

% ------------------------------------------------------------
\subsection{The Rigidity-Sensitivity Trade-off}
\label{III-subsec:rigidity}

\begin{proposition}[Optimal ego rigidity]
\label{III-prop:optimal_rigidity}
Let the total expected loss be
$\mathcal{L}_{\mathrm{total}}
(\mathcal{I}_{\mathrm{ego}})
= \mathcal{L}_{\mathrm{estimation}}
+ \lambda\,\mathcal{L}_{\mathrm{calibration}}$,
where $\mathcal{L}_{\mathrm{estimation}}$ is the
mean-squared drift-estimation error
(bounded by~\eqref{III-eq:SRCR}) and
$\mathcal{L}_{\mathrm{calibration}}$ is the cost of
adjusting the frame (proportional to the frame rotation
distance, hence larger when the ego is rigid and must be
overcome).
Under~\textup{(C1)--(C5)}, there exists an optimal ego
rigidity $\mathcal{I}_{\mathrm{ego}}^*$ that minimises
$\mathcal{L}_{\mathrm{total}}$.

\emph{Too rigid}
($\mathcal{I}_{\mathrm{ego}} \gg n_{\mathrm{eff}}\,\mathcal{I}_F$):
the ego overwhelms the data; the agent is blind to drift.
\emph{Too soft}
($\mathcal{I}_{\mathrm{ego}} \ll n_{\mathrm{eff}}\,\mathcal{I}_F$):
the agent overreacts to noise; calibration cost is high.
The optimum balances sensitivity against stability.
\end{proposition}

\begin{proof}
The estimation loss decreases with
$\mathcal{I}_{\mathrm{ego}}$ (the prior sharpens the
bound~\eqref{III-eq:SRCR} when $\sigma_0 \approx \sigma^*$
but increases it when misaligned).
The calibration cost increases with
$\mathcal{I}_{\mathrm{ego}}$ (a rigid ego resists rotation).
The sum is a convex function of
$\mathcal{I}_{\mathrm{ego}}$ under standard regularity,
so a minimum exists.
\end{proof}

% ============================================================
\section{The Calibration Loop}
\label{III-sec:loop}

% ------------------------------------------------------------
\subsection{The Natural Gradient Update Law}
\label{III-subsec:update_law}

The meta-observer updates the gauge parameter $\sigma$
following the natural gradient on the statistical
manifold~$(\mathcal{M}_G,\,g)$:
\begin{equation}
\label{III-eq:update_law}
\dot{\sigma}
= -\eta\,g^{-1}(\sigma)\,
  \nabla_\sigma L_{\mathrm{frame}}(\sigma),
\end{equation}
where $\eta > 0$ is the adaptation rate and the
\emph{frame loss} is
\begin{equation}
\label{III-eq:frame_loss}
L_{\mathrm{frame}}(\sigma)
:= \mathbb{E}_\sigma\!\left[
  -\mathcal{S}_{\mathrm{vis}}(\sigma)\right].
\end{equation}
The frame loss is minimised at the optimal gauge
$\sigma^*$ that maximises visible survival.
The Fisher metric enters through the inverse $g^{-1}$
in the natural gradient, not as a penalty term:
it defines the \emph{geometry} of the update, ensuring
reparametrisation invariance.

\begin{remark}[Reparametrisation invariance]
\label{III-rem:reparam}
The natural gradient~\eqref{III-eq:update_law} is invariant
under reparametrisation of the gauge manifold
$\mathcal{M}_G$: the update direction does not depend on the
choice of coordinates for $\sigma$.
This is essential because the gauge manifold inherits its
geometry from the Clifford algebra, and no canonical
coordinate system is preferred.
\end{remark}

% ------------------------------------------------------------
\subsection{Lyapunov Stability of the Loop}
\label{III-subsec:lyapunov}

\paragraph{Drift velocity.}
Let $\sigma^*(t)$ denote the instantaneous optimal gauge
parameter (the minimiser of $L_{\mathrm{frame}}$ at
time~$t$; Paper~II, Definition~27).
Define the \emph{drift velocity}
$\dot{\sigma}^* := d\sigma^*/dt$, measured with respect to
the Fisher metric~$g$; its norm
$\|\dot{\sigma}^*\|_g
:= \sqrt{g_{ij}\,\dot{\sigma}^{*i}\,\dot{\sigma}^{*j}}$
is the instantaneous rate at which the environment's
optimal frame rotates on the gauge manifold.

\begin{definition}[Lyapunov monitoring function]
\label{III-def:lyapunov}
The \emph{Lyapunov monitoring function} is the squared
geodesic distance on the statistical manifold from the
current frame to the instantaneous optimal frame:
\begin{equation}
\label{III-eq:lyapunov}
V(\sigma)
:= d_{\mathrm{geo}}\!\left(\sigma,\,\sigma^*(t)\right)^2,
\end{equation}
where $d_{\mathrm{geo}}$ is the geodesic distance in the
Fisher metric~$g$.
\end{definition}

\begin{theorem}[Loop Tracking Bound]
\label{III-thm:loop_stability}
Under assumptions~\textup{(C1)--(C5)}, the natural gradient
update~\eqref{III-eq:update_law} applied to the Lyapunov
monitoring function~\eqref{III-eq:lyapunov} satisfies
\begin{equation}
\label{III-eq:lyapunov_decrease}
\frac{dV}{dt}
\;\leq\; -2\eta\,\alpha\,V
\;+\; 2\sqrt{V}\;\bigl\|\dot{\sigma}^*\bigr\|_g,
\end{equation}
where $\alpha > 0$ is the persistent excitation constant
(Definition~\ref{III-def:PE_constant} below)
and $\|\dot{\sigma}^*\|_g$ is the instantaneous drift speed
of the optimal frame.
Consequently:
\begin{enumerate}
\item[\textup{(a)}] \textbf{Tracking.}
  Whenever $\sqrt{V} >
  \|\dot{\sigma}^*\|_g / (\eta\,\alpha)$,
  we have $dV/dt < 0$: the loop actively reduces the
  mismatch.
\item[\textup{(b)}] \textbf{Tracking neighbourhood.}
  The mismatch converges to a neighbourhood of the set
  of stationary points of $L_{\mathrm{frame}}$.
  Assuming non-degeneracy (local strong convexity near
  $\sigma^*$, consistent with persistent
  excitation~(C5) in standard adaptive-control
  settings~\cite{AstromWittenmark1995}),
  this neighbourhood has size
  \begin{equation}
  \label{III-eq:tracking_neighbourhood}
  V_\infty
  \;:=\; \frac{\bigl\|\dot{\sigma}^*\bigr\|_g^2}
  {(\eta\,\alpha)^2}.
  \end{equation}
  For bounded drift
  ($\|\dot{\sigma}^*\|_g \leq \Lambda_{\max}$), the
  mismatch is bounded:
  $\limsup_{t\to\infty} V(t)
  \leq \Lambda_{\max}^2/(\eta\alpha)^2$.
\item[\textup{(c)}] \textbf{Static limit.}
  When $\sigma^* = \mathrm{const}$
  ($\dot{\sigma}^* = 0$), the bound reduces to
  $dV/dt \leq -2\eta\alpha\,V$,
  giving exponential convergence
  $V(t) \leq V(0)\,e^{-2\eta\alpha\,t}$.
\end{enumerate}
\end{theorem}

\begin{proof}
Since $V(\sigma) = d_{\mathrm{geo}}(\sigma,\,\sigma^*(t))^2$
and $\sigma^*(t)$ is time-varying, the total derivative
has two contributions:
\begin{equation*}
\frac{dV}{dt}
= \underbrace{\frac{\partial V}{\partial \sigma}
  \cdot \dot{\sigma}}_{\text{control}}
\;+\; \underbrace{\frac{\partial V}{\partial \sigma^*}
  \cdot \dot{\sigma}^*}_{\text{drift}}.
\end{equation*}

\paragraph{Control term.}
In normal coordinates centred at $\sigma^*$, let
$\delta\sigma := \sigma - \sigma^*$.
The control contribution is
$2\,g(\delta\sigma,\,\dot{\sigma})
= 2\,g(\delta\sigma,\,-\eta\,g^{-1}\nabla L_{\mathrm{frame}})
= -2\eta\,\langle \delta\sigma,\,
\nabla L_{\mathrm{frame}}\rangle$.
Since $\sigma^*$ minimises $L_{\mathrm{frame}}$ by
definition, $L_{\mathrm{frame}}$ is locally strongly
convex near $\sigma^*$ under persistent
excitation~(C5) (the Hessian of $L_{\mathrm{frame}}$
at $\sigma^*$ is bounded below by $\alpha\,g$,
where $\alpha$ is the persistent excitation constant).
Therefore
$\langle \delta\sigma,\,\nabla L_{\mathrm{frame}}\rangle
\geq \alpha\,|\delta\sigma|_g^2 = \alpha\,V$,
giving a control contribution $\leq -2\eta\,\alpha\,V$.

\paragraph{Drift term.}
The drift contribution is
$-2\,g(\delta\sigma,\,\dot{\sigma}^*)$.
By Cauchy--Schwarz:
$|g(\delta\sigma,\,\dot{\sigma}^*)|
\leq |\delta\sigma|_g\,\|\dot{\sigma}^*\|_g
= \sqrt{V}\,\|\dot{\sigma}^*\|_g$.
Hence the drift contribution is bounded by
$+2\sqrt{V}\,\|\dot{\sigma}^*\|_g$.

\paragraph{Combined.}
Adding both contributions
gives~\eqref{III-eq:lyapunov_decrease}.
Part~(a) follows by setting
$dV/dt < 0$; part~(b) by solving $dV/dt = 0$ for
the fixed point $\sqrt{V_\infty}
= \|\dot{\sigma}^*\|_g/(\eta\alpha)$;
part~(c) by setting $\dot{\sigma}^* = 0$.
\end{proof}

% ------------------------------------------------------------
\subsection{Convergence Rate under Persistent Excitation}
\label{III-subsec:convergence}

\begin{definition}[Persistent excitation constant]
\label{III-def:PE_constant}
The \emph{persistent excitation constant} $\alpha > 0$ is
the minimum eigenvalue of the time-averaged Fisher
information matrix:
\begin{equation}
\label{III-eq:PE_constant}
\bar{g}(t)
:= \frac{1}{T}\int_t^{t+T}
g(\sigma(s))\,ds
\;\succeq\; \alpha\,I
\qquad\text{for all } t,
\end{equation}
guaranteed to exist by~\textup{(C5)} and~\textup{(C4)}.
\end{definition}

\begin{remark}[Tracking vs convergence]
\label{III-rem:tracking}
In the static case ($\sigma^* = \mathrm{const}$),
Theorem~\ref{III-thm:loop_stability}(c) gives pure exponential
convergence:
$V(t) \leq V(0)\,e^{-2\eta\alpha\,t}$.
Under environmental drift, convergence to zero is
\emph{not} possible---instead the loop maintains the
mismatch within the tracking
neighbourhood~\eqref{III-eq:tracking_neighbourhood}.
The tracking error $V_\infty$ grows with drift speed
$\|\dot{\sigma}^*\|_g$ and decreases with loop parameters
$\eta$ and $\alpha$.
If the free-energy budget is insufficient to maintain
$\eta\,\alpha > \Lambda$ (the drift rate), the tracking
neighbourhood expands and the Delusion Trap re-emerges.
This connects the Lyapunov stability of the loop
directly to the thermodynamic budget
(Section~\ref{III-sec:cost}).
\end{remark}

\begin{remark}[The necessity of novelty]
\label{III-rem:novelty}
If $h_\mu \to 0$ (the environment ceases to generate new
information), the persistent excitation constant
$\alpha \to 0$ and the tracking neighbourhood
$V_\infty = \|\dot{\sigma}^*\|_g^2/(\eta\alpha)^2 \to \infty$:
the loop loses all ability to track.
\emph{Memory without novelty cannot sustain self-reference.}
This is the information-theoretic expression of a basic
physical principle: a system in thermodynamic equilibrium
cannot ``learn'' about itself.
\end{remark}

% ------------------------------------------------------------
\subsection{The Four-Part Structure Proposition}
\label{III-subsec:four_part}

We are now in a position to state the capstone result of
the T-DOME sequence.

\begin{proposition}[Sufficient Architecture for Persistent Agents]
\label{III-prop:four_part}
Within the class of agents satisfying~\textup{(C1)--(C5)},
a sufficient architecture for maintaining a
non-equilibrium steady state~\textup{(NESS)} in an open,
drifting environment under bounded computation comprises
the following four structural layers:
\begin{enumerate}
\item[\textup{(I)}] \textbf{External observable geometry.}
  The environmental observable algebra supports a
  metric structure; $Cl(1,3)$ serves as the running
  example throughout the programme, but the argument
  applies to any algebra satisfying~(C1).
  \emph{Assumption:}
  established
  in~\cite{Liu2026HAFF_A,Liu2026HAFF_B,Liu2026QRAIF_A};
  adopted here as a modelling premise.
\item[\textup{(II)}] \textbf{Internal control algebra.}
  The agent carries an internal algebra isomorphic to
  $Cl(V,q)$ with realizability embedding
  $\phi: Cl(V,q) \hookrightarrow Cl(1,3)$.
  \emph{Assumption:}
  established
  in~\cite{Liu2026QRAIF_B,Liu2026QRAIF_C};
  adopted here as a modelling premise.
\item[\textup{(III)}] \textbf{Self-monitoring function.}
  The agent maintains a Lyapunov function
  $V(\sigma)$~\eqref{III-eq:lyapunov} satisfying the
  tracking bound~\eqref{III-eq:lyapunov_decrease},
  implemented via a second-order control loop
  operating on the Fisher information of its own
  prediction stream.  The loop keeps the mismatch
  within the tracking
  neighbourhood~\eqref{III-eq:tracking_neighbourhood}.
  \emph{Source:} this paper,
  Theorem~\ref{III-thm:loop_stability}.
\item[\textup{(IV)}] \textbf{Biased, non-Markovian memory.}
  The agent carries path-dependent state
  (non-Markovian memory kernel $\mathcal{K}(t,s)$)
  compressed through a gauge-fixed reference frame
  (the ego $\mathfrak{E}$).
  \emph{Source:}
  Paper~I~\cite{Liu2026TDOME_I} (memory necessity)
  and Paper~II~\cite{Liu2026TDOME_II} (ego necessity).
\end{enumerate}
Without any one of the four layers, the agent fails:
\begin{itemize}
\item Without~(I): no physical embedding---the agent
  cannot interact with the Lorentzian environment.
\item Without~(II): no channel discrimination---the agent
  cannot distinguish survival-relevant from irrelevant
  information.
\item Without~(III): the Delusion Trap---the ego
  rigidifies and prediction error diverges exponentially.
\item Without~(IV): the Markovian Ceiling and
  computational paralysis---no temporal accumulation, no
  tractable processing.
\end{itemize}
\end{proposition}

\begin{proof}
Layers~(I) and~(II) are modelling
assumptions adopted
from~\cite{Liu2026HAFF_A,Liu2026HAFF_B,Liu2026QRAIF_A,Liu2026QRAIF_B,Liu2026QRAIF_C};
their sufficiency within those frameworks is established
therein.
The sufficiency of~(III) follows from the present paper:
Theorem~\ref{III-thm:first_order} shows that first-order
control is insufficient to escape the Delusion Trap, and
Theorem~\ref{III-thm:loop_stability} shows that the tracking
bound is sufficient.
The sufficiency of~(IV) follows from
Paper~I~\cite{Liu2026TDOME_I}
(Markovian Ceiling $\mathcal{S} \leq 0$)
and Paper~II~\cite{Liu2026TDOME_II}
(Computational Ceiling and necessity of SSB).

The ``without'' claims follow from the respective crisis
theorems: Paper~I's Theorem~14 (Markovian Ceiling),
Paper~II's Theorem~7 (Computational Ceiling)
and Theorem~29 (Delusion Trap), and the present
Theorem~\ref{III-thm:first_order}.
\end{proof}

% ============================================================
\section{Thermodynamic Cost}
\label{III-sec:cost}

% ------------------------------------------------------------
\subsection{The Three Cost Components}
\label{III-subsec:cost_components}

The self-referential calibration loop requires three
distinct operations, each carrying an irreducible
thermodynamic cost:

\paragraph{1.\ Sensing cost.}
The meta-observer must read the prediction residuals from
the ego's processing pipeline.
This requires monitoring $k^*$ foreground channels, each
producing $h_\mu$ bits per unit time:
\begin{equation}
\label{III-eq:W_sense}
\dot{W}_{\mathrm{sense}}
\;\geq\; k_BT\,\ln 2 \cdot h_\mu\,k^*.
\end{equation}
(Landauer cost of reading $h_\mu\,k^*$ bits per unit
time.)

\paragraph{2.\ Computing cost.}
Evaluating the Fisher information
$\mathcal{I}_F(\sigma)$ from the residual stream requires
the meta-observer to process
$\mathcal{C}_{\mathrm{meta}}$ bits per unit time:
\begin{equation}
\label{III-eq:W_compute}
\dot{W}_{\mathrm{compute}}
\;\geq\; k_BT\,\ln 2 \cdot \mathcal{C}_{\mathrm{meta}}.
\end{equation}

\paragraph{3.\ Actuating cost.}
Rotating the gauge parameter from the current frame
$\sigma$ to the estimated optimal frame
$\hat{\sigma}^*$ is a finite-time thermodynamic
transformation on the gauge manifold.
By the Sivak--Crooks bound
(Proposition~\ref{III-prop:sivak_crooks}):
\begin{equation}
\label{III-eq:W_actuate}
\dot{W}_{\mathrm{actuate}}
\;\geq\; \frac{\mathcal{L}^2(\sigma,\,\hat{\sigma}^*)}
  {\tau_{\mathrm{recalib}}^2},
\end{equation}
where $\mathcal{L}(\sigma,\,\hat{\sigma}^*)$ is the
thermodynamic length~\eqref{III-eq:thermo_length} of the
geodesic from $\sigma$ to $\hat{\sigma}^*$, and
$\tau_{\mathrm{recalib}}$ is the recalibration time.

% ------------------------------------------------------------
\subsection{The Thermodynamic Cost Theorem}
\label{III-subsec:cost_theorem}

\begin{theorem}[Thermodynamic Cost of Self-Referential
Calibration]
\label{III-thm:loop_cost}
Under assumptions~\textup{(C1)--(C5)}, the minimum
dissipation rate of the self-referential calibration loop
satisfies
\begin{equation}
\label{III-eq:loop_cost}
\dot{W}_{\mathrm{loop}}
\;\geq\; k_BT\,\ln 2\,\left[
  h_\mu\,k^*
  + \mathcal{C}_{\mathrm{meta}}
\right]
+ \frac{\mathcal{L}^2(\sigma,\,\sigma^*)}
  {\tau_{\mathrm{recalib}}^2}.
\end{equation}
The first bracketed term is the \emph{information tax}
(the Landauer cost of sensing and computing).
The second term is the \emph{geometric tax}
(the Sivak--Crooks cost of actuating the frame rotation).
\end{theorem}

\begin{proof}
We must establish that the three lower bounds can be
summed, i.e.\ that no single physical process can
simultaneously satisfy two or more of them.

The three operations act on \emph{disjoint physical
degrees of freedom}:
\begin{enumerate}
\item \emph{Sensing} reads the prediction residuals
  $\{e_t\}$ from the ego's foreground channels.
  The relevant degrees of freedom are the sensor
  registers that copy bits from the foreground subspace
  $V_{\mathrm{fg}}$.
  Each bit erased carries the Landauer
  cost $k_BT\ln 2$.
\item \emph{Computing} evaluates the Fisher information
  $\mathcal{I}_F(\sigma)$ from the copied residuals.
  The relevant degrees of freedom are the processor
  logic states of the meta-observer.
  These are distinct from the sensor registers: the
  processor manipulates the data \emph{after} it has
  been read, and its own state transitions carry an
  independent Landauer cost.
\item \emph{Actuating} rotates the gauge parameter from
  $\sigma$ to $\hat{\sigma}^*$.
  The relevant degrees of freedom are the control
  fields that implement the frame rotation on the
  agent's internal algebra $Cl(V,q)$.
  This is a physical transformation of the agent's
  hardware state, governed by the Sivak--Crooks bound
  on finite-time thermodynamic transformations.
  The $\tau_{\mathrm{recalib}}^{-2}$ scaling of the
  dissipation \emph{rate} follows from the
  Sivak--Crooks bound $W_{\mathrm{ex}} \geq
  \mathcal{L}^2/\tau$ (excess \emph{work}), divided by
  $\tau_{\mathrm{recalib}}$ to convert to a rate.
\end{enumerate}
Under the assumption that the three operations are
physically realised on separable degrees of freedom
(no shared erasure accounting),
the sets are disjoint
(sensor $\cap$ processor $= \emptyset$, processor
$\cap$ actuator $= \emptyset$, sensor $\cap$ actuator
$= \emptyset$), and the Landauer bound for each is independent.
Moreover, the actuating cost involves a different
\emph{type} of bound (thermodynamic length, not Landauer
erasure), reinforcing the independence.
The total lower bound is
therefore the sum of the three individual
bounds~\eqref{III-eq:W_sense}--\eqref{III-eq:W_actuate}.
\end{proof}

% ------------------------------------------------------------
\subsection{The Complete Persistence Budget}
\label{III-subsec:persistence}

\begin{corollary}[Persistence Budget]
\label{III-cor:persistence}
Combining the results of Papers~I, II, and~III, the minimum
free-energy dissipation rate for a persistent,
self-calibrating agent in a drifting environment is
\begin{equation}
\label{III-eq:persistence_budget}
\dot{W}_{\mathrm{total}}
\;\geq\; \underbrace{k_BT\,\ln 2 \cdot h_\mu}_{%
  \text{Paper~I: memory}}
+ \underbrace{k_BT\,\ln 2 \cdot h_\mu\,k^*}_{%
  \text{Paper~II: ego processing}}
+ \underbrace{k_BT\,\ln 2\,\left[
  h_\mu\,k^*
  + \mathcal{C}_{\mathrm{meta}}
\right]
+ \frac{\mathcal{L}^2}
  {\tau_{\mathrm{recalib}}^2}}_{%
  \text{Paper~III: self-calibration loop}}.
\end{equation}
Below this budget, the agent must sacrifice one or more of
the four structural layers
(Proposition~\ref{III-prop:four_part}):
losing memory (Paper~I crisis),
losing the ego (Paper~II crisis), or
losing self-calibration (Paper~III crisis, the Delusion Trap).
\end{corollary}

\begin{remark}[The cost of selfhood]
\label{III-rem:selfhood_cost}
Equation~\eqref{III-eq:persistence_budget} is the first
explicit, calculable lower bound on the thermodynamic cost
of maintaining a self-referential agent in a drifting
environment.
It shows that ``selfhood'' is not free: the ego
(Paper~II) and its calibration loop (Paper~III) each add
irreducible energy taxes on top of the memory cost
(Paper~I).
The total cost grows with the environmental complexity
($h_\mu$), the agent's representational capacity ($k^*$),
the meta-observer's computational power
($\mathcal{C}_{\mathrm{meta}}$), and the drift rate
(through $\mathcal{L}$ and $\tau_{\mathrm{recalib}}$).
\end{remark}

% ============================================================
\section{Worked Example: Qubit in a Drifting
Two-Channel Bath}
\label{III-sec:example}

% ------------------------------------------------------------
\subsection{Model Setup}
\label{III-subsec:model_III}

We extend the two-channel qubit model from
Paper~II~(Section~6) by introducing environmental drift.

\paragraph{Inherited setup.}
A qubit ($\dim\mathcal{H}_S = 2$) with internal algebra
$Cl(0,2) \cong \mathbb{H}$ ($D = 4$), coupled to two
bosonic channels:
\begin{itemize}
\item Dephasing channel ($\sigma_z$):
  $J_z(\omega) = 2\lambda_z\gamma_z\omega/
  (\omega^2 + \gamma_z^2)$.
\item Dissipative channel ($\sigma_x$):
  $J_x(\omega) = 2\lambda_x\gamma_x\omega/
  (\omega^2 + \gamma_x^2)$.
\end{itemize}
Paper~II's ego selects $V_{\mathrm{fg}}
= \mathrm{span}\{1,\mathbf{k}\}$ (the dephasing subspace),
discarding $V_{\mathrm{bg}}
= \mathrm{span}\{\mathbf{i},\mathbf{j}\}$.

\paragraph{Environmental drift.}
We now allow the dephasing coupling to drift exponentially
(matching Paper~II's Delusion Trap analysis):
\begin{equation}
\label{III-eq:drift_model}
\lambda_z(t)
= \lambda_z^{(0)}\bigl(1 + \theta_0\,e^{\Lambda t}\bigr),
\qquad
\theta_0 = 0.02,
\quad
\Lambda = 0.08\,\omega_0.
\end{equation}
The optimal frame $\mathcal{F}^*(t)$ rotates in
$SO(3)$ as the relative survival values of the two
channels change.  The Delusion Trap time
$t_{\mathrm{del}}
= \Lambda^{-1}\ln\!\bigl(\pi/(4\theta_0)\bigr)
\approx 45.9\,\omega_0^{-1}$.

\paragraph{Parameter mapping.}
\begin{center}
\small
\begin{tabular}{@{}lcl@{}}
\toprule
\textbf{Quantity} & \textbf{Value} & \textbf{Source} \\
\midrule
$D = \dim Cl(0,2)$ & 4 & Paper~II \\
$k^*$ & 2 & Paper~II, Theorem~17 \\
$\mathcal{C}_{\mathrm{budget}}$ & $2\,h_\mu$ & Paper~II \\
$\theta_0$ (initial misalignment) & 0.02 & this example \\
$\Lambda$ (drift rate) & $0.08\,\omega_0$
  & Eq.~\eqref{III-eq:drift_model} \\
$t_{\mathrm{del}}$ & $45.9\,\omega_0^{-1}$
  & Paper~II, Delusion Trap \\
$\eta$ (adaptation rate) & $0.5$ & meta-observer \\
\bottomrule
\end{tabular}
\end{center}

% ------------------------------------------------------------
\subsection{Fisher Information under Drift}
\label{III-subsec:fisher_drift}

As the coupling $\lambda_z(t)$ drifts, the decoherence
function $p_z(t)$ (Paper~II, Eq.~(34)) changes, shifting the
residual distribution.
The self-referential Fisher information
$\mathcal{I}_F(\sigma)$ measures this shift.

For the qubit model, the Fisher information with respect to
the frame angle $\phi$ (parametrising the $SO(3)$ rotation
between the current and optimal frames) is
\begin{equation}
\label{III-eq:fisher_qubit}
\mathcal{I}_F(\phi)
= \frac{(\partial_\phi\,\bar{e})^2}
  {\mathrm{Var}(e)}
\approx \frac{4\,\mathcal{S}_{\mathrm{tot}}^2\,
  \theta^2}
  {h_\mu / n_{\mathrm{eff}}},
\end{equation}
where $\bar{e} = \mathbb{E}[e\,|\,\phi]$ is the expected
residual,
$\theta = \theta(\phi)$ is the mismatch angle, and
$n_{\mathrm{eff}}$ is the effective sample size
(Remark~\ref{III-rem:effective_independence}).

When the frame is well-aligned ($\theta \approx 0$):
$\mathcal{I}_F \approx 0$.
As drift accumulates ($\theta$ grows):
$\mathcal{I}_F$ increases quadratically, producing a
detectable ``stress signal'' consistent with
Theorem~\ref{III-thm:detectability}.

% ------------------------------------------------------------
\subsection{Loop Dynamics: Self-Calibration in Action}
\label{III-subsec:loop_dynamics}

Under the natural gradient
update~\eqref{III-eq:update_law}, the frame angle
$\phi(t)$ tracks the drifting optimal frame
$\phi^*(t)$.
The Lyapunov function
$V(t) = (\phi(t) - \phi^*(t))^2$ is governed by the
tracking bound~\eqref{III-eq:lyapunov_decrease}:
the loop drives $V$ toward the tracking neighbourhood
$V_\infty = \|\dot{\sigma}^*\|_g^2/(\eta\alpha)^2$,
with the approach rate set by the persistent
excitation constant $\alpha$ and the adaptation
rate~$\eta$.

\paragraph{Comparison.}
\begin{itemize}
\item \textbf{Without loop} (Paper~II agent): the mismatch
  grows as $\theta(t) = \theta_0\,e^{\Lambda t}$,
  reaching $\pi/4$ at $t_{\mathrm{del}}$.
  The agent is delusional.
\item \textbf{With loop} (Paper~III agent): the mismatch
  oscillates around zero, bounded by the estimation
  noise floor
  $\theta_{\mathrm{min}}
  \sim 1/\sqrt{n_{\mathrm{eff}}\,\mathcal{I}_F^{\mathrm{env}}}$
  (the Cram\'{e}r--Rao limit).
  The agent remains calibrated.
\end{itemize}

A multi-dimensional numerical evaluation extending
this qubit illustration to continuous drift is presented
in Section~\ref{III-sec:numerical}.

% ------------------------------------------------------------
\subsection{Thermodynamic Cost Evaluation}
\label{III-subsec:cost_eval}

For the qubit example with $k^* = 2$, $h_\mu = 1$
(normalised), $\mathcal{C}_{\mathrm{meta}} = 1\,h_\mu$
(minimal meta-observer):
\begin{align}
\dot{W}_{\mathrm{sense}}
&\geq k_BT\,\ln 2 \cdot 1 \cdot 2
= 2\,k_BT\,\ln 2, \label{III-eq:cost_sense_ex} \\
\dot{W}_{\mathrm{compute}}
&\geq k_BT\,\ln 2 \cdot 1
= k_BT\,\ln 2, \label{III-eq:cost_compute_ex} \\
\dot{W}_{\mathrm{actuate}}
&\geq \frac{\mathcal{L}^2}{\tau_{\mathrm{recalib}}^2}
\approx \frac{\theta_0^2\,\tau_{\mathrm{relax}}}
  {\tau_{\mathrm{recalib}}^2}\,k_BT.
  \label{III-eq:cost_actuate_ex}
\end{align}
The total loop cost is dominated by the information tax
(sensing + computing) at $\sim 3\,k_BT\,\ln 2$ per unit
time, with the geometric tax (actuating) contributing a
smaller correction proportional to $\theta_0^2$.

For comparison, Paper~I's memory cost is
$\dot{W}_{\mathrm{mem}} \geq k_BT\,\ln 2$ and
Paper~II's ego processing cost is
$\dot{W}_{\mathrm{ego}} \sim 2\,k_BT\,\ln 2\cdot h_\mu$.
The self-calibration loop adds approximately $50\%$ to the
total energy budget---a significant but bounded cost for
escaping the Delusion Trap.

% ============================================================
\section{Numerical Demonstration}
\label{III-sec:numerical}

The preceding sections establish analytic bounds and a
low-dimensional worked example.  We now demonstrate
computationally that the three core phenomena---delusion
separation, detectable staleness, and an optimal calibration
budget---emerge in a minimal multi-dimensional system under
continuous drift.  Full code and parameters are provided for
reproducibility.

% ------------------------------------------------------------
\subsection{Model}
\label{III-subsec:demo_model}

\paragraph{Environment.}
A $d$-dimensional linear prediction task:
$y(t) = \mathbf{w}(t)^\top \mathbf{x}(t)
+ \sigma\,\epsilon(t)$,
$\mathbf{x}(t) \sim \mathcal{N}(\mathbf{0}, \mathbf{I}_d)$,
$\epsilon \sim \mathcal{N}(0,1)$.
The weight vector $\mathbf{w}(t) \in \mathbb{S}^{d-1}$
drifts by receiving random perturbations on
\emph{background} dimensions only (indices $k,\ldots,d{-}1$),
then renormalising.  Signal therefore migrates progressively
from the ego's foreground to its blind sector.

\paragraph{Agents.}
\begin{itemize}
\item \textbf{Fixed ego} (Paper~II analogue):
  learns a linear model on a \emph{fixed} foreground
  subspace of dimension~$k$ via stochastic gradient descent
  (SGD, rate~$\eta$, decay~$\lambda$).
  Embodies the ``frozen gauge'' of Paper~II.
\item \textbf{Calibrated loop} (Paper~III analogue):
  identical ego plus a staleness sentinel and recalibration
  mechanism.
  The sentinel tracks $g_i = \mathrm{EMA}(|e\,x_i|)$ for
  each dimension~$i$ (an absolute-gradient proxy),
  computes the fraction of top-$k$ gradient dimensions
  \emph{not} in the current foreground as a frame-staleness
  index $m \in [0,1]$, and triggers
  recalibration when
  $\mathrm{EMA}(m) > \theta$.
  After recalibration, a settling period
  of~$\tau$ steps elapses before the sentinel resumes
  monitoring.
\end{itemize}

\paragraph{Parameters.}
\begin{center}
\small
\begin{tabular}{@{}lcl@{}}
\toprule
\textbf{Quantity} & \textbf{Value} & \textbf{Role} \\
\midrule
$d$ & 20 & full ambient dimension \\
$k$ & 5  & ego foreground dimension ($k/d = 0.25$) \\
$\sigma$ & 0.1 & observation noise std \\
$\eta$ & 0.01 & SGD learning rate \\
$\lambda$ & 0.998 & SGD weight decay \\
$\theta$ & 0.25 & staleness threshold \\
$\Lambda$ & variable & drift rate per step \\
$\tau$ & variable & settling period (cooldown) \\
\bottomrule
\end{tabular}
\end{center}

\paragraph{Oracle metrics.}
Neither agent has access to $\mathbf{w}(t)$.
We evaluate performance externally using the \emph{oracle
full-space error}:
\begin{equation}
\label{III-eq:oracle_error}
\mathcal{E}_{\mathrm{full}}
= \bigl\|\mathbf{w}_{\mathrm{ego}}
  - \mathbf{w}^*_{\mathrm{fg}}\bigr\|^2
+ \bigl\|\mathbf{w}^*_{\mathrm{bg}}\bigr\|^2,
\end{equation}
where $\mathbf{w}^*_{\mathrm{fg}}$ and
$\mathbf{w}^*_{\mathrm{bg}}$ denote the true weight vector
restricted to foreground and background coordinates
respectively, and $\mathbf{w}_{\mathrm{ego}}$ is the ego's
foreground-supported estimator lifted to the full space.
The first term captures foreground tracking error (accessible
to the ego); the second captures hidden-sector signal
(invisible).

% ------------------------------------------------------------
\subsection{Results}
\label{III-subsec:demo_results}

\paragraph{Result 1: Delusion-correction separation
(Figure~\ref{III-fig:demo_trap}).}
At drift rate $\Lambda = 0.02$, settling period $\tau = 200$,
and $T = 5\,000$ steps, three phenomena are visible:

\begin{enumerate}
\item[(a)]
\emph{Delusion trap.}
The ego's foreground tracking error converges
to near zero, while the true full-space error rises
toward $\sim\!1$ and stabilises.
The growing gap between the two is the hidden sector,
confirming the prediction
of Theorem~\ref{III-thm:first_order}: first-order
monitoring cannot detect frame drift.

\item[(b)]
\emph{Detectability.}
The staleness sentinel produces a clean sawtooth:
rising from zero after each recalibration, crossing the
threshold $\theta = 0.25$, and triggering frame reset
(25~events over $T = 5\,000$).
This is consistent with the predicted growth trend of the
self-referential Fisher signal
(Theorem~\ref{III-thm:detectability}).

\item[(c)]
\emph{Net benefit.}
The calibrated loop achieves
$\mathcal{E}_{\mathrm{full}} \approx 0.74$
versus the fixed ego's $\approx 1.02$:
a $27\%$ reduction in true prediction error.
\end{enumerate}

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]{fig_delusion_trap.pdf}
\caption{%
\textbf{Delusion trap and calibration loop.}
$d = 20$, $k = 5$, $\Lambda = 0.02$, $\tau = 200$,
$T = 5\,000$.
\textbf{(a)}~Foreground tracking error (blue) decreases
toward zero while true full-space error (red) increases;
the shaded region is the hidden sector, invisible to the ego.
\textbf{(b)}~Frame-staleness sentinel (purple) rises
monotonically between recalibration events (orange),
producing a sawtooth with 25 threshold crossings.
\textbf{(c)}~The calibrated loop (green) maintains
lower true error than the fixed ego (red);
the grey dashed line shows the foreground energy fraction
decaying as signal migrates to the background.}
\label{III-fig:demo_trap}
\end{figure}

\paragraph{Result 2: Phase structure and optimal
calibration budget
(Figures~\ref{III-fig:demo_phase}--\ref{III-fig:demo_alpha}).}
We scan 16 drift rates $\Lambda \in [0.005, 0.08]$ and
16 settling periods $\tau \in [15, 800]$
(logarithmically spaced), running both agents for
$T = 4\,000$ steps across 6 random seeds per grid point.

Figure~\ref{III-fig:demo_phase}(a) shows the performance
gain $\Delta = \mathcal{E}_{\mathrm{ego}}
- \mathcal{E}_{\mathrm{loop}}$:
the loop improves over the ego (green) across most of
the parameter space, with a boundary at $\Delta = 0$
(dashed) below which recalibration is counterproductive
(very low drift, where the overhead of re-learning
exceeds the benefit of tracking).
The solid curve traces the \emph{optimal settling period}
$\tau_{\mathrm{opt}}(\Lambda)$---the recalibration
period minimising $\mathcal{E}_{\mathrm{loop}}$---which
decreases monotonically from $\sim\!370$ steps at
$\Lambda = 0.005$ to $\sim\!100$ at $\Lambda = 0.08$.
Figure~\ref{III-fig:demo_phase}(b) shows that calibration
frequency increases smoothly with drift and with shorter
settling period, exhibiting the cost--performance
trade-off of Theorem~\ref{III-thm:loop_cost}.

Extracting $\tau_{\mathrm{opt}}(\Lambda)$ yields the
\emph{optimal calibration frequency}
$\alpha_{\mathrm{opt}}(\Lambda)
= 1/\tau_{\mathrm{opt}}$
(Figure~\ref{III-fig:demo_alpha}).
The curve is smooth and monotonically increasing:
faster drift demands tighter calibration.
It saturates at high $\Lambda$ near
$\alpha_{\mathrm{opt}} \approx 0.01$ per step
($\tau_{\mathrm{opt}} \approx 100$), of the same
order as the learner's settling time.
This is consistent with the intuition that drift
estimation requires a minimum observation window;
the self-referential Cram\'{e}r--Rao bound
(Theorem~\ref{III-thm:SRCR}) provides the analytic
counterpart of this computational floor.

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]%
  {fig_phase_with_boundary.pdf}
\caption{%
\textbf{Phase structure and calibration cost.}
$16 \times 16$ grid, $T = 4\,000$, 6 seeds per point.
\textbf{(a)}~Performance gain $\Delta$; green = loop
improves on ego, red = counterproductive.
Solid curve: $\tau_{\mathrm{opt}}(\Lambda)$.
Dashed: $\Delta = 0$ boundary.
\textbf{(b)}~Calibration frequency (thermodynamic cost
proxy: recalibration events per step, proportional to
energy expenditure under a fixed per-recalibration cost
model); $\tau_{\mathrm{opt}}$ overlaid.}
\label{III-fig:demo_phase}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]{fig_alpha_opt.pdf}
\caption{%
\textbf{Optimal calibration frequency.}
\textbf{Left:}
$\tau_{\mathrm{opt}}(\Lambda)$ decreases monotonically
with drift rate.
\textbf{Right:}
$\alpha_{\mathrm{opt}}(\Lambda) = 1/\tau_{\mathrm{opt}}$
increases with drift rate and saturates at the learner's
settling timescale ($\sim\!100$ steps), consistent with
an observation-window floor.}
\label{III-fig:demo_alpha}
\end{figure}

% ------------------------------------------------------------
\subsection{Scope of This Demonstration}
\label{III-subsec:demo_scope}

This demonstration \textbf{does} show:
\begin{enumerate}
\item The delusion-correction separation predicted by
  Theorems~\ref{III-thm:first_order}
  and~\ref{III-thm:detectability} emerges in a minimal
  stochastic system with continuous drift.
\item A frame-staleness signal with clean threshold
  dynamics exists and triggers effective recalibration.
\item An optimal calibration frequency
  $\alpha_{\mathrm{opt}}(\Lambda)$ exists, increases
  monotonically with drift rate, and saturates at the
  learner's settling timescale.
\item The cost--performance trade-off of
  Theorem~\ref{III-thm:loop_cost} manifests as a structured
  phase diagram with an explicit
  $\tau_{\mathrm{opt}}$ boundary.
\end{enumerate}

\noindent
In summary, this demonstration validates the
\emph{existence} and \emph{detectability} of the
loop--cost trade-off in a minimal linear setting;
it does not claim universality across architectures
or environment classes.

\medskip
This demonstration does \textbf{not} show:
\begin{enumerate}
\item That the specific functional form of
  $\alpha_{\mathrm{opt}}(\Lambda)$ matches the analytic
  Cram\'{e}r--Rao prediction in the
  large-$d$ limit.  The demonstration confirms the
  monotonic trend and saturation; deriving the exact
  scaling exponent from Theorem~\ref{III-thm:SRCR}
  remains open.
\item That the results generalise to all environment
  classes.  The model uses Gaussian features, linear
  regression, and isotropic background drift; extensions
  to non-linear, non-Gaussian, or structured-drift
  settings require further investigation.
\item That the calibration loop is optimal among all
  possible adaptive strategies.  It implements one
  specific realisation of the calibration-loop
  architecture.
\end{enumerate}

\paragraph{Reproducibility.}
The complete simulation is a self-contained Python script
(\texttt{tdome\_demo.py}, $\sim\!550$ lines, requiring
only NumPy and Matplotlib) with fixed random seeds.
All figures in this section can be reproduced by
executing the script after setting the output directory
variable \texttt{BASE} to the desired path.

% ============================================================
\section{Discussion}
\label{III-sec:discussion}

% ------------------------------------------------------------
\subsection{Summary of Results}
\label{III-subsec:summary}

\begin{center}
\small
\setlength{\tabcolsep}{4pt}%
\begin{tabular}{@{}lp{6cm}c@{}}
\toprule
\textbf{Result} & \textbf{Statement} & \textbf{Sec.} \\
\midrule
First-Order Insufficiency
  & Raw prediction error cannot detect frame drift
  & \ref{III-subsec:first_order} \\[3pt]
Drift Detectability
  & Self-referential Fisher information grows
    quadratically with accumulated drift
  & \ref{III-subsec:self_ref_fisher} \\[3pt]
Self-Referential CR Bound
  & Drift estimation bounded by
    $1/(n_{\mathrm{eff}}\,\mathcal{I}_F + \mathcal{I}_{\mathrm{ego}})$
  & \ref{III-subsec:SRCR} \\[3pt]
Loop Tracking Bound
  & Lyapunov $V$ with tracking neighbourhood
    $V_\infty = \|\dot{\sigma}^*\|^2/(\eta\alpha)^2$
  & \ref{III-subsec:lyapunov} \\[3pt]
Four-Part Structure
  & Persistent agents require four structural layers
  & \ref{III-subsec:four_part} \\[3pt]
Loop Cost
  & $\dot{W}_{\mathrm{loop}} \geq k_BT\,\ln 2\,[h_\mu\,k^*
    + \mathcal{C}_{\mathrm{meta}}]
    + \mathcal{L}^2/\tau_{\mathrm{recalib}}^2$
  & \ref{III-subsec:cost_theorem} \\[3pt]
Persistence Budget
  & Total cost: memory + ego + loop
  & \ref{III-subsec:persistence} \\[3pt]
Numerical Demonstration
  & Delusion separation, sentinel detection,
    $\alpha_{\mathrm{opt}}(\Lambda)$ boundary
  & \ref{III-sec:numerical} \\
\bottomrule
\end{tabular}
\end{center}

% ------------------------------------------------------------
\subsection{The Complete Logic Chain}
\label{III-subsec:logic_chain}

Papers~I--III trace an irreversible
thermodynamic logic chain:

\begin{center}
\small
\setlength{\tabcolsep}{3pt}%
\begin{tabular}{@{}lp{3.2cm}p{3.8cm}l@{}}
\toprule
\textbf{Paper} & \textbf{Crisis} & \textbf{Resolution}
  & \textbf{What is born} \\
\midrule
Paper~I
  & Markovian trap: no history
  & Non-Markovian memory
  & \textbf{Temporal accumulation} \\[3pt]
Paper~II
  & Computation explosion: $\infty$~memory, finite budget
  & Gauge SSB: $Cl(V,q) \to V_{\mathrm{fg}}
    \oplus V_{\mathrm{bg}}$
  & \textbf{Compressed ref.\ frame} \\[3pt]
Paper~III
  & Delusion trap: fixed bias, drifting world
  & Fisher self-referential calibration; tracking bound
  & \textbf{Reflexivity} \\
\bottomrule
\end{tabular}
\end{center}

Each resolution creates the precondition for the next
crisis.
The chain terminates at Paper~III: the self-referential
calibration loop does not create a further crisis requiring a
``Paper~IV,'' because the loop is \emph{self-correcting}
by construction (Theorem~\ref{III-thm:loop_stability}).
Its only vulnerability is the thermodynamic budget
(Theorem~\ref{III-thm:loop_cost}): if the agent's free-energy
supply falls below the persistence
budget~\eqref{III-eq:persistence_budget}, the loop degrades
and the Delusion Trap re-emerges.
This is not a new crisis but the Second Law itself: all
order requires free-energy dissipation.

% ------------------------------------------------------------
\subsection{What This Paper Does and Does Not Show}
\label{III-subsec:claims}

This paper \textbf{does} show:
\begin{enumerate}
\item Under environmental drift~(C2) and bounded
  computation~(C1), first-order control fails to detect
  frame drift (Theorem~\ref{III-thm:first_order}).
\item Self-referential Fisher information provides a
  quadratically growing signal sufficient for drift
  detection before the Delusion Trap
  (Theorem~\ref{III-thm:detectability}).
\item Drift estimation precision is bounded by the
  Self-Referential Cram\'{e}r--Rao bound
  (Theorem~\ref{III-thm:SRCR}).
\item The calibration loop tracks the optimal frame
  within a bounded neighbourhood under a Lyapunov
  tracking bound
  (Theorem~\ref{III-thm:loop_stability}).
\item The thermodynamic cost of the loop is calculable
  (Theorem~\ref{III-thm:loop_cost}).
\end{enumerate}

\medskip
This paper does \textbf{not} show:
\begin{enumerate}
\item That self-referential calibration implies or requires
  phenomenal consciousness, subjective experience, or
  qualia. ``Reflexivity'' as used here denotes
  second-order control, nothing more.
\item That the Lyapunov function $V$ is a measure of
  ``awareness.'' It is a control-theoretic stability
  condition, not a consciousness metric.
\item That the Four-Part Structure Proposition is a complete
  characterisation of agency. It states sufficient
  conditions under~(C1)--(C5); other architectures may
  also suffice.
\item That Fisher information requires the agent to
  ``know'' it is computing Fisher information.
  The computation can be implemented implicitly by any
  physical system whose dynamics approximate the natural
  gradient.
\item That the calibration loop eliminates the ego's bias.
  It tracks and compensates for drift in the bias;
  the four bias terms of Paper~II persist.
\item That the thermodynamic cost bounds are achievable by
  any specific physical implementation.
  They are information-theoretic lower bounds.
\item That this framework applies to all possible systems.
  It applies to systems satisfying~(C1)--(C5).
\item That the structural parallel with philosophical
  concepts of self-awareness constitutes a philosophical
  or metaphysical claim.
\item That the Clifford algebra is the only possible
  algebraic setting. Other control algebras may yield
  analogous results with different quantitative bounds.
\end{enumerate}

\medskip
We have established a budgeted self-referential calibration
loop that detects drift via an intrinsic Fisher signal,
yields a falsifiable stability criterion, and incurs an
unavoidable thermodynamic cost.
In the context of Papers~I--III, this completes the
programme's third step by turning bias (Paper~II)
into a dynamically monitored and correctable quantity.

% ============================================================
% REFERENCES
% ============================================================


% ============================================================================
% UNIFIED BIBLIOGRAPHY
% ============================================================================
\begin{thebibliography}{99}

\bibitem{Amari1985}
S.-i.~Amari,
\emph{Differential-Geometrical Methods in Statistics},
Lecture Notes in Statistics \textbf{28}, Springer (1985).

\bibitem{Amari1998}
S.-i.~Amari,
\emph{Natural gradient works efficiently in learning},
Neural Computation \textbf{10}, 251 (1998).

\bibitem{AmariNagaoka2000}
S.-i.~Amari and H.~Nagaoka,
\emph{Methods of Information Geometry},
Translations of Mathematical Monographs \textbf{191},
AMS (2000).

\bibitem{Ashby1956}
W.~R.~Ashby,
\emph{An Introduction to Cybernetics},
Chapman \& Hall (1956).

\bibitem{AstromWittenmark1995}
K.~J.~\AA{}str\"{o}m and B.~Wittenmark,
\emph{Adaptive Control},
2nd ed., Addison-Wesley (1995).

\bibitem{BaratoSeifert2015}
A.~C.~Barato and U.~Seifert,
\emph{Thermodynamic uncertainty relation for biomolecular
processes},
Phys.\ Rev.\ Lett.\ \textbf{114}, 158101 (2015).

\bibitem{Bennett1982}
C.~H.~Bennett,
\emph{The thermodynamics of computation---a review},
Int.\ J.\ Theor.\ Phys.\ \textbf{21}, 905 (1982).

\bibitem{BialekNemenmanTishby2001}
W.~Bialek, I.~Nemenman, and N.~Tishby,
\emph{Predictability, complexity, and learning},
Neural Computation \textbf{13}, 2409 (2001).

\bibitem{BreuerLainePiilo2009}
H.-P.~Breuer, E.-M.~Laine, and J.~Piilo,
\emph{Measure for the Degree of Non-Markovian Behavior of Quantum Processes in Open Systems},
Phys.\ Rev.\ Lett.\ \textbf{103}, 210401 (2009).

\bibitem{BreuerPetruccione2002}
H.-P.~Breuer and F.~Petruccione,
\emph{The Theory of Open Quantum Systems},
Oxford University Press (2002).

\bibitem{Cencov1982}
N.~N.~\v{C}encov,
\emph{Statistical Decision Rules and Optimal Inference},
Translations of Mathematical Monographs \textbf{53},
AMS (1982).

\bibitem{CoverThomas2006}
T.~M.~Cover and J.~A.~Thomas,
\emph{Elements of Information Theory},
2nd ed., Wiley (2006).

\bibitem{Crooks2007}
G.~E.~Crooks,
\emph{Measuring thermodynamic length},
Phys.\ Rev.\ Lett.\ \textbf{99}, 100602 (2007).

\bibitem{CrutchfieldYoung1989}
J.~P.~Crutchfield and K.~Young,
\emph{Inferring statistical complexity},
Phys.\ Rev.\ Lett.\ \textbf{63}, 105 (1989).

\bibitem{EspositoLindenbergVandenBroeck2010}
M.~Esposito, K.~Lindenberg, and C.~Van~den~Broeck,
\emph{Entropy production as correlation between system and reservoir},
New J.\ Phys.\ \textbf{12}, 013013 (2010).

\bibitem{GKS1976}
V.~Gorini, A.~Kossakowski, and E.~C.~G.~Sudarshan,
\emph{Completely positive dynamical semigroups of $N$-level systems},
J.\ Math.\ Phys.\ \textbf{17}, 821 (1976).

\bibitem{Ito2018}
S.~Ito,
\emph{Stochastic thermodynamic interpretation of
information geometry},
Phys.\ Rev.\ Lett.\ \textbf{121}, 030605 (2018).

\bibitem{JohnsonLindenstrauss1984}
W.~B.~Johnson and J.~Lindenstrauss,
\emph{Extensions of Lipschitz mappings into a Hilbert space},
Contemp.\ Math.\ \textbf{26}, 189 (1984).

\bibitem{Landauer1961}
R.~Landauer,
\emph{Irreversibility and heat generation in the
computing process},
IBM J.\ Res.\ Dev.\ \textbf{5}, 183 (1961).

\bibitem{Lindblad1976}
G.~Lindblad,
\emph{On the generators of quantum dynamical semigroups},
Commun.\ Math.\ Phys.\ \textbf{48}, 119 (1976).

\bibitem{Nakajima1958}
S.~Nakajima,
\emph{On quantum theory of transport phenomena},
Prog.\ Theor.\ Phys.\ \textbf{20}, 948 (1958).

\bibitem{Rao1945}
C.~R.~Rao,
\emph{Information and the accuracy attainable in the
estimation of statistical parameters},
Bull.\ Calcutta Math.\ Soc.\ \textbf{37}, 81 (1945).

\bibitem{RivasHuelgaPlenio2014}
\'{A}.~Rivas, S.~F.~Huelga, and M.~B.~Plenio,
\emph{Quantum non-Markovianity: characterization, quantification and detection},
Rep.\ Prog.\ Phys.\ \textbf{77}, 094001 (2014).

\bibitem{SagawaUeda2010}
T.~Sagawa and M.~Ueda,
\emph{Generalized Jarzynski Equality under Nonequilibrium Feedback Control},
Phys.\ Rev.\ Lett.\ \textbf{104}, 090602 (2010).

\bibitem{SagawaUeda2012}
T.~Sagawa and M.~Ueda,
\emph{Fluctuation Theorem with Information Exchange},
Phys.\ Rev.\ Lett.\ \textbf{109}, 180602 (2012).

\bibitem{Schrodinger1944}
E.~Schr\"odinger,
\emph{What is Life?},
Cambridge University Press (1944).

\bibitem{ShaliziCrutchfield2001}
C.~R.~Shalizi and J.~P.~Crutchfield,
\emph{Computational mechanics: Pattern and prediction, structure and simplicity},
J.\ Stat.\ Phys.\ \textbf{104}, 817 (2001).

\bibitem{Shannon1959}
C.~E.~Shannon,
\emph{Coding theorems for a discrete source with a
fidelity criterion},
IRE Nat.\ Conv.\ Rec., Part~4, pp.~142--163 (1959).

\bibitem{Simon1955}
H.~A.~Simon,
\emph{A behavioral model of rational choice},
Quarterly J.\ of Economics \textbf{69}, 99 (1955).

\bibitem{Sims2003}
C.~A.~Sims,
\emph{Implications of rational inattention},
J.\ Monetary Economics \textbf{50}, 665 (2003).

\bibitem{SivakCrooks2012}
D.~A.~Sivak and G.~E.~Crooks,
\emph{Thermodynamic metrics and optimal paths},
Phys.\ Rev.\ Lett.\ \textbf{108}, 190602 (2012).

\bibitem{Spohn1978}
H.~Spohn,
\emph{Entropy production for quantum dynamical semigroups},
J.\ Math.\ Phys.\ \textbf{19}, 1227 (1978).

\bibitem{Tishby2000}
N.~Tishby, F.~C.~Pereira, and W.~Bialek,
\emph{The information bottleneck method},
in Proc.\ 37th Allerton Conf.\ on Communication, Control,
and Computing (1999); arXiv:physics/0004057 (2000).

\bibitem{Zurek2009}
W.~H.~Zurek,
\emph{Quantum Darwinism},
Nature Physics \textbf{5}, 181 (2009).

\bibitem{Zwanzig1960}
R.~Zwanzig,
\emph{Ensemble method in the theory of irreversibility},
J.\ Chem.\ Phys.\ \textbf{33}, 1338 (1960).

\bibitem{vanTrees1968}
H.~L.~van Trees,
\emph{Detection, Estimation, and Modulation Theory},
Part~I, Wiley (1968).

\bibitem{vonFoerster2003}
H.~von Foerster,
\emph{Understanding Understanding: Essays on Cybernetics
and Cognition},
Springer (2003).

\bibitem{Liu2026HAFF_A}
S.~Liu,
\emph{Emergent Geometry from Coarse-Grained Observable Algebras},
Zenodo (2026), DOI: 10.5281/zenodo.18361707.

\bibitem{Liu2026HAFF_B}
S.~Liu,
\emph{Accessibility, Stability, and Emergent Geometry},
Zenodo (2026), DOI: 10.5281/zenodo.18367061.

\bibitem{Liu2026HAFF_C}
S.~Liu,
\emph{Causation, Agency, and Existence},
Zenodo (2026), DOI: 10.5281/zenodo.18391651.

\bibitem{Liu2026HAFF_F}
S.~Liu,
\emph{Temporal Asymmetry as Accessibility Propagation},
Zenodo (2026), DOI: 10.5281/zenodo.18417099.

\bibitem{Liu2026HAFF_G}
S.~Liu,
\emph{Structural Limits of Unification: Accessibility,
Incompleteness, and the Necessity of a Final Cut},
Zenodo (2026), DOI: 10.5281/zenodo.18402908.

\bibitem{Liu2026QRAIF_A}
S.~Liu,
\emph{Algebraic Constraints on the Emergence of Lorentzian Metrics in Entropic Gravity Frameworks},
Zenodo (2026), DOI: 10.5281/zenodo.18525877.

\bibitem{Liu2026QRAIF_B}
S.~Liu,
\emph{Thermodynamic Stability Constraints on the Operator Algebra of Persistent Open Quantum Subsystems},
Zenodo (2026), DOI: 10.5281/zenodo.18525891.

\bibitem{Liu2026QRAIF_C}
S.~Liu,
\emph{The Realizability Bridge: Algebraic Closure in the
Q-RAIF Framework},
Zenodo (2026), DOI: 10.5281/zenodo.18528935.

\bibitem{Liu2026TDOME_I}
S.~Liu,
\emph{Non-Markovian Memory and the Thermodynamic Necessity
of Temporal Accumulation},
Zenodo (2026), DOI: 10.5281/zenodo.18574342.

\bibitem{Liu2026TDOME_II}
S.~Liu,
\emph{Spontaneous Symmetry Breaking of Reference Frames
as a Computational Cost Minimization Strategy},
Zenodo (2026), DOI: 10.5281/zenodo.18579703.

\bibitem{Liu2026TDOME_III}
S.~Liu,
\emph{Fisher Information Geometry and the Thermodynamic Cost
of Self-Referential Calibration},
Zenodo (2026), DOI: 10.5281/zenodo.18591771.

\end{thebibliography}

\end{document}
