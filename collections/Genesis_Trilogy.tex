% ============================================================================
% The Genesis Trilogy
% Complete Collected Volume
% ============================================================================

\documentclass[12pt,a4paper,openany]{book}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amsfonts,amsthm}
\usepackage{physics}
\usepackage{graphicx}
\usepackage[hidelinks]{hyperref}
\usepackage{tikz}
\usepackage{geometry}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{array}
\usepackage{booktabs}
\usepackage{tcolorbox}
\usepackage{xcolor}
\usepackage{caption}
\usepackage{float}

\usetikzlibrary{shapes,arrows}

\geometry{a4paper, margin=1in, headheight=28pt}

\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{constraint}[theorem]{Constraint}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE,RO]{\thepage}
\fancyhead[RE]{\textit{The Genesis Trilogy}}
\fancyhead[LO]{\textit{\leftmark}}
\renewcommand{\headrulewidth}{0.4pt}

\title{
  \vspace{-2cm}
  {\Huge\textbf{The Genesis Trilogy}}\\[1cm]
  {\Large\textit{Emergent Geometry, Algebraic Persistence,\\
  and the Architecture of the Observer}}\\[2cm]
  {\large Complete Collected Volume}\\[0.5cm]
  {\normalsize HAFF \textperiodcentered{} Q-RAIF \textperiodcentered{} T-DOME}
}

\author{
  \textbf{Sidong Liu, PhD}\\[0.5em]
  iBioStratix Ltd\\[0.3em]
  \texttt{sidongliu@hotmail.com}
}

\date{February 2026}

\begin{document}

\frontmatter
\maketitle

\newpage
\thispagestyle{empty}
\vspace*{\fill}
\begin{center}
\textbf{Publication Record}\\[2em]
\begin{tabular}{lll}
\multicolumn{3}{l}{\textbf{Part~I --- HAFF: The Holographic Alaya-Field Framework}} \\[0.5em]
Paper A & DOI: 10.5281/zenodo.18361707 & Emergent Geometry \\
Paper B & DOI: 10.5281/zenodo.18367061 & Accessibility \& Stability \\
Essay C & DOI: 10.5281/zenodo.18374806 & Causation \& Agency \\
Paper D & DOI: 10.5281/zenodo.18388882 & Gravitational Phenomena \\
Paper E & DOI: 10.5281/zenodo.18400066 & Measurement \\
Paper F & DOI: 10.5281/zenodo.18400426 & Temporal Asymmetry \\
Paper G & DOI: 10.5281/zenodo.18402908 & Structural Limits \\
Postscript & DOI: 10.5281/zenodo.18407368 & Closure of Structure \\[1em]
\multicolumn{3}{l}{\textbf{Part~II --- Q-RAIF: Quantum Reference Algebra for Information Flow}} \\[0.5em]
Paper A & DOI: 10.5281/zenodo.18525877 & Lorentzian Metrics \\
Paper B & DOI: 10.5281/zenodo.18525891 & Thermodynamic Stability \\
Paper C & DOI: 10.5281/zenodo.18528935 & Realizability Bridge \\[1em]
\multicolumn{3}{l}{\textbf{Part~III --- T-DOME: Thermodynamic Dynamics of Observer-Memory Entanglement}} \\[0.5em]
Paper I & DOI: 10.5281/zenodo.18574342 & Non-Markovian Memory \\
Paper II & DOI: 10.5281/zenodo.18579703 & Symmetry Breaking \\
Paper III & DOI: 10.5281/zenodo.18591771 & Self-Referential Calibration \\
\end{tabular}
\\[3em]
\textit{This collected volume compiles previously published works\\
for archival and reference purposes.}
\\[2em]
\copyright{} 2026 Sidong Liu. All rights reserved.
\end{center}
\vspace*{\fill}

\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}

This volume collects the thirteen papers and postscript comprising the Genesis Trilogy---a programme that investigates, from first principles, the minimal structural conditions under which physical descriptions, persistent agents, and self-referential observers can arise within quantum theory.

The programme is organised in three parts:

\begin{enumerate}
\item \textbf{Part~I: HAFF} (Papers A--G, Essay~C, Postscript).
  The Holographic Alaya-Field Framework treats the tensor factorisation of Hilbert space as a derived, rather than assumed, structure.  Starting from a single global quantum state and coarse-grained observable algebras, it demonstrates that:
  (a)~emergent geometry, locality, and topology follow from algebraic accessibility;
  (b)~gravitational phenomena arise as evolution \emph{of} the accessible algebra;
  (c)~measurement is selection \emph{within} the accessible algebra;
  (d)~temporal asymmetry is a propagation property of informational redundancy; and
  (e)~the framework is structurally incomplete---it cannot self-ground its own starting point.
  This incompleteness motivates Parts~II and~III.

\item \textbf{Part~II: Q-RAIF} (Papers A--C).
  The Quantum Reference Algebra for Information Flow asks what algebraic structure a persistent subsystem must possess if it is to survive within the geometry established by Part~I.  The three papers show that:
  (a)~boundary algebras compatible with emergent Lorentzian geometry must respect three constraints (associativity, metric compatibility, indefinite signature), selecting Clifford algebra $Cl(1,3)$;
  (b)~thermodynamic stability of a non-equilibrium steady state requires a Clifford control algebra $Cl(V,q)$ for Lyapunov-stable channel discrimination; and
  (c)~realizability forces the internal algebra to embed in the environmental algebra, $Cl(V,q) \hookrightarrow Cl(1,3)$---algebraic natural selection.

\item \textbf{Part~III: T-DOME} (Papers I--III).
  The Thermodynamic Dynamics of Observer-Memory Entanglement characterises the internal architecture that makes persistence possible.  The three papers trace an irreversible logic chain:
  (a)~\emph{Memory}: Markovian dynamics impose a survival ceiling; non-Markovian memory (temporal accumulation) is necessary, but creates a memory catastrophe under finite resources;
  (b)~\emph{Ego}: bounded computation forces spontaneous symmetry breaking of the agent's reference frame, enabling tractable processing but introducing systematic bias; and
  (c)~\emph{Loop}: the agent's own prediction-residual stream carries a Fisher-information signal that enables self-referential calibration, with an explicit thermodynamic cost.
\end{enumerate}

Together, the three parts establish a \textbf{Four-Part Structure Proposition}: within the class of agents satisfying the standing assumptions, a sufficient architecture for persistent far-from-equilibrium existence comprises (1)~an external observable geometry, (2)~an internal control algebra, (3)~a self-monitoring Lyapunov function, and (4)~biased non-Markovian memory.

Each layer is the necessary resolution of the previous layer's survival crisis, and simultaneously the source of the next crisis.  The programme terminates when the self-referential loop closes: beyond that point, the framework's own structural incompleteness---identified in HAFF Paper~G---precludes further internal completion.

\bigskip
\noindent\textbf{Keywords}: emergent geometry, accessible algebras, coarse-graining, Clifford algebra, algebraic natural selection, non-Markovian dynamics, spontaneous symmetry breaking, Fisher information, self-referential calibration, Lyapunov stability, thermodynamic cost

\tableofcontents

\mainmatter


% ============================================================================
% PART I: HAFF
% ============================================================================
\part{HAFF: The Holographic Alaya-Field Framework}
\label{part:HAFF}

% ============================================================================
% Paper A
% ============================================================================
\chapter{Emergent Geometry from Coarse-Grained Observable Algebras}
\label{H-chap:paperA}

\begin{center}
\textit{Paper A}\\[0.5em]
Originally published: Zenodo, DOI: 10.5281/zenodo.18361707
\end{center}

\bigskip

\noindent\textbf{Preliminary Remark (Structural Stance).}
In much of modern theoretical physics, it is tacitly assumed that the decomposition of a system into subsystems is either physically given or at least unproblematic. 
Hilbert spaces are factorized, degrees of freedom are labeled, and geometry is inferred from relations between these parts.

In this work, we adopt a different structural stance. 
We treat the universal quantum state as given, but regard subsystem structure, locality, and geometry as secondary constructs arising from restrictions on observable algebras. 
The guiding question is not how geometry emerges from quantum states, but how different effective realities can emerge from the \emph{same} state once no preferred factorization is assumed.

This shift is modest in formalism but radical in implication: it relocates the origin of structure from states to algebras, and from kinematics to accessibility.

\medskip

\section*{Abstract}

We construct a theoretical framework where the tensor factorization of a Hilbert space is treated as a dynamical variable rather than a kinematic background. 
By lifting the ``Alaya'' concept to a globally entangled vacuum state $|\Psi_{\text{vac}}\rangle$, we demonstrate that local geometry emerges from specific observable subalgebras $\mathcal{A}_i \subset \mathcal{B}(\mathcal{H})$. 
We prove that non-commuting coarse-graining maps induce topologically distinct emergent spacetimes from the same underlying state.
The analysis is structural in nature: we do not propose new dynamics, but examine consistency and consequences of removing subsystem factorization from fundamental assumptions. 
This approach is complementary to existing interpretational frameworks and suggests natural connections to algebraic quantum field theory, entanglement-based approaches to spacetime, and quantum information theory.


\section{Introduction}

\subsection{Motivation}

Two central problems in contemporary theoretical physics concern the emergence of classicality and the emergence of geometry. 
In quantum foundations, the measurement problem asks how effectively classical behavior arises from an underlying quantum description. 
Decoherence theory has provided a powerful account of this process by explaining the suppression of interference between certain degrees of freedom through environmental entanglement \cite{Zurek2003}. 
However, this explanation typically presupposes a fixed decomposition of the total system into subsystems, distinguishing ``system,'' ``apparatus,'' and ``environment'' from the outset.

A closely related emergence problem appears in quantum gravity. 
A growing body of work suggests that spacetime geometry is not fundamental, but arises from patterns of quantum entanglement \cite{Maldacena1999,VanRaamsdonk2010}. 
In holographic settings, geometric quantities are related to entanglement measures via precise correspondences, most notably the Ryu--Takayanagi formula \cite{RyuTakayanagi2006}. 
Yet these constructions likewise assume a prior specification of spatial regions or tensor factors, with geometry inferred only after such a subdivision has been fixed.

In both contexts, the emergence problem is addressed only after a subsystem decomposition has been assumed.
The structure responsible for classicality or geometry is therefore explained relative to a partition whose origin remains largely unexamined.

\subsection{The Structural Gap}

The assumption of a given subsystem structure is often treated as innocuous, or as a matter of convenient description. 
However, from a fundamental perspective, there is no canonical tensor factorization of a generic Hilbert space, nor a unique way to decompose a global quantum state into subsystems.
While this issue is occasionally acknowledged in passing \cite{Zanardi2004,Viola2004}, its consequences for emergence are rarely explored systematically.

The present work does not challenge the empirical success of decoherence theory, entanglement-based approaches to geometry, or the algebraic formulation of quantum theory.
Rather, we make explicit a structural assumption common to these frameworks and investigate the consequences of relaxing it.
Our focus is on what follows if subsystem structure itself is treated as emergent, rather than fundamental.

\subsection{Our Contribution}

We formulate a framework in which subsystem structure is not assumed \emph{a priori}, but arises from a choice of coarse-graining over observable algebras.
Within this framework, we show that different coarse-grainings of the same global quantum state generically induce inequivalent effective geometries.
We further clarify why this inequivalence cannot be reduced to a coordinate transformation, but reflects a genuine multiplicity of effective structures at the emergent level.

The analysis is structural in nature.
Our aim is not to propose a new dynamical mechanism, but to examine the consistency and consequences of removing subsystem factorization from the set of fundamental assumptions.

\subsection{Terminology: The Alaya-Field}

Throughout this work, we adopt the term \emph{Alaya-Field} to denote the fundamental, non-factorized structure prior to any subsystem decomposition.
This terminology, borrowed from Yog\=ac\=ara philosophy (referring to the ``storehouse consciousness''), is used here strictly in a technical sense.

In what follows, the Alaya-Field does not refer merely to a vector in Hilbert space, but to the triple
\[
(\mathcal{H}_U, \mathcal{A}_U, |\Omega\rangle),
\]
where $\mathcal{A}_U$ is a von Neumann algebra acting on $\mathcal{H}_U$ and $|\Omega\rangle$ is a cyclic and separating vector.
The emphasis is on the absence of a canonical factorization, not on the particular choice of state.

Mathematically, this corresponds to the cyclic vector of a Type III$_1$ von Neumann algebra in algebraic quantum field theory \cite{Haag1996}, representing a holistically entangled substrate containing the localized ``seeds'' (eigenmodes) of all possible emergent geometries.
This usage is intended to evoke the non-factorized, pre-geometric nature of the fundamental quantum structure, without importing any metaphysical commitments.

\subsection{Structure of the Paper}

The paper is organized as follows.
In Section~\ref{H-sec:A-nopref}, we review the absence of a canonical subsystem decomposition in quantum theory and formalize this observation.
Section~\ref{H-sec:A-coarse} introduces coarse-graining in terms of observable algebras and analyzes how effective subsystem descriptions arise from this procedure.
In Section~\ref{H-sec:A-geometry}, we show how entanglement relations between these induced subsystems give rise to an effective notion of connectivity and geometry, and demonstrate the dependence of this geometry on the chosen coarse-graining.
Section~\ref{H-sec:A-discussion} discusses the scope and conceptual implications of the framework, its relation to existing approaches, and possible directions for future work.
We conclude in Section~\ref{H-sec:A-conclusion} with a summary of results and open questions.

\section{Absence of Canonical Tensor Factorization}
\label{H-sec:A-nopref}

\subsection{The Factorization Problem}

In standard quantum mechanics, the state space of a composite system is constructed as a tensor product of subsystem Hilbert spaces. 
This construction presupposes that a natural decomposition into subsystems has already been identified. 
However, for a given Hilbert space $\mathcal{H}_{\text{total}}$, there is no unique or canonical way to express it as a tensor product $\mathcal{H}_A \otimes \mathcal{H}_B$ without additional physical input.

\begin{theorem}[Absence of Canonical Tensor Factorization]
\label{H-thm:A-nofact}
Let $\mathcal{H}_{\text{total}}$ be a finite or separable infinite-dimensional Hilbert space, and let
\[
|\Psi_U\rangle \in \mathcal{H}_{\text{total}}
\]
be a pure state.
Assume that for every nontrivial tensor factorization
\[
\mathcal{H}_{\text{total}} = \mathcal{H}_A \otimes \mathcal{H}_B
\]
the reduced state $\rho_A = \mathrm{Tr}_B(|\Psi_U\rangle\langle\Psi_U|)$ has nonzero von Neumann entropy.
Then there exists \textbf{no unique or canonically preferred tensor factorization} of $\mathcal{H}_{\text{total}}$ into subsystems relative to which $|\Psi_U\rangle$ is separable or weakly entangled.
In particular, any two such factorizations are related by a global unitary transformation that does not preserve subsystem structure.
\end{theorem}

\begin{proof}[Proof sketch]
\begin{enumerate}
\item Assume by contradiction that there exists a canonically preferred factorization $\mathcal{H}_{\text{total}} = \mathcal{H}_A \otimes \mathcal{H}_B$.
\item Such a factorization defines a preferred subalgebra $\mathcal{A} = \mathcal{B}(\mathcal{H}_A) \otimes \mathbf{1}_B$.
\item However, for a generic pure state $|\Psi_U\rangle$, the entanglement entropy $S(\rho_A)$ is near maximal (Page theorem \cite{Page1993}), implying that no subsystem observables associated with $\mathcal{A}$ admit an interpretation as localized or weakly correlated degrees of freedom.
\item Moreover, it is known that for any given pure state, one can construct infinitely many inequivalent tensor factorizations related by global unitaries $U \in \mathcal{U}(\mathcal{H}_{\text{total}})$ such that:
\[
|\Psi_U\rangle = U(|\psi_A\rangle \otimes |\psi_B\rangle)
\]
for suitably chosen factorizations.
\item Therefore, separability or locality cannot single out a preferred factorization without introducing additional structure external to $|\Psi_U\rangle$.
\item Hence, no canonical tensor factorization exists. \qed
\end{enumerate}
\end{proof}

\begin{remark}[Relation to prior work]
The observation that tensor product structures are not canonical was recognized early in the foundations of quantum theory, and has been systematically analyzed by Zanardi and collaborators \cite{Zanardi2001,Zanardi2004} in the context of quantum error correction and noiseless subsystems.
Their work demonstrated that subsystem decompositions are effectively determined by sets of accessible observables rather than being intrinsic to the Hilbert space.
The present framework extends this perspective to the context of holographic geometry and entanglement-based spacetime emergence, where the choice of observable algebra determines not only subsystem structure but also the emergent geometric description.
\end{remark}

\begin{remark}
We do not claim that subsystem decompositions are impossible or unphysical, but that they are not uniquely determined by the universal quantum state alone. 
This observation motivates the search for additional structure that specifies how a subsystem decomposition arises in concrete physical contexts.
\end{remark}

\subsection{Relation to Algebraic Approaches}

The absence of a canonical factorization has been recognized in various contexts, including algebraic quantum field theory where observable algebras take precedence over tensor product structures \cite{Haag1996}.
Our framework builds on these insights by treating coarse-graining structure as the fundamental input from which subsystem decompositions emerge.

\section{Observer-Dependent Coarse-Graining and Effective States}
\label{H-sec:A-coarse}

\subsection{Coarse-Graining Structure}

Before introducing the formal definition, we emphasize that the introduction of an observable algebra does not reinstate a tensor factorization. 
Operators may act irreducibly on $\mathcal{H}_{\text{total}}$ without inducing any subsystem decomposition. 
In algebraic quantum field theory, observable algebras are defined independently of any global tensor product structure \cite{Haag1996}.
Furthermore, a coarse-graining is not selected by an agent, but instantiated by a concrete physical interaction structure.

\begin{definition}[Operational Coarse-Graining Structure]
\label{H-def:A-coarse}
Let $\mathcal{H}_U$ be the universal Hilbert space. 
A \textbf{coarse-graining structure} $\mathbf{c}$ is defined as a pair
\[
\boxed{\mathbf{c} \equiv (\mathcal{A}_{\mathbf{c}}, \Phi_{\mathbf{c}})}
\]
where:
\begin{enumerate}
\item $\mathcal{A}_{\mathbf{c}} \subset \mathcal{B}(\mathcal{H}_U)$ is an \textbf{accessible observable algebra}, a $*$-subalgebra that is physically realizable and closed under operationally feasible combinations.
\item $\Phi_{\mathbf{c}}: \mathcal{B}(\mathcal{H}_U) \to \mathcal{B}(\mathcal{H}_{\text{eff}}(\mathbf{c}))$ is a completely positive trace-preserving (CPTP) map implementing an operational reduction of the universal state.
We specifically restrict attention to maps $\Phi$ that preserve the identity and reflect a loss of access to specific degrees of freedom (e.g., restriction to a von Neumann subalgebra, or partial trace over hidden factors).
\end{enumerate}
\end{definition}

\begin{remark}[Non-uniqueness of observable algebras]
It is important to note that the specification of an observable algebra $\mathcal{A}_{\mathbf{c}}$ is not assumed to be unique. 
In algebraic quantum field theory and quantum information theory, there exists no theorem guaranteeing a unique maximal observable algebra associated with a given physical system without additional structure. 
The coexistence of multiple admissible algebras reflects physical underdetermination rather than subjectivity or observer dependence.
\end{remark}

\subsection{Refinement Structure of Coarse-Grainings}

\begin{definition}[Refinement Relation]
\label{H-def:A-refine}
Given two coarse-graining structures $\mathbf{c}_1, \mathbf{c}_2$, we say $\mathbf{c}_1 \succeq \mathbf{c}_2$ if there exists a CPTP map
\[
\Lambda: \mathcal{B}(\mathcal{H}_{\text{eff}}(\mathbf{c}_1)) \to \mathcal{B}(\mathcal{H}_{\text{eff}}(\mathbf{c}_2))
\]
such that
\[
\Phi_{\mathbf{c}_2} = \Lambda \circ \Phi_{\mathbf{c}_1}
\]
In this case, $\mathbf{c}_2$ is a \textbf{further coarse-graining} of $\mathbf{c}_1$.
\end{definition}

\begin{remark}[Multiplicity of coarse-graining maps]
For a fixed observable algebra $\mathcal{A}_{\mathbf{c}}$, there generally exist multiple completely positive trace-preserving maps implementing distinct coarse-graining procedures. 
The present framework does not require the selection of a preferred CPTP map. 
Rather, different maps correspond to physically realizable information-loss mechanisms, such as tracing over inaccessible degrees of freedom or effective decoherence channels.
\end{remark}

Different coarse-graining choices are related not by unitary symmetry, but by information-theoretic refinement maps, forming a partially ordered structure rather than a group.

\subsection{Core Theorem}

\begin{theorem}[Coarse-graining Induced Inequivalence]
\label{H-thm:A-inequiv}
Let $|\Psi_U\rangle \in \mathcal{H}_{\text{total}}$ be a universal quantum state. 
Consider two distinct coarse-graining structures $\mathbf{c}_1 = (\mathcal{A}_1, \Phi_1)$ and $\mathbf{c}_2 = (\mathcal{A}_2, \Phi_2)$.
If $\mathbf{c}_1 \not\sim \mathbf{c}_2$ (i.e., they are not related by unitary equivalence), then:
\begin{enumerate}
\item[(a)] The effective Hilbert spaces are inequivalent: $\mathcal{H}_{\text{eff}}(\mathbf{c}_1) \not\cong \mathcal{H}_{\text{eff}}(\mathbf{c}_2)$
\item[(b)] The induced POVM structures are incompatible: $\{\hat{E}_\alpha^{(1)}\} \neq \{\hat{E}_\beta^{(2)}\}$
\item[(c)] The entanglement structures differ: $S_A^{(1)}(\rho_{\text{eff}}^{(1)}) \neq S_A^{(2)}(\rho_{\text{eff}}^{(2)})$ for generic subsystems $A$.
\end{enumerate}
\end{theorem}

\begin{proof}[Proof sketch]
By definition, $\Phi_1$ and $\Phi_2$ implement distinct information compressions.
This induces distinct reduced states: $\rho_1 = \Phi_1(|\Psi_U\rangle\langle\Psi_U|) \neq \rho_2 = \Phi_2(|\Psi_U\rangle\langle\Psi_U|)$.
Since entanglement entropy is a faithful measure of information structure, different compressions yield different entanglement patterns.
By the refinement relation (Definition~\ref{H-def:A-refine}), no unitary can relate them unless $\mathbf{c}_1 \succeq \mathbf{c}_2$ or vice versa.
\end{proof}

\begin{remark}[Relation to decoherence theory]
We emphasize that the present framework is fully compatible with standard decoherence theory and does not modify its dynamical content. 
Decoherence successfully explains the emergence of classical behavior given a fixed system--environment decomposition. 
The novelty of the present approach lies instead in treating such subsystem decompositions as coarse-graining--dependent and not fundamental.
\end{remark}

\subsection{Clarification on Subsystem Structure}

Subsystems are not fundamental inputs to the framework, but derived representations induced by a chosen observable algebra. 
The connectivity measure defined in Section~\ref{H-sec:A-geometry} acts on these representations, and is not used to define the algebra itself. 
The causal order is:
\[
\text{Observable Algebra} \to \text{Representation} \to \text{Entanglement} \to \text{Connectivity} \to \text{Geometry}
\]
No geometric structure is presupposed in the definition of coarse-graining.

\subsection{Algebraic Perspective on Subsystems}

A potential concern is whether the use of observable algebras implicitly presupposes a subsystem decomposition. 
We stress that this is not the case. 
Observable algebras need not be defined via a tensor factorization of the total Hilbert space.

In algebraic quantum field theory, local algebras are assigned to spacetime regions without invoking a global tensor product structure \cite{Haag1996}. 
Subsystems arise only at the level of representations induced by a chosen algebra, rather than serving as its foundational input. 
In this sense, subsystem structure is emergent rather than fundamental.

\begin{remark}[Subsystems as induced representations]
Within the present framework, subsystems are not primitive entities. 
They emerge as representations associated with a given observable algebra and coarse-graining structure. 
This avoids circularity by reversing the usual explanatory order: observable structure precedes subsystem identification.
\end{remark}

\section{Entanglement Structure and Emergent Geometry}
\label{H-sec:A-geometry}

\subsection{Mutual Information as Connectivity Measure}

We stress that no geometric structure is assumed in the definition of the coarse-graining introduced in Section~\ref{H-sec:A-coarse}. 
Geometry only appears at the level of entanglement relations between the induced subsystems.

Given a coarse-graining structure $\mathbf{c} = (\mathcal{A},\Phi)$ as defined in Section~\ref{H-sec:A-coarse}, the universal quantum state $|\Psi_U\rangle$ induces a family of effective subsystems $\{A,B,\dots\}$ associated with subalgebras of $\mathcal{A}$.
For any such pair of subsystems $A$ and $B$, we consider the quantum mutual information
\begin{equation}
I_{\mathbf{c}}(A:B) = S_{\mathbf{c}}(A) + S_{\mathbf{c}}(B) - S_{\mathbf{c}}(AB),
\end{equation}
where $S_{\mathbf{c}}(\cdot)$ denotes the von Neumann entropy computed after coarse-graining.

\begin{definition}[Entanglement-Induced Connectivity]
\label{H-def:A-connectivity}
Let $A$ and $B$ be two disjoint subsystems induced by $\mathbf{c}$.
We define an effective \textbf{proximity measure} $\mu_{\mathbf{c}}(A,B)$ based on the quantum mutual information:
\begin{equation}
\mu_{\mathbf{c}}(A,B) := I_{\mathbf{c}}(A:B) = S(\rho_A) + S(\rho_B) - S(\rho_{AB}).
\end{equation}
While $\mu_{\mathbf{c}}$ does not itself constitute a metric (as it violates the triangle inequality), it induces a weighted topology where highly correlated degrees of freedom are effectively ``closer.''
The emergent metric $g_{ab}$ is derived from the infinitesimal variation of this measure under perturbations of the coarse-graining, analogous to the definition of the Quantum Fisher Information Metric (QFIM) \cite{Petz1996}.
\end{definition}

This quantity should be understood as a \emph{connectivity measure} rather than a fundamental spacetime distance.
In general, mutual information does not define a metric on arbitrary quantum subsystems.
However, it acquires a natural geometric interpretation under physically motivated assumptions, which we make explicit below.

\paragraph{Assumptions.}
Throughout this section, we restrict attention to coarse-grainings that satisfy a geometric admissibility condition:

\begin{definition}[Geometric Admissibility]
\label{H-def:A-geoadmit}
A coarse-graining structure $\mathbf{c}$ is said to be \textbf{geometrically admissible} if the induced mutual information satisfies:
\begin{enumerate}
\item \emph{Finite correlation length:} The state $|\Psi_U\rangle$ exhibits exponentially decaying correlations with respect to the induced subsystems, as is typical for gapped systems, ground states of local Hamiltonians, and holographic large-$N$ states.
\item \emph{Monotonic decay under refinement:} Mutual information decreases monotonically as subsystems become more refined.
\item \emph{Stability under perturbations:} The entanglement structure is robust under small perturbations of $\Phi_{\mathbf{c}}$.
\end{enumerate}
\end{definition}

Not all coarse-grainings admit a geometric interpretation. 
Geometry is not generic; it is a \emph{special phase} of information organization.
We further assume coarse-graining consistency: all entropic quantities are computed using a single coarse-graining structure $\mathbf{c}$, avoiding any mixing of inequivalent observable algebras.

Under these assumptions, the entanglement-induced connectivity $\mu_{\mathbf{c}}(A,B)$ is non-negative, symmetric, and vanishes if and only if the subsystems are uncorrelated at the level resolved by $\mathbf{c}$.
Moreover, in regimes where mutual information decays monotonically with separation, $\mu_{\mathbf{c}}$ induces an effective notion of spatial proximity.

\begin{remark}
The connectivity $\mu_{\mathbf{c}}(A,B)$ should be understood as an \emph{effective, coarse-graining--dependent measure of correlation}, rather than a fundamental spacetime metric.
A true metric structure emerges only in the continuum limit via the QFIM construction.
\end{remark}

In the continuum limit of densely overlapping subsystems, the collection of connectivity measures $\{\mu_{\mathbf{c}}(A,B)\}$ defines a weighted graph structure which, under appropriate conditions, admits a geometric interpretation via the quantum Fisher information metric \cite{Petz1996}, as we now outline.

\subsection{From Entanglement to Geometry}

The idea that spacetime geometry is encoded in quantum entanglement has been explored extensively in the context of holography.
In particular, the Ryu--Takayanagi formula relates the entanglement entropy of a boundary region $A$ to the area of an extremal surface $\gamma_A$ in the bulk \cite{RyuTakayanagi2006},
\begin{equation}
S(A) = \frac{\mathrm{Area}(\gamma_A)}{4G_N},
\end{equation}
suggesting a direct correspondence between entanglement structure and geometric data.

More generally, Van Raamsdonk has argued that the connectivity of spacetime is controlled by the pattern of entanglement between subsystems \cite{VanRaamsdonk2010}.
In this perspective, highly entangled degrees of freedom correspond to nearby regions in the emergent geometry, while weakly entangled subsystems are geometrically distant.

The entanglement-induced connectivity $\mu_{\mathbf{c}}(A,B)$ provides a concrete realization of this idea.
Given a collection of subsystems induced by $\mathbf{c}$, the mutual information defines a weighted graph whose vertices correspond to subsystems and whose edge weights encode entanglement strength.

In tensor network constructions such as MERA, similar entanglement graphs admit a natural geometric interpretation, with graph distance approximating continuum spatial distance \cite{Swingle2012}.
Taking an appropriate continuum limit, one recovers an effective Riemannian manifold whose metric reflects the underlying entanglement structure.

In this sense, geometry emerges not as an additional postulate, but as an effective description of how information is distributed and shared among coarse-grained degrees of freedom.

\subsection{Coarse-Graining Dependence of Geometry}

We now turn to the central observation of this section: the emergent geometry depends essentially on the choice of coarse-graining structure.

\begin{theorem}[Coarse-graining dependent geometry]
\label{H-thm:A-geom}
Let $\mathbf{c}_1$ and $\mathbf{c}_2$ be two inequivalent coarse-graining structures, as defined in Section~\ref{H-sec:A-coarse}, acting on the same global quantum state $|\Psi_U\rangle$.
Then the induced connectivity functions $\mu^{(1)}$ and $\mu^{(2)}$ are generically not related by a diffeomorphism, and give rise to inequivalent emergent geometries.
\end{theorem}

\begin{proof}
Let $\mathcal{A}_1, \mathcal{A}_2 \subset \mathcal{B}(\mathcal{H}_U)$ be the observable algebras associated with coarse-grainings $\mathbf{c}_1, \mathbf{c}_2$.
Since $\mathbf{c}_1 \not\sim \mathbf{c}_2$, there exists no unitary $U$ such that $U \mathcal{A}_1 U^\dagger = \mathcal{A}_2$.
The entropy of a region $R$ in the emergent geometry is given by $S(R) = -\mathrm{Tr}(\rho_R \log \rho_R)$ where $\rho_R = \Phi|_{\mathcal{A}_R}(|\Psi\rangle\langle\Psi|)$.
Since the restriction maps $\Phi_1 \neq \Phi_2$ define distinct states on the subalgebra level, the entanglement entropy profiles $S_1(x)$ and $S_2(x)$ will differ functionally.

Entanglement entropy profiles encode geometric data in a wide class of systems. 
In holographic theories this relation is made precise by the Ryu--Takayanagi formula $S(R) \sim \text{Area}(\gamma_R)/4G_N$ \cite{RyuTakayanagi2006}, while more generally it is reflected in the emergence of effective distance measures from entanglement decay.
Thus distinct entropy profiles imply distinct area functionals and hence distinct metrics $g_{\mu\nu}^{(1)} \neq g_{\mu\nu}^{(2)}$.
\end{proof}

A simple conceptual illustration is provided by contrasting spatial coarse-graining with momentum-space coarse-graining.
In the former case, entanglement typically obeys an area law and supports a local, connected geometry.
In the latter, long-range entanglement is generic, leading to a highly non-local entanglement graph and a qualitatively different emergent geometry.
Importantly, both descriptions arise from the same underlying state $|\Psi_U\rangle$.

Thus, the geometry inferred from entanglement is not an intrinsic property of the quantum state alone, but depends on how information is rendered accessible through coarse-graining.

\subsection{Beyond Coordinate Choice}

It is important to distinguish the dependence described above from an ordinary change of coordinates.
A diffeomorphism acts within a fixed algebra of observables, preserving the underlying notion of what is measurable.
By contrast, a change of coarse-graining alters the observable algebra itself, modifying which correlations are accessible and how subsystems are defined.

These are categorically distinct operations.
Since the algebra of observables differs, the resulting geometries cannot be related by a mere diffeomorphism.
In extreme cases, changes in coarse-graining may even alter basic connectivity properties of the emergent space.

We return to the conceptual implications of this distinction in the Discussion.

\begin{figure}[ht]
\centering
\begin{tikzpicture}[>=stealth, auto, node distance=3cm]
    % Styles
    \tikzstyle{state} = [circle, draw, thick, fill=gray!10, minimum size=2.5cm, align=center]
    \tikzstyle{filter} = [rectangle, draw, thick, fill=white, minimum width=2.5cm, minimum height=1cm]
    \tikzstyle{geo} = [ellipse, draw, thick, dashed, minimum width=2.5cm, minimum height=1.5cm, align=center]
    
    % Nodes
    \node[state] (Alaya) {Global State\\$|\Psi_{\text{vac}}\rangle$\\(Alaya-Field)};
    
    \node[filter] (Filter1) [below left of=Alaya, xshift=-1cm, yshift=-1cm] {Algebra $\mathcal{A}_1$};
    \node[filter] (Filter2) [below right of=Alaya, xshift=1cm, yshift=-1cm] {Algebra $\mathcal{A}_2$};
    
    \node[geo] (Geo1) [below of=Filter1, yshift=-1cm] {Geometry $M_1$\\($g_{\mu\nu}^{(1)}$)};
    \node[geo] (Geo2) [below of=Filter2, yshift=-1cm] {Geometry $M_2$\\($g_{\mu\nu}^{(2)}$)};
    
    % Arrows
    \draw[->, thick] (Alaya) -- node[left, font=\footnotesize] {Coarse Grain $\Phi_1$} (Filter1);
    \draw[->, thick] (Alaya) -- node[right, font=\footnotesize] {Coarse Grain $\Phi_2$} (Filter2);
    
    \draw[->, double, thick] (Filter1) -- node[left, font=\footnotesize] {Induces} (Geo1);
    \draw[->, double, thick] (Filter2) -- node[right, font=\footnotesize] {Induces} (Geo2);
    
    % Interaction
    \draw[<->, dotted, very thick] (Geo1) -- node[below, font=\footnotesize] {Inequivalent ($M_1 \not\cong M_2$)} (Geo2);

\end{tikzpicture}
\caption{Schematic of the HAFF structure. A single global state $|\Psi_{\text{vac}}\rangle$ (Alaya) projects into topologically distinct emergent spacetimes ($M_1, M_2$) depending on the choice of observable algebra ($\mathcal{A}_1, \mathcal{A}_2$). This illustrates that geometry is observer-dependent in the fundamental sense.}
\label{H-fig:haff_scheme}
\end{figure}

\section{Discussion}
\label{H-sec:A-discussion}

\subsection{Relation to Existing Frameworks}

The framework developed in this work is not intended as a replacement for existing interpretational or algebraic approaches to quantum theory.
Rather, it is best understood as orthogonal to several well-established lines of thought, addressing a distinct structural question.
In this section, we briefly clarify its relation to three representative frameworks:

\subsubsection{Relation to QBism}

QBism emphasizes the role of agents and their personal probability assignments in quantum theory, interpreting the quantum state as an expression of subjective belief rather than an objective property of a system.
In contrast, the present framework assumes a single, objective global quantum state throughout.
No agent-dependent elements enter the formalism, and no interpretational commitments regarding belief, experience, or decision theory are required.

The point of contact lies solely in the rejection of a privileged subsystem decomposition.
While QBism attributes this absence to the primacy of the agent, our framework treats it as a structural feature of quantum theory itself.
Coarse-grainings are not chosen by agents, but instantiated by concrete physical interaction structures.
The resulting multiplicity of effective descriptions reflects physical underdetermination rather than subjectivity.

\subsubsection{Relation to Many-Worlds and Decoherence-Based Approaches}

Many-Worlds--type interpretations and decoherence-based accounts provide a compelling explanation of classical behavior within quantum mechanics by analyzing branching structures relative to a fixed subsystem decomposition.
Our framework does not modify this analysis, nor does it introduce an alternative account of branching or classicality.

The difference lies at a prior level.
Decoherence theory presupposes a tensor factorization into system, apparatus, and environment.
Here, we instead ask how such subsystem structures arise in the first place.
In this sense, the framework is complementary to decoherence-based approaches: it leaves their dynamical conclusions intact while removing subsystem factorization from the list of fundamental assumptions.

\subsubsection{Relation to Algebraic Quantum Field Theory}

The closest structural affinity of the present work is with algebraic quantum field theory (AQFT).
In AQFT, observable algebras are taken as primary, and states are defined as positive linear functionals over these algebras, without reliance on a global tensor product structure.
Our use of observable algebras and their representations is directly inspired by this tradition.

The present framework may be viewed as extending this algebraic perspective by emphasizing the role of coarse-graining relations between algebras.
Different choices of coarse-graining induce different effective representations and, consequently, different entanglement structures.
The novelty lies not in the algebraic formalism itself, but in using it to analyze the emergence and non-uniqueness of geometric descriptions.

Taken together, these comparisons situate the present work as a structural investigation into the conditions under which subsystem structure and geometry emerge.
It neither commits to a particular interpretation of quantum mechanics nor proposes a new dynamical law, but instead clarifies how several existing frameworks implicitly rely on assumptions that can be made explicit and, in some cases, relaxed.

\subsection{Scope and Limitations}

The present work is concerned with structural consistency rather than phenomenological prediction. 
Observable consequences depend on the physical mechanisms implementing a given coarse-graining, which lie beyond the scope of this paper. 
This is analogous to effective field theory, where multiple UV completions may share the same low-energy structure. 
Future work will explore concrete physical realizations and their empirical signatures.

\subsection{Philosophical Implications}

We emphasize that the framework assumes a single, objective global quantum state $|\Psi_U\rangle$. 
What is coarse-graining--dependent is not reality itself, but the effective structures used to describe it. 
This position is compatible with scientific realism while acknowledging the role of operational context in physical description.

\subsection{Future Directions}

While the present work is deliberately limited to a structural analysis of subsystem emergence and geometry within a fixed global quantum state, it naturally opens several directions for further investigation. 
We emphasize that the following points are not results established here, but rather indicate possible extensions where the current framework may provide useful conceptual or technical guidance.

\subsubsection{Dynamical Models of Coarse-Graining Selection}

In this work, coarse-graining structures are treated as fixed relational inputs, instantiated by concrete physical interaction patterns. 
A natural next step is to investigate whether such coarse-grainings can themselves be characterized dynamically.

One possible direction is to study how interaction Hamiltonians, coupling strengths, or network topologies bias the emergence of particular subalgebra structures over others. 
This could clarify under what physical conditions certain factorizations become robust or persistent, and whether transitions between inequivalent coarse-grainings admit an effective dynamical description.

Importantly, such an analysis would remain compatible with globally unitary evolution, treating coarse-graining selection as an emergent, effective phenomenon rather than a modification of fundamental dynamics.

\subsubsection{Connections to Quantum Information and Complexity}

The non-uniqueness of emergent geometry highlighted here suggests a close connection to quantum information--theoretic notions such as entanglement structure, operator complexity, and resource constraints.

Future work could explore whether preferred geometric descriptions correlate with informational criteria---for example, minimal description length, stability under noise, or computational accessibility of observables. 
Such considerations may help explain why certain coarse-grainings are physically salient, even when many are formally admissible.

This perspective may also provide a bridge to recent work on complexity-based approaches to spacetime emergence, without committing to any particular complexity measure at the present stage.

\subsubsection{Extensions to Quantum Field Theory and Continuum Limits}

While the framework has been formulated in abstract Hilbert space terms, an important open question concerns its implementation in quantum field--theoretic settings, where issues of locality, algebraic nets, and continuum limits arise.

In particular, it would be valuable to examine how coarse-graining relations between observable algebras interact with the locality structures emphasized in algebraic quantum field theory, and whether familiar spacetime geometries can be recovered as stable fixed points of such relations.

We stress that the present work does not resolve these questions, but provides a structural language in which they can be posed more precisely.

\subsubsection{Empirical and Phenomenological Implications}

At the level developed here, the framework is primarily structural and conceptual. 
Nevertheless, future investigations may ask whether different coarse-graining choices lead to distinguishable effective descriptions, for example in semiclassical regimes, quantum gravity--motivated models, or analogue systems.

Such studies could clarify whether the non-uniqueness of emergent geometry has observable consequences, or whether physical constraints effectively suppress this freedom in realistic settings.

Any empirical analysis would necessarily require additional assumptions beyond those adopted in this work, and thus lies outside its present scope.

\subsubsection{Conceptual Clarifications and Interpretational Interfaces}

Finally, although the framework is intentionally neutral with respect to interpretations of quantum mechanics, it may serve as a useful interface for comparative studies. 
By making explicit the structural assumptions underlying subsystem decomposition and geometry, it could help clarify which features are interpretation-dependent and which arise more generally from the formalism itself.

We view this not as an attempt to adjudicate between interpretations, but as an opportunity to sharpen the questions they address.

\medskip

Taken together, these directions suggest that the framework developed here is best viewed as a scaffold: it does not dictate specific physical models, but provides a structured setting in which questions about subsystems, geometry, and emergence can be formulated with greater precision.

\section{Conclusion}
\label{H-sec:A-conclusion}

We have presented a framework in which subsystem structure is not presupposed, but emerges from coarse-graining over observable algebras. 
The central results are:

\begin{enumerate}
\item A generic quantum state admits no canonical tensor factorization (Theorem~\ref{H-thm:A-nofact}).
\item Different coarse-graining structures induce inequivalent effective subsystem descriptions (Theorem~\ref{H-thm:A-inequiv}).
\item These inequivalent coarse-grainings generically give rise to distinct emergent geometries (Theorem~\ref{H-thm:A-geom}), and this distinction cannot be reduced to coordinate choice.
\end{enumerate}

The framework is deliberately limited in scope. 
We have not proposed new dynamics, derived empirical predictions, or resolved interpretational debates. 
Instead, we have examined the structural consequences of removing subsystem factorization from the list of fundamental assumptions.

This investigation reveals that the emergence of geometry is more context-dependent than often acknowledged. 
Geometry is not an intrinsic property of a quantum state alone, but depends on how information is rendered accessible through coarse-graining. 
This perspective is compatible with, and complementary to, existing approaches including decoherence theory, holographic duality, and algebraic quantum field theory.

Several open questions remain. 
Can coarse-graining structures themselves be characterized dynamically? 
Do informational or complexity-based criteria select physically preferred coarse-grainings? 
Can the framework be extended to quantum field theory and reconciled with standard locality structures? 
These questions lie beyond the present scope, but the structural setting developed here provides a language in which they can be formulated with greater precision.

Ultimately, this work suggests that the relationship between quantum states, subsystems, and geometry is more subtle than the standard picture implies. 
By making explicit an assumption that is often left implicit, we hope to have clarified the conditions under which emergence occurs and opened new avenues for investigating the foundations of quantum theory and spacetime.


% ============================================================================
% Paper B
% ============================================================================
\chapter{Accessibility, Stability, and Emergent Geometry}
\label{H-chap:paperB}

\begin{center}
\textit{Paper B}\\[0.5em]
Originally published: Zenodo, DOI: 10.5281/zenodo.18367061
\end{center}

\bigskip

\section*{Abstract}

This paper provides conceptual clarification of the Holographic Alaya-Field Framework (HAFF) introduced in our previous work. 
We address three potential misreadings: subjectivism (that observers create spacetime), anti-realism (that geometry is illusory), and trivialism (that the framework reduces to coordinate choice). 
By analyzing the structural notion of accessibility via stability conditions, delineating boundaries with existing interpretations (AQFT, RQM, QBism, MWI), and characterizing emergent geometry as a stable organizational phase, we clarify what the framework commits to and what it does not. 
This analysis is purely interpretational; no new formal results are introduced.


\section{Introduction}
\label{H-sec:B-intro}

Our previous work established a framework in which emergent geometry depends on the choice of observable algebra acting on a global quantum state \cite{Liu2026}. 
The technical results—in particular, that inequivalent coarse-graining structures induce inequivalent geometric structures from the same underlying state—are formally precise and mathematically consistent. 
However, structural novelty of this kind is particularly vulnerable to interpretational confusion. 
The present paper addresses these interpretational implications and clarifies the conceptual commitments of the framework.

\subsection{The Risk of Misreading}

The claim that geometry is coarse-graining-dependent naturally invites several misreadings, each of which conflates distinct notions of dependence. 
Three such misreadings are especially common:

\begin{enumerate}
\item \emph{Subjectivism}: The view that observers or agents create spacetime through their choices or beliefs, collapsing the framework into an epistemic or observer-relative interpretation.
\item \emph{Anti-realism}: The view that spacetime has no objective existence, and that emergent geometry is therefore illusory or merely pragmatic.
\item \emph{Trivialism}: The view that coarse-graining-dependent geometry reduces to a choice of coordinates or descriptive convention, with no substantive physical consequences.
\end{enumerate}

Each of these readings is incorrect, but each arises naturally from surface-level features of the formalism. 
The purpose of this paper is to block such misreadings by clarifying the nature of accessibility, the structural role of observable algebras, and the ontological status of emergent geometry within the framework.

\subsection{Scope and Objectives}

This paper does not introduce new formal results, derive additional theorems, or propose modifications to the mathematical structure presented in our previous work. 
Rather, it provides a systematic interpretational analysis aimed at three specific objectives:

\begin{enumerate}
\item \emph{Clarify the notion of accessibility}: We demonstrate that accessibility, as employed in the framework, is a structural and operational concept determined by stability properties of subalgebras, not an epistemic or observer-dependent notion.
\item \emph{Delineate boundaries with existing interpretations}: We situate the framework in relation to algebraic quantum field theory, relational quantum mechanics, QBism, and the Many-Worlds interpretation, clarifying points of agreement, divergence, and complementarity.
\item \emph{Characterize the ontological status of emergent geometry}: We argue that geometry functions as a stable organizational phase of quantum information, analogous to phases in condensed matter systems, avoiding both naive realism and anti-realist eliminativism.
\end{enumerate}

Importantly, this analysis does not constitute a defense of the framework, nor does it aim to persuade readers of its correctness. 
The goal is clarity: to ensure that the structural commitments of the framework are understood on their own terms, and that criticisms, if any, are directed at what the framework actually claims rather than at interpretational projections.

\subsection{What This Paper Does Not Do}

To further delimit scope, we note explicitly what this paper does \emph{not} attempt:

\begin{itemize}
\item It does not propose new dynamics, empirical predictions, or modifications to quantum mechanics.
\item It does not claim that the framework resolves outstanding problems in quantum gravity, quantum foundations, or the measurement problem.
\item It does not advocate for any particular metaphysical or philosophical position beyond the minimal structural commitments required by the formalism itself.
\item It does not interpret the framework as implying idealism, observer-created reality, or any form of mind-dependence.
\end{itemize}

The analysis remains strictly within the domain of structural interpretation: identifying what the mathematical formalism commits to, what it leaves open, and how it relates to existing approaches.

\subsection{Organization}

The paper proceeds as follows. Section~\ref{H-sec:B-stance} briefly recapitulates the structural stance adopted in our previous work, emphasizing the priority of observable algebras over tensor factorizations and the role of coarse-graining in defining effective subsystems. 

Section~\ref{H-sec:B-accessibility} provides a detailed analysis of accessibility, demonstrating that it is determined by stability conditions on subalgebras rather than by observer choices or epistemic limitations. A taxonomy is introduced distinguishing subjective, relational, and structural notions of dependence, situating the present framework firmly within the third category.

Section~\ref{H-sec:B-relations} examines the relationship between the framework and four representative approaches: algebraic quantum field theory, relational quantum mechanics, QBism, and the Many-Worlds interpretation. Each subsection clarifies points of conceptual overlap and structural divergence, preventing conflation while identifying opportunities for complementarity.

Section~\ref{H-sec:B-geometry_phase} argues that emergent geometry should be understood as a stable organizational phase of entanglement structure, drawing on analogies with condensed matter physics. This perspective avoids treating geometry as either fundamental or illusory, instead characterizing it as contingent but objective—dependent on physical conditions rather than epistemic contexts.

Section~\ref{H-sec:B-scope} delimits the structural assumptions of the framework, enumerates what it does not commit to, and outlines open questions for future investigation. Particular attention is given to the distinction between structural analysis and metaphysical advocacy.

\subsection{Methodological Note}

Throughout this paper, we adopt a deliberately conservative rhetorical stance. Claims are hedged with modal qualifiers ("may suggest," "is consistent with," "can be understood as") not out of uncertainty regarding the formal results, but to avoid overstating interpretational conclusions. The goal is to present the framework as one coherent way of organizing the conceptual landscape, not as the uniquely correct interpretation.

This methodological caution reflects a broader commitment: interpretational clarity is best served by precision and restraint, not by advocacy or polemics. We aim to make the framework legible to researchers across different interpretational traditions, facilitating comparison and critique rather than preempting it.

\section{Structural Stance Recap}
\label{H-sec:B-stance}

We briefly recapitulate the structural stance of our previous work without repeating full mathematical derivations.

The framework rests on three formal results:
\begin{enumerate}
\item \textbf{No canonical factorization} (Theorem 1): A generic pure state admits no unique or canonically preferred tensor factorization into subsystems. Any such decomposition requires additional structure beyond the state itself.

\item \textbf{Coarse-graining-induced inequivalence} (Theorem 2): Different choices of observable algebra $\mathcal{A}_{\mathbf{c}}$ acting on the same global state $|\Psi_U\rangle$ induce inequivalent effective subsystem descriptions, characterized by distinct reduced density matrices, entanglement patterns, and POVM structures.

\item \textbf{Geometry dependence} (Theorem 3): Inequivalent coarse-graining structures generically induce inequivalent geometric structures from the same underlying state, which may include distinct topological features in certain cases. This inequivalence cannot be reduced to a diffeomorphism or coordinate transformation, as it reflects differences in the underlying observable algebra.
\end{enumerate}

The conceptual core can be summarized by reversing the standard explanatory arrow:

\begin{center}
\textbf{Standard:} State + Tensor factorization $\to$ Subsystems $\to$ Entanglement $\to$ Geometry
\end{center}

\begin{center}
\textbf{HAFF:} State + Observable algebra $\to$ Effective subsystems $\to$ Entanglement $\to$ Geometry
\end{center}

We emphasize that the observable algebra $\mathcal{A}_{\mathbf{c}}$ is not an arbitrary choice, but is determined by the physical interaction structure encoded in the Hamiltonian, specifying which degrees of freedom couple and how (see Section~\ref{H-sec:B-accessibility} for detailed discussion).

This reversal has a modest but consequential implication: subsystem structure, and consequently geometry, is not intrinsic to the quantum state alone but depends on which observables are accessible—where accessibility is understood in a precise, structural sense developed in the next section.

\section{Accessibility vs Observer-Dependence}
\label{H-sec:B-accessibility}

The notion of accessibility is central to the framework, and it is here that the risk of misreading is greatest. We clarify that accessibility, as employed in HAFF, is a structural property determined by physical stability conditions, not an epistemic or agent-dependent notion.

\subsection{Three Notions of Dependence}

To prevent conflation, we distinguish three distinct senses in which a physical quantity might be said to "depend on" something:

\begin{table}[h]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Type} & \textbf{Depends On} & \textbf{Example} & \textbf{Framework} \\
\hline
Subjective & Agent's beliefs/knowledge & Bayesian probability & QBism \\
Relational & Reference system & Velocity in SR & RQM \\
Structural & Physical interaction pattern & Decoherence basis & HAFF \\
\hline
\end{tabular}
\caption{Taxonomy of dependence notions}
\label{H-tab:dependence}
\end{table}

HAFF's notion of accessibility falls squarely in the third category.

\subsection{Algebraic Grounding of Stability}

To address potential concerns regarding circularity in defining accessibility, we provide an algebraic characterization of stability that does not presuppose factorization or observer-dependent choices.

Consider a subalgebra $\mathcal{A} \subset \mathcal{B}(\mathcal{H})$ acting on the global state $\rho$. We define $\mathcal{A}$ to be \emph{stable} if it satisfies the following criteria:

\paragraph{Criterion 1: Dynamical Invariance.}
Expectation values of operators in $\mathcal{A}$ remain approximately invariant under physically motivated dynamical maps $\mathcal{E}$ (representing decoherence, RG flow, or measurement-induced back-action):
\begin{equation}
\|\mathcal{E}(\hat{O}) - \hat{O}\| \ll \epsilon \quad \forall \hat{O} \in \mathcal{A},
\end{equation}
for suitably small $\epsilon$ set by physical precision.

\paragraph{Criterion 2: Environmental Redundancy (Quantum Darwinism).}
Following Zurek's quantum Darwinism framework \cite{Zurek2009}, stable subalgebras are those whose information is redundantly encoded in environmental degrees of freedom. Formally, the subalgebra $\mathcal{A}$ should approximately commute with the environmental algebra $\mathcal{A}_E$ generated by accessible environmental observables:
\begin{equation}
[\hat{O}, \hat{E}] \approx 0 \quad \forall \hat{O} \in \mathcal{A}, \, \hat{E} \in \mathcal{A}_E.
\end{equation}
This ensures that states in $\mathcal{A}$ act as \emph{pointer states}, robustly imprinted on the environment and thus operationally accessible through multiple independent measurements.

\paragraph{Criterion 3: Non-scrambling Subspace.}
In the language of quantum information scrambling \cite{Hayden2007}, stable algebras correspond to \emph{non-scrambling subspaces}—degrees of freedom that do not rapidly lose local correlations under unitary evolution. Quantitatively, the out-of-time-order correlator (OTOC) associated with operators in $\mathcal{A}$ should exhibit slow decay:
\begin{equation}
\langle [\hat{O}_\mathcal{A}(t), \hat{V}(0)]^2 \rangle \ll 1 \quad \text{for } t \ll \tau_{\text{scrambling}}.
\end{equation}

These criteria are purely algebraic and operational: they refer only to operator commutation relations, dynamical maps, and measurable correlators, without invoking subjective observer choices. Stability, in this sense, is a \emph{structural property} determined by the physical interaction Hamiltonian and the global quantum state.

Multiple stability criteria may select different subalgebras, reflecting different physical regimes (equilibrium vs. out-of-equilibrium, weak vs. strong coupling, etc.). This plurality is a feature analogous to how different symmetry-breaking patterns yield distinct thermodynamic phases.

\begin{tcolorbox}[colback=gray!5!white,colframe=black!75!black,title=\textbf{Remark: The Hamiltonian as Physical Input}]
A potential objection to the structural account of accessibility is that the interaction Hamiltonian $\hat{H}_{\text{int}}$ appears to be an arbitrary input, merely displacing observer-dependence from the algebra to the choice of Hamiltonian. We clarify that this is a misunderstanding of the framework's commitments.

The Hamiltonian is not a free parameter chosen by an observer, but a \emph{physical specification of which degrees of freedom interact and how}. In this respect, it plays a role analogous to the stress-energy tensor $T_{\mu\nu}$ in general relativity: it is input data describing the causal structure of the system, not a coordinate choice or descriptive convention.

Concretely:
\begin{itemize}
\item In quantum optics, $\hat{H}_{\text{int}}$ describes atom-photon coupling strengths and selection rules, determined by atomic energy levels and field modes.
\item In condensed matter systems, it encodes lattice structure, tunneling amplitudes, and interaction potentials, all fixed by material properties.
\item In holographic models (AdS/CFT), the boundary Hamiltonian is determined by the conformal field theory's operator content and coupling constants.
\end{itemize}

The claim is not that observers are irrelevant, but that they do not \emph{create} the interaction structure—they probe it. Different experimental setups may access different subalgebras, but which algebras are stable under given interactions is an objective, physical fact, independent of epistemic context.

This is precisely analogous to how different coordinate systems in general relativity yield different component expressions for the metric $g_{\mu\nu}$, but the spacetime geometry itself (characterized by invariants like the Ricci scalar $R$) is coordinate-independent. Here, different accessible algebras yield different effective descriptions, but which algebras are stable under physical dynamics is interaction-dependent, not observer-dependent.

We emphasize: the framework does not solve the problem of \emph{why} a particular Hamiltonian describes our universe (just as GR does not explain why $T_{\mu\nu}$ has its observed form). That question lies in the domain of fundamental theory or cosmology. What the framework does is analyze the \emph{consequences} of a given interaction structure for emergent subsystem decomposition and geometry.
\end{tcolorbox}

\paragraph{Pre-geometric Interaction Structure.}
A potential concern is that the Hamiltonian $\hat{H}_{\text{int}}$ itself presupposes spacetime structure (e.g., via spatial locality in $\hat{H} = \sum_{i,j} J_{ij} \hat{\sigma}_i \cdot \hat{\sigma}_j$), creating a circular dependence: geometry emerges from algebras determined by a Hamiltonian that already assumes geometry.

We clarify that the Hamiltonian input to HAFF is \emph{pre-geometric}: it is specified as an abstract interaction graph or tensor network, where edges represent couplings and nodes represent degrees of freedom, with no reference to background metric structure. The notion of "locality" in such Hamiltonians is graph-theoretic (e.g., nearest-neighbor on a lattice or tree) rather than metric-geometric.

Crucially, the \emph{effective spacetime geometry} that emerges from stable algebras may differ from the graph structure of the input Hamiltonian. For instance:
\begin{itemize}
\item In tensor network models (MERA), the input is a discrete causal network, but the emergent geometry can be continuous AdS space \cite{Swingle2012}.
\item In spin chain models, the Hamiltonian is defined on a 1D lattice, but entanglement structure can induce higher-dimensional effective geometry.
\item In holographic duality (AdS/CFT), the boundary Hamiltonian is defined on a fixed $(d-1)$-dimensional manifold, but the bulk geometry (including its dimensionality) emerges dynamically.
\end{itemize}

Thus, the input interaction structure constrains but does not uniquely determine the emergent geometry—it serves as a \emph{seed} or \emph{scaffold}, not a blueprint. The framework asks: given a pre-geometric interaction graph, which stable algebras emerge, and what geometric structures do they induce?

This perspective aligns with recent work on "locality from entanglement" \cite{VanRaamsdonk2010}, where spatial locality is itself understood as arising from entanglement patterns rather than being presupposed.

\section{Relations to Existing Interpretations}
\label{H-sec:B-relations}

We now situate HAFF relative to four representative frameworks, clarifying conceptual boundaries and identifying points of potential complementarity.

\subsection{Algebraic Quantum Field Theory (AQFT)}

The closest structural affinity of HAFF is with algebraic quantum field theory \cite{Haag1996,Araki1999}. In AQFT, observable algebras are treated as primary, with states defined as positive linear functionals over these algebras. Crucially, local algebras are assigned to spacetime regions without relying on a global tensor product structure.

HAFF extends this algebraic perspective by emphasizing \emph{coarse-graining relations} between algebras. In standard AQFT, locality is typically presupposed: algebras are indexed by spacetime regions, and the split property ensures independence of spacelike-separated algebras. In HAFF, we relax this assumption and instead treat \emph{stability under physical interactions} as the criterion for algebra selection.

The transformation can be summarized as:
\begin{center}
\textbf{AQFT}: Spacetime regions $\to$ Local algebras $\to$ States \\
\textbf{HAFF}: Interaction structure $\to$ Stable algebras $\to$ Effective geometry
\end{center}

This is not a replacement of AQFT but an exploration of its structure in contexts where spacetime locality is not presupposed. The framework may be understood as asking: what happens to the algebraic approach when we do not assume a background spacetime to index our algebras?

\subsection{Relational Quantum Mechanics (RQM)}

Relational quantum mechanics \cite{Rovelli1996,LaudisaRovelli2021} emphasizes that the values of physical quantities are defined only relative to observer systems, rejecting the notion of absolute, observer-independent observables. In Rovelli's formulation, quantum mechanics is fundamentally a theory of \emph{interactions} rather than systems: what exists are relational facts, not intrinsic properties.

There is significant conceptual overlap with HAFF: both frameworks reject privileged subsystem decompositions and treat quantum descriptions as contextual. However, a key difference concerns the \emph{stabilization of relata}.

RQM analyzes relations between systems whose existence is typically taken as given (or at least presupposed operationally through interaction records). HAFF provides a mechanism for the \emph{stabilization of distinct relata} from the underlying quantum field, identifying which subsystem partitions are robustly maintained under decoherence and measurement-induced dynamics.

In this sense, HAFF may provide the stable nodes required for RQM's relational network: before relations can exist, there must be relata stable enough to participate in interactions. HAFF addresses how such stable relata emerge from the pre-factorized quantum substrate.

These are complementary rather than competing perspectives: RQM asks what observables mean relative to a system, HAFF asks which systems stabilize as distinct relata in the first place. The two frameworks operate at different levels of analysis and could in principle be combined, with HAFF providing the stability conditions under which RQM's relational structure becomes well-defined.

\subsection{QBism}

QBism \cite{Fuchs2014,FuchsMerminSchack2014} interprets quantum states as expressions of an agent's personal beliefs about measurement outcomes, emphasizing the subjective, agent-centric nature of quantum probability assignments.

Here, the distinction from HAFF is sharpest. While both frameworks reject naive realism about the quantum state, they differ fundamentally in their treatment of dependence:

\begin{itemize}
\item \textbf{QBism}: Quantum states represent personal beliefs. Dependence is epistemic and agent-centric.
\item \textbf{HAFF}: Observable algebras are selected by physical interaction structure. Dependence is structural and interaction-centric.
\end{itemize}

The key point is that interactions are not agents: they have no beliefs, make no decisions, and exist independently of any epistemic perspective. The accessible algebra in HAFF is determined by which degrees of freedom couple via the Hamiltonian, not by what any observer happens to know or believe.

We emphasize that this is a categorical difference, not a matter of one framework being "more correct" than the other. QBism and HAFF address different questions and operate within different conceptual frameworks. The point of comparison is simply to clarify that HAFF's notion of accessibility does not reduce to QBist agent-dependence.

\subsection{Many-Worlds Interpretation (MWI)}

The Many-Worlds interpretation \cite{Wallace2012} explains the emergence of classical behavior through decoherence-induced branching, all occurring within globally unitary quantum evolution.

HAFF shares with MWI a commitment to:
\begin{itemize}
\item A single, objective global quantum state
\item Unitary evolution without collapse
\item Effective classicality emerging from entanglement structure
\end{itemize}

However, MWI typically presupposes a tensor factorization into system and environment as input, analyzing how this decomposition gives rise to branch structure. Recent work in the MWI tradition (e.g., Wallace, Saunders) addresses emergent decoherence structure, but typically within a framework where tensor factorization is assumed at the fundamental level.

HAFF complements MWI by examining the preconditions for any branching structure: before branches can emerge, there must be a notion of subsystems relative to which branching occurs. In this sense, HAFF may provide a structural framework relevant to understanding how the effective subsystem decompositions presupposed by branching emerge in the first place.

This is a point of potential contact rather than a hierarchical claim: we do not argue that MWI requires HAFF, but that the two frameworks address distinct but related aspects of quantum structure.

\section{Geometry as a Stable Organizational Phase}
\label{H-sec:B-geometry_phase}

\paragraph{Conceptual Disclaimer.}
Before discussing the analogy with condensed matter phases, we stress that this analogy is \emph{conceptual rather than rigorous}. Unlike in condensed matter, where a Hamiltonian uniquely determines phase structure via symmetry-breaking or RG fixed points, the HAFF framework does not posit a master Hamiltonian governing the selection of accessible algebras. The purpose of the analogy is to clarify how emergent geometry can be understood as a stable organizational pattern of entanglement, highlighting similarities in stability and robustness properties, not to assert a formal one-to-one mapping. We adopt this analogy solely as a heuristic for guiding intuition, and all structural conclusions are derived independently of it.

\paragraph{Contingent Objectivity.}
A central claim of this section is that emergent geometry is \emph{contingent but objective}. This phrasing may initially appear paradoxical, so we clarify its meaning through analogy with thermodynamic quantities.

Consider temperature $T$ in statistical mechanics: it is contingent on the choice of thermodynamic ensemble (microcanonical, canonical, grand canonical), yet within any given ensemble, $T$ is an objective, measurable property determined by the system's microstate distribution. No observer dependence enters once the ensemble is specified—different observers measuring the same ensemble will agree on $T$.

Similarly, in the HAFF framework, emergent geometry is contingent on the choice of accessible algebra $\mathcal{A}_{\mathbf{c}}$, which in turn is determined by the physical interaction structure (as discussed in Section~\ref{H-sec:B-accessibility}). Once $\mathcal{A}_{\mathbf{c}}$ is specified by the coupling pattern encoded in the interaction Hamiltonian, the induced geometry is an objective feature of the entanglement structure: different observers with access to the same algebra will infer the same metric $g_{\mu\nu}$ (up to diffeomorphism).

The contingency lies in the physical conditions that select the algebra—just as temperature depends on which statistical ensemble describes the system's preparation. But \emph{objectivity does not require uniqueness}; it requires only mind-independence given fixed physical context. A quantity can be observer-independent even if multiple such quantities exist under different physical conditions.

This resolves an apparent tension: geometry is not "fundamental" in the sense of being unique and unchanging across all contexts, but it is also not "illusory" or merely conventional. It is a stable, measurable feature of quantum correlations that emerges robustly under appropriate stability conditions, much like crystalline order emerges robustly below a critical temperature.

\subsection{The Phase Analogy}

With these caveats in place, we develop the analogy with condensed matter phases.

In statistical mechanics, different thermodynamic phases (solid, liquid, gas, magnetic, superconducting) represent distinct organizational patterns of microscopic degrees of freedom. These phases are:
\begin{itemize}
\item \textbf{Emergent}: They arise from collective behavior, not from individual constituents.
\item \textbf{Stable}: They persist under perturbations below characteristic energy scales.
\item \textbf{Observable}: They manifest in measurable order parameters.
\item \textbf{Contingent}: They depend on external conditions (temperature, pressure, fields).
\end{itemize}

We propose that emergent geometry in HAFF exhibits analogous features:

\begin{table}[h]
\centering
\begin{tabular}{|l|l|}
\hline
\textbf{Condensed Matter} & \textbf{HAFF} \\
\hline
Hamiltonian $\hat{H}$ & Pre-geometric interaction graph \\
Control parameter (Temperature $T$) & Entanglement density / Scrambling rate \\
Symmetry breaking & Algebra selection \\
Order parameter $\langle M \rangle$ & Entanglement pattern $I(A:B)$ \\
Phase transition & Geometry emergence \\
Critical temperature $T_c$ & Stability threshold $\rho_{\text{crit}}$ \\
\hline
\end{tabular}
\caption{Analogy between condensed matter phases and emergent geometry. The control parameter in HAFF is entanglement density (or equivalently, the scrambling rate in large-$N$ limits), which plays a role analogous to temperature in statistical mechanics. Below a critical entanglement density, stable geometric structures emerge; above it, the system exhibits highly non-local, scrambled correlations with no coherent metric description. These correspondences are illustrative and heuristic, not exact mathematical mappings.\footnotemark}
\label{H-tab:phase}
\end{table}

\footnotetext{In holographic models (AdS/CFT), the analogous control parameter is the ratio $\ell_{\text{AdS}}/\ell_{\text{Planck}}$, which governs the transition from classical bulk geometry to quantum gravitational regime \cite{Maldacena1999}.}

Just as ferromagnetism is a stable organizational pattern of spin alignment below the Curie temperature, geometry may be understood as a stable organizational pattern of entanglement structure under specific accessibility conditions.

\paragraph{Control Parameter and Criticality.}
A key feature of phase transitions is the existence of a \emph{control parameter} (e.g., temperature, pressure, external field) that governs which phase is realized. In the HAFF framework, the analogous control parameter is the \emph{entanglement density} of the global state $|\Psi_U\rangle$, defined operationally as the average mutual information per degree of freedom:
\begin{equation}
\rho_{\text{ent}} \equiv \frac{1}{N} \sum_{\langle i,j \rangle} I(i:j),
\end{equation}
where the sum runs over subsystem pairs and $N$ is the total number of degrees of freedom.

At low entanglement density ($\rho_{\text{ent}} \ll \rho_{\text{crit}}$), the state exhibits area-law scaling, allowing stable geometric descriptions to emerge. At high entanglement density ($\rho_{\text{ent}} \gg \rho_{\text{crit}}$), the state becomes highly scrambled, with volume-law entanglement and no coherent metric structure—analogous to the high-temperature disordered phase in spin systems.

In holographic contexts, this parameter corresponds to the ratio of bulk curvature radius to Planck length, $\ell_{\text{AdS}}/\ell_P$, which controls the transition from semiclassical geometry to stringy/quantum gravity regime \cite{Maldacena1999}.

This perspective suggests that geometry is not merely emergent but \emph{critically emergent}: it appears as a stable organizational pattern only when entanglement structure satisfies specific density constraints, much like crystalline order emerges only below the melting temperature.

\subsection{Geometric Admissibility}

Not all coarse-graining structures admit geometric interpretation. As discussed in our previous work (Definition 4.2), we require geometric admissibility conditions:
\begin{enumerate}
\item Finite correlation length (exponentially decaying correlations)
\item Monotonic decay of mutual information under refinement
\item Stability under perturbations
\end{enumerate}

These conditions are not arbitrary but reflect empirical observations from known emergent geometries:
\begin{itemize}
\item \textbf{AdS/CFT}: Boundary states with area-law entanglement give rise to smooth bulk geometries \cite{RyuTakayanagi2006}.
\item \textbf{Tensor networks}: MERA and similar structures with finite bond dimension naturally induce geometric connectivity \cite{Swingle2012}.
\item \textbf{Condensed matter}: Ground states of local Hamiltonians typically satisfy area laws and admit geometric descriptions.
\end{itemize}

Geometry, in this view, is not generic but represents a special organizational phase characterized by specific entanglement structure. This perspective explains why geometry appears in our effective descriptions: it is the stable attractor for certain classes of quantum states under physically relevant coarse-graining procedures.

\section{Scope and Future Directions}
\label{H-sec:B-scope}

\subsection{Structural Assumptions}

The framework rests on three core assumptions:
\begin{enumerate}
\item \textbf{Global state objectivity}: There exists a universal quantum state $|\Psi_U\rangle$, independent of observers.
\item \textbf{Algebraic priority}: Observable algebras, determined by physical interaction structure, are more fundamental than tensor factorizations.
\item \textbf{Stability-based emergence}: Effective subsystem structure and geometry emerge from stable subalgebras under physically motivated coarse-graining.
\end{enumerate}

\subsection{What the Framework Does NOT Commit To}

To prevent interpretational overreach, we explicitly enumerate what the framework does \emph{not} claim:

\begin{itemize}
\item That observers create reality or that consciousness plays a fundamental role
\item That spacetime is illusory or that geometry has no objective existence
\item That quantum mechanics is incomplete or requires modification
\item That the framework solves the measurement problem
\item That Buddhist metaphysics or any other philosophical tradition is presupposed
\end{itemize}

The framework is structurally neutral regarding these questions. It analyzes consequences of relaxing the assumption of canonical tensor factorization, but does not commit to any particular metaphysical position beyond what the formalism requires.

\subsection{Open Questions}

The following questions represent concrete technical research directions rather than fundamental gaps in the framework. Some (particularly those concerning empirical signatures) require additional physical assumptions beyond the structural analysis presented here, and are best addressed in specific model implementations.

\begin{enumerate}
\item \textbf{Dynamical algebra selection}: Can interaction Hamiltonians, coupling strengths, or network topologies be shown to select particular stable algebras over others?

\item \textbf{Information-theoretic criteria}: Do preferred geometric descriptions correlate with minimal description length, robustness under noise, or computational accessibility?

\item \textbf{Quantum field theory extensions}: How does the framework interact with locality structures in algebraic QFT? Can continuum limits be rigorously constructed?

\item \textbf{Empirical signatures}: Do different coarse-graining choices lead to distinguishable effective descriptions in semiclassical regimes or quantum gravity-motivated models?

\item \textbf{Connections to quantum complexity}: How does the framework relate to recent work on complexity-based approaches to spacetime emergence?
\end{enumerate}

These questions are intentionally left open. The present work provides a structural scaffold within which they can be formulated precisely, but does not claim to resolve them.

\subsection{Beyond Structural Analysis}

The framework developed here is deliberately limited to structural and interpretational analysis. Broader philosophical implications—concerning causation, free will, ontology, and connections to contemplative traditions—lie beyond the scope of this technical paper. Such questions are addressed in a companion philosophical essay currently in preparation.

\section{Conclusion}

We have clarified the conceptual commitments of the Holographic Alaya-Field Framework, addressing three potential misreadings:

\begin{enumerate}
\item \textbf{Against subjectivism}: Accessibility is defined structurally via stability conditions determined by physical interaction structure, not by observer beliefs or epistemic states.

\item \textbf{Against anti-realism}: Emergent geometry is a stable, measurable feature of entanglement structure—contingent on physical conditions but objective within those conditions, analogous to thermodynamic phases.

\item \textbf{Against trivialism}: Coarse-graining dependence reflects genuine physical structure (accessible algebras), not mere coordinate choice. Different algebras induce inequivalent geometries that cannot be related by diffeomorphism.
\end{enumerate}

The framework has been situated relative to AQFT (closest affinity), RQM (complementary), QBism (categorically distinct), and MWI (potentially complementary). Throughout, we have emphasized what the framework commits to structurally and what it leaves open interpretionally.

The central insight is modest but consequential: by removing tensor factorization from fundamental assumptions and treating it as emergent from coarse-graining structure, we reveal that geometry is more context-dependent than typically acknowledged—not in an epistemic or observer-relative sense, but in a structural, interaction-dependent sense.

This perspective does not resolve deep problems in quantum foundations or quantum gravity, but it clarifies the conditions under which subsystem structure and geometry emerge. By making explicit an assumption that is often left implicit, we hope to have opened new avenues for investigating the relationship between quantum states, observable structure, and spacetime.


% ============================================================================
% Essay C
% ============================================================================
\chapter{Causation, Agency, and Existence}
\label{H-chap:paperC}

\begin{center}
\textit{Essay C}\\[0.5em]
Originally published: Zenodo, DOI: 10.5281/zenodo.18374806
\end{center}

\bigskip

\section*{Abstract}

This essay examines the structural conditions under which agency, causation, and existence can be coherently discussed in the absence of foundational subsystem decompositions. Building on recent work in quantum information theory and algebraic approaches to quantum mechanics, Parts I--III develop a framework in which causal relations, agent boundaries, and existential claims emerge from stability properties of accessible observable algebras rather than from intrinsic substance or preferred factorizations.

Part I argues that causation can be understood as stable asymmetry within coarse-grained structures without requiring fundamental temporal ordering. Part II analyzes agency as boundary-stabilization''”a non-scrambling subspace that propagates constraints without presupposing a metaphysically autonomous agent. Part III recasts existence in terms of relational form rather than intrinsic being, developing a notion of ``emptiness'' as absence of substance compatible with objectivity.

Part IV explores whether these structural features find formal parallels in Buddhist philosophical frameworks, particularly Yog\=ac\=ara and M\=adhyamaka traditions. The analysis emphasizes interpretive humility: parallels are offered as invitations to dialogue, not demonstrations of equivalence. The essay's contribution is methodological''”clarifying structural constraints on emergence''”rather than doctrinal.

\medskip

\noindent\textbf{Keywords}: agency, emergence, structural realism, coarse-graining, accessible algebras, Buddhist philosophy, emptiness, comparative philosophy


\tableofcontents

\section{Introduction}
\label{H-sec:C-intro}

Contemporary philosophy of physics faces a structural puzzle. When quantum systems lack canonical subsystem decompositions, how should we understand causation, agency, and existence? If there is no preferred way to carve reality into parts, what becomes of the conceptual apparatus built on the assumption of well-defined relata?

This essay develops a framework in which these notions emerge from \emph{stability properties of accessible algebras} rather than from intrinsic substance or preferred factorizations. The analysis proceeds in four parts.

\paragraph{Roadmap.}
Part I examines causation without temporal foundations, arguing that causal relations can be understood as stable asymmetries in coarse-grained structure. Part II analyzes agency as boundary-stabilization''”the capacity of certain subsystems to maintain non-scrambling coherence while propagating constraints. Part III recasts existence in terms of relational patterns rather than intrinsic being, developing a technical sense of ``emptiness'' compatible with structural realism.

Part IV explores whether these structural features find formal parallels in Buddhist philosophical traditions, particularly Yog\=ac\=ara and M\=adhyamaka. The analysis emphasizes interpretive humility: we identify structural similarities without claiming ontological identity, historical influence, or doctrinal convergence.

\paragraph{Methodological stance.}
This is a structural investigation, not a metaphysical proposal. We do not claim that consciousness creates reality, that Buddhist texts anticipated quantum mechanics, or that comparative philosophy resolves foundational problems. Rather, we clarify how certain structural constraints''”particularly the absence of canonical factorization''”reshape discussions of emergence, agency, and existence across different conceptual traditions.

The essay's contribution is methodological: it demonstrates how attention to algebraic structure can discipline interpretive claims and reveal unexpected points of contact between seemingly disparate frameworks.

\paragraph{Relation to prior work.}
This essay builds on technical results developed in companion papers \cite{Liu2026PaperA,Liu2026PaperB}, which establish that inequivalent coarse-graining structures induce inequivalent effective geometries from the same global quantum state. Here, we explore philosophical consequences of this structural dependence for traditional metaphysical categories.

\section{Part I: Causation Without Foundations}
\label{H-sec:C-causation}

\subsection{The Standard Picture and Its Assumptions}
\label{H-sec:C-I.1}

Causal relations are typically understood as relations between events ordered by time. Event $A$ causes event $B$ if: (i) $A$ temporally precedes $B$, (ii) $A$ and $B$ are spatially connectible, and (iii) interventions on $A$ counterfactually affect $B$ \cite{Pearl2009}.

This picture presupposes several structural features:
\begin{itemize}
\item A well-defined notion of temporal ordering
\item Spatially localized events with clear boundaries
\item Stable subsystem decompositions supporting counterfactual reasoning
\end{itemize}

In quantum contexts without canonical factorization, none of these features is guaranteed. Time may be emergent rather than fundamental \cite{PageWootters1983}. Spatial locality depends on choice of coarse-graining \cite{Liu2026PaperA}. Subsystem boundaries are algebra-dependent rather than intrinsic.

\subsection{Causation as Stable Asymmetry}
\label{H-sec:C-I.2}

We propose that causation can be understood as \emph{stable asymmetry in accessible structure}, without requiring fundamental temporal ordering.

\begin{definition}[Causal Structure as Asymmetric Accessibility]
\label{H-def:C-causal-asymmetry}
Let $\mathcal{A}_{\mathbf{c}}$ be an accessible algebra determined by coarse-graining structure $\mathbf{c}$. A \textbf{causal relation} between subsystems $A$ and $B$ exists if there is a stable asymmetry in their correlation structure:
\begin{equation}
I(A_{\text{past}}:B_{\text{future}}) > I(B_{\text{past}}:A_{\text{future}}),
\end{equation}
where mutual information is computed relative to $\mathcal{A}_{\mathbf{c}}$, and ``past/future'' refer to coarse-graining-dependent orderings that admit thermodynamic interpretation.
\end{definition}

This definition makes no reference to fundamental time. Instead, it identifies causation with robust directional structure in how information propagates through accessible degrees of freedom.

\paragraph{Multiple causal arrows and thermodynamic consistency.}
An important subtlety: different coarse-graining structures may induce distinct''”and potentially conflicting''”causal arrows from the same global state. Since the ``past/future'' labels in Definition \ref{H-def:C-causal-asymmetry} are grounded in thermodynamic gradients, and thermodynamics itself is coarse-graining-dependent \cite{Wallace2012Time}, multiple inequivalent causal structures may coexist.

This is not a defect but a structural feature: just as different accessible algebras induce different effective geometries \cite{Liu2026PaperA}, they may induce different effective causal orderings. Consistency requires only that causal arrows align with entropy increase within each coarse-graining context. Conflicts between causal arrows derived from inequivalent coarse-grainings reflect genuine structural inequivalence, not mere coordinate choice.

In physical systems, thermodynamic consistency conditions typically select compatible coarse-grainings''”those yielding aligned causal arrows at macroscopic scales. But in principle, the framework admits context-dependent causal structure, with no unique ``fundamental'' arrow privileged independently of accessibility constraints.

\subsection{Thermodynamic Grounding}
\label{H-sec:C-I.3}

The asymmetry in Definition \ref{H-def:C-causal-asymmetry} can be grounded in thermodynamic considerations. Systems approaching equilibrium exhibit increasing entropy, inducing a preferred temporal direction even when microscopic dynamics are time-symmetric \cite{Wallace2012Time}.

Crucially, this thermodynamic arrow is \emph{context-dependent}: it depends on which macrostates are accessible, which in turn depends on coarse-graining structure. Different accessible algebras may induce different thermodynamic gradients, hence different effective causal structures.

\subsection{Counterfactuals Without Intrinsic Relata}
\label{H-sec:C-I.4}

Interventionist accounts of causation rely on counterfactual reasoning: $A$ causes $B$ if intervening on $A$ would change $B$ \cite{Woodward2003}. This appears to require well-defined intervention targets''”subsystems $A$ and $B$ with stable identities.

However, counterfactuals can be reformulated in algebraic terms. An intervention on $A$ corresponds to applying a CPTP map $\Phi_{\text{int}}$ to observables in subalgebra $\mathcal{A}_A$. The counterfactual dependence of $B$ on $A$ is then measured by how sensitive observables in $\mathcal{A}_B$ are to perturbations of $\mathcal{A}_A$.

This reformulation makes no reference to intrinsic subsystem boundaries. Intervention targets are defined by accessible algebras, which are themselves context-dependent.

\subsection{Memory as Informational Constraint}
\label{H-sec:C-I.5}

Causal relations leave traces''”memory records that constrain future accessible states. In quantum systems, memory can be understood as constraint propagation through entanglement structure \cite{Hayden2007}.

A subsystem $M$ acts as a memory of event $A$ if observables in $\mathcal{A}_M$ remain correlated with past observables in $\mathcal{A}_A$ despite environmental decoherence:
\begin{equation}
I(A_{\text{past}}:M_{\text{present}}) \gg I(A_{\text{past}}:E_{\text{present}}),
\end{equation}
where $E$ represents generic environmental degrees of freedom.

Memory, on this account, is not storage of intrinsic properties but maintenance of relational structure across time''”a pattern of correlations that persists under dynamical evolution.

\subsection{Worked Example: Two-Qubit Causal Asymmetry}
\label{H-sec:C-I.5example}

To clarify Definition \ref{H-def:C-causal-asymmetry}, we present a minimal worked example using a two-qubit system.

\paragraph{Setup.}
Consider a composite system of two qubits, $A$ and $B$, initially in a maximally entangled Bell state:
\begin{equation}
|\Psi_{\text{AB}}\rangle = \frac{1}{\sqrt{2}}\left(|00\rangle + |11\rangle\right).
\end{equation}

We introduce asymmetric environmental coupling: qubit $A$ couples strongly to a thermal bath $E_A$, while $B$ remains weakly coupled to $E_B$. The total Hamiltonian includes:
\begin{equation}
\hat{H} = \hat{H}_A + \hat{H}_B + \lambda_A \hat{\sigma}_A^z \otimes \hat{B}_{E_A} + \lambda_B \hat{\sigma}_B^z \otimes \hat{B}_{E_B},
\end{equation}
where $\lambda_A \gg \lambda_B$, and $\hat{B}_{E_i}$ are bath operators.

\paragraph{Coarse-graining.}
We trace over environmental degrees of freedom, defining accessible algebra $\mathcal{A}_{\mathbf{c}} = \text{span}\{\hat{\sigma}_A^x, \hat{\sigma}_A^z, \hat{\sigma}_B^x, \hat{\sigma}_B^z\}$ (Pauli observables).

\paragraph{Dynamical evolution.}
Due to asymmetric decoherence, the reduced density matrix evolves as:
\begin{align}
\rho_{AB}(0) &= |\Psi_{\text{AB}}\rangle\langle\Psi_{\text{AB}}|, \\
\rho_{AB}(t) &\approx \frac{1}{2}\left(|00\rangle\langle 00| + e^{-\Gamma_A t}|01\rangle\langle 10| + e^{-\Gamma_A t}|10\rangle\langle 01| + |11\rangle\langle 11|\right),
\end{align}
where $\Gamma_A \propto \lambda_A^2$ is the decoherence rate for qubit $A$.

\paragraph{Causal asymmetry.}
We compute mutual information at different times:
\begin{align}
I(A_{\text{early}}:B_{\text{late}}) &= S(A_{\text{early}}) + S(B_{\text{late}}) - S(AB), \\
I(B_{\text{early}}:A_{\text{late}}) &= S(B_{\text{early}}) + S(A_{\text{late}}) - S(AB).
\end{align}

At $t = 0$, mutual information is symmetric: $I(A:B) = 2 \log 2$ (maximal entanglement).

At $t \gg \Gamma_A^{-1}$, qubit $A$ has fully decohered while $B$ retains coherence longer. Measuring $A$ early provides information about $B$ late, but not vice versa:
\begin{equation}
I(A_{\text{early}}:B_{\text{late}}) > I(B_{\text{early}}:A_{\text{late}}).
\end{equation}

\paragraph{Interpretation.}
The asymmetry arises from differential coupling to environments''”a thermodynamic gradient inducing directional information flow. Qubit $A$ acts as a ``past'' influence on $B$ (causal), while $B$ does not significantly constrain $A$'s future (non-causal in reverse direction).

This exemplifies Definition \ref{H-def:C-causal-asymmetry}: causal structure emerges from stable asymmetry in coarse-grained correlations, grounded in thermodynamic irreversibility, without presupposing fundamental temporal ordering.

\paragraph{Context-dependence.}
Crucially, if we had chosen a different coarse-graining''”say, tracing over qubit degrees of freedom and retaining environmental observables''”the causal arrow could reverse or disappear. The asymmetry is \emph{real} (measurable within $\mathcal{A}_{\mathbf{c}}$) but \emph{context-dependent} (algebra-relative).

\subsection{From Causation to Agency}
\label{H-sec:C-I.6}

The transition from causation to agency requires an additional structural feature: \emph{stable subsystem boundaries that support constraint propagation}.

An agent is not merely a locus of causal influence, but a subsystem capable of maintaining coherent constraint propagation despite environmental coupling. This suggests analyzing agency in terms of \emph{non-scrambling subspaces}''”degrees of freedom that resist rapid information delocalization \cite{Hayden2007}.

Part II develops this connection, arguing that agency emerges from boundary-stabilization rather than metaphysical autonomy.

\paragraph{Summary.} Causation can be understood as stable asymmetry in coarse-grained accessible structure. This account makes no reference to fundamental time, intrinsic relata, or metaphysically basic events. Causal structure is context-dependent but objective''”determined by physical interaction patterns rather than observer beliefs.

\section{Part II: Agency as Emergent Constraint Structure}
\label{H-sec:C-agency}

\subsection{The Problem of Autonomous Agents}
\label{H-sec:C-II.1}

Traditional accounts treat agents as metaphysically autonomous entities''”unified subjects possessing intrinsic intentionality and causal efficacy. This picture faces two challenges in quantum contexts without canonical factorization.

First, if subsystem boundaries are algebra-dependent, what distinguishes an ``agent'' from an arbitrary collection of degrees of freedom? Second, if quantum dynamics are unitary and deterministic at the global level, how can agents possess genuine causal autonomy?

We argue that both challenges dissolve once agency is recast as a structural feature''”boundary-stabilization under constraint propagation''”rather than a metaphysical primitive.

\paragraph{Physical grounding of algebra selection.}
Before explicating the structural role of accessible algebras, we briefly address the dynamical origin of their selection. As established in our companion analysis regarding stability conditions \cite{Liu2026PaperB}, the specific observable algebra $\mathcal{A}_{\mathbf{c}}$ is not determined by arbitrary subjective choice or metaphysical agency. Rather, it is physically selected by the system's interaction structure''”specifically, by the requirement that the algebra remains robust under environmental decoherence (quantum Darwinism) and stable over relevant timescales. The ``filter'' is thus instantiated by the objective Hamiltonian couplings of the underlying field, ensuring that the emergence of effective geometry is grounded in physical dynamics rather than intentionality. We take this stability-selected structure as the starting point for the following structural analysis.

\subsection{Agency as Boundary-Stabilization}
\label{H-sec:C-II.2}

An \emph{agent}, in the structural sense, is a subsystem whose boundaries remain stable under dynamical evolution and whose internal degrees of freedom exhibit coordinated constraint propagation.

\begin{definition}[Agent-Like Subsystem]
\label{H-def:C-agent-subsystem}
A subsystem $\mathcal{A}_{\text{agent}}$ exhibits \textbf{agent-like behavior} if:
\begin{enumerate}
\item \textbf{Boundary stability}: The subalgebra $\mathcal{A}_{\text{agent}}$ is approximately preserved under physically relevant dynamical maps:
\begin{equation}
\|\mathcal{E}_t(\mathcal{A}_{\text{agent}}) - \mathcal{A}_{\text{agent}}\| < \epsilon
\end{equation}
for timescales relevant to constraint propagation.

\item \textbf{Non-scrambling coherence}: Observables in $\mathcal{A}_{\text{agent}}$ exhibit slow out-of-time-order correlator (OTOC) growth:
\begin{equation}
\langle [\hat{O}_{\text{agent}}(t), \hat{V}(0)]^2 \rangle \ll 1 \quad \text{for } t \ll \tau_{\text{scrambling}}.
\end{equation}

\item \textbf{Constraint propagation}: Internal correlations support directed information flow toward system boundaries, enabling intervention on environmental degrees of freedom.
\end{enumerate}
\end{definition}

\begin{remark}[Operational Threshold for Meaningful Agency]
\label{H-rem:agency-threshold}
Definition \ref{H-def:C-agent-subsystem} characterizes agent-like behavior structurally, but does not specify when such behavior constitutes \emph{meaningful} or \emph{significant} agency. In highly entangled quantum systems, transient non-scrambling may occur at very short timescales without supporting sustained constraint propagation.

We suggest an operational threshold: a subsystem exhibits \textbf{operationally significant agency} if:
\begin{equation}
\tau_{\text{coherence}} \gg \tau_{\text{env}},
\end{equation}
where $\tau_{\text{coherence}}$ is the timescale over which $\mathcal{A}_{\text{agent}}$ maintains boundary stability and non-scrambling coherence, and $\tau_{\text{env}}$ is the characteristic environmental decoherence time.

More precisely, we require:
\begin{equation}
\frac{\tau_{\text{coherence}}}{\tau_{\text{env}}} > \kappa,
\end{equation}
where $\kappa \sim 10^2$--$10^3$ is an empirically determined threshold below which constraint propagation becomes operationally inaccessible.

For biological agents, $\tau_{\text{coherence}}$ spans seconds to hours (for cognitive processes) or years (for identity persistence), while $\tau_{\text{env}} \sim 10^{-13}$--$10^{-3}$ seconds (molecular to neural timescales). For quantum systems at room temperature, $\tau_{\text{env}} \sim 10^{-15}$--$10^{-12}$ seconds, making sustained agency extraordinarily rare without active error correction or topological protection.

This threshold distinguishes:
\begin{itemize}
\item \textbf{Transient non-scrambling}: Fluctuations in highly entangled systems (no operational agency)
\item \textbf{Sustained boundary-stabilization}: Persistent subsystems supporting intervention (operational agency)
\end{itemize}

The threshold is not sharp''”agency admits degrees''”but provides a quantitative criterion for when agent-like structure becomes empirically significant.
\end{remark}

This definition makes no reference to consciousness, phenomenology, or intrinsic intentionality. Agency is characterized purely in terms of stability properties and information-theoretic structure.

\subsection{Will as Constraint Propagation}
\label{H-sec:C-II.3}

What, then, becomes of ``will'' or ``intention'' in this framework?

We suggest that will can be understood as \emph{constraint propagation structure}''”patterns of internal correlation that bias future accessible states toward specific outcomes. An agent ``wills'' action $A$ if its internal state $\rho_{\text{agent}}$ is such that future measurements will register correlation with $A$ with high probability.

\paragraph{Analogy: Thermostat control.}
Consider a thermostat coupled to a heating system. The thermostat's internal state (temperature reading) constrains future system behavior (heater activation), despite having no phenomenological experience. This is constraint propagation without metaphysical agency.

The analogy is limited: biological agents exhibit far richer constraint structure. But it clarifies the conceptual move''”replacing metaphysical autonomy with structural analysis of how internal states bias future trajectories.

\subsection{The Phenomenology-Structure Gap}
\label{H-sec:C-II.4}

An immediate objection: this account leaves no room for phenomenology''”the felt quality of agency, the subjective sense of ``I am acting.''

We acknowledge this gap. The framework developed here is \emph{structural}, concerned with information-theoretic organization. It does not address the \emph{explanatory gap} between structure and experience \cite{Levine1983,Chalmers1996}.

\begin{tcolorbox}[colback=gray!5!white,colframe=black!75!black,title=\textbf{Speculative Connection: Neural Constraint Propagation}]
\textbf{Caveat}: The following connects structural features to neuroscience, but remains speculative. We note these as suggestive parallels, not established mechanisms.

Recent work in computational neuroscience suggests that neural ``will'' may correspond to hierarchical constraint propagation through cortical-basal ganglia loops \cite{Graybiel2008}. Habitual behavior emerges when constraint patterns stabilize, while ``voluntary'' action involves flexible reconfiguration of these patterns \cite{Yin2006}.

If agency is boundary-stabilization, then the phenomenology of ``willing'' may correspond to proprioceptive monitoring of constraint reconfiguration''”the felt sense of internal degrees of freedom reorganizing in preparation for action \cite{Haggard2005}.

This remains highly speculative and does not bridge the explanatory gap. We raise it only to illustrate how structural analysis might interface with empirical research programs.
\end{tcolorbox}

\subsection{Degrees of Agency}
\label{H-sec:C-II.5}

The framework suggests that agency is not all-or-nothing, but admits degrees. Systems exhibit more or less agent-like behavior depending on:
\begin{itemize}
\item \textbf{Boundary stability duration}: How long does $\mathcal{A}_{\text{agent}}$ remain well-defined?
\item \textbf{Scrambling timescale}: How quickly do internal correlations delocalize?
\item \textbf{Constraint propagation fidelity}: How reliably do internal states bias future trajectories?
\end{itemize}

Simple thermostats exhibit minimal agency (short timescales, limited constraint structure). Biological organisms exhibit far richer agency (extended coherence, complex constraint networks). But both are comprehensible within the same structural framework.

\subsection{Relation to Free Will Debates}
\label{H-sec:C-II.6}

Traditional free will debates ask: are agents causally autonomous, or are their actions determined by prior states and laws? This presupposes well-defined agent boundaries and unambiguous causal histories''”precisely what the framework questions.

On the structural account, the relevant question is not ``Are agents free?'' but ``Under what conditions do subsystems exhibit stable constraint-propagation structure?'' This reformulation may dissolve certain traditional impasses while opening new empirical questions about stability conditions and scrambling timescales.

We do not claim to resolve free will debates''”only to clarify how they depend on assumptions about subsystem structure that are themselves context-dependent.

\paragraph{Summary.} Agency can be understood as boundary-stabilization supporting constraint propagation, rather than metaphysical autonomy. This account is eliminativist about intrinsic intentionality but realist about structural patterns of constraint. It leaves the phenomenology-structure gap unresolved but clarifies the information-theoretic conditions under which agent-like subsystems emerge.

\section{Part III: Existence Without Substance}
\label{H-sec:C-existence}

\subsection{The Realism Problem}
\label{H-sec:C-III.1}

Parts I--II analyzed causation and agency as context-dependent but objective''”dependent on coarse-graining structure but not on observer beliefs. This raises an existential question: if fundamental structures (subsystems, geometries, agents) are context-dependent, what ontological status do they possess?

Two extremes must be avoided:
\begin{enumerate}
\item \textbf{Naive realism}: Treating emergent structures as metaphysically fundamental, ignoring their context-dependence.
\item \textbf{Anti-realism}: Denying objective reality to context-dependent structures, collapsing into subjectivism.
\end{enumerate}

We propose a middle path: \emph{structural realism about relational patterns}. Existence is understood not as possession of intrinsic properties, but as participation in stable relational structures.

\subsection{Form Without Substance}
\label{H-sec:C-III.2}

Consider the temperature of a gas. Temperature is \emph{context-dependent}: it depends on which degrees of freedom are macroscopically accessible. Different coarse-grainings may yield different effective temperatures for the same microstate.

Yet temperature is not merely subjective. Given a coarse-graining, temperature is an objective, measurable quantity with predictive power. It is \emph{relationally real}''”real within a specified context, but lacking intrinsic existence independent of that context.

\begin{definition}[Relational Existence]
\label{H-def:C-relational-existence}
An entity $X$ possesses \textbf{relational existence} relative to structure $\mathcal{S}$ if:
\begin{enumerate}
\item $X$ is well-defined and stable within $\mathcal{S}$
\item $X$ participates in objective relational patterns (correlations, symmetries, invariants)
\item $X$ may be absent or differently constituted under alternative structures $\mathcal{S}'$
\end{enumerate}
\end{definition}

This notion captures \emph{form without substance}: patterns that are objectively real without possessing intrinsic being.

\subsection{Emptiness as Technical Concept}
\label{H-sec:C-III.3}

We introduce \emph{emptiness} as a technical term denoting absence of intrinsic existence compatible with relational reality.

\begin{definition}[Emptiness (Technical Sense)]
\label{H-def:C-emptiness-technical}
An entity $X$ is \textbf{empty} (in the technical sense) if:
\begin{enumerate}
\item $X$ lacks intrinsic being independent of relational context
\item $X$ exhibits stable patterns within specified contexts
\item The absence of intrinsic being does not entail non-existence or illusoriness
\end{enumerate}
\end{definition}

This usage is stipulative and should not be confused with colloquial meanings (``containing nothing'') or metaphysical nihilism (``nothing really exists''). Emptiness, in this technical sense, is compatible with robust realism about relational structures.

\subsection{Examples of Relational Existence}
\label{H-sec:C-III.4}

\paragraph{Temperature.}
As discussed in \S\ref{H-sec:C-III.2}, temperature is context-dependent but objective. Different coarse-grainings yield different effective temperatures, yet temperature remains a genuine physical quantity within each context.

\paragraph{Quasiparticles in condensed matter.}
Phonons, magnons, and other quasiparticles are collective excitations''”emergent entities with no counterpart in the microscopic Hamiltonian. They are empty of intrinsic being (there are no ``phonon particles'' in fundamental theory) yet fully real within effective descriptions \cite{Ladyman2007}.

\emph{Operationally}, quasiparticles are defined by stable relational patterns in measurable observables:
\begin{itemize}
\item \textbf{Spectral weight}: Well-defined peaks in momentum-resolved spectroscopy ($A(\mathbf{k},\omega)$)
\item \textbf{Dispersion relations}: Stable functional dependence $\omega(\mathbf{k})$ across parameter ranges
\item \textbf{Finite lifetimes}: Decay rates $\Gamma(\mathbf{k})$ obeying systematic scaling laws
\item \textbf{Scattering cross-sections}: Reproducible interaction amplitudes in transport experiments
\end{itemize}

These observables are context-dependent''”they depend on temperature, pressure, doping, and measurement resolution''”yet objectively real within specified experimental contexts. This exemplifies relational existence: patterns that are measurable, predictive, and stable, despite lacking intrinsic being independent of effective theory.

\paragraph{Subsystems in quantum mechanics.}
As established in prior work \cite{Liu2026PaperA}, subsystem decompositions are coarse-graining-dependent. A quantum state may admit infinitely many inequivalent factorizations, none privileged. Yet within any given factorization, subsystems exhibit objective entanglement structure and support meaningful predictions.

These examples illustrate a common pattern: entities that are \emph{empty} (lacking intrinsic being) yet \emph{existent} (participating in stable relational structures).

\subsection{Structural Invariants and Objectivity}
\label{H-sec:C-III.5}

A potential objection: if everything is context-dependent, what grounds objectivity?

The answer lies in \emph{structural invariants}''”features preserved across context transformations. While subsystem decompositions are coarse-graining-dependent, certain global properties (total entropy, symmetry groups, topological invariants) remain well-defined independently of factorization.

Objectivity does not require context-independence. It requires only that relational patterns exhibit stability and predictive power within specified contexts, and that transformations between contexts preserve identifiable structural features.

This perspective aligns with \emph{structural realism} in philosophy of science: what is objectively real is relational structure, not intrinsic substance \cite{Ladyman2007,French2014}.

\subsection{Existence and Non-Existence}
\label{H-sec:C-III.6}

The framework suggests a taxonomy of existential claims:

\begin{table}[h]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Type} & \textbf{Characterization} & \textbf{Example} \\
\hline
Intrinsic existence & Context-independent being & Classical particles (if fundamental) \\
Relational existence & Context-dependent but objective & Temperature, subsystems \\
Conventional existence & Context-dependent and agent-relative & Money, legal rights \\
Non-existence & Absent from all relevant contexts & Phlogiston, luminiferous ether \\
\hline
\end{tabular}
\caption{Taxonomy of existential claims. The framework developed here concerns relational existence''”entities that are context-dependent but objective. These correspondences are analytical distinctions, not ontological commitments.}
\label{H-tab:existence-taxonomy}
\end{table}

Emergent structures discussed in Parts I--II (causal relations, agent boundaries, geometric features) belong to the second category: relationally existent. They are empty of intrinsic being yet objectively real within specified coarse-graining contexts.

\paragraph{Summary.} Existence can be understood in terms of relational patterns rather than intrinsic substance. ``Emptiness,'' in the technical sense developed here, denotes absence of intrinsic being compatible with objectivity. This perspective avoids both naive realism and anti-realist eliminativism, offering a middle path grounded in structural invariance.

\section{Part IV: Interpretive Bridges to Buddhist Philosophy}
\label{H-sec:C-bridges}

\subsection{Methodological Preface}
\label{H-sec:C-IV.1}

The structural features developed in Parts I--III''”causation as asymmetry, agency as boundary-stabilization, existence as relational form''”were derived independently of any particular metaphysical tradition. We now explore whether these features find formal parallels in Buddhist philosophical frameworks.

Several caveats are essential:

\begin{tcolorbox}[colback=gray!5!white,colframe=black!75!black,title=\textbf{Methodological Caveats}]
\begin{enumerate}
\item \textbf{No historical causation}: We do not claim that Buddhist texts influenced quantum mechanics, or vice versa. Any parallels are structural convergences, not genealogical connections.

\item \textbf{No doctrinal advocacy}: Identifying formal similarities does not constitute endorsement of Buddhist metaphysics, soteriology, or religious practices.

\item \textbf{No cultural essentialism}: Buddhism comprises diverse traditions spanning two millennia. References here focus on specific textual traditions (primarily Yog\=ac\=ara and M\=adhyamaka), not ``Buddhism'' as a monolithic whole.

\item \textbf{No mystical reduction}: We reject interpretations conflating quantum mechanics with consciousness studies, New Age thought, or perennialist philosophy. Our analysis is structural and comparative, not mystical.

\item \textbf{Interpretive humility}: Parallels are offered as invitations to dialogue, not demonstrations of equivalence. The comparative exercise is exploratory, not conclusive.
\end{enumerate}
\end{tcolorbox}

With these caveats in place, we proceed to examine possible structural correspondences.

\subsection{Yog\=ac\=ara and Accessible Algebras}
\label{H-sec:C-IV.2}

Yog\=ac\=ara (``Yoga practice'') is a Mah\=ay\=ana Buddhist philosophical school emphasizing the role of consciousness (\emph{vija±\=ana}) in constituting experienced reality. Central to Yog\=ac\=ara is the concept of \textbf{\=alaya-vija±\=ana} (Skt., ``storehouse consciousness''), a foundational stratum of mind that stores karmic seeds (\emph{b\={\i}ja}) conditioning future experience \cite{Asanga_Mahayana,Vasubandhu_Trimsika}.

A structural parallel may be noted: \=alaya-vija±\=ana functions as a holistic substrate from which individuated mental states emerge, analogous to how subsystem structures emerge from coarse-graining a global quantum state \cite{Lusthaus2002,Waldron2003}.

\begin{table}[h]
\centering
\begin{tabular}{|l|l|}
\hline
\textbf{Yog\=ac\=ara Concept} & \textbf{HAFF Analog} \\
\hline
\=Alaya-vija±\=ana (storehouse consciousness) & Global quantum state $|\Psi_U\rangle$ \\
B\={\i}ja (karmic seeds) & Eigenmodes of accessible algebras \\
Prav\d{r}tti-vija±\=ana (active consciousness) & Effective subsystem $\rho_{\text{eff}}$ \\
\=Asraya-par\=av\d{r}tti (basis-transformation) & Coarse-graining map $\Phi_{\mathbf{c}}$ \\
\hline
\end{tabular}
\caption{Possible formal parallels between Yog\=ac\=ara concepts and HAFF structures. \textbf{Disclaimer}: These correspondences are formal analogies highlighting structural similarities, not claims of ontological identity or historical influence. Yog\=ac\=ara is a soteriological framework concerned with liberation from suffering; HAFF is a structural analysis of quantum emergence. The table illustrates conceptual resonances, not equivalences.}
\label{H-tab:yogacara-parallel}
\end{table}

\begin{tcolorbox}[colback=gray!5!white,colframe=black!75!black,title=\textbf{Critical Clarification: Against Panpsychism}]
The structural parallel between \=alaya-vija±\=ana and the global quantum state $|\Psi_U\rangle$ does \textbf{not} imply:
\begin{itemize}
\item That quantum states possess consciousness or phenomenological properties
\item That the universe is fundamentally mental or experiential (idealism)
\item That matter is constituted by or reducible to mind (panpsychism)
\item That information or quantum information is intrinsically conscious
\end{itemize}

The analogy is \emph{purely structural}: both frameworks describe how individuated entities emerge from holistic substrates via coarse-graining or cognitive filtering. Yog\=ac\=ara's substrate is explicitly mental (\emph{vija±\=ana}, consciousness); HAFF's substrate is explicitly physical (quantum state in Hilbert space).

Any appearance of convergence concerns \emph{formal pattern}''”the structure of emergence''”not ontological content. We emphatically reject interpretations that would construe this parallel as supporting quantum consciousness theories, New Age mysticism, or perennialist claims about universal mind.

The comparison is offered in the spirit of \emph{structural analogy}, not metaphysical synthesis.
\end{tcolorbox}

However, critical divergences must be noted:
\begin{itemize}
\item Yog\=ac\=ara is primarily concerned with \emph{mental} phenomena and the path to liberation, while HAFF analyzes \emph{physical} structure without soteriological commitments.
\item \=Alaya-vija±\=ana is explicitly described as a form of consciousness, while $|\Psi_U\rangle$ is not imbued with phenomenological properties.
\item The Yog\=ac\=ara framework is embedded in Buddhist ethics and meditation practice, which have no counterpart in HAFF's purely structural analysis.
\end{itemize}

The parallel, if valid, concerns \emph{formal structure}''”both frameworks describe how individuated entities emerge from holistic substrates''”not phenomenological or ontological content.

\subsection{M\=adhyamaka and Emptiness}
\label{H-sec:C-IV.3}

The M\=adhyamaka (``Middle Way'') tradition, founded by N\=ag\=arjuna (c.\ 2nd century CE), articulates \textbf{Å›\=unyat\=a} (Skt., ``emptiness'') as the absence of \textbf{svabh\=ava} (Skt., ``intrinsic nature'' or ``own-being'') \cite{Nagarjuna_MMK_Garfield1995}. 

This concept bears structural resemblance to the notion of ``emptiness'' developed in Part III (Â§\ref{H-sec:C-III.3}), where it denoted absence of intrinsic being without entailing non-existence. We emphasize that this parallel concerns the \emph{structural form} of the claim''”denial of substance while affirming functional reality''”not historical influence or causal connection \cite{Garfield2002,Siderits2007}.

N\=ag\=arjuna's central argument proceeds via \emph{prasaá¹…ga} (reductio) reasoning: all phenomena are empty because they arise dependently (\emph{prat\={\i}tyasamutp\=ada}), and what arises dependently cannot possess intrinsic nature. This is formalized in the famous verse:
\begin{quote}
\emph{``Whatever arises dependently is said to be empty. That, being a dependent designation, is itself the middle way.''} (MMK 24:18) \cite{Nagarjuna_MMK_Garfield1995}
\end{quote}

A structural reading: entities lacking intrinsic being (empty) can nonetheless participate in stable relational networks (dependent arising). This maps onto the framework developed in Â§\ref{H-sec:C-III.4}: subsystems are empty (coarse-graining-dependent, lacking intrinsic factorization) yet existent (exhibiting objective entanglement structure).

\paragraph{Recursive emptiness and second-order structure.}
A subtle question arises: in M\=adhyamaka, emptiness applies universally, including to emptiness itself''”``emptiness is empty'' (\emph{Å›\=unyat\=a-Å›\=unyat\=a}). Does HAFF's relational existence admit similar recursive application?

The answer is affirmative in a formal sense. Observable algebras $\mathcal{A}_{\mathbf{c}}$ are themselves relationally defined: they depend on physical interaction structure (Hamiltonian coupling), experimental apparatus constraints, and resolution limitations. There is no ``algebra of all algebras'' existing independently of physical context.

Moreover, the coarse-graining maps $\Phi_{\mathbf{c}}$ that select accessible algebras are context-dependent: different experimental setups, measurement resolutions, or dynamical timescales induce different $\Phi$ structures. Thus, \emph{the apparatus of emergence is itself emergent}''”coarse-graining structure arises from prior coarse-graining choices in a potentially infinite regress.

This mirrors M\=adhyamaka's insight that even the \emph{tools of analysis} (concepts, language, logical operations) are empty''”lacking intrinsic being while remaining functionally effective. In HAFF, even the ``machinery'' of accessible algebras is context-dependent, yet this does not undermine objectivity: structural invariants (entanglement entropy, symmetry groups) remain well-defined across contexts.

The parallel is formal: both frameworks acknowledge that \emph{relational structure goes ``all the way down,''} with no metaphysically foundational level immune to context-dependence. However, M\=adhyamaka deploys this insight soteriologically (to undermine attachment to fixed views), while HAFF employs it descriptively (to clarify structural constraints on emergence).

\paragraph{Key divergence.}
M\=adhyamaka Å›\=unyat\=a is deployed soteriologically''”to undermine attachment to fixed views and facilitate liberation. HAFF's ``emptiness'' is a technical descriptor of relational structure, with no soteriological function. The similarity is formal, not practical or existential.

\subsection{Karma and Constraint Propagation}
\label{H-sec:C-IV.4}

Buddhist karma doctrine holds that intentional actions leave traces (\emph{sa\.msk\=ara}, ``formations'') that condition future experience. In Yog\=ac\=ara, these traces are stored in \=alaya-vija±\=ana as \emph{v\=asan\=a} (``karmic impressions'') \cite{Waldron2003}.

A structural analogy: karma may be understood as \emph{constraint propagation through entanglement structure}''”past actions (interventions on accessible algebras) leave informational imprints that bias future trajectories \cite{Gombrich1996,Harvey2000}.

This is consonant with the account of memory developed in Â§\ref{H-sec:C-I.5}: causal traces are not storage of intrinsic properties but maintenance of relational structure across time.

\paragraph{Critical limitation.}
Buddhist karma is inherently normative: actions are classified as wholesome (\emph{kuÅ›ala}) or unwholesome (\emph{akuÅ›ala}) based on ethical criteria and soteriological consequences. HAFF's constraint propagation is descriptive, lacking normative content. The formal parallel does not extend to ethical or soteriological dimensions.

\subsection{Limits and Divergences}
\label{H-sec:C-IV.5}

Having noted possible parallels, we now emphasize substantive divergences''”areas where Buddhist frameworks and HAFF diverge structurally, methodologically, or conceptually. This section is weighted equally to Â§\ref{H-sec:C-IV.2}--\ref{H-sec:C-IV.4} to prevent over-interpreting formal similarities.

\subsubsection{Phenomenological vs.\ Structural Orientation}

Buddhist philosophy is fundamentally concerned with first-person experience and liberation from suffering (\emph{du\d{h}kha}). Yog\=ac\=ara and M\=adhyamaka analyze consciousness, perception, and mental afflictions (\emph{kleÅ›a}) as prerequisites for soteriological transformation.

HAFF, by contrast, is a third-person structural framework with no phenomenological commitments. It analyzes information-theoretic organization without addressing subjective experience, qualia, or the explanatory gap between structure and consciousness.

\textbf{Consequence}: Any parallel between \=alaya-vija±\=ana and $|\Psi_U\rangle$ cannot extend to phenomenological dimensions. HAFF does not explain consciousness, nor does it claim that quantum states possess mental properties.

\subsubsection{Soteriological vs.\ Descriptive Goals}

Buddhist frameworks are \emph{pragmatic} in orientation: concepts are introduced to facilitate liberation, not to accurately describe metaphysical reality. As the Buddha reportedly stated, philosophical speculation is a ``thicket of views'' (\emph{di\d{t}\d{t}hi-gahaá¹‡a}) distracting from the path \cite{SuttaNipata}.

HAFF is \emph{descriptive}: it aims to clarify structural constraints on emergence without prescribing practices or soteriological goals. There is no ``path'' in HAFF, no liberation to achieve, no suffering to overcome.

\textbf{Consequence}: Structural parallels do not imply that HAFF serves Buddhist soteriological purposes, nor that Buddhist practice requires acceptance of quantum mechanics.

\subsubsection{Rebirth, Cosmology, and Ethics}

Traditional Buddhist cosmology includes rebirth across multiple realms, karmic causation spanning lifetimes, and detailed ethical taxonomies. These elements are absent from''”and irrelevant to''”HAFF's structural analysis.

HAFF makes no claims about:
\begin{itemize}
\item Post-mortem continuity of consciousness
\item Karmic retribution across lifetimes
\item Ethical status of actions
\item Cosmological realms or deities
\item Meditation practices or contemplative attainments
\end{itemize}

\textbf{Consequence}: Identifying formal parallels does not validate Buddhist cosmology, rebirth doctrine, or ethical systems. The frameworks operate in disjoint conceptual spaces.

\subsubsection{Ontological Commitments}

While both frameworks reject intrinsic substance, they differ in ontological commitments:
\begin{itemize}
\item \textbf{Buddhist frameworks} (particularly Yog\=ac\=ara) often privilege mind or consciousness as fundamental, with matter derivative.
\item \textbf{HAFF} remains neutral on mind-matter relations, analyzing quantum structure without metaphysical commitments about consciousness.
\end{itemize}

Additionally, M\=adhyamaka's ``two truths'' doctrine''”distinguishing conventional (\emph{sa\.mv\d{r}ti}) from ultimate (\emph{param\=artha}) reality''”has no clear analog in HAFF. HAFF distinguishes context-dependent from invariant structures, but this is epistemological (about what can be known) rather than ontological (about levels of reality).

\subsubsection{Methodological Incommensurability}

Buddhist philosophy employs contemplative introspection, textual hermeneutics, and dialectical reasoning as primary methods. HAFF employs mathematical formalism, operator algebras, and information theory.

These methodologies are not mutually translatable. One cannot \emph{meditate} one's way to understanding quantum entanglement, nor \emph{calculate} one's way to soteriological insight. The parallels identified are \emph{structural}, not methodological.

\paragraph{Summary of divergences.}
The frameworks differ in:
\begin{enumerate}
\item Explanatory target (phenomenology vs.\ structure)
\item Pragmatic goal (liberation vs.\ description)
\item Scope (ethics/cosmology vs.\ physics)
\item Ontological commitments (consciousness-first vs.\ neutral)
\item Methodology (contemplative vs.\ mathematical)
\end{enumerate}

These divergences are not defects but reflect different intellectual projects. Recognizing formal parallels does not collapse these distinctions.

\subsection{Interpretive Humility}
\label{H-sec:C-IV.6}

We conclude Part IV by reaffirming interpretive humility. The parallels identified''”between accessible algebras and \=alaya-vija±\=ana, between emptiness and Å›\=unyat\=a, between constraint propagation and karma''”are \emph{suggestive but inconclusive}.

They suggest that:
\begin{enumerate}
\item Certain structural features (holistic substrates, relational existence, informational constraints) appear across traditions when thinkers grapple with similar conceptual problems.
\item Cross-cultural philosophical dialogue may benefit from precise structural comparison, avoiding both premature dismissal and uncritical conflation.
\item Formal parallels can motivate further investigation without requiring doctrinal convergence.
\end{enumerate}

They do \emph{not} suggest that:
\begin{enumerate}
\item Buddhist philosophy anticipated quantum mechanics or modern physics.
\item Quantum mechanics validates Buddhist metaphysics or soteriology.
\item Structural similarities entail ontological identity.
\item Comparative philosophy resolves foundational debates in either tradition.
\end{enumerate}

The exercise is exploratory: we map conceptual terrain, noting points of contact and divergence, without claiming to adjudicate between frameworks. Our contribution is methodological''”demonstrating how attention to algebraic structure can discipline comparative claims and prevent both over-interpretation and premature dismissal.

\section{Conclusion: Structural Constraints and Interpretive Modesty}
\label{H-sec:C-conclusion}

This essay has developed a structural framework for understanding causation, agency, and existence in quantum contexts without canonical subsystem decompositions. The analysis proceeded in four parts.

\paragraph{Part I: Causation.}
Causal relations can be understood as stable asymmetries in accessible structure, without requiring fundamental temporal ordering or intrinsic relata. This account is context-dependent but objective, grounded in thermodynamic gradients and informational constraint propagation.

\paragraph{Part II: Agency.}
Agent-like behavior emerges from boundary-stabilization''”subsystems maintaining non-scrambling coherence while propagating constraints. This account is eliminativist about intrinsic intentionality but realist about structural patterns. The phenomenology-structure gap remains unresolved.

\paragraph{Part III: Existence.}
Existential claims can be reformulated in terms of relational patterns rather than intrinsic substance. ``Emptiness,'' in the technical sense developed here, denotes absence of intrinsic being compatible with objectivity. This perspective avoids both naive realism and anti-realist eliminativism.

\paragraph{Part IV: Interpretive Bridges.}
Formal parallels may exist between these structural features and concepts in Buddhist philosophy (particularly Yog\=ac\=ara and M\=adhyamaka traditions). However, substantive divergences in methodology, goals, and scope prevent conflation. Parallels are offered as invitations to dialogue, not demonstrations of equivalence.

\subsection{Methodological Contribution}

The essay's primary contribution is methodological: it demonstrates how structural analysis can discipline interpretive claims across multiple domains.

\begin{enumerate}
\item \textbf{In quantum foundations}: By clarifying how causation, agency, and existence depend on coarse-graining structure, the framework reveals which features are context-dependent and which admit invariant characterization.

\item \textbf{In philosophy of science}: By developing relational existence without metaphysical substance, the framework contributes to structural realist programs while avoiding reification of emergent entities.

\item \textbf{In comparative philosophy}: By identifying formal parallels while respecting substantive divergences, the framework models how cross-cultural comparison can proceed without cultural essentialism or premature synthesis.
\end{enumerate}

\subsection{What This Essay Does Not Claim}

To prevent misreading, we reiterate what the essay does \emph{not} claim:

\begin{itemize}
\item That consciousness creates reality or plays a fundamental physical role
\item That Buddhist texts anticipated quantum mechanics or modern physics
\item That quantum mechanics validates any particular metaphysical or religious tradition
\item That structural parallels resolve foundational problems in physics or philosophy
\item That comparative philosophy provides unique insights unavailable within traditions
\end{itemize}

The analysis is structural and comparative, not metaphysical or apologetic.

\subsection{Open Questions}

Several questions remain open:

\begin{enumerate}
\item \textbf{Phenomenology}: How, if at all, does structural organization relate to subjective experience? The framework developed here is silent on the explanatory gap.

\item \textbf{Normativity}: Can constraint propagation ground normative distinctions, or does ethics require additional conceptual resources beyond structural analysis?

\item \textbf{Comparative methodology}: What criteria should govern cross-cultural philosophical comparison? When do formal parallels indicate genuine convergence versus superficial similarity?

\item \textbf{Empirical implications}: Do different coarse-graining choices lead to observationally distinguishable predictions in realistic physical systems?

\item \textbf{Contemplative epistemology}: Can first-person contemplative methods contribute to structural understanding, or are mathematical and phenomenological investigations fundamentally disjoint?
\end{enumerate}

These questions are not deficiencies but opportunities for future investigation. The framework provides conceptual scaffolding for pursuing them with greater precision.

\subsection{Final Reflection}

The absence of canonical subsystem decompositions in quantum mechanics is not merely a technical curiosity. It reshapes how we think about emergence, identity, and existence across multiple domains''”from quantum gravity to philosophy of mind to cross-cultural hermeneutics.

By attending to structural constraints''”particularly the dependence of effective descriptions on accessible algebras''”we can navigate between naive realism and anti-realist eliminativism, between cultural essentialism and dismissive parochialism, between metaphysical dogmatism and interpretive nihilism.

The resulting picture is one of \emph{structured pluralism}: multiple effective descriptions, none metaphysically privileged, yet constrained by objective relational patterns and transformation principles. Reality is not uniquely carved at the joints, but neither is it infinitely malleable. The joints themselves are context-dependent yet objective.

This perspective invites humility. We cannot claim unique access to fundamental structure, nor can we dismiss alternative frameworks as merely conventional. Instead, we map the space of possibilities, identify structural invariants, and acknowledge the limits of any single descriptive framework.

In this spirit, the essay concludes not with answers but with refined questions''”questions shaped by attention to algebraic structure, informed by cross-cultural comparison, and disciplined by interpretive modesty.


% ============================================================================
% Paper D
% ============================================================================
\chapter{Gravitational Phenomena as Emergent Properties}
\label{H-chap:paperD}

\begin{center}
\textit{Paper D}\\[0.5em]
Originally published: Zenodo, DOI: 10.5281/zenodo.18388882
\end{center}

\bigskip

\section*{Abstract}

We propose that gravitational phenomena arise from the adiabatic evolution of accessible observable algebras as the global quantum state evolves. Building on recent work demonstrating that inequivalent coarse-graining structures induce inequivalent effective geometries, we argue that gravity is categorically distinguished from gauge interactions: gauge forces operate \emph{within} a fixed algebra $\mathcal{A}$, while gravitational dynamics reflects the \emph{flow} of $\mathcal{A}$ itself. This framework provides: (1) a generative mechanism for gravitational dynamics via state-dependent algebra selection; (2) a structural derivation of the equivalence principle from algebraic universality; (3) identification of the emergent metric with the Quantum Fisher Information Metric. We do not derive the Einstein equations, but propose a conceptual framework that explains gravity's distinctive features''”universality, dynamical geometry, and resistance to naive quantization''”as consequences of algebra evolution rather than force mediation.


\section{Introduction}
\label{H-sec:D-intro}

\subsection{The Quantization Problem}

Among the four fundamental interactions, gravity occupies a singular position. While the strong, weak, and electromagnetic forces have been successfully incorporated into the framework of quantum field theory, gravity has resisted analogous treatment for nearly a century. The difficulties are well known: naive quantization of general relativity yields a non-renormalizable theory, and more sophisticated approaches''”string theory, loop quantum gravity, asymptotic safety''”remain either incomplete or empirically unconfirmed \cite{Kiefer2012}.

A common diagnosis attributes this difficulty to the self-referential nature of gravity: the metric tensor both defines the arena in which physics takes place and participates as a dynamical variable within that arena. Quantizing gravity thus appears to require quantizing spacetime itself''”a conceptually and technically formidable task.

\subsection{An Alternative Diagnosis}

In this paper, we explore an alternative structural diagnosis. We suggest that the difficulty may arise not because gravity is a particularly subtle force, but because gravity may not be a force at all''”at least not in the same categorical sense as gauge interactions.

The proposal rests on a simple observation: all descriptions of physical systems presuppose some decomposition of the total system into subsystems. In quantum mechanics, this corresponds to a tensor factorization of the Hilbert space. However, as has been established in foundational work on quantum information theory \cite{Zanardi2001,Zanardi2004} and developed in our previous analysis \cite{Liu2026PaperA}, there is no canonical or physically privileged factorization for a generic quantum state. Different choices of factorization''”or more generally, different choices of accessible observable algebra''”yield inequivalent physical descriptions.

We propose that gauge forces and gravity may be distinguished at this structural level:

\begin{itemize}
    \item \textbf{Gauge forces} describe interactions between degrees of freedom \emph{within} a given subsystem decomposition.
    \item \textbf{Gravitational phenomena} reflect properties of the decomposition \emph{itself}''”specifically, how effective geometry emerges from the pattern of accessible observables.
\end{itemize}

If this reframing is correct, it may help clarify why gravity resists quantization: one cannot straightforwardly quantize the choice of how to divide a system into parts, because that choice is logically prior to the application of quantum dynamics to those parts.

\subsection{Scope and Limitations}

We emphasize at the outset what this paper does and does not attempt.

\textbf{This paper does:}
\begin{itemize}
    \item Offer a structural reframing of the distinction between gravity and gauge forces
    \item Draw on established results concerning coarse-graining and emergent geometry
    \item Identify this perspective as a possible diagnostic for the quantization problem
\end{itemize}

\textbf{This paper does not:}
\begin{itemize}
    \item Propose new dynamical equations
    \item Derive the Einstein field equations or their quantum corrections
    \item Claim to solve the problem of quantum gravity
    \item Introduce observer-dependent, consciousness-related, or interpretational elements
\end{itemize}

The analysis is structural in nature. We examine the conceptual architecture underlying descriptions of gravity and gauge forces, and suggest that a categorical distinction at the level of observable algebras may illuminate longstanding difficulties.

\subsection{Outline}

Section~\ref{H-sec:D-factorization} reviews the factorization problem: the absence of a canonical subsystem decomposition in quantum theory, and its implications for emergent structure. Section~\ref{H-sec:D-distinction} develops the proposed distinction between gauge forces and gravity in terms of their relation to observable algebra selection. Section~\ref{H-sec:D-technical} provides a technical formulation, including the central conjecture and the identification of the emergent metric with the Quantum Fisher Information Metric. Section~\ref{H-sec:D-relation} discusses connections to existing approaches including AdS/CFT, tensor networks, and thermodynamic gravity. Section~\ref{H-sec:D-limitations} states explicit scope limitations. Section~\ref{H-sec:D-open} outlines open questions, and Section~\ref{H-sec:D-conclusion} concludes.

\section{The Factorization Problem}
\label{H-sec:D-factorization}

\subsection{No Canonical Tensor Factorization}

In standard quantum mechanics, composite systems are described by tensor products of subsystem Hilbert spaces: $\mathcal{H}_{\text{total}} = \mathcal{H}_A \otimes \mathcal{H}_B$. This structure is typically taken as given, with subsystems identified by physical intuition or experimental arrangement.

However, for a generic Hilbert space $\mathcal{H}$, there is no unique or canonical way to express it as a tensor product. Any finite-dimensional Hilbert space of dimension $d = d_1 \times d_2$ admits a factorization $\mathcal{H} \cong \mathcal{H}_{d_1} \otimes \mathcal{H}_{d_2}$, but the choice of such a factorization is not determined by the Hilbert space structure alone.

This observation was formalized by Zanardi and collaborators \cite{Zanardi2001,Zanardi2004}, who demonstrated that tensor product structures are determined by the algebra of accessible observables rather than by intrinsic properties of the state space. A change in which observables are accessible corresponds to a change in how the system is effectively decomposed into subsystems.

\subsection{Coarse-Graining and Effective Descriptions}

Building on this foundation, our previous work \cite{Liu2026PaperA} established that:

\begin{proposition}[Coarse-Graining Induced Inequivalence]
\label{H-prop:inequiv}
Let $|\Psi_U\rangle \in \mathcal{H}_{\text{total}}$ be a global quantum state, and let $\mathbf{c}_1, \mathbf{c}_2$ be two inequivalent coarse-graining structures (defined by distinct accessible algebras $\mathcal{A}_1, \mathcal{A}_2$). Then the effective descriptions induced by $\mathbf{c}_1$ and $\mathbf{c}_2$ are generically inequivalent: they yield different reduced states, different entanglement structures, and''”crucially''”different effective geometries.
\end{proposition}

The key point is that this inequivalence is not merely a matter of coordinate choice or descriptive convention. Different accessible algebras define different physical contents: different sets of measurable quantities, different notions of locality, and different effective spacetime structures.

\subsection{Geometry from Entanglement}

The connection between entanglement and geometry has been extensively studied in the context of holographic duality. The Ryu-Takayanagi formula \cite{RyuTakayanagi2006} and its generalizations establish that, in certain settings, geometric quantities (areas of extremal surfaces) are directly related to entanglement entropies of boundary regions:
\begin{equation}
S_A = \frac{\text{Area}(\gamma_A)}{4 G_N \hbar}.
\end{equation}

More broadly, Van Raamsdonk \cite{VanRaamsdonk2010} and others have argued that spacetime connectivity itself may be understood as a manifestation of quantum entanglement: regions that are highly entangled are geometrically ``close,'' while weakly entangled regions are ``far apart'' or even disconnected.

Within the present framework, these results acquire a natural interpretation. If geometry emerges from entanglement structure, and entanglement structure depends on how the system is decomposed into subsystems, then geometry is ultimately determined by the choice of accessible observable algebra.

\begin{remark}[Geometry as Coarse-Graining Dependent]
Effective spacetime geometry is not an intrinsic property of the global quantum state $|\Psi_U\rangle$. It is a derived quantity, dependent on the coarse-graining structure $\mathbf{c}$ that specifies which observables are accessible. Different coarse-grainings may yield geometries that differ not only in metric components, but in topology and connectivity.
\end{remark}

\begin{remark}[Relation to Prior Work]
While the non-uniqueness of tensor factorization has been widely discussed in the quantum information literature \cite{Zanardi2001,Zanardi2004}, its implications for distinguishing gravitational phenomena from gauge interactions at a structural level have not, to our knowledge, been made explicit. The present work develops this connection.
\end{remark}

This observation sets the stage for the distinction we develop in the next section.

\section{A Structural Distinction: Gauge Forces vs.\ Gravity}
\label{H-sec:D-distinction}

\subsection{Forces Within a Factorization}

Consider the standard description of gauge interactions. In quantum electrodynamics, the electromagnetic force is mediated by photon exchange between charged particles. In quantum chromodynamics, gluons mediate the strong force between quarks. In each case, the interaction is described as a coupling between degrees of freedom that are already identified as distinct subsystems.

Formally, gauge theories are constructed on a fixed background: a spacetime manifold $M$ equipped with a principal bundle whose structure group is the gauge group ($U(1)$, $SU(2)$, $SU(3)$, etc.). Matter fields are sections of associated bundles, and gauge fields are connections on the principal bundle. The dynamics describes how these fields interact \emph{given} the background structure.

Crucially, the identification of ``electron here'' and ``photon there'' presupposes a decomposition of the total system into localized subsystems. The gauge interaction operates \emph{within} this decomposition, coupling degrees of freedom that have already been distinguished.

\subsection{Gravity: A Different Category?}

General relativity describes gravity not as a force between objects on a fixed background, but as the curvature of spacetime itself. The metric tensor $g_{\mu\nu}$ is both the arena in which physics unfolds and a dynamical variable subject to the Einstein equations.

This dual role has long been recognized as the source of conceptual and technical difficulties. But the present framework suggests a sharper formulation of the distinction.

If gauge forces operate within a given subsystem decomposition, we propose that gravitational phenomena may be understood as reflecting properties of the decomposition itself. Specifically:

\begin{itemize}
    \item The effective geometry''”the metric, the notion of distance, the causal structure''”emerges from the pattern of entanglement among accessible degrees of freedom.
    \item This pattern is determined by the choice of accessible observable algebra.
    \item Gravitational phenomena, in this view, are not interactions between pre-existing objects, but manifestations of how effective spacetime structure responds to changes in what is accessible.
\end{itemize}

We emphasize that this proposal does not deny that gravity is geometrical at the effective level. Rather, it suggests that the \emph{origin} of this geometry may lie in how accessible observables define effective subsystems. The geometry remains real and physically consequential; what changes is the account of where it comes from.

\subsection{An Intuitive Picture}

To fix intuitions, consider the following analogy.

Imagine a map of a territory. On the map, one can trace routes between cities''”these routes depend on the geography depicted. Now consider the \emph{projection} used to create the map: Mercator, Robinson, or some other. Different projections yield different maps with different distance relationships and shape distortions.

In this analogy:
\begin{itemize}
    \item \textbf{Gauge forces} are like routes on the map''”interactions that take place within a given representational structure.
    \item \textbf{Gravity} is like the projection itself''”a property of how the representation is constructed, not a feature operating within it.
\end{itemize}

Changing the projection does not add new routes; it changes what ``distance'' and ``proximity'' mean. Similarly, changing the accessible observable algebra does not introduce new forces; it changes the effective geometry in which all forces are described.

\begin{remark}[Intuitive Picture]
This analogy is offered for conceptual orientation, not as a precise technical claim. The formal relationship between observable algebra selection and effective geometry requires the machinery developed in \cite{Liu2026PaperA} and subsequent sections of this paper.
\end{remark}

\subsection{Implications for Quantization}

If this structural distinction is correct, it may illuminate the difficulty of quantizing gravity.

Quantizing a gauge theory means promoting classical fields to operator-valued distributions on a fixed background, subject to appropriate commutation relations and dynamics. The background''”including the decomposition into subsystems''”is held fixed while the fields are quantized.

But if gravity reflects the choice of decomposition itself, then ``quantizing gravity'' would require quantizing the selection of how to divide the system into parts. This is a categorically different task. It is not a matter of promoting a classical field to a quantum operator; it is a matter of making the \emph{framework in which quantization is defined} itself subject to quantum uncertainty.

This may explain why straightforward approaches to quantum gravity encounter difficulties: they attempt to apply quantization procedures designed for systems \emph{within} a fixed decomposition to a structure that determines the decomposition itself.

This perspective does not introduce new dynamics or predictions, but may offer diagnostic value: it suggests a structural reason why gravity resists the quantization procedures that succeed for gauge interactions, and points toward the need for approaches that do not presuppose a fixed subsystem decomposition.

\begin{remark}[Diagnostic Value]
We do not claim that this perspective solves the problem of quantum gravity. Rather, we suggest that it offers diagnostic value: it identifies a structural reason why gravity may resist the techniques that succeed for gauge forces, and points toward the need for approaches that do not presuppose a fixed subsystem decomposition.
\end{remark}

\subsection{Relation to Background Independence}

The idea that gravity is connected to ``background independence'' is well established in the quantum gravity literature \cite{Rovelli2004,Smolin2006}. The present proposal may be viewed as a sharpening of this intuition in terms of observable algebras.

Background independence is often formulated as the requirement that physical laws not depend on a fixed spacetime metric. In the present framework, this requirement is subsumed under a more general principle: physical content should not depend on a particular choice of accessible observable algebra, or at least should transform covariantly under changes in that choice.

This suggests that a satisfactory theory of quantum gravity may need to be formulated not in terms of fields on a spacetime manifold, but in terms of structures that are prior to''”or more fundamental than''”the decomposition into spatially localized subsystems.

\begin{remark}[Context-Dependence vs.\ Observer-Dependence]
A potential misreading of this proposal is that it renders gravity ``observer-dependent'' or subjective. We stress that this is not the case. The selection of accessible observable algebras is constrained by physical interactions and stability criteria (such as decoherence structure and dynamical invariance), not by subjective choice or epistemic limitation. The resulting effective geometry is \emph{context-dependent}''”it depends on which physical degrees of freedom are stably accessible''”but not \emph{observer-relative} in any subjective sense. This distinction is developed in detail in \cite{Liu2026PaperB}.
\end{remark}

\subsection{The Equivalence Principle from Algebraic Universality}

A central puzzle in gravitational physics is the universality of free fall: why do all forms of matter and energy couple to gravity in the same way? In standard approaches, this ``equivalence principle'' is imposed as an empirical postulate. Here, we suggest it may follow structurally from the algebraic perspective.

The key observation is that the effective geometry is not a property of any particular matter field, but a property of the \emph{accessible algebra} $\mathcal{A}_{\mathbf{c}}$ itself. All observable matter fields are, by definition, constructed from operators in $\mathcal{A}_{\mathbf{c}}$ or its representations. Consequently, they must necessarily inhabit the geometry induced by $\mathcal{A}_{\mathbf{c}}$.

There is no ``second geometry'' for a different particle species to follow, because any operator outside $\mathcal{A}_{\mathbf{c}}$ is operationally inaccessible within the given coarse-graining context. The universality of gravitational coupling is thus not an additional postulate, but a logical consequence of the universality of the observable algebra.

\begin{remark}[Dark Sector as Algebraic Inaccessibility]
This perspective suggests a natural interpretation of ``dark'' degrees of freedom. Matter that does not couple to our accessible algebra $\mathcal{A}_{\mathbf{c}}$''”while potentially present in the global state $|\Psi_U\rangle$''”would be operationally invisible except through its gravitational effects on the geometry induced by $\mathcal{A}_{\mathbf{c}}$. This is speculative but structurally consistent with the framework.
\end{remark}

\section{Technical Formulation}
\label{H-sec:D-technical}

\subsection{Setup and Notation}

We consider a global quantum system described by a Hilbert space $\mathcal{H}$ with algebra of bounded operators $\mathcal{B}(\mathcal{H})$.

A \emph{coarse-graining} is specified by the selection of an accessible subalgebra $\mathcal{A} \subset \mathcal{B}(\mathcal{H})$, representing the observables that remain stable under relevant dynamical and environmental constraints.

\begin{definition}[Accessible Algebra]
\label{H-def:D-accessible}
Following \cite{Liu2026PaperA,Liu2026PaperB}, an \textbf{accessible algebra} $\mathcal{A}_{\mathbf{c}} \subset \mathcal{B}(\mathcal{H}_U)$ is a $*$-subalgebra satisfying three stability criteria:
\begin{enumerate}
    \item \textbf{Dynamical invariance:} Expectation values of operators in $\mathcal{A}_{\mathbf{c}}$ remain approximately invariant under physically motivated dynamical maps $\mathcal{E}$:
    \begin{equation}
    \|\mathcal{E}(\hat{O}) - \hat{O}\| \ll \epsilon \quad \forall \hat{O} \in \mathcal{A}_{\mathbf{c}}.
    \end{equation}
    
    \item \textbf{Environmental redundancy (Quantum Darwinism):} The subalgebra approximately commutes with the environmental algebra $\mathcal{A}_E$:
    \begin{equation}
    [\hat{O}, \hat{E}] \approx 0 \quad \forall \hat{O} \in \mathcal{A}_{\mathbf{c}}, \, \hat{E} \in \mathcal{A}_E.
    \end{equation}
    
    \item \textbf{Non-scrambling:} Out-of-time-order correlators exhibit slow decay:
    \begin{equation}
    \langle [\hat{O}_{\mathcal{A}}(t), \hat{V}(0)]^2 \rangle \ll 1 \quad \text{for } t \ll \tau_{\text{scrambling}}.
    \end{equation}
\end{enumerate}
A \textbf{coarse-graining structure} is the pair $\mathbf{c} \equiv (\mathcal{A}_{\mathbf{c}}, \Phi_{\mathbf{c}})$, where $\Phi_{\mathbf{c}}$ is a CPTP map implementing the operational reduction.
\end{definition}

No assumption is made that such a subalgebra admits a unique or canonical tensor factorization of $\mathcal{H}$.

\begin{remark}
This notion of accessible algebra follows the spirit of algebraic quantum mechanics and quantum information--theoretic approaches, without assuming a preferred subsystem decomposition.
\end{remark}

\subsection{Entanglement Structure and Induced Geometry}

Given a choice of accessible algebra $\mathcal{A}_{\mathbf{c}}$, one may consider the entanglement structure induced by restricting the global state $\rho$ to $\mathcal{A}_{\mathbf{c}}$.

Following insights from holography and tensor network constructions, patterns of entanglement within $\mathcal{A}_{\mathbf{c}}$ may be associated with an effective distance structure on equivalence classes of observables.

Crucially, this effective geometry depends on:
\begin{itemize}
    \item the choice of $\mathcal{A}_{\mathbf{c}}$,
    \item the stability of correlations under coarse-grained dynamics,
    \item and the redundancy of information encoding.
\end{itemize}

No claim is made that this geometry is fundamental. It is an effective description, valid within the context defined by $\mathcal{A}_{\mathbf{c}}$.

\subsection{Central Conjecture}

We now state the central conjecture of this paper explicitly.

\begin{conjecture}[Gravity as Adiabatic Algebra Evolution]
\label{H-conj:main}
Gravitational dynamics corresponds to the \textbf{adiabatic flow} of the accessible algebra $\mathcal{A}_{\mathbf{c}}(t)$, tracked by the stability conditions (Definition~\ref{H-def:D-accessible}) acting on the evolving global state $|\Psi_U(t)\rangle$.

Specifically:
\begin{enumerate}
    \item The global state evolves unitarily: $|\Psi_U(t)\rangle = U(t)|\Psi_U(0)\rangle$.
    \item The stability criteria determine which subalgebra $\mathcal{A}_{\mathbf{c}}(t) \subset \mathcal{B}(\mathcal{H}_U)$ is accessible at each time.
    \item As the state evolves, the optimal stable algebra shifts: $\mathcal{A}_{\mathbf{c}}(t) \to \mathcal{A}_{\mathbf{c}}(t + dt)$.
    \item This shift $\dot{\mathcal{A}}_{\mathbf{c}}(t)$ manifests phenomenologically as the dynamical curvature of spacetime''”i.e., as gravity.
\end{enumerate}

In contrast, unitary evolution of observables \emph{within} a fixed algebra $\mathcal{A}_{\mathbf{c}}$ manifests as gauge interactions. The categorical distinction is:
\begin{itemize}
    \item \textbf{Gauge dynamics:} Evolution within $\mathcal{A}_{\mathbf{c}}$ (fixed stage, moving actors)
    \item \textbf{Gravitational dynamics:} Evolution of $\mathcal{A}_{\mathbf{c}}$ itself (moving stage)
\end{itemize}
\end{conjecture}

This formulation addresses a key objection: if algebras are kinematical background, how can gravity be dynamical? The answer is that the \emph{selection} of which algebra is stable is itself state-dependent, and state evolution induces algebra flow.

\begin{remark}[Status of Algebraic Variations]
The adiabatic approximation assumes that algebra transitions occur slowly relative to internal dynamics within $\mathcal{A}_{\mathbf{c}}$. Rapid transitions would correspond to strong gravitational effects or spacetime singularities''”regimes where the effective geometric description breaks down. The question of what dynamics, if any, governs non-adiabatic transitions is left open (see Section~\ref{H-sec:D-open}).
\end{remark}

\subsection{Metric from Quantum Information Geometry}

To make the algebra-geometry correspondence precise, we identify the emergent metric with the \textbf{Quantum Fisher Information Metric (QFIM)}, a standard construction in quantum information geometry \cite{Petz1996,Bengtsson2006}.

Let $\{\lambda^\mu\}$ be parameters labeling deformations of the accessible algebra or its defining stability surface. The induced metric $g_{\mu\nu}$ on the manifold of effective descriptions is given by:
\begin{equation}
g_{\mu\nu}(\lambda) = \frac{1}{2} \text{Tr}\left( \rho(\lambda) \{ L_\mu, L_\nu \} \right),
\end{equation}
where $L_\mu$ is the symmetric logarithmic derivative satisfying
\begin{equation}
\partial_\mu \rho = \frac{1}{2}(\rho L_\mu + L_\mu \rho).
\end{equation}

This construction has several attractive features:
\begin{itemize}
    \item It is coordinate-independent and intrinsically quantum.
    \item It reduces to the classical Fisher metric in appropriate limits.
    \item It is directly related to distinguishability of quantum states''”geometrically ``close'' states are hard to distinguish operationally.
\end{itemize}

Under the hypothesis that gravitational dynamics reflects algebra evolution (Conjecture~\ref{H-conj:main}), the Einstein tensor $G_{\mu\nu}$ may be understood as describing the curvature of this information manifold. Changes in the accessible algebra,
\begin{equation}
\mathcal{A}_{\mathbf{c}} \to \mathcal{A}_{\mathbf{c}} + \delta\mathcal{A}_{\mathbf{c}},
\end{equation}
induce metric perturbations $\delta g_{\mu\nu}$ that correspond, in the effective geometric description, to gravitational waves.

\begin{remark}[Relation to Holographic Results]
In AdS/CFT, the Ryu-Takayanagi formula provides a precise relationship: $S_A = \text{Area}(\gamma_A)/4G_N$. The QFIM construction is consistent with this correspondence: the Fisher information metric on boundary states induces a bulk geometry whose areas encode entanglement entropies \cite{Lashkari2014,Faulkner2014}. The present framework proposes that this relationship is not specific to holography but reflects a general structural principle.
\end{remark}

\subsection{What This Section Does Not Claim}

To prevent misreading, we state explicitly what this technical formulation does \emph{not} attempt:

\begin{itemize}
    \item It does not derive gravitational field equations.
    \item It does not specify a dynamics for coarse-graining selection.
    \item It does not claim empirical adequacy or testable predictions.
    \item It does not introduce observer-dependent or consciousness-related elements.
\end{itemize}

The role of this section is to demonstrate internal coherence between the structural claims of Sections~1--3 and existing entanglement--geometry correspondences in the literature.

\section{Relation to Existing Approaches}
\label{H-sec:D-relation}

The perspective developed in this paper does not compete with existing approaches to quantum gravity and emergent spacetime. Rather, it may be understood as offering a \emph{conceptual umbrella} under which several distinct research programs can be situated. We briefly discuss four such connections.

\subsection{AdS/CFT and Holographic Duality}

The AdS/CFT correspondence \cite{Maldacena1999} provides the most concrete realization of geometry emerging from quantum entanglement. In this framework, a $(d+1)$-dimensional gravitational theory in anti-de Sitter space is dual to a $d$-dimensional conformal field theory on its boundary.

The Ryu-Takayanagi formula \cite{RyuTakayanagi2006} and its generalizations establish that geometric quantities in the bulk (areas of extremal surfaces) correspond to entanglement entropies in the boundary theory:
\begin{equation}
S_A = \frac{\text{Area}(\gamma_A)}{4 G_N \hbar}.
\end{equation}

Within the present framework, AdS/CFT may be viewed as a specific instance of the general principle that geometry emerges from entanglement structure. The boundary CFT defines a particular accessible algebra, and the bulk geometry is the effective geometry induced by that algebra.

\begin{remark}[Not a Replacement]
We do not claim that the present framework explains or derives AdS/CFT. Rather, AdS/CFT provides concrete evidence that the structural relationship between accessible algebras and effective geometry''”which we propose as general''”is realized in at least one well-understood setting.
\end{remark}

\subsection{Tensor Networks and MERA}

Tensor network constructions, particularly the Multi-scale Entanglement Renormalization Ansatz (MERA) \cite{Vidal2008,Swingle2012}, provide discrete models in which geometry emerges from entanglement structure.

In MERA, a quantum state is constructed by successive layers of disentanglers and isometries. The network structure itself defines an effective geometry: the ``depth'' direction in the network corresponds to a radial direction in an emergent spacetime, with properties reminiscent of AdS geometry.

This construction illustrates concretely how:
\begin{itemize}
    \item A choice of coarse-graining (the tensor network structure) determines entanglement patterns.
    \item Entanglement patterns induce effective geometric relationships.
    \item Different network structures yield different effective geometries from the same boundary data.
\end{itemize}

The present framework generalizes this observation: tensor networks are specific implementations of coarse-graining structures, and MERA-type emergence is a special case of the algebra-to-geometry correspondence we propose.

\subsection{Jacobson's Thermodynamic Derivation}

Jacobson's remarkable result \cite{Jacobson1995} showed that Einstein's field equations can be derived from thermodynamic considerations applied to local Rindler horizons, assuming the Bekenstein-Hawking entropy formula and the Clausius relation $\delta Q = T \, dS$.

This derivation suggests that gravity may be ``thermodynamic''''”an effective description arising from coarse-graining over microscopic degrees of freedom, rather than a fundamental force.

The present perspective is consonant with Jacobson's approach:
\begin{itemize}
    \item Both treat gravitational dynamics as emergent rather than fundamental.
    \item Both connect gravity to entropy and information-theoretic quantities.
    \item Both suggest that the Einstein equations describe effective, coarse-grained physics.
\end{itemize}

The contribution of the present work is to embed this intuition within a more general framework: the selection of accessible algebras as the structural origin of effective geometry.

\subsection{Background Independence in Loop Quantum Gravity}

Loop quantum gravity \cite{Rovelli2004,Thiemann2007} pursues quantization of gravity while maintaining background independence''”the principle that physical laws should not depend on a fixed spacetime metric.

The present framework shares this commitment to background independence, but approaches it differently:
\begin{itemize}
    \item Loop quantum gravity seeks to quantize the metric directly, constructing spacetime from spin networks.
    \item The present approach treats spacetime as an effective structure emergent from accessible algebra selection.
\end{itemize}

These are not mutually exclusive. It is conceivable that spin network states could be understood as specific implementations of accessible algebras, with loop quantum gravity dynamics describing transitions between such algebras. We do not develop this connection here, but note it as a direction for future investigation.

\subsection{Summary: A Conceptual Umbrella}

\begin{table}[ht]
\centering
\small
\begin{tabular}{|p{2.8cm}|p{4.5cm}|p{5.5cm}|}
\hline
\textbf{Approach} & \textbf{Key Mechanism} & \textbf{Relation to Present Work} \\
\hline
AdS/CFT & Holographic duality & Specific instance of algebra $\to$ geometry \\
\hline
Tensor Networks & Discrete entanglement structure & Concrete implementation of coarse-graining \\
\hline
Jacobson & Thermodynamic derivation & Consonant emergent perspective \\
\hline
Loop QG & Background-independent quantization & Shared commitment, different strategy \\
\hline
\end{tabular}
\caption{Relation of the present framework to existing approaches. The present work does not replace any of these programs, but offers a unifying structural perspective.}
\label{H-tab:relation}
\end{table}

We emphasize that the present framework does not claim superiority over these approaches. Each addresses aspects of quantum gravity that the present structural analysis does not. Our contribution is to articulate a perspective in which these diverse programs may be seen as exploring different facets of a common structural insight: that gravity is connected to the selection of how quantum degrees of freedom are organized into effective subsystems.

\section{Explicit Scope Limitations}
\label{H-sec:D-limitations}

To ensure clarity regarding the claims of this paper, we state explicitly what it does and does not assert.

\subsection{What This Paper Claims}

\begin{enumerate}
    \item \textbf{Categorical distinction:} Gauge forces and gravity are distinguished at the level of their relation to subsystem decomposition''”gauge forces operate within a fixed decomposition, while gravitational phenomena reflect the evolution of the decomposition itself.
    
    \item \textbf{Generative mechanism:} Gravitational dynamics arises from the adiabatic flow of accessible algebras as the global quantum state evolves (Conjecture~\ref{H-conj:main}).
    
    \item \textbf{Equivalence principle:} The universality of gravitational coupling follows from the universality of the observable algebra''”all accessible matter inhabits the geometry defined by $\mathcal{A}_{\mathbf{c}}$.
    
    \item \textbf{Information-geometric metric:} The emergent spacetime metric can be identified with the Quantum Fisher Information Metric on the space of effective descriptions.
    
    \item \textbf{Conceptual umbrella:} Several existing research programs (holography, tensor networks, thermodynamic gravity) may be situated under this common structural framework.
\end{enumerate}

\subsection{What This Paper Does Not Claim}

\begin{enumerate}
    \item \textbf{No new dynamics:} We do not propose equations of motion, Lagrangians, or dynamical principles beyond those already established.
    
    \item \textbf{No derivation of Einstein equations:} We do not claim to derive general relativity or its quantum corrections from first principles.
    
    \item \textbf{No empirical predictions:} We do not offer testable predictions that distinguish this perspective from standard approaches.
    
    \item \textbf{No resolution of quantum gravity:} We do not claim to solve the problem of quantum gravity; we offer a diagnostic perspective, not a solution.
    
    \item \textbf{No observer-dependence:} The framework does not render gravity subjective or observer-relative. Accessible algebras are constrained by physical criteria, not by epistemic states of observers.
    
    \item \textbf{No interpretational commitments:} The analysis is compatible with various interpretations of quantum mechanics and does not require commitment to any particular one.
\end{enumerate}

\section{Open Questions}
\label{H-sec:D-open}

The structural analysis presented here raises several questions that lie beyond its scope but may be fruitful for future investigation.

\subsection{Dynamics of Coarse-Graining Selection}

If gravitational phenomena reflect changes in accessible algebra structure, what determines how such structures evolve? Is there a ``meta-dynamics'' governing transitions between coarse-grainings, or are these transitions themselves emergent from more fundamental principles?

\subsection{Recovery of Classical Limits}

How does the Newtonian limit of gravity emerge from this perspective? In standard general relativity, the weak-field, slow-motion limit yields Newtonian gravity. What is the analogous limit in a framework where gravity reflects coarse-graining structure?

\subsection{Black Hole Thermodynamics}

Black hole entropy is intimately connected to both geometry (horizon area) and information theory (entanglement entropy). How does the present framework illuminate''”or constrain''”accounts of black hole thermodynamics?

\subsection{Cosmological Implications}

Does the coarse-graining perspective have implications for cosmology? Could the large-scale structure of the universe, or cosmological puzzles such as the horizon problem, be related to properties of cosmic-scale accessible algebras?

\subsection{Mathematical Formalization}

Can the conjecture stated in Section~\ref{H-sec:D-technical} be formalized with sufficient precision to permit mathematical investigation? What would constitute a proof''”or disproof''”of the claim that gravitational phenomena are coarse-graining effects?

\section{Conclusion}
\label{H-sec:D-conclusion}

We have proposed a structural framework in which gravitational phenomena arise from the adiabatic evolution of accessible observable algebras as the global quantum state evolves.

The core claims are:
\begin{enumerate}
    \item \textbf{Categorical distinction:} Gauge forces describe dynamics \emph{within} a fixed algebra $\mathcal{A}_{\mathbf{c}}$; gravity describes the evolution \emph{of} $\mathcal{A}_{\mathbf{c}}$ itself.
    
    \item \textbf{Generative mechanism:} As the global state $|\Psi_U(t)\rangle$ evolves, stability conditions select different optimal algebras $\mathcal{A}_{\mathbf{c}}(t)$. This flow manifests as spacetime curvature.
    
    \item \textbf{Equivalence principle:} All observable matter couples universally to gravity because all observables are, by definition, elements of the same algebra $\mathcal{A}_{\mathbf{c}}$.
    
    \item \textbf{Information geometry:} The emergent metric is the Quantum Fisher Information Metric on the manifold of effective descriptions.
\end{enumerate}

This framework does not derive the Einstein equations from first principles, nor does it resolve the problem of quantum gravity. However, it offers more than a diagnostic: it proposes a \emph{generative mechanism} that explains why gravity has the structural features it does''”universality, dynamical geometry, resistance to naive quantization.

The perspective is consistent with, and provides a conceptual umbrella for, existing research programs: holographic duality (where boundary entanglement encodes bulk geometry), tensor networks (where network structure induces effective geometry), and thermodynamic approaches (where Einstein equations emerge from entropy considerations).

We conclude with a reflection. The difficulty of quantizing gravity may not be purely technical. If gravity is the evolution of the stage on which quantum mechanics is performed, rather than an actor on that stage, then quantizing gravity requires quantizing the framework of quantization itself. This is not a problem to be solved by better regularization schemes, but a conceptual challenge requiring us to think beyond fixed subsystem decompositions.

The path forward may lie not in quantizing forces, but in understanding what determines the structure of accessibility''”and how that structure flows.


% ============================================================================
% Paper E
% ============================================================================
\chapter{Measurement as Accessibility}
\label{H-chap:paperE}

\begin{center}
\textit{Paper E}\\[0.5em]
Originally published: Zenodo, DOI: 10.5281/zenodo.18400066
\end{center}

\bigskip

\section*{Abstract}

We propose that quantum measurement is not a primitive process but a manifestation of accessibility constraints on operator algebras. Building on the Holographic Alaya-Field Framework (HAFF), we identify three structural constraints---interaction coupling, dynamical stability, and environmental redundancy---that jointly determine which observables are accessible within a given physical context. Measurement outcomes are reinterpreted as the eigenvalue structure of operators satisfying these constraints, and the definiteness of outcomes is traced to redundant environmental encoding rather than wave function collapse. This framework maintains compatibility with unitary quantum mechanics while providing a structural account of why certain observables acquire definite values. The analysis is structural in nature: we do not propose new dynamics or modifications to quantum mechanics, but clarify the conditions under which measurement-like phenomena emerge from algebraic constraints. Connections to decoherence theory, quantum Darwinism, and algebraic quantum field theory are discussed, along with explicit non-claims to prevent misinterpretation.


\section{Introduction}
\label{H-sec:E-intro}

\subsection{The Measurement Problem Reconsidered}

The quantum measurement problem has resisted resolution for nearly a century. In its sharpest form, the problem asks: how do definite measurement outcomes arise from quantum states that, prior to measurement, assign non-trivial amplitudes to multiple possibilities? Standard quantum mechanics provides rules for computing outcome probabilities but does not explain the transition from superposition to definiteness.

Various approaches have been proposed: collapse postulates that modify unitary evolution, many-worlds interpretations that deny the uniqueness of outcomes, and decoherence-based accounts that explain the suppression of interference without addressing the selection of particular results. Each approach has merits, but none has achieved consensus.

\subsection{A Structural Reframing}

This paper proposes a different perspective. Rather than asking how measurement \emph{causes} definite outcomes, we ask: under what structural conditions do observables \emph{acquire} the status of being measurable in the first place?

The central claim is:

\begin{quote}
\textbf{Measurement is not a primitive process, but a manifestation of accessibility constraints on operator algebras.}
\end{quote}

Within the Holographic Alaya-Field Framework (HAFF) developed in previous papers \cite{Liu2026PaperA,Liu2026PaperB,Liu2026PaperC,Liu2026PaperD}, physical descriptions are formulated relative to accessible observable algebras $\mathcal{A}_{\mathbf{c}} \subset \mathcal{B}(\mathcal{H}_U)$. Not all mathematically definable operators correspond to physically realizable measurements. The present paper identifies three structural constraints that jointly determine which operators are accessible:

\begin{enumerate}
    \item \textbf{Interaction Constraint}: The observable must couple to external degrees of freedom.
    \item \textbf{Stability Constraint}: The observable must persist under dynamical evolution.
    \item \textbf{Redundancy Constraint}: Information about the observable must be redundantly encoded in the environment.
\end{enumerate}

Observables satisfying all three constraints constitute the accessible algebra. Measurement outcomes are then understood as the eigenvalue structure of these accessible observables, and definiteness arises from the redundancy of environmental records rather than from any modification of unitary dynamics.

\subsection{Scope and Limitations}

We emphasize what this paper does and does not attempt.

\textbf{This paper does:}
\begin{itemize}
    \item Provide a structural characterization of measurement in terms of algebraic accessibility
    \item Identify three physical constraints that jointly determine accessible observables
    \item Connect measurement to established frameworks (decoherence, quantum Darwinism, AQFT)
    \item Maintain compatibility with unitary quantum mechanics
\end{itemize}

\textbf{This paper does not:}
\begin{itemize}
    \item Propose new dynamics or modifications to quantum mechanics
    \item Explain why specific measurement outcomes occur (the ``outcome problem'')
    \item Resolve interpretational debates about the ontology of quantum states
    \item Invoke consciousness, observers, or subjective elements
\end{itemize}

The analysis is structural: we clarify conditions under which measurement-like phenomena emerge, without claiming to have solved the measurement problem in its deepest form.

\subsection{Outline}

Section~\ref{H-sec:E-background} reviews relevant background on algebraic approaches to quantum mechanics and the HAFF framework. Section~\ref{H-sec:E-constraints} develops the three accessibility constraints in detail. Section~\ref{H-sec:E-measurement} reframes measurement in terms of these constraints. Section~\ref{H-sec:E-relations} discusses connections to existing approaches. Section~\ref{H-sec:E-nonclaims} states explicit non-claims. Section~\ref{H-sec:E-connection} situates the paper within the broader HAFF program. Section~\ref{H-sec:E-conclusion} concludes.

\section{Background}
\label{H-sec:E-background}

\subsection{Algebraic Approaches to Quantum Mechanics}

In the algebraic formulation of quantum mechanics, the fundamental objects are not wave functions or Hilbert spaces, but algebras of observables. A quantum system is characterized by a $*$-algebra $\mathcal{A}$ of bounded operators, and states are positive linear functionals on $\mathcal{A}$ \cite{Haag1996,Araki1999}.

This perspective has several advantages. It does not presuppose a specific Hilbert space representation, accommodates systems with infinitely many degrees of freedom, and naturally incorporates superselection rules. Most importantly for our purposes, it treats the specification of observables as logically prior to the specification of states.

\subsection{Observable Algebras in AQFT}

In algebraic quantum field theory (AQFT), local observable algebras $\mathcal{A}(\mathcal{O})$ are associated with spacetime regions $\mathcal{O}$, without invoking a global tensor product structure \cite{Haag1996}. The key insight is that subsystem structure emerges from the algebra of observables rather than being presupposed.

The HAFF framework extends this perspective by treating the selection of accessible algebras as physically constrained rather than given. Building on foundational work demonstrating that tensor product structures are observable-induced \cite{Zanardi2001,Zanardi2004}, different physical contexts---characterized by different interaction structures, stability conditions, and environmental couplings---yield different accessible algebras, and hence different effective physical descriptions.

\subsection{Accessible Algebras in HAFF}

Following \cite{Liu2026PaperA,Liu2026PaperB}, we define:

\begin{definition}[Accessible Algebra]
\label{H-def:E-accessible}
An \textbf{accessible algebra} $\mathcal{A}_{\mathbf{c}} \subset \mathcal{B}(\mathcal{H}_U)$ is a $*$-subalgebra satisfying physical constraints that ensure its elements correspond to operationally realizable observables within a given context $\mathbf{c}$.
\end{definition}

The subscript $\mathbf{c}$ denotes the \emph{context}---the totality of physical conditions (interaction Hamiltonian, environmental structure, timescales) that determine which observables are accessible. Different contexts yield different accessible algebras from the same underlying Hilbert space.

The present paper specifies three constraints that jointly determine $\mathcal{A}_{\mathbf{c}}$.

\section{Accessibility as Physical Constraint}
\label{H-sec:E-constraints}

We now develop the three constraints that determine which observables belong to the accessible algebra.

\subsection{Constraint 1: Interaction Coupling}

\begin{constraint}[Interaction]
\label{H-const:interaction}
An observable $\hat{O} \in \mathcal{B}(\mathcal{H}_U)$ satisfies the \textbf{interaction constraint} if it couples non-trivially to external degrees of freedom via the interaction Hamiltonian:
\begin{equation}
[\hat{O}, \hat{H}_{\text{int}}] \neq 0.
\end{equation}
\end{constraint}

\paragraph{Physical interpretation.}
An observable that commutes with all interaction terms is dynamically inert: it cannot be probed, recorded, or correlated with any external system. Such observables are mathematically well-defined but physically inaccessible.

\paragraph{Relation to measurement.}
Measurement requires that the system observable become correlated with apparatus degrees of freedom. This correlation is mediated by interaction. Observables that do not couple to any external system cannot, even in principle, be measured.

\begin{remark}
The interaction constraint is necessary but not sufficient for accessibility. An observable may couple to external degrees of freedom yet fail to satisfy stability or redundancy requirements.
\end{remark}

\subsection{Constraint 2: Dynamical Stability}

\begin{constraint}[Stability]
\label{H-const:stability}
An observable $\hat{O}$ satisfies the \textbf{stability constraint} if it remains approximately invariant under physically relevant dynamical maps $\mathcal{E}_t$:
\begin{equation}
\|\mathcal{E}_t(\hat{O}) - \hat{O}\| < \epsilon
\end{equation}
for timescales $t$ relevant to the physical process under consideration.
\end{constraint}

\paragraph{Physical interpretation.}
Observables that scramble rapidly---spreading their information across many degrees of freedom faster than any recording process can track---cannot be reliably measured. Stability ensures that the observable persists long enough to be correlated with records.

\paragraph{Relation to scrambling.}
In the language of quantum chaos, stable observables are those with slow out-of-time-order correlator (OTOC) growth \cite{Hayden2007}:
\begin{equation}
\langle [\hat{O}(t), \hat{V}(0)]^2 \rangle \ll 1 \quad \text{for } t \ll \tau_{\text{scrambling}}.
\end{equation}
Observables satisfying this condition resist rapid delocalization and maintain their identity under dynamical evolution.

\paragraph{Relation to decoherence.}
The stability constraint is closely related to the selection of pointer observables in decoherence theory \cite{Zurek2003}. Pointer observables are those that remain stable under system-environment interaction, forming the preferred basis in which the density matrix becomes approximately diagonal.

\begin{remark}[Threshold $\epsilon$]
The threshold $\epsilon$ is not a fundamental constant but depends on the physical context: the precision of available recording mechanisms, the timescales of interest, and the noise level of the environment. This context-dependence is a feature, not a bug---it reflects the operational nature of accessibility.
\end{remark}

\subsection{Constraint 3: Environmental Redundancy}

\begin{constraint}[Redundancy]
\label{H-const:redundancy}
An observable $\hat{O}$ satisfies the \textbf{redundancy constraint} if information about $\hat{O}$ is redundantly encoded across multiple independent environmental fragments $\{E_k\}$:
\begin{equation}
I(\hat{O} : E_k) \approx H(\hat{O}) \quad \text{for many } k,
\end{equation}
where $I(\cdot : \cdot)$ denotes quantum mutual information and $H(\cdot)$ denotes von Neumann entropy.
\end{constraint}

\paragraph{Physical interpretation.}
Redundancy ensures that information about the observable is not localized in a single environmental degree of freedom but is broadcast across many independent fragments. This makes the information robust and intersubjectively accessible: multiple independent observers can extract the same information without disturbing each other's records.

\paragraph{Relation to quantum Darwinism.}
The redundancy constraint formalizes the central insight of quantum Darwinism \cite{Zurek2009}: classical objectivity arises when information about a system is redundantly imprinted on the environment. Observables satisfying this constraint are precisely those for which multiple observers can agree on measurement outcomes.

\paragraph{Operational significance.}
Redundancy distinguishes \emph{objective} from \emph{subjective} information. An observable whose information is encoded in only a single environmental fragment is accessible to at most one observer; different observers would obtain different, incompatible records. Redundancy ensures that the observable's value is a matter of intersubjective fact.

\begin{remark}[Relation to classical objectivity]
The redundancy constraint provides a structural account of why certain observables behave ``classically'': their values are recorded multiply and independently, making them robust against local perturbations and accessible to multiple agents.
\end{remark}

\subsection{The Accessible Algebra}

\begin{definition}[Accessible Algebra via Constraints]
\label{H-def:E-accessible-full}
The \textbf{accessible algebra} $\mathcal{A}_{\mathbf{c}}$ relative to context $\mathbf{c}$ is the set of all observables satisfying Constraints~\ref{H-const:interaction}, \ref{H-const:stability}, and~\ref{H-const:redundancy}:
\begin{equation}
\mathcal{A}_{\mathbf{c}} = \{\hat{O} \in \mathcal{B}(\mathcal{H}_U) : \hat{O} \text{ satisfies Constraints 1, 2, and 3}\}.
\end{equation}
\end{definition}

The accessible algebra is not fixed \emph{a priori} but is determined by the physical context. Different interaction Hamiltonians, environmental structures, and timescales yield different accessible algebras from the same underlying Hilbert space.

\begin{table}[ht]
\centering
\small
\begin{tabular}{|p{2.5cm}|p{5cm}|p{5cm}|}
\hline
\textbf{Constraint} & \textbf{Condition} & \textbf{Physical Meaning} \\
\hline
Interaction & $[\hat{O}, \hat{H}_{\text{int}}] \neq 0$ & Observable couples to external degrees of freedom \\
\hline
Stability & $\|\mathcal{E}_t(\hat{O}) - \hat{O}\| < \epsilon$ & Observable persists under dynamics \\
\hline
Redundancy & $I(\hat{O} : E_k) \approx H(\hat{O})$ & Information redundantly encoded \\
\hline
\end{tabular}
\caption{Summary of the three accessibility constraints.}
\label{H-tab:constraints}
\end{table}

\section{Measurement Reframed}
\label{H-sec:E-measurement}

We now apply the accessibility framework to reinterpret quantum measurement.

\subsection{What Can Be Measured}

Within the present framework, the question ``What can be measured?'' receives a precise answer:

\begin{quote}
\textbf{An observable can be measured if and only if it belongs to the accessible algebra $\mathcal{A}_{\mathbf{c}}$.}
\end{quote}

Observables outside $\mathcal{A}_{\mathbf{c}}$---those failing one or more of the three constraints---are not measurable within context $\mathbf{c}$, regardless of their mathematical definition. This does not mean they ``do not exist'' in any metaphysical sense, but that they do not correspond to operationally realizable measurements within the given physical context.

\subsection{Measurement Outcomes}

Given an accessible observable $\hat{O} \in \mathcal{A}_{\mathbf{c}}$, its measurement outcomes are identified with its eigenvalue structure:

\begin{quote}
\textbf{Measurement outcomes are the eigenvalues of accessible observables.}
\end{quote}

This identification is standard in quantum mechanics. The novelty lies in restricting attention to \emph{accessible} observables: only those satisfying the three constraints yield operationally meaningful outcomes.

\subsection{Definiteness from Redundancy}

The definiteness of measurement outcomes---the fact that measurements yield single, definite results rather than superpositions---is traced to the redundancy constraint rather than to wave function collapse.

When an observable $\hat{O}$ satisfies the redundancy constraint, its eigenvalue is recorded in multiple independent environmental fragments. These records are mutually consistent: any fragment yields the same information about $\hat{O}$. This redundancy constitutes the objective, intersubjective definiteness of the measurement outcome.

\begin{quote}
\textbf{Definiteness is not imposed by collapse but constituted by redundant environmental encoding.}
\end{quote}

The global quantum state remains in superposition; what becomes definite is the content of redundant records, which all agree on the same eigenvalue.

\subsection{The Outcome Problem}

The framework does not explain why a \emph{particular} eigenvalue is recorded rather than another. This ``outcome problem'' remains open:

\begin{quote}
\textbf{We explain why outcomes are definite (redundancy), not why they are what they are.}
\end{quote}

This limitation is shared with decoherence-based approaches. The present framework does not claim to resolve this aspect of the measurement problem, only to clarify the structural conditions under which definite outcomes become possible.

\subsection{Measurement Without Observers}

A crucial feature of the framework is that measurement is characterized without reference to observers, agents, or consciousness:

\begin{quote}
\textbf{The ``observer'' is replaced by the ``interaction context.''}
\end{quote}

Any physical system satisfying the three constraints---be it a photon counter, a mineral surface, or an interstellar dust grain---constitutes a ``measurement site'' for the relevant observables. Human observers are a special case, not a privileged category.

\section{Relation to Existing Approaches}
\label{H-sec:E-relations}

\subsection{Decoherence Theory}

Decoherence theory explains how interference between quantum states is suppressed through environmental entanglement \cite{Zurek2003}. The present framework is fully compatible with decoherence and may be viewed as extending it in two respects:

\begin{enumerate}
    \item We make explicit the \emph{conditions} under which decoherence selects a preferred basis (the stability and redundancy constraints).
    \item We embed decoherence within the broader HAFF framework, connecting it to emergent geometry and gravitational phenomena.
\end{enumerate}

\subsection{Quantum Darwinism}

Quantum Darwinism \cite{Zurek2009} emphasizes the role of environmental redundancy in establishing classical objectivity. The redundancy constraint (Constraint~\ref{H-const:redundancy}) formalizes this insight as a criterion for accessibility.

The present framework may be viewed as situating quantum Darwinism within an algebraic setting, treating redundancy as one of three jointly necessary conditions for observability rather than as a standalone principle.

\subsection{QBism}

QBism \cite{Fuchs2014} interprets quantum states as expressions of an agent's beliefs. The present framework differs fundamentally: accessibility is determined by physical interaction structure, not by agent beliefs.

The key difference:
\begin{itemize}
    \item \textbf{QBism}: Dependence on agent's epistemic state (belief-determined)
    \item \textbf{HAFF}: Dependence on interaction structure (interaction-determined)
\end{itemize}

Both reject naive realism about quantum states, but the present framework maintains objectivity by grounding accessibility in physical constraints rather than subjective beliefs.

\subsection{Relational Quantum Mechanics}

Relational quantum mechanics (RQM) \cite{Rovelli1996} holds that quantum states are relational---defined only relative to a reference system. The present framework shares the emphasis on relationality but differs in its treatment of what grounds the relation:

\begin{itemize}
    \item \textbf{RQM}: Relations between systems (system-relative)
    \item \textbf{HAFF}: Stability conditions on algebras (interaction-determined)
\end{itemize}

HAFF may provide the stable ``nodes'' required for RQM's relational network: before relations can exist, there must be relata stable enough to participate in interactions.

\subsection{Algebraic Quantum Field Theory}

The closest structural affinity is with algebraic quantum field theory (AQFT) \cite{Haag1996}. Both frameworks treat observable algebras as primary and states as secondary. The present framework extends AQFT by:

\begin{enumerate}
    \item Providing explicit criteria (the three constraints) for algebra selection
    \item Connecting algebra selection to measurement and emergent geometry
    \item Situating AQFT insights within the broader HAFF program
\end{enumerate}

\begin{table}[ht]
\centering
\small
\begin{tabular}{|p{3cm}|p{4cm}|p{5.5cm}|}
\hline
\textbf{Approach} & \textbf{Key Mechanism} & \textbf{Relation to HAFF} \\
\hline
Decoherence & Environmental entanglement & Compatible; constraints specify conditions \\
\hline
Quantum Darwinism & Redundant encoding & Redundancy constraint formalizes this \\
\hline
QBism & Agent beliefs & Categorically distinct; HAFF is interaction-determined \\
\hline
RQM & System relations & Complementary; HAFF provides stable relata \\
\hline
AQFT & Observable algebras & Closest affinity; HAFF adds selection criteria \\
\hline
\end{tabular}
\caption{Relation of the present framework to existing approaches.}
\label{H-tab:relations}
\end{table}

\section{What This Paper Does NOT Claim}
\label{H-sec:E-nonclaims}

To prevent misinterpretation, we state explicitly what the paper does not claim.

\begin{enumerate}
    \item \textbf{No resolution of the outcome problem.} We do not explain why particular measurement outcomes occur, only why outcomes are definite.
    
    \item \textbf{No collapse postulate.} The framework assumes unitary evolution throughout. Definiteness arises from redundancy, not from non-unitary collapse.
    
    \item \textbf{No modification of quantum mechanics.} We do not propose new equations, new dynamics, or modifications to the standard formalism.
    
    \item \textbf{No consciousness or observer-dependence.} Accessibility is determined by physical constraints, not by conscious observers or epistemic states.
    
    \item \textbf{No claim that all measurement problems are solved.} The framework addresses the definiteness problem but leaves other aspects (the preferred basis problem, the tails problem) to be addressed in conjunction with existing approaches.
    
    \item \textbf{No claim of novelty regarding decoherence.} The framework builds on and is compatible with decoherence theory; it does not replace it.
    
    \item \textbf{No claim of universal applicability.} The analysis is confined to the HAFF framework and does not assert that all approaches to measurement must adopt this structure.
    
    \item \textbf{No metaphysical conclusions.} We do not claim that the accessible algebra exhausts reality, only that it exhausts what is operationally measurable within a given context.
    
    \item \textbf{No derivation of Born rule.} The framework does not derive the Born rule for outcome probabilities; it assumes standard quantum probability.
    
    \item \textbf{No claim about quantum-classical divide.} We do not assert a sharp boundary between quantum and classical; accessibility is context-dependent and admits degrees.
    
    \item \textbf{No hidden variables.} The framework does not invoke hidden variables or additional ontology beyond standard quantum mechanics.
    
    \item \textbf{No many-worlds commitment.} The framework is compatible with, but does not require, many-worlds interpretations.
    
    \item \textbf{No claim of interpretational neutrality.} While the framework avoids some interpretational commitments, it does adopt the structural stance of HAFF, which may not be neutral with respect to all interpretations.
\end{enumerate}

\section{Connection to the HAFF Framework}
\label{H-sec:E-connection}

\subsection{Relation to Previous Papers}

The present paper (Paper E) is part of a series developing the Holographic Alaya-Field Framework:

\begin{itemize}
    \item \textbf{Paper A} \cite{Liu2026PaperA}: Establishes that inequivalent coarse-graining structures induce inequivalent effective geometries from the same global quantum state.
    
    \item \textbf{Paper B} \cite{Liu2026PaperB}: Clarifies the structural (vs.\ epistemic) nature of accessibility and situates HAFF relative to existing interpretations.
    
    \item \textbf{Paper C} \cite{Liu2026PaperC}: Explores philosophical implications for causation, agency, and existence.
    
    \item \textbf{Paper D} \cite{Liu2026PaperD}: Proposes that gravitational dynamics corresponds to the adiabatic evolution of accessible algebras.
    
    \item \textbf{Paper E} (this paper): Reframes measurement as a manifestation of accessibility constraints.
    
    \item \textbf{Paper F} (forthcoming): Addresses temporal asymmetry as accessibility propagation.
\end{itemize}

\subsection{The Diagnostic Triangle: D + E + F}

Papers D, E, and F form a ``diagnostic triangle'' within the HAFF framework:

\begin{table}[ht]
\centering
\small
\begin{tabular}{|p{1.5cm}|p{2.5cm}|p{3.5cm}|p{4.5cm}|}
\hline
\textbf{Paper} & \textbf{Phenomenon} & \textbf{Traditional View} & \textbf{HAFF Reframing} \\
\hline
D & Gravity & Fundamental force & Evolution of accessible algebra \\
\hline
E & Measurement & Primitive process & Selection within accessible algebra \\
\hline
F & Time & Fundamental parameter & Direction of accessibility propagation \\
\hline
\end{tabular}
\caption{The diagnostic triangle: gravity, measurement, and time reframed as aspects of algebraic accessibility.}
\label{H-tab:triangle}
\end{table}

The unifying insight is that force, measurement, and time are not fundamental but are different projections of the structure of accessible algebras.

\subsection{Structural Link to Gravity}

Paper D establishes that gravity corresponds to the evolution of the accessible algebra $\mathcal{A}_{\mathbf{c}}(t)$. The present paper clarifies what determines $\mathcal{A}_{\mathbf{c}}$ at any given time: the three accessibility constraints.

The connection may be summarized as follows:

\begin{quote}
If gravity (Paper D) describes how information maps to spatial curvature, then measurement (Paper E) reveals the pruning criterion that determines which information participates in that mapping. Without accessibility constraints, the holographic map would include non-physical operators and yield divergent geometry. The finiteness of gravity is grounded in the finiteness of the accessible algebra.
\end{quote}

\section{Conclusion}
\label{H-sec:E-conclusion}

We have proposed that quantum measurement is not a primitive process but a manifestation of accessibility constraints on operator algebras.

The central results are:

\begin{enumerate}
    \item \textbf{Three accessibility constraints}: Interaction coupling, dynamical stability, and environmental redundancy jointly determine which observables are accessible within a given physical context.
    
    \item \textbf{Measurement reframed}: What can be measured is determined by membership in the accessible algebra; measurement outcomes are eigenvalues of accessible observables; definiteness arises from redundant environmental encoding.
    
    \item \textbf{Observer-independence}: The framework characterizes measurement without reference to observers, consciousness, or subjective elements. The ``observer'' is replaced by the ``interaction context.''
    
    \item \textbf{Compatibility}: The framework is compatible with unitary quantum mechanics, decoherence theory, and quantum Darwinism, while providing a structural account that connects measurement to the broader HAFF program.
\end{enumerate}

The framework does not resolve all aspects of the measurement problem. It does not explain why particular outcomes occur, nor does it derive the Born rule. What it provides is a structural clarification: the conditions under which measurement-like phenomena emerge from physical constraints on operator algebras.

Within the HAFF program, measurement joins gravity and time as phenomena that are not fundamental but emerge from the structure of accessible algebras. This diagnostic unification does not constitute a Theory of Everything, but it suggests that seemingly disparate foundational puzzles may share a common structural origin.


% ============================================================================
% Paper F
% ============================================================================
\chapter{Temporal Asymmetry as Accessibility Propagation}
\label{H-chap:paperF}

\begin{center}
\textit{Paper F}\\[0.5em]
Originally published: Zenodo, DOI: 10.5281/zenodo.18400426
\end{center}

\bigskip

\section*{Abstract}

We propose that temporal and causal asymmetry arise from the directional structure of accessibility propagation. Building on the Holographic Alaya-Field Framework (HAFF), which characterizes measurement as the selection of stable accessible algebras, we argue that the ``arrow of time'' is not a fundamental parameter but a consequence of how information spreads irreversibly into environmental degrees of freedom. The redundancy constraint central to accessibility---that information must be multiply recorded to be operationally accessible---is inherently asymmetric: information expands from few to many degrees of freedom, but the reverse process is statistically suppressed to the point of physical uninstantiability. This asymmetry defines a preferred direction that we identify with temporal ordering. No fundamental time parameter is assumed; all temporal ordering emerges from a partial order induced by algebraic inclusion and redundancy monotonicity. Causation is reframed as constraint propagation along this direction, with retrocausal trajectories being non-generic (measure zero) rather than forbidden by principle. A minimal mathematical model demonstrating irreversible redundancy expansion is provided in the appendix.


\section{Introduction}
\label{H-sec:F-intro}

\subsection{The Problem of Time's Arrow}

Among the deepest puzzles in physics is the origin of temporal asymmetry. The fundamental laws of physics---Newtonian mechanics, electromagnetism, quantum mechanics---are time-reversal invariant or nearly so. Yet our experience of the world is profoundly asymmetric: eggs break but do not unbreak; we remember the past but not the future; causes precede effects.

This tension between microscopic reversibility and macroscopic irreversibility has been recognized since Boltzmann's work on statistical mechanics \cite{Boltzmann1896}. The standard resolution appeals to special initial conditions: the universe began in a low-entropy state, and the second law of thermodynamics reflects the statistical tendency to evolve toward higher entropy \cite{Penrose1989,Carroll2010}.

While this explanation is widely accepted, it raises further questions:
\begin{itemize}
    \item Why should initial conditions be ``special''? What selects them?
    \item Is the thermodynamic arrow the only arrow, or are there independent sources of temporal asymmetry?
    \item In quantum gravity, where time itself may be emergent, how does any notion of ``before'' and ``after'' arise?
\end{itemize}

The present work does not claim to resolve these questions definitively. Instead, it offers a structural reframing: temporal asymmetry may be understood as a consequence of how accessible algebras propagate information.

\subsection{Central Thesis}

We propose that temporal asymmetry can be understood as follows:

\begin{quote}
\textbf{Central Thesis:} No fundamental time parameter is assumed. All temporal ordering emerges from a partial order induced by algebraic inclusion and redundancy monotonicity. The ``arrow of time'' is the direction of irreversible accessibility propagation---information spreads from localized degrees of freedom into distributed environmental records, and this expansion is statistically irreversible.
\end{quote}

This thesis builds on the accessibility framework developed in Paper E \cite{Liu2026PaperE}. Recall that an observable is accessible only if information about it is redundantly recorded in multiple environmental fragments (the redundancy constraint). This redundancy is achieved through physical processes that spread information outward---precisely the processes that define thermodynamic irreversibility.

The key insight is that the redundancy constraint is inherently asymmetric:
\begin{itemize}
    \item \textbf{Forward direction}: Information spreads from system to environment, creating multiple records. This satisfies the redundancy constraint.
    \item \textbf{Backward direction}: Contracting distributed information back into a localized system would require precise coordination of many degrees of freedom---a process of measure zero in the space of dynamical trajectories.
\end{itemize}

This asymmetry is not imposed by hand; it follows from the structure of accessibility itself.

\subsection{Scope and Limitations}

We state explicitly what this paper does and does not attempt.

\textbf{This paper does:}
\begin{itemize}
    \item Propose a structural account of temporal asymmetry based on accessibility propagation
    \item Derive temporal ordering from redundancy structure without assuming fundamental time
    \item Connect this account to the thermodynamic and quantum arrows
    \item Reframe causation as constraint propagation along the accessibility direction
    \item Provide a minimal mathematical model (Appendix A) demonstrating irreversible redundancy expansion
    \item Situate the analysis within the broader HAFF framework
\end{itemize}

\textbf{This paper does not:}
\begin{itemize}
    \item Derive the second law of thermodynamics from first principles
    \item Explain why initial conditions are low-entropy
    \item Resolve metaphysical debates about the nature of time (A-theory vs.\ B-theory, presentism vs.\ eternalism)
    \item Address free will, agency, or the phenomenology of temporal experience
    \item Propose new dynamical equations or empirical predictions
\end{itemize}

The analysis is structural. We examine how temporal asymmetry relates to accessibility structure, without claiming that this analysis exhausts the content of the problem.

\begin{remark}[Relation to Papers D and E]
Paper D \cite{Liu2026PaperD} argued that gravity reflects the evolution of accessible algebras. Paper E \cite{Liu2026PaperE} argued that measurement reflects the selection of accessible algebras. The present paper argues that time reflects the \emph{directionality} of accessibility propagation. Together, these three papers characterize the diagnostic layer of the HAFF framework:
\begin{itemize}
    \item D: Geometry (algebra evolution)
    \item E: Measurement (algebra selection)
    \item F: Time (algebra propagation direction)
\end{itemize}
\end{remark}

\subsection{Outline}

Section~\ref{H-sec:F-background} reviews the status of time in various physical theories. Section~\ref{H-sec:F-accessibility} develops the core technical content: how the accessibility constraints generate directional structure. Section~\ref{H-sec:F-causation} reframes causation as constraint propagation along the accessibility direction. Section~\ref{H-sec:F-relations} compares the present approach to existing accounts of temporal asymmetry. Section~\ref{H-sec:F-noncommitments} states explicit non-commitments. Section~\ref{H-sec:F-connection} discusses connections to the HAFF framework. Section~\ref{H-sec:F-conclusion} concludes. Appendix~\ref{H-app:model} provides a minimal mathematical model demonstrating the irreversibility of redundancy expansion.

\section{Background: Time in Physics}
\label{H-sec:F-background}

Before developing the accessibility-based account, we briefly review the status of time in major physical theories. The purpose is to identify a common structural assumption: that time is an external parameter, given rather than derived.

\subsection{Time in Classical and Quantum Mechanics}

In Newtonian mechanics, time is an absolute parameter. The equations of motion are time-reversal invariant: if $\mathbf{x}(t)$ is a solution, so is $\mathbf{x}(-t)$ (with velocities reversed). There is no intrinsic arrow.

In quantum mechanics, time evolution is governed by the Schr\"odinger equation:
\begin{equation}
i\hbar \frac{\partial}{\partial t} |\psi\rangle = \hat{H} |\psi\rangle.
\end{equation}
This equation is unitary and reversible. The apparent irreversibility of measurement is an interpretational issue, not a feature of the formalism itself.

\subsection{Time in Quantum Gravity}

In canonical approaches to quantum gravity, the Wheeler-DeWitt equation takes the form:
\begin{equation}
\hat{H} |\Psi\rangle = 0,
\end{equation}
where $|\Psi\rangle$ is the wave function of the universe. This equation contains no time parameter; the universe is described by a static state satisfying a constraint equation \cite{DeWitt1967}.

The Page-Wootters mechanism \cite{PageWootters1983} recovers effective time evolution from correlations between a ``clock'' subsystem and the rest of the universe within a timeless universal state. However, this mechanism explains how time \emph{ordering} emerges from correlations but does not explain why this ordering is \emph{asymmetric}.

\subsection{The Common Thread}

Across these theories, time appears either as an external parameter or as an emergent concept requiring additional input. The present framework offers a third perspective: time as a \textbf{structural consequence} of accessibility propagation, with directionality arising from the statistical asymmetry of redundancy expansion.

\section{Accessibility and Directionality}
\label{H-sec:F-accessibility}

We now develop the central technical content: how the accessibility constraints generate a preferred direction that can be identified with temporal ordering.

\subsection{Recap: The Redundancy Constraint}

Paper E \cite{Liu2026PaperE} established that an observable $\hat{O}$ belongs to the accessible algebra $\mathcal{A}_{\mathbf{c}}$ only if it satisfies three constraints, including the \emph{redundancy constraint}:
\begin{equation}
I(\hat{O} : E_k) \approx H(\hat{O}) \quad \text{for many } k,
\end{equation}
where $I(\cdot : \cdot)$ denotes quantum mutual information, $H(\cdot)$ denotes von Neumann entropy, and $\{E_k\}$ are independent environmental fragments.

This constraint ensures that information about accessible observables is distributed across multiple environmental subsystems, enabling intersubjective objectivity.

\subsection{The Redundancy Index}

We introduce a quantitative measure of redundancy:

\begin{definition}[Redundancy Index]
\label{H-def:F-redundancy}
For an observable $\hat{O}$ and environment $E = \bigotimes_k E_k$ consisting of $N$ fragments, the \textbf{redundancy index} $\mathcal{R}(\hat{O})$ is the number of environmental fragments that have acquired nearly complete information about $\hat{O}$:
\begin{equation}
\mathcal{R}(\hat{O}) = \sum_{k=1}^{N} \Theta\left( I(\hat{O} : E_k) - (1-\delta) H(\hat{O}) \right),
\end{equation}
where $\Theta$ is the Heaviside step function and $\delta \ll 1$ is the information loss tolerance.
\end{definition}

High redundancy ($\mathcal{R} \sim N$) corresponds to classical, objective observables. Low redundancy ($\mathcal{R} \sim 1$) corresponds to quantum, contextual observables.

\subsection{Asymmetry of Redundancy Flow}

The central observation is that redundancy expansion and contraction are radically asymmetric:

\begin{proposition}[Asymmetry of Redundancy Flow]
\label{H-prop:asymmetry}
Let $\hat{O}$ be an observable of a central system $S$ interacting with an $N$-fragment environment $E$. Then:
\begin{enumerate}
    \item \textbf{Expansion is generic}: Under typical interactions, $\mathcal{R}(\hat{O})$ increases from $\mathcal{R} = 0$ toward $\mathcal{R} \sim N$.
    \item \textbf{Contraction is non-generic}: The phase space volume of trajectories along which $\mathcal{R}$ decreases is exponentially suppressed:
    \begin{equation}
    \frac{\text{Vol}(\mathcal{R} \downarrow)}{\text{Vol}(\mathcal{R} \uparrow)} \sim e^{-\alpha N}
    \end{equation}
    for some $\alpha > 0$ depending on the fragment dimensions.
\end{enumerate}
\end{proposition}

The proof is provided in Appendix~\ref{H-app:model}. The key insight is that expansion requires only generic spreading of correlations, while contraction requires exponentially precise conspiracy among $N$ independent fragments.

\subsection{Temporal Direction from Redundancy Gradient}

This asymmetry induces a natural ordering on configurations of the accessible algebra:

\begin{definition}[Accessibility Ordering]
\label{H-def:F-ordering}
Let $\mathcal{A}_\alpha$ and $\mathcal{A}_\beta$ be two configurations of the accessible algebra (corresponding to different redundancy structures). We define the partial order:
\begin{equation}
\mathcal{A}_\alpha \prec \mathcal{A}_\beta \quad \Leftrightarrow \quad \mathcal{A}_\alpha \subset \mathcal{A}_\beta \text{ and } \mathcal{R}(\mathcal{A}_\beta) \geq \mathcal{R}(\mathcal{A}_\alpha).
\end{equation}
\end{definition}

This partial order is not imposed externally but emerges from the statistical structure of redundancy propagation. It constitutes the structural origin of temporal direction.

\begin{tcolorbox}[colback=gray!5!white,colframe=black!75!black,title=\textbf{Clarification: Arrow Without Fundamental Time}]
No fundamental time parameter is assumed. What might conventionally be written as $\mathcal{A}(t_1)$ and $\mathcal{A}(t_2)$ with $t_1 < t_2$ is here understood as $\mathcal{A}_\alpha \prec \mathcal{A}_\beta$---a partial order on algebraic configurations induced by redundancy monotonicity.

``Dynamical trajectories'' are not functions $\hat{O}(t)$ parametrized by external time, but \textbf{directed paths through the space of accessible algebras} $\{\mathcal{A}_\alpha\}$, with direction determined by the redundancy gradient:
\begin{equation}
\mathcal{A}_\alpha \subset \mathcal{A}_\beta \quad \text{with} \quad \mathcal{R}(\mathcal{A}_\beta) \geq \mathcal{R}(\mathcal{A}_\alpha).
\end{equation}

Time is not a parameter but the \textbf{inclusion order of accessible structures}.
\end{tcolorbox}

\subsection{The Statistical Nature of the Arrow}

The arrow of time, in this framework, is neither:
\begin{itemize}
    \item A fundamental law (time-reversal symmetry is not violated)
    \item A thermodynamic accident (entropy is not the primary concept)
    \item A cosmological boundary condition (no special initial state is assumed)
\end{itemize}

Rather, it is a \emph{statistical gradient}: the overwhelming majority of accessible-algebra configurations lie in the direction of increasing redundancy. Trajectories toward decreasing redundancy exist in principle but occupy exponentially vanishing phase space volume.

\begin{quote}
\textbf{Time is the statistical gradient of redundancy.}
\end{quote}

\subsection{Relation to Thermodynamic Arrow}

The accessibility arrow and the thermodynamic arrow are closely related but not identical:

\begin{table}[ht]
\centering
\small
\begin{tabular}{|p{3.5cm}|p{4.5cm}|p{4.5cm}|}
\hline
\textbf{Feature} & \textbf{Thermodynamic Arrow} & \textbf{Accessibility Arrow} \\
\hline
Defined by & Entropy increase & Redundancy expansion \\
\hline
Requires & Coarse-graining choice & Accessibility constraints \\
\hline
Fundamental quantity & $S = -k_B \text{Tr}(\rho \ln \rho)$ & $\mathcal{R}[\mathcal{A}]$ (redundancy index) \\
\hline
Applies to & Macroscopic systems & Any system with environment \\
\hline
\end{tabular}
\caption{Comparison of thermodynamic and accessibility arrows.}
\label{H-tab:arrows}
\end{table}

The accessibility arrow may be viewed as a \emph{generalization} of the thermodynamic arrow: it applies whenever accessibility constraints are satisfied, even in contexts where thermodynamic entropy is not well-defined (e.g., quantum gravitational regimes where spacetime is emergent).

\section{Causation as Constraint Propagation}
\label{H-sec:F-causation}

Having established that accessibility propagation defines a preferred direction, we now reframe causation in these terms.

\subsection{Causation Without Fundamental Time}

Traditional accounts of causation presuppose temporal ordering: causes precede effects. But if temporal ordering itself emerges from accessibility structure, causation must be reframed accordingly.

\begin{definition}[Causal Relation]
\label{H-def:F-causal}
An observable $\hat{A}$ is \textbf{causally prior} to observable $\hat{B}$ (written $\hat{A} \rightsquigarrow \hat{B}$) if:
\begin{enumerate}
    \item $\hat{A}$ and $\hat{B}$ are both accessible: $\hat{A}, \hat{B} \in \mathcal{A}_{\mathbf{c}}$
    \item The redundancy of $\hat{A}$ is established before the redundancy of $\hat{B}$: $\mathcal{R}(\hat{A})$ saturates at algebraic configuration $\mathcal{A}_\alpha$ while $\mathcal{R}(\hat{B})$ saturates at $\mathcal{A}_\beta$ with $\mathcal{A}_\alpha \prec \mathcal{A}_\beta$
    \item Counterfactual dependence holds: perturbations of $\hat{A}$ induce correlated perturbations of $\hat{B}$
\end{enumerate}
\end{definition}

This definition grounds causation in the propagation of accessibility constraints through environmental redundancy.

\subsection{Why Retrocausation is Non-Generic}

A persistent question in philosophy of physics is whether retrocausation---effects preceding causes---is possible. The present framework provides a structural answer:

\begin{proposition}[Suppression of Retrocausation]
\label{H-prop:retro}
Retrocausal trajectories are not excluded by principle, but are non-generic to the extent of being physically uninstantiable.
\end{proposition}

\begin{proof}[Proof sketch]
For $\hat{B}$ to causally influence $\hat{A}$ when $\mathcal{R}(\hat{A})$ is already saturated (information about $\hat{A}$ distributed across $N$ environmental fragments), the influence would need to:
\begin{enumerate}
    \item Propagate through all $N$ fragments simultaneously
    \item Reconverge the distributed information coherently
    \item Do so without disturbing the existing redundancy structure
\end{enumerate}
The phase space volume for such trajectories scales as $e^{-\alpha N}$ (Appendix~\ref{H-app:model}), rendering them statistically negligible for macroscopic $N$.
\end{proof}

\begin{remark}
This result does not ``forbid'' retrocausation by fiat. Rather, it explains why retrocausal scenarios---while not logically impossible---do not occur: they require exponentially fine-tuned conspiracies in Hilbert space that generically do not obtain. This is stronger than any ``causal postulate'' because it derives from the geometry of state space, not from an imposed principle.
\end{remark}

\subsection{Causal Structure Without Spacetime}

The causal relation $\rightsquigarrow$ defines a partial order on accessible observables with the following properties:
\begin{itemize}
    \item \textbf{Irreflexive}: $\hat{A} \not\rightsquigarrow \hat{A}$
    \item \textbf{Asymmetric}: $\hat{A} \rightsquigarrow \hat{B}$ implies $\hat{B} \not\rightsquigarrow \hat{A}$ (by Proposition~\ref{H-prop:retro})
    \item \textbf{Transitive}: $\hat{A} \rightsquigarrow \hat{B}$ and $\hat{B} \rightsquigarrow \hat{C}$ implies $\hat{A} \rightsquigarrow \hat{C}$
\end{itemize}

These properties are characteristic of causal structure and emerge here without presupposing a background temporal manifold.

\section{Relation to Existing Approaches}
\label{H-sec:F-relations}

We situate the accessibility-based account relative to existing approaches to temporal asymmetry.

\subsection{Comparison Table}

\begin{table}[ht]
\centering
\small
\begin{tabular}{|p{2.8cm}|p{3.5cm}|p{3.5cm}|p{3cm}|}
\hline
\textbf{Approach} & \textbf{Source of Arrow} & \textbf{What It Presupposes} & \textbf{Relation to HAFF} \\
\hline
Thermodynamic & Entropy increase & Coarse-graining choice & Accessibility more fundamental \\
\hline
Cosmological & Low-entropy Big Bang & Boundary conditions & Explains initial conditions \\
\hline
Decoherence & Interference suppression & System-environment split & Special case of accessibility \\
\hline
Causal set & Fundamental partial order & Causal order as primitive & HAFF derives the order \\
\hline
Page-Wootters & Correlations in static $|\Psi\rangle$ & Timeless formulation & HAFF adds directionality \\
\hline
\textbf{Accessibility} & \textbf{Redundancy expansion} & \textbf{Interaction structure} & \textbf{---} \\
\hline
\end{tabular}
\caption{Comparison of approaches to temporal asymmetry.}
\label{H-tab:comparison}
\end{table}

\subsection{Key Distinctions}

\textbf{Thermodynamic arrow}: The accessibility arrow is closely related but more fundamental. Entropy increase presupposes a coarse-graining; accessibility expansion explains \emph{why} certain coarse-grainings are physically relevant.

\textbf{Page-Wootters}: Both approaches treat time as emergent. Page-Wootters explains how time \emph{appears}; the accessibility framework explains why it has a \emph{direction}.

\textbf{Retrocausality programs}: Some approaches explore retrocausal models \cite{Price2012}. The present framework does not exclude retrocausation in principle but explains its non-occurrence: retrocausal trajectories occupy exponentially vanishing phase space volume.

\section{What This Paper Does NOT Claim}
\label{H-sec:F-noncommitments}

To prevent misreading, we state explicitly what this paper does \emph{not} claim.

\begin{enumerate}
    \item \textbf{No claim that time is unreal or illusory.} The framework reframes temporal asymmetry as emergent from accessibility structure, but this does not imply that time is ``merely subjective'' or non-existent.
    
    \item \textbf{No adjudication between A-theory and B-theory of time.} The framework is compatible with both presentism and eternalism.
    
    \item \textbf{No explanation of initial conditions.} We do not explain why the universe began with low redundancy, only why redundancy generically increases thereafter.
    
    \item \textbf{No resolution of the problem of time in quantum gravity.} The framework clarifies what temporal asymmetry \emph{means} in accessibility terms but does not derive time from the Wheeler-DeWitt equation.
    
    \item \textbf{No claims about consciousness or subjective time.} The phenomenology of temporal experience is not addressed.
    
    \item \textbf{No novel empirical predictions.} The analysis is structural, not dynamical.
    
    \item \textbf{No claim that retrocausation is impossible.} Retrocausation is statistically suppressed (measure zero), not logically forbidden.
    
    \item \textbf{No modification of quantum mechanics.} The framework assumes standard unitary evolution throughout.
\end{enumerate}

\section{Connection to HAFF Framework}
\label{H-sec:F-connection}

This paper completes the diagnostic layer of the HAFF framework.

\subsection{The D + E + F Diagnostic Triangle}

Papers D, E, and F form a coherent triad, each addressing a different aspect of how structure emerges from accessible algebras:

\begin{table}[ht]
\centering
\small
\begin{tabular}{|p{1.5cm}|p{2.5cm}|p{4cm}|p{4.5cm}|}
\hline
\textbf{Paper} & \textbf{Phenomenon} & \textbf{Traditional View} & \textbf{HAFF Reframing} \\
\hline
D & Gravity & Force between masses & Evolution of accessible algebra \\
\hline
E & Measurement & Primitive process & Selection within accessible algebra \\
\hline
F & Time & Fundamental parameter & Direction of accessibility propagation \\
\hline
\end{tabular}
\caption{The D + E + F diagnostic triangle.}
\label{H-tab:triad}
\end{table}

The unifying theme is that features traditionally taken as fundamental---force, measurement, time---may be understood as emergent properties of accessibility structure.

\subsection{Structural Link: D + E + F}

The three papers form a symmetric closed structure:
\begin{itemize}
    \item \textbf{D (Gravity)}: The evolution $\mathcal{A}_{\mathbf{c}}(t)$ of the accessible algebra manifests as curved geometry.
    \item \textbf{E (Measurement)}: The selection of $\mathcal{A}_{\mathbf{c}}$ via physical constraints manifests as objective outcomes.
    \item \textbf{F (Time)}: The direction of redundancy expansion within $\mathcal{A}_{\mathbf{c}}$ manifests as the causal arrow.
\end{itemize}

\subsection{Boundary Note: Toward Layer III}

The completion of Layer II (diagnostic unification) sets the stage for Layer III: the structural limits of the framework itself.

A key insight from D + E + F is that what appears fundamental (force, measurement, time) is actually emergent from accessible algebras. But this raises a question: \emph{What determines the accessible algebra structure itself?}

Layer III (Paper G) will argue that this question admits no complete answer within the framework---not because the framework is incomplete, but because any answer would require a ``meta-framework'' to justify, leading to infinite regress. The boundary is structural, not epistemic.

A theory that claims to explain everything must know where it must stop.

\section{Conclusion}
\label{H-sec:F-conclusion}

\subsection{Summary of Results}

We have proposed a structural account of temporal asymmetry and causation based on accessibility propagation. The central results are:

\begin{enumerate}
    \item \textbf{Time without fundamental parameter}: All temporal ordering emerges from a partial order induced by algebraic inclusion and redundancy monotonicity. No external time parameter is assumed.
    
    \item \textbf{The accessibility arrow}: Redundancy expansion is generic; redundancy contraction is exponentially suppressed. This asymmetry defines a preferred direction.
    
    \item \textbf{Causation as constraint propagation}: Causal relations emerge from constraint propagation along the accessibility arrow. Causes are sources of redundancy expansion; effects are regions of redundant recording.
    
    \item \textbf{Retrocausation non-generic}: Retrocausal trajectories are not excluded by principle, but are non-generic to the extent of being physically uninstantiable.
    
    \item \textbf{Diagnostic layer complete}: With Papers D, E, and F, the HAFF framework provides unified structural accounts of gravity, measurement, and time.
\end{enumerate}

\subsection{Closing Remark}

The arrow of time has puzzled physicists and philosophers for over a century. We do not claim to have dissolved this puzzle. What we have done is reframe it:

\begin{quote}
The question is not ``Why does entropy increase?'' but ``Why does accessibility expand?''
\end{quote}

The answer---that expansion is generic while contraction requires exponential fine-tuning---follows from the geometry of Hilbert space in interacting systems. This does not explain everything. But by identifying the structural basis of temporal asymmetry, we clarify what remains to be explained---and what, perhaps, lies beyond the reach of structural analysis altogether.

\section{A Minimal Model of Irreversible Redundancy Expansion}
\label{H-app:model}

To rigorously demonstrate the central thesis of Section~\ref{H-sec:F-accessibility}---that accessibility expansion is generic while contraction is statistically suppressed---we consider a finite-dimensional model of a central system interacting with a fragmented environment.

\subsection{The Star-Graph Interaction Setup}

Consider a central system $S$ (the ``source'' of accessibility) and an environment $E$ consisting of $N$ independent subsystems (fragments) $E_1, E_2, \ldots, E_N$. The total Hilbert space is:
\begin{equation}
\mathcal{H}_{\text{tot}} = \mathcal{H}_S \otimes \mathcal{H}_{E_1} \otimes \mathcal{H}_{E_2} \otimes \cdots \otimes \mathcal{H}_{E_N}.
\end{equation}

The interaction Hamiltonian generating accessibility is chosen to be of the ``pre-measurement'' type:
\begin{equation}
\hat{H}_{\text{int}} = g \sum_{k=1}^{N} \hat{O}_S \otimes \hat{M}_k,
\end{equation}
where $\hat{O}_S$ is the observable of $S$ becoming accessible, $\hat{M}_k$ are the monitoring operators of the environmental fragments, and $g$ is the coupling strength.

\subsection{Dynamics of Redundancy}

Assume the initial state is uncorrelated:
\begin{equation}
|\Psi(0)\rangle = |s\rangle_S \otimes |e_0\rangle_{E_1} \otimes |e_0\rangle_{E_2} \otimes \cdots \otimes |e_0\rangle_{E_N}.
\end{equation}

Under the unitary evolution $U(t) = e^{-i\hat{H}_{\text{int}}t/\hbar}$, the state evolves into an entangled superposition. For $\hat{O}_S$ with eigenstates $|o_i\rangle$:
\begin{equation}
|\Psi(t)\rangle = \sum_i c_i |o_i\rangle_S \otimes |E_i^{(1)}(t)\rangle \otimes |E_i^{(2)}(t)\rangle \otimes \cdots \otimes |E_i^{(N)}(t)\rangle,
\end{equation}
where $|E_i^{(k)}(t)\rangle$ are the relative states of the environmental fragments.

The mutual information $I(\hat{O}_S : E_k)$ grows as the fragments become correlated with $S$. By standard decoherence results \cite{Zurek2003}, for small $t$:
\begin{equation}
I(\hat{O}_S : E_k) \sim (gt)^2.
\end{equation}

\subsection{Proof of Asymmetry}

\textbf{Forward Evolution (Generic Expansion):}

As $t$ increases, information spreads to more fragments. For $gt \gg 1$, the redundancy index approaches its maximum:
\begin{equation}
\mathcal{R}(\hat{O}_S) \to N.
\end{equation}
This state corresponds to the ``classical plateau'' where the algebra generated by $\hat{O}_S$ is maximally accessible.

\textbf{Backward Evolution (Contraction Suppression):}

Consider the time-reversed evolution from a state of high redundancy. For $\mathcal{R}$ to decrease, the $N$ environmental fragments must conspiratorially un-correlate with $S$ simultaneously.

In the phase space of the total system $\mathcal{H}_{\text{tot}}$, let $V_{\text{low}}$ be the volume of states with low redundancy ($\mathcal{R} < \mathcal{R}_{\text{crit}}$) and $V_{\text{high}}$ be the volume of states with high redundancy ($\mathcal{R} \sim N$).

By counting Hilbert space dimensions, the ratio is exponentially suppressed:
\begin{equation}
\frac{V_{\text{low}}}{V_{\text{high}}} \sim e^{-\alpha N},
\end{equation}
where $\alpha > 0$ depends on the dimension of the fragments.

\subsection{Conclusion of Appendix}

While the dynamical laws ($U(t) = e^{-i\hat{H}t/\hbar}$) are reversible, the \textbf{Accessibility Flow} is structurally irreversible:
\begin{itemize}
    \item A trajectory starting in $V_{\text{low}}$ generically moves to $V_{\text{high}}$ (time arrow $\to$).
    \item A trajectory starting in $V_{\text{high}}$ will almost never spontaneously fluctuate back to $V_{\text{low}}$ within the recurrence time of the universe.
\end{itemize}

The irreversibility comes from \textbf{state space volume}, not from dynamical asymmetry. This is the structural basis of the accessibility arrow:

\begin{center}
\fbox{\textbf{Time is the statistical gradient of Redundancy.}}
\end{center}


% ============================================================================
% Paper G
% ============================================================================
\chapter{Structural Limits of Unification}
\label{H-chap:paperG}

\begin{center}
\textit{Paper G}\\[0.5em]
Originally published: Zenodo, DOI: 10.5281/zenodo.18402908
\end{center}

\bigskip

\section*{Abstract}

This paper examines the structural conditions under which a unificatory physical framework must terminate its explanatory extension. Building on recent work demonstrating that gravitational phenomena, measurement outcomes, and temporal asymmetries can be jointly reframed as consequences of accessible observable algebra selection, we argue that such frameworks cannot be simultaneously complete and self-grounding. The incompleteness identified here is neither formal (in the G\"{o}del--Turing sense) nor epistemic, but architectural: it arises from the non-self-grounding character of accessibility-based physical description. We establish a structural lemma showing that any attempt to internalize accessibility conditions within the framework they enable leads to either infinite regress or explanatory collapse. The stopping point identified is therefore not discretionary but forced by the framework's own explanatory architecture. This analysis does not claim generality beyond the specific formalism developed; whether alternative approaches would encounter analogous limits remains an open question. The contribution is methodological: to articulate the conditions under which recognizing structural boundaries becomes a requirement of explanatory coherence rather than an admission of incompleteness.


\section{Introduction}
\label{H-sec:G-intro}

\subsection{The Expectation of Completeness}

The aspiration toward a unified physical description has historically been guided by the expectation that deeper unification corresponds to increased completeness. In this traditional view, apparent multiplicity---of forces, degrees of freedom, or explanatory principles---is taken to signal provisional fragmentation, to be resolved by a more fundamental theory. A Theory of Everything, in its strongest formulation, is therefore often assumed to be both unifying and self-grounding: it should not only subsume all known interactions under a single framework, but also account for the conditions under which its own descriptions are possible.

The present work does not adopt this expectation. Instead, it advances a more restricted claim: that unification may be achievable only up to a structurally imposed boundary, beyond which further explanatory extension would undermine the coherence of the framework itself. This claim does not arise from epistemic modesty, nor from skepticism regarding the scope of physical explanation, but from the internal architecture of the formalism developed in the preceding papers of this series \cite{Liu2026PaperA,Liu2026PaperB,Liu2026PaperC,Liu2026PaperD,Liu2026PaperE,Liu2026PaperF}, which builds on foundational observations regarding the non-uniqueness of tensor factorizations \cite{Zanardi2001,Zanardi2004}.

\subsection{Summary of the Preceding Framework}

Across Papers D--F, gravitational phenomena, measurement outcomes, and temporal asymmetries are jointly reframed as consequences of structural selection: specifically, the selection of accessible observable algebras and associated coarse-grainings. No new fundamental entities are postulated, and no modification of underlying dynamics is proposed. Rather, phenomena traditionally treated as primitive are shown to emerge from constraints on how physical descriptions are stably instantiated.

\begin{itemize}
    \item \textbf{Paper D}: Gravitational dynamics corresponds to the adiabatic flow of the accessible algebra $\mathcal{A}_{\mathbf{c}}(t)$, not to a force operating within a fixed algebra.
    \item \textbf{Paper E}: Measurement is not a primitive process but a manifestation of accessibility constraints on operator algebras---specifically, the selection of observables satisfying interaction, stability, and redundancy criteria.
    \item \textbf{Paper F}: Temporal directionality is identified with the direction of irreversible accessibility propagation, grounded in the asymmetric expansion of redundant environmental records.
\end{itemize}

These results share a common structure: each phenomenon is traced to accessibility conditions rather than to fundamental ontology. This constitutes a genuine unification at the level of explanatory architecture.

\subsection{The Problem of Self-Grounding}

However, this reframing has a nontrivial implication. If the explanatory power of the framework depends essentially on restrictions---on what is accessible, stable, and non-scrambling---then unification cannot consist in the removal of all such restrictions. To do so would be to erase the very conditions that render physical description meaningful. Unification, in this sense, cannot be both total and self-enclosed.

The unifying move, therefore, is not a convergence toward an all-encompassing description, but a clarification of how far structural explanation can be coherently extended before it becomes reflexive. The aim of this final layer is to articulate that stopping point and to demonstrate that it is structurally forced rather than pragmatically chosen.

\subsection{Scope and Limitations}

Several clarifications are necessary at the outset.

First, the incompleteness identified in this paper is not formal in the sense of G\"{o}del's incompleteness theorems. We do not claim that the framework contains undecidable propositions within a formal system, nor do we invoke metamathematical results. The incompleteness is \emph{architectural}: it concerns the explanatory roles within a physical framework, not provability within a formal calculus.

Second, we do not claim that the structural limits identified here apply universally to all conceivable approaches to unification. The present analysis is confined to the algebraic and coarse-graining-based framework developed in Papers A--F. Whether alternative formalisms---category-theoretic, non-algebraic, or radically background-free---would exhibit analogous limits is an open question that we do not address.

Third, the stopping point identified is not temporal, existential, or normative. It does not mark the end of physics, nor a claim about the limits of human knowledge. It marks the point at which the framework's internal explanatory resources are exhausted without circularity.

\subsection{Structure of the Paper}

Section~\ref{H-sec:G-accessibility} develops the notion of accessibility as a non-global structural constraint and clarifies its distinction from epistemic limitations. Section~\ref{H-sec:G-lemma} establishes a structural lemma demonstrating that accessibility-based descriptions cannot be self-grounding without collapse or regress. Section~\ref{H-sec:G-collapse} presents a concrete collapse scenario illustrating what would occur if the framework were extended beyond its structural boundary. Section~\ref{H-sec:G-cut} characterizes the final cut as a forced stopping point rather than a discretionary choice. Section~\ref{H-sec:G-nonclaims} states explicit non-claims to prevent misinterpretation. Section~\ref{H-sec:G-conclusion} concludes with reflections on the methodological significance of the analysis.

\section{Accessibility as a Non-Global Constraint}
\label{H-sec:G-accessibility}

\subsection{The Role of Accessibility in HAFF}

Central to the HAFF framework is the notion of accessibility. Physical descriptions are not formulated over the full algebra of global observables, but over restricted subalgebras determined by interaction structure, dynamical stability, and environmental redundancy. These restrictions are not introduced as pragmatic simplifications, nor as reflections of limited knowledge. They are constitutive of what counts as a well-defined physical description in the first place.

In Papers D--F, this point is developed across distinct domains:

\begin{itemize}
    \item Effective geometry is shown to depend on coarse-grainings that preserve entanglement structure over relevant timescales.
    \item Measurement outcomes are shown to arise from dynamically stable partitions that resist rapid scrambling.
    \item Temporal directionality is associated with asymmetric information flow under constrained interactions.
\end{itemize}

In each case, the phenomenon under consideration becomes intelligible only relative to a selected accessible algebra.

\subsection{Structural vs.\ Epistemic Constraints}

A crucial distinction must be drawn between epistemic and structural constraints. This distinction is contested in philosophy of physics, and we acknowledge that what follows adopts it as a working criterion rather than a demonstrated result.

\begin{definition}[Epistemic Constraint]
A constraint is \textbf{epistemic} if it concerns what can be known, inferred, or verified by agents, given their informational position.
\end{definition}

\begin{definition}[Structural Constraint]
A constraint is \textbf{structural} if it concerns what descriptions are well-defined, given a pattern of physical interactions, independent of any agent's knowledge or epistemic state.
\end{definition}

The HAFF framework relies exclusively on the latter notion. Accessibility is determined by stability criteria---dynamical invariance, environmental redundancy (quantum Darwinism), and non-scrambling behavior---that are properties of the Hamiltonian and the global quantum state, not of observers.

Crucially, the selection of an accessible algebra is not arbitrary. Given a fixed interaction structure, different agents---or no agents at all---will identify the same accessible observables. This is the sense in which accessibility is structural rather than epistemic: it is interaction-determined, not belief-determined.

\begin{remark}[Contested Distinction]
We acknowledge that this distinction between epistemic and structural constraints is philosophically contested. The framework does not claim to have resolved this broader debate. However, the burden of argument lies with the critic to demonstrate that the stability criteria invoked in Papers A--F reduce to epistemic conditions, rather than with the framework to prove a negative. The working distinction is adopted on the grounds that interaction-determined constraints are conceptually prior to agent-relative knowledge.
\end{remark}

\subsection{Non-Globality of Accessibility}

Accessibility is not a global property of the underlying theory. There is no privileged, all-encompassing accessible algebra from which all others can be derived. Each effective description presupposes its own restrictions, and those restrictions cannot be fully specified from within the description they enable.

This asymmetry is decisive. Any attempt to internalize the conditions of accessibility would require a further level of description, governed by its own accessibility conditions. The implications of this observation are developed in the following section.

\section{A Structural Lemma on Self-Grounding}
\label{H-sec:G-lemma}

\subsection{Statement of the Lemma}

We now state the central structural result of this paper.

\begin{lemma}[Structural Non-Self-Grounding]
\label{H-lem:nonsg}
Within the HAFF framework, no description can simultaneously:
\begin{enumerate}
    \item[(i)] specify the structure of accessibility, and
    \item[(ii)] be formulated entirely within that same accessibility structure,
\end{enumerate}
without collapse into circularity or triviality.
\end{lemma}

\subsection{Argument}

The argument proceeds in five steps.

\paragraph{Step 1: All physical descriptions in HAFF are formulated relative to an accessible algebra.}
This is not an optional modeling choice but the basic condition under which any observable, geometry, or temporal ordering becomes definable. Papers D--F establish that gravitational dynamics, measurement outcomes, and causal direction all presuppose restriction to a stable accessible subalgebra $\mathcal{A}_{\mathbf{c}} \subset \mathcal{B}(\mathcal{H}_U)$.

\paragraph{Step 2: Accessibility itself is defined by selection criteria.}
Stability, redundancy, and interaction locality determine which subalgebras are accessible. These criteria are conditions of possibility for description, not objects described within the description.

\paragraph{Step 3: Attempting to internalize accessibility requires re-applying accessibility criteria to themselves.}
That is, one would need an accessible algebra that describes the selection of the accessible algebra itself. The framework would have to render the conditions of its own applicability as objects within its descriptive scope.

\paragraph{Step 4: This generates a fixed-point requirement.}
The framework would have to identify an algebra $\mathcal{A}^*$ that:
\begin{itemize}
    \item is accessible because it satisfies the stability criteria, and
    \item simultaneously encodes the criteria by which it is judged accessible.
\end{itemize}
Symbolically, one would require:
\begin{equation}
\mathcal{A}^* \in \text{Acc}(\mathcal{A}^*),
\end{equation}
where $\text{Acc}(\cdot)$ denotes the set of algebras satisfying the accessibility criteria defined within the argument algebra.

\paragraph{Step 5: Such a fixed point is generically unavailable.}
Except in degenerate cases---trivial algebras (containing only the identity) or total algebras (the full $\mathcal{B}(\mathcal{H}_U)$ that erases all structure)---the selection criteria cannot be satisfied by their own output. A non-trivial accessible algebra defines distinctions (between accessible and inaccessible, stable and scrambled, redundant and local); encoding the criteria for those distinctions within the algebra would require the algebra to contain its own meta-description, which exceeds the information available at the object level.

\subsection{Conclusion of the Lemma}

Therefore, the framework cannot close on itself without either:
\begin{itemize}
    \item collapsing into triviality (everything accessible, nothing distinguished), or
    \item introducing an external meta-structure (violating internal coherence).
\end{itemize}

The stopping point is not pragmatic. It is forced by the non-self-grounding character of accessibility-based description.

\begin{remark}[Framework-Relative Claim]
This is a necessity claim internal to the framework's architecture, not a universal limitation on explanation. We do not claim that all physical theories must exhibit this structure, only that the HAFF framework, as developed, does.
\end{remark}

\section{A Collapse Scenario}
\label{H-sec:G-collapse}

To make the structural lemma concrete, we now present a hypothetical extension of HAFF that attempts to fully internalize accessibility as an object-level dynamical variable, and show that this attempt fails.

\subsection{Hypothetical Extension}

\paragraph{Step 1: Treat accessibility as a physical observable.}
Suppose one introduces an operator or state variable $\hat{A}$ encoding ``degree of accessibility'' for subalgebras. This variable would quantify, for each subalgebra $\mathcal{A} \subset \mathcal{B}(\mathcal{H}_U)$, the extent to which it satisfies the stability criteria.

\paragraph{Step 2: Demand dynamical laws for accessibility.}
To be explanatory, $\hat{A}$ must:
\begin{itemize}
    \item evolve under some dynamics, and
    \item be measurable within the theory.
\end{itemize}

\paragraph{Step 3: Apply accessibility criteria to $\hat{A}$.}
But measurability requires that $\hat{A}$ itself satisfy:
\begin{itemize}
    \item stability under interaction,
    \item redundancy across environments, and
    \item non-scrambling behavior.
\end{itemize}
That is, $\hat{A}$ must belong to some accessible algebra $\mathcal{A}_{\hat{A}}$.

\subsection{Two Fatal Outcomes}

\paragraph{Outcome (a): Infinite regress.}
The algebra $\mathcal{A}_{\hat{A}}$ that makes $\hat{A}$ accessible is itself defined by accessibility criteria. To explain why $\mathcal{A}_{\hat{A}}$ is accessible, one would need a further algebra $\mathcal{A}_{\mathcal{A}_{\hat{A}}}$, and so on. Each level of accessibility-description requires a higher-level accessibility structure to define its observables. The regress does not terminate.

\paragraph{Outcome (b): Totalization collapse.}
To avoid regress, one might declare everything accessible---that is, take $\mathcal{A}_{\mathbf{c}} = \mathcal{B}(\mathcal{H}_U)$. But then:
\begin{itemize}
    \item no algebra selection remains,
    \item no measurement distinction exists (all observables are equally accessible),
    \item effective geometry loses definition (no coarse-graining induces structure), and
    \item temporal direction vanishes (no asymmetric accessibility propagation).
\end{itemize}
The framework either never terminates or destroys the very distinctions it set out to explain.

\subsection{Conclusion of the Scenario}

Any attempt to go ``beyond'' Papers D--F by internalizing accessibility eliminates the explanatory power already achieved. This is not philosophical caution. It is structural self-destruction.

The collapse scenario demonstrates concretely what the structural lemma establishes abstractly: the framework cannot extend itself to explain its own conditions of applicability without losing the capacity to explain anything at all.

\section{The Necessity of a Final Cut}
\label{H-sec:G-cut}

\subsection{Stopping as Structural Necessity}

The preceding analyses motivate a specific sense in which the HAFF framework is incomplete. This incompleteness is neither formal nor metaphysical. It does not arise from undecidable propositions, nor from claims about the limits of human cognition. Rather, it is structural: a consequence of the fact that explanatory resources cannot simultaneously function as both explanans and explanandum.

Within the framework developed here, gravity, measurement, and time are unified at the level of structural selection. They are shown to depend on how observable algebras are restricted and stabilized. This constitutes a genuine unification, insofar as disparate phenomena are traced to a common architectural feature. Yet the framework does not, and cannot, provide a further account of why those accessibility conditions obtain, without appealing to structures that would themselves require explanation under the same terms.

\subsection{The Final Cut}

The notion of a ``final cut'' is introduced to mark this boundary. It does not denote a temporal endpoint, nor a claim about the completion of physics. It denotes the point at which the internal explanatory strategy of the framework reaches saturation. Beyond this point, further elaboration would no longer clarify structure, but obscure it by erasing the asymmetries that make explanation possible.

The introduction of a final cut is not a discretionary methodological choice, nor a gesture of philosophical modesty. It is the point at which the framework exhausts its own internal resources without contradiction.

Beyond this point, any further extension would require the framework to explain the conditions of its own applicability using those very conditions---a requirement that admits no non-degenerate solution (Lemma~\ref{H-lem:nonsg}).

The stopping point is therefore not selected but encountered. It is the boundary at which explanation ceases to be generative and becomes self-consuming.

\subsection{Incompleteness as Internal Limit}

In this sense, the incompleteness identified here is not provisional, nor external, nor epistemic. It is structural and internal: a limit imposed by the framework's success in making accessibility do explanatory work.

The framework terminates not in absence, but at the level of unselected structure---a domain that admits no geometry, no temporal ordering, and no observational standpoint, yet functions as the necessary substrate from which all three are selectively realized.

A theory may approach totality only by knowing where it must stop---relative to its own structure.

\begin{remark}[Non-Arbitrary Stopping]
The stopping point is non-arbitrary in the following precise sense: any proposed extension beyond this point can be shown to lead either to regress (Section~\ref{H-sec:G-collapse}, Outcome a) or to collapse (Section~\ref{H-sec:G-collapse}, Outcome b). The burden of argument therefore shifts to those who claim that further extension is possible: they must specify how regress or collapse is avoided.
\end{remark}

\section{Scope and Non-Claims}
\label{H-sec:G-nonclaims}

To prevent misinterpretation, several non-claims must be stated explicitly.

\begin{enumerate}
    \item \textbf{No invocation of G\"{o}del's theorems.} This work does not invoke G\"{o}del's incompleteness theorems, nor does it rely on any formal analogy to them. The incompleteness identified here is architectural, not metamathematical. It concerns explanatory roles within a physical framework, not provability within a formal system.
    
    \item \textbf{No claim of universal applicability.} No claim is made that accessibility constraints apply universally across all conceivable approaches to unification. The present analysis is confined to the algebraic and coarse-graining-based framework developed in Papers A--F.
    
    \item \textbf{Contested distinction acknowledged.} The distinction between structural and epistemic constraints is acknowledged to be contested in the philosophy of physics. The framework adopts this distinction as a working criterion, grounded in interaction-determined stability conditions. It does not claim to have resolved the broader philosophical debate.
    
    \item \textbf{No foreclosure of alternative frameworks.} The identification of a final cut does not preclude further physical progress, alternative models, or deeper insights within other frameworks. It merely states that, within the present formalism, further internal extension would be incoherent.
    
    \item \textbf{No uniqueness claim.} We do not claim that this stopping point is unique. Other frameworks may stop elsewhere, or may not require stopping at all. The claim is only that, given the explanatory architecture adopted here, the stopping point identified is forced.
    
    \item \textbf{No philosophical finality.} This is a structural observation within a specific formalism, not a philosophical conclusion about the ultimate nature of reality or the limits of knowledge as such. The stopping point identified is methodological and structural, not existential.
    
    \item \textbf{No consciousness or observer-creation claims.} The framework does not claim that consciousness plays a fundamental role, that observers create reality, or that accessibility is observer-relative in any subjective sense.
    
    \item \textbf{No claim of novelty regarding theoretical presupposition.} We acknowledge that the observation that explanatory frameworks have presuppositions they cannot fully explain is familiar in philosophy of science. The contribution here is to show that the specific HAFF framework forces this conclusion through its reliance on accessibility, not merely that it is compatible with it.
\end{enumerate}

\section{Conclusion}
\label{H-sec:G-conclusion}

\subsection{Summary of Results}

This paper has examined the structural conditions under which the HAFF framework must terminate its explanatory extension.

The central results are:

\begin{enumerate}
    \item \textbf{Accessibility as non-global constraint}: Physical descriptions in HAFF are formulated relative to accessible algebras, which are determined by stability criteria that cannot be fully specified from within the descriptions they enable.
    
    \item \textbf{Structural non-self-grounding} (Lemma~\ref{H-lem:nonsg}): No description within HAFF can simultaneously specify the structure of accessibility and be formulated entirely within that accessibility structure, without collapse or regress.
    
    \item \textbf{Collapse scenario}: Any attempt to internalize accessibility as an object-level variable leads to infinite regress or totalization collapse, eliminating the framework's explanatory power.
    
    \item \textbf{Forced stopping point}: The final cut is not discretionary but encountered as a structural necessity---the point at which further extension would be self-consuming rather than generative.
\end{enumerate}

\subsection{Methodological Significance}

Unification is often equated with the elimination of boundaries. The analysis presented here suggests a different criterion: that a unifying framework should distinguish between boundaries that are provisional and those that are structural.

Papers D--F identify such structural boundaries in the treatment of gravity, measurement, and time. This final layer marks the point at which acknowledging those boundaries becomes a condition of explanatory clarity rather than an admission of incompleteness.

The value of the framework lies not in its ability to say everything, but in its ability to determine what cannot be said without loss of coherence. At that point, stopping is not a retreat, but a completion.

\subsection{Open Questions}

Several questions remain beyond the scope of this analysis:

\begin{itemize}
    \item Whether alternative frameworks (category-theoretic, non-algebraic, or background-free) would exhibit analogous structural limits.
    \item Whether the structural/epistemic distinction adopted here can be given a more robust philosophical foundation.
    \item Whether the collapse scenario admits any non-trivial avoidance strategies not considered here.
\end{itemize}

These questions are left for future investigation.


% ============================================================================
% Postscript
% ============================================================================
\chapter*{Postscript: On the Closure of Structure}
\addcontentsline{toc}{chapter}{Postscript}

\begin{center}
\textit{Originally published: Zenodo, DOI: 10.5281/zenodo.18407368}
\end{center}

\bigskip

% ============================================================================
% POSTSCRIPT
% ============================================================================

In the Holographic Alaya--Field Framework, the universe has been treated not as a collection of fundamental objects, but as a bounded domain of accessibility within a single global operator structure \cite{Liu2026PaperA,Liu2026PaperB}. Throughout this work, gravity, time, and measurement have appeared only insofar as stable distinctions are sustained by a persistent separation---what we have called the Cut---between accessible subalgebras and the total algebra \cite{Liu2026PaperE,Liu2026PaperG}. The philosophical implications of this structural stance---for causation, agency, and existence---have been explored in the accompanying essay \cite{Liu2026PaperC}.

Pushing this framework to its logical limit raises a natural question: what becomes of the theory when such distinctions can no longer be maintained?

\section*{Heat Death as Accessibility Saturation}

From a structural perspective, the conventional notion of heat death admits a reinterpretation. Rather than signifying the disappearance of physical existence, it corresponds to the saturation of accessibility. As informational redundancy becomes maximal, differences between subsystems cease to be stably recordable \cite{Zurek2009}. The gradients that underwrite locality, temporal ordering, and effective classicality flatten into a homogeneous configuration.

In this limit, the Cut loses operational meaning. No stable partition remains that could support observers, records, or localized descriptions. The system approaches the undifferentiated operator structure introduced at the beginning of this work---a state of maximal symmetry and minimal distinguishability.

\section*{Structural Equivalence of Origin and Terminus}

Crucially, this endpoint is not structurally distinct from the origin. The state of maximal entropy reached at late times is, in algebraic terms, indistinguishable from the maximally symmetric pre-differentiated configuration. The difference between ``beginning'' and ``end'' is therefore not ontological, but structural: it reflects whether accessibility constraints are present or dissolved.

Mathematically, let $\mathcal{A}_{\text{total}}$ denote the full operator algebra and let $S[\rho]$ denote the von Neumann entropy of a state $\rho$. At both temporal extremes:
\begin{equation}
\lim_{t \to 0^+} S[\rho(t)] \approx \lim_{t \to \infty} S[\rho(t)] \approx S_{\max},
\end{equation}
where the limits are understood in terms of accessible structure rather than absolute time. The initial state (pre-Cut) and the final state (post-dissolution) occupy the same region of algebraic configuration space---both correspond to conditions under which no stable coarse-graining can be sustained.

\section*{Bounded Evolution Without Cyclicity}

Seen this way, cosmic evolution traces neither a linear narrative nor a teleological arc. It is instead bounded by two structurally equivalent limits: one preceding the emergence of stable distinctions, and one following their dissolution. The domain in which physics, observation, and meaning are possible occupies only the intermediate regime, where the Cut is sustained.

This observation carries no additional dynamical claims, nor does it posit a cosmological cycle in the sense of a Big Bounce or oscillating universe model \cite{Penrose2010}. It merely completes the logical closure of the framework developed here. The theory describes the conditions under which structure can appear, persist, and ultimately fail. Beyond those conditions, no further physical description is available---not because reality ends, but because the criteria for description are no longer satisfied.

\section*{The Contingency of Intelligibility}

If the work has a final implication, it is a modest one: intelligibility itself is contingent. The universe is describable only while distinctions endure. Understanding this boundary does not diminish the value of structure; it clarifies the narrow window in which structure---and thus physics---is possible.

The framework terminates not in absence, but at the level of unselected structure: a domain that admits no geometry, no temporal ordering, and no observational standpoint, yet functions as the necessary substrate from which all three are selectively realized.

\begin{remark}[On Structural Closure]
The identification of origin and terminus as algebraically equivalent does not constitute a prediction about cosmological dynamics. It is a statement about the explanatory boundaries of accessibility-based description. Within those boundaries, the framework provides a unified account of gravity, measurement, and time \cite{Liu2026PaperD,Liu2026PaperE,Liu2026PaperF}. Beyond them, no description formulated in terms of accessible algebras can be coherently maintained \cite{Liu2026PaperG}.
\end{remark}

\section*{Concluding Reflection}

The value of a theoretical framework lies not only in what it explains, but in what it determines cannot be explained without loss of coherence. The stopping point identified in this work is not a failure of explanation but its completion. A theory that claims to explain everything must know where it must stop.

\bigskip

\noindent\textit{Clarity does not require totality. And knowing where to stop is sometimes the most precise act of understanding.}

\newpage

% ============================================================================
% REFERENCES
% ============================================================================

% ============================================================================
% Acknowledgments
% ============================================================================

% ============================================================================
% PART II: Q-RAIF
% ============================================================================
\part{Q-RAIF: Quantum Reference Algebra for Information Flow}
\label{part:QRAIF}

% ============================================================================
% PAPER A
% ============================================================================
\chapter{Algebraic Constraints on the Emergence of Lorentzian Metrics in Entropic Gravity Frameworks}
\label{Q-chap:paperA}

\begin{center}
\textit{Paper A --- ``The Water''}\\[0.5em]
Originally published: Zenodo, DOI: 10.5281/zenodo.18525877
\end{center}

\bigskip

% ============================================================
\section*{Abstract}
We investigate the algebraic conditions under which an emergent bulk geometry acquires a Lorentzian signature within the framework of entropic gravity.
While thermodynamic approaches to gravity~\cite{Jacobson1995,Verlinde2011} and the Ryu--Takayanagi formula~\cite{RyuTakayanagi2006} relate entanglement entropy to geometric data, the specific algebraic mechanism constraining the spacetime signature remains an open question.

We identify three independent constraints on the boundary algebra---associativity, metric compatibility, and causal channel encoding---and argue that their simultaneous satisfaction naturally selects a \textbf{Clifford algebra} $Cl(V,q)$ as the minimal compatible structure.
We support this claim by systematically examining alternative algebraic frameworks (von Neumann factors, $C^*$-algebras, Jordan algebras, Lie algebras) and demonstrating that each fails to satisfy at least one constraint.
A worked example using a qubit tensor network illustrates how the three constraints operate in a concrete setting.

The analysis complements the Holographic Alaya-Field Framework (HAFF)~\cite{Liu2026HAFF_A,Liu2026HAFF_B}, which establishes that geometry emerges from coarse-graining of observable algebras: the present work characterizes the algebraic constraints that any such emergent geometry must satisfy to be Lorentzian.

\medskip
\noindent\textbf{Keywords}: emergent geometry, Clifford algebra, entropic gravity, holographic principle, signature selection, algebraic quantum gravity


% ============================================================
\section{Introduction}
\label{Q-A-sec:intro}

\subsection{Context and Motivation}

The AdS/CFT correspondence~\cite{Maldacena1999} and the Ryu--Takayanagi formula~\cite{RyuTakayanagi2006} have established that spacetime geometry can be viewed as an emergent property of quantum entanglement.
Thermodynamic approaches~\cite{Jacobson1995,Verlinde2011} further suggest that the Einstein equations arise as an equation of state.
Yet a critical question remains: \textit{What algebraic constraints ensure that the emergent geometry is Lorentzian?}

Most models assume the $(1,3)$ signature \textit{a priori}.
We argue that this assumption can be partially justified by examining the algebraic consistency conditions on the boundary degrees of freedom.

\subsection{Relation to HAFF}

The Holographic Alaya-Field Framework~\cite{Liu2026HAFF_A,Liu2026HAFF_B} demonstrates that inequivalent coarse-graining structures on a global quantum state induce inequivalent emergent geometries.
HAFF establishes \emph{that} geometry emerges from observable algebras; the present work addresses \emph{what algebraic constraints} such emergent geometry must satisfy to be Lorentzian.

\begin{center}
\begin{tabular}{ll}
\textbf{HAFF} & Geometry is coarse-graining-dependent (the ``ocean'') \\
\textbf{This paper} & Lorentzian signature is algebraically constrained (the ``water'')
\end{tabular}
\end{center}

\subsection{Scope and Disclaimers}

This work does not propose a new fundamental theory of gravity, nor does it claim to derive $Cl(1,3)$ from first principles alone.
Rather, it identifies a set of physically motivated algebraic constraints and argues that Clifford algebra is the minimal structure satisfying all of them simultaneously.
The argument is presented as a \emph{consistency analysis}, not a uniqueness proof.

The specific value $(1,3)$ for the signature requires additional input beyond the algebraic constraints developed here (e.g., observational dimensionality or anomaly cancellation arguments).
We do not address why spacetime has $3+1$ dimensions.

% ============================================================
\section{Candidate Algebraic Structures}
\label{Q-A-sec:candidates}

Before deriving constraints, we survey the landscape of algebraic structures that could, in principle, describe boundary degrees of freedom in a holographic setting.
This survey serves as the basis for the exclusion argument in Section~\ref{Q-A-sec:exclusion}.

\begin{definition}[Boundary Algebra]
Let $\mathcal{A}_\partial$ be the algebra of observables on a holographic boundary.
We require: (a)~$\mathcal{A}_\partial$ acts faithfully on $\mathcal{H}_\partial$; (b)~$\mathcal{A}_\partial$ admits a trace compatible with the holographic entropy bound; (c)~coarse-graining of $\mathcal{A}_\partial$ induces an effective bulk description.
\end{definition}

The following algebraic families are candidates:

\begin{enumerate}
\item \textbf{von Neumann algebras} (Type I, II, III): Associative, closed under adjoint, weakly closed. Standard in algebraic QFT~\cite{Haag1996}. Type~III$_1$ factors are generic in relativistic QFT.
\item \textbf{$C^*$-algebras}: Associative Banach algebras with involution. More general than von Neumann algebras. Standard framework for quantum observables.
\item \textbf{Lie algebras}: Antisymmetric bracket $[A,B] = -[B,A]$, satisfying the Jacobi identity. Encode infinitesimal symmetries. The universal enveloping algebra is associative.
\item \textbf{Jordan algebras}: Commutative but generally non-associative: $A \circ B = B \circ A$, satisfying the Jordan identity. Proposed for quantum mechanics by Jordan, von Neumann, and Wigner (1934).
\item \textbf{Octonion algebras}: Non-associative division algebra. Explored in the context of exceptional structures in string theory~\cite{Gunaydin1973}.
\item \textbf{Clifford algebras} $Cl(V,q)$: Associative, generated by a vector space $V$ with quadratic form $q$, subject to $v^2 = q(v)\mathbf{1}$. Encode both metric and algebraic structure~\cite{Hestenes1966,Doran2003}.
\end{enumerate}

% ============================================================
\section{Three Algebraic Constraints}
\label{Q-A-sec:constraints}

We now derive three constraints from physically motivated requirements and examine which candidate algebras survive.

\subsection{Constraint I: Associativity}

\begin{lemma}[Associativity from Compositional Consistency]
\label{Q-A-lem:assoc}
If the boundary algebra supports well-defined time evolution (evolution operators forming a semigroup), it must be associative.
\end{lemma}

\begin{proof}
The semigroup property requires $(U(t_1)U(t_2))U(t_3) = U(t_1)(U(t_2)U(t_3))$ for all $t_i \geq 0$.
In a non-associative algebra, different bracketings of $n$ sequential operations produce $C_n \sim 4^n / n^{3/2}$ distinct results (Catalan numbers), generating uncontrolled ambiguity that grows exponentially with the number of time steps.

We note that this constraint is automatically satisfied by operator algebras on Hilbert spaces, where composition of linear maps is inherently associative.
The constraint therefore functions as a \emph{structural boundary condition}: it delineates the algebraic regime in which consistent dynamics is possible, rather than excluding a plausible physical alternative.
For analysis of non-associative dynamics and their instabilities, see~\cite{Schafer1966,Gunaydin1973}.
\end{proof}

\textbf{Exclusions}: Jordan algebras and octonion algebras are non-associative and are excluded by Constraint~I.

\subsection{Constraint II: Metric Compatibility}
\label{Q-A-sec:constraint2}

\begin{lemma}[Non-Degenerate Bilinear Form from Holographic Error Correction]
\label{Q-A-lem:metric}
For the boundary algebra to support error correction compatible with holographic bulk reconstruction, a non-degenerate bilinear form must be available on the space of boundary operators.
\end{lemma}

\begin{proof}
Error correction in the holographic context requires quantifying the ``distance'' between the actual boundary state and the target code subspace.
This requires a Lyapunov-type function $V(\delta\rho) \geq 0$ with $\dot{V} < 0$ under the correction protocol, which in turn requires a gradient flow:
\begin{equation}
\dot{\lambda} = -\Gamma\, G^{-1} \nabla_\lambda V,
\end{equation}
where $G$ is a metric on the parameter manifold of boundary states.

\textbf{Important distinction}: The metric $G$ appearing here is an \emph{information-geometric} metric on the space of boundary states (analogous to the Fisher--Rao metric~\cite{Petz1996}), not the emergent spacetime metric $g_{\mu\nu}$.
However, recent results in holographic entanglement~\cite{Faulkner2014,Lashkari2014} establish that linearized perturbations of the bulk metric $\delta g_{\mu\nu}$ are encoded in the boundary modular Hamiltonian and its associated Fisher information.
Specifically, the quantum-corrected Ryu--Takayanagi formula~\cite{Faulkner2014} implies:
\begin{equation}
\delta S_A = \delta \langle K_A \rangle + \delta S_{\text{bulk}},
\end{equation}
where $K_A$ is the boundary modular Hamiltonian and $S_A$ is the boundary entanglement entropy.
The structure of $G_{\text{info}}$ on the boundary therefore constrains the structure of $g_{\mu\nu}$ in the bulk.

The requirement is thus that the boundary algebra carries a non-degenerate bilinear form compatible with this holographic encoding.
Standard quantum-state metrics (Bures, Fisher--Rao) are positive-definite and satisfy non-degeneracy, but they do not encode signature information (see Constraint~III).
\end{proof}

\textbf{Exclusions}: Lie algebras carry a Killing form, but it may be degenerate (for non-semisimple algebras) and does not naturally encode a quadratic form on the generating vector space.
General $C^*$-algebras and von Neumann algebras support multiple choices of metric (Bures, Hilbert--Schmidt, etc.) but none is canonically ``built in'' to the algebraic structure itself.

\subsection{Constraint III: Causal Channel Encoding}

\begin{lemma}[Indefinite Signature from Causality]
\label{Q-A-lem:signature}
For the emergent geometry to distinguish time-like from space-like separation, the bilinear form must have indefinite signature $(p,q)$ with $p \geq 1$, $q \geq 1$.
\end{lemma}

\begin{proof}
A positive-definite metric treats all directions identically---no causal cone structure exists.
Distinguishing causal from acausal domains requires at least one time-like and one space-like direction, hence indefinite signature.

We emphasize that this constraint does not determine the specific values of $p$ and $q$.
The identification $(p,q) = (1,3)$ requires additional input: the observational dimensionality of macroscopic spacetime.
The present argument establishes only that indefiniteness is necessary for causality, not that $(1,3)$ is the unique solution.
\end{proof}

\textbf{Exclusions}: All positive-definite metrics (including standard Bures and Fisher--Rao on quantum state spaces) fail Constraint~III.
This is the constraint that separates Clifford algebras (which carry a built-in quadratic form of arbitrary signature) from generic associative algebras with positive-definite metrics.

% ============================================================
\subsection{Exclusion of Alternative Algebras}
\label{Q-A-sec:exclusion}

We now systematically evaluate each candidate from Section~\ref{Q-A-sec:candidates}:

\begin{table}[h]
\centering
\begin{tabular}{@{}lcccl@{}}
\toprule
\textbf{Algebra} & \textbf{I: Assoc.} & \textbf{II: Metric} & \textbf{III: Indef.} & \textbf{Status} \\
\midrule
von Neumann (Type III$_1$) & \checkmark & $\sim$ & $\times$ & No built-in signature \\
$C^*$-algebra (general) & \checkmark & $\sim$ & $\times$ & Metric not canonical \\
Lie algebra & \checkmark$^*$ & $\times$ & --- & No quadratic form \\
Jordan algebra & $\times$ & \checkmark & --- & Non-associative \\
Octonion algebra & $\times$ & \checkmark & --- & Non-associative \\
\textbf{Clifford} $Cl(V,q)$ & \checkmark & \checkmark & \checkmark & \textbf{All satisfied} \\
\bottomrule
\end{tabular}
\caption{Evaluation of candidate algebras against three constraints.
$\checkmark$: satisfied; $\times$: violated; $\sim$: partially satisfied (metric exists but is not built-in or canonical).
$^*$Lie algebras are not associative, but their universal enveloping algebras are.}
\label{Q-A-tab:exclusion}
\end{table}

The key observation is that Clifford algebras are distinguished by having the quadratic form $q$ \emph{built into} the algebraic structure via the defining relation $v^2 = q(v)\mathbf{1}$.
Other associative algebras (von Neumann, $C^*$) can be \emph{equipped with} metrics, but do not carry a canonical one; the metric is an additional choice external to the algebra.
In the holographic context, where the boundary algebra must encode bulk metric information, this built-in feature becomes a substantive advantage rather than a mere convenience.

% ============================================================
\subsection{Worked Example: Qubit Tensor Network}
\label{Q-A-sec:toymodel}

To illustrate how the three constraints operate concretely, consider a tensor network model of holographic bulk reconstruction.

\paragraph{Setup.}
Take $N$ qubits arranged on a MERA (multiscale entanglement renormalization ansatz) tensor network~\cite{Swingle2012,Vidal2008}.
The boundary algebra is generated by tensor products of Pauli operators $\{\sigma_x, \sigma_y, \sigma_z\}$ acting on individual qubits.

\paragraph{Constraint I.}
The Pauli algebra is associative (it consists of $2 \times 2$ matrices).
If we were to replace the Pauli operators with elements of an octonion algebra (which is non-associative), the isometry conditions defining the MERA network---specifically, $V^\dagger V = \mathbf{1}$, which requires associative composition---would fail.

\paragraph{Constraint II.}
The Pauli operators satisfy $\{\sigma_i, \sigma_j\} = 2\delta_{ij}\mathbf{1}$, which defines a \emph{positive-definite} quadratic form.
This is the Clifford algebra $Cl(3,0)$ (or equivalently $Cl(0,3)$, since $Cl(3,0) \cong Cl(0,3)$ as algebras over $\mathbb{R}$).
The quadratic form is built into the anticommutation relation.

\paragraph{Constraint III.}
The Pauli algebra alone encodes a Euclidean signature $(3,0)$.
To obtain a Lorentzian signature, we must introduce a distinguished direction corresponding to the modular Hamiltonian $K$, which generates modular flow (the boundary analog of time evolution in the bulk).
The extended algebra $\{i K, \sigma_x, \sigma_y, \sigma_z\}$ then satisfies anticommutation relations encoding signature $(1,3)$:
\begin{equation}
(iK)^2 = -\mathbf{1}, \qquad \sigma_i^2 = +\mathbf{1}, \qquad \{iK, \sigma_i\} = 0.
\end{equation}
This is precisely $Cl(1,3)$.

\paragraph{Lesson.}
The tensor network example illustrates how associativity (isometry conditions), built-in metric (Pauli anticommutation), and indefinite signature (modular flow direction) naturally combine to produce Clifford structure in a concrete holographic model.

% ============================================================
\subsection{The Algebraic Compatibility Theorem}

\begin{theorem}[Clifford Compatibility]
\label{Q-A-thm:selection}
Among finitely-generated associative algebras over a vector space $V$ equipped with a non-degenerate quadratic form $q$, the Clifford algebra $Cl(V,q)$ is the universal (and hence minimal) such structure, by its universal property.
\end{theorem}

\begin{proof}
Constraint~I requires associativity; Constraint~II requires a non-degenerate quadratic form on the generating space; Constraint~III requires indefinite signature.
The universal property of Clifford algebras~\cite{Hestenes1966,Doran2003} states that $Cl(V,q)$ is the unique (up to isomorphism) associative algebra generated by $V$ subject to $v^2 = q(v)\mathbf{1}$.
Any other associative algebra satisfying these constraints contains $Cl(V,q)$ as a subalgebra (or quotient), making Clifford the minimal compatible structure.
\end{proof}

\begin{remark}[Scope of the Claim]
Theorem~\ref{Q-A-thm:selection} is a statement about \emph{algebraic compatibility}, not physical uniqueness.
It asserts that Clifford algebra is the natural minimal framework for encoding the three constraints simultaneously.
It does not exclude larger structures, nor does it claim that physics \emph{must} use the minimal option.
The theorem should be understood as identifying an algebraic bottleneck rather than deriving a unique physical theory.
\end{remark}

% ============================================================
\section{Entropic Gravity from Algebraic Structure}
\label{Q-A-sec:entropic}

\subsection{Holographic Screen and Einstein Equations}

Following Jacobson~\cite{Jacobson1995}, the entropic force $F = T \nabla S$ and the holographic entropy bound $S \leq A / 4G$ reproduce the Einstein field equations in the thermodynamic limit.
This derivation assumes local Lorentz invariance---a condition naturally satisfied when the boundary algebra is Clifford-compatible, since $Cl(1,3)$ contains $\mathrm{Spin}(1,3)$ (the double cover of the Lorentz group) as its even subalgebra.

\subsection{Relation to HAFF Emergence Chain}

Within HAFF, geometry emerges via:
\[
\text{Observable Algebra} \to \text{Representation} \to \text{Entanglement} \to \text{Connectivity} \to \text{Geometry}
\]
The present work adds a constraint on the final arrow: among geometrically admissible coarse-grainings~\cite{Liu2026HAFF_A}, those producing Lorentzian geometry must induce effective algebras compatible with $Cl(1,3)$.

\subsection{Relation to Algebraic QFT}
\label{Q-A-sec:aqft}

In algebraic quantum field theory (AQFT)~\cite{Haag1996}, local observable algebras associated with spacetime regions are generically Type~III$_1$ von Neumann factors.
These algebras are associative and support rich mathematical structure, but they do not carry a canonical metric of indefinite signature.

The connection to Lorentzian structure emerges through the Tomita--Takesaki theorem: for any cyclic and separating state, the modular operator $\Delta$ generates a one-parameter group (modular flow) that, in the Bisognano--Wichmann theorem, coincides with the boost generator in Rindler spacetime.
This modular flow singles out a \emph{time-like direction} within the algebraic structure.

In the HAFF framework, the accessible algebra $\mathcal{A}_{\mathbf{c}}$ can be understood as a stable subalgebra of a Type~III$_1$ factor.
The present analysis suggests that when such a subalgebra supports a Lorentzian bulk description, it must admit a $Cl(1,3)$ representation---where the modular flow direction provides the time-like generator and spatial locality provides the space-like generators.

This perspective connects the present work to Witten's observation~\cite{Witten2018} that Type~III$_1$ algebras are essential in gravitational settings, and to Connes' noncommutative geometry program~\cite{Connes1994}, where Clifford algebras play a central role in the spectral characterization of Riemannian (and pseudo-Riemannian) manifolds.

% ============================================================
\section{Discussion}
\label{Q-A-sec:discussion}

\subsection{What This Result Does and Does Not Show}

\textbf{Does show:}
Clifford algebra is the minimal algebraic structure simultaneously satisfying associativity, metric compatibility, and causal channel encoding.
The exclusion argument (Table~\ref{Q-A-tab:exclusion}) demonstrates that alternative algebras fail at least one constraint.
The tensor network example (Section~\ref{Q-A-sec:toymodel}) illustrates the constraints in a concrete model.

\textbf{Does not show:}
Why $3+1$ dimensions rather than some other $(p,q)$---the argument constrains to $Cl(p,q)$ for any $p \geq 1$; the value $(1,3)$ requires additional input.
That gravity \emph{is} entropic---we derive consistency conditions within the entropic gravity framework.
That $Cl(1,3)$ is the \emph{unique} boundary algebra---larger algebras containing $Cl(1,3)$ as a subalgebra are also compatible.
A complete theory of quantum gravity.

\subsection{Convergence with Paper B}

The companion paper (Chapter~\ref{Q-chap:paperB}) arrives at $Cl(V,q)$ from a completely different direction: thermodynamic stability of persistent open quantum subsystems.

\begin{center}
\begin{tabular}{@{}lll@{}}
\toprule
& \textbf{Paper A (this work)} & \textbf{Paper B} \\
\midrule
Question & What algebra does geometry need? & What algebra does persistence need? \\
Method & Holographic consistency & Lyapunov stability \\
Perspective & The world (``ocean'') & The subsystem (``fish'') \\
Result & $Cl(1,3)$ from signature & $Cl(V,q)$ from error stability \\
\bottomrule
\end{tabular}
\end{center}

We note that this convergence is \emph{heuristic rather than deductive}: it suggests that Clifford algebra occupies a distinguished position in the landscape of emergent algebraic structures, but does not constitute a proof.
The convergence motivates further investigation, particularly through more elaborate models and deeper connections to established algebraic frameworks.

\subsection{Open Problems}

\begin{enumerate}
\item \textbf{Dimensionality}: What additional constraints (anomaly cancellation, stability of persistent subsystems, observational input) fix $(p,q) = (1,3)$?
\item \textbf{Constructive derivation}: Can Clifford generators be explicitly constructed from modular Hamiltonians or Tomita--Takesaki data in holographic models?
\item \textbf{Relation to noncommutative geometry}: How does the present analysis connect to Connes' spectral triples, where Clifford algebras characterize the Dirac operator?
\item \textbf{Tensor network realization}: Can the qubit toy model of Section~\ref{Q-A-sec:toymodel} be made rigorous in the context of holographic error-correcting codes?
\end{enumerate}

% ============================================================
\section{Conclusion}

We have argued that the Lorentzian metric structure in entropic gravity frameworks is algebraically constrained by three independent requirements: associativity, metric compatibility (with holographic encoding), and indefinite signature.
A systematic exclusion of alternative algebras (von Neumann, $C^*$, Jordan, Lie, octonion) shows that Clifford algebra $Cl(V,q)$ is the minimal structure satisfying all three simultaneously.

This result connects the top-down perspective of HAFF (geometry emerges from observable algebras) with bottom-up algebraic constraints (any causal geometry must be Clifford-compatible).
It does not constitute a derivation of Lorentzian gravity from first principles, but identifies an algebraic bottleneck through which any emergent causal geometry must pass.

% ============================================================


% ============================================================================
% PAPER B
% ============================================================================
\chapter{Thermodynamic Stability Constraints on the Operator Algebra of Persistent Open Quantum Subsystems}
\label{Q-chap:paperB}

\begin{center}
\textit{Paper B --- ``The Fish''}\\[0.5em]
Originally published: Zenodo, DOI: 10.5281/zenodo.18525891
\end{center}

\bigskip

% ============================================================
\section{Introduction}
\label{Q-B-sec:intro}

The interaction of a quantum system with a large environment typically leads to decoherence and thermalization~\cite{Breuer2002,Weiss2012}.
Maintaining a NESS requires continuous energetic cost~\cite{Seifert2012,Jarzynski2011}, which can be modeled as a feedback control process~\cite{Sagawa2012,Parrondo2015}.
We address: \textit{What algebraic structures allow the internal control dynamics to remain Lyapunov stable?}

\subsection{Three-Paper Structure}

\begin{center}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Paper} & \textbf{Question} & \textbf{Analogy} \\
\midrule
HAFF~\cite{Liu2026HAFF_A} & How does geometry emerge? & Ocean \\
Q-RAIF A~\cite{Liu2026QRAIF_A} & What algebra does geometry need? & Water \\
This work & What algebra does survival need? & Fish \\
\bottomrule
\end{tabular}
\end{center}

\subsection{Anti-Solipsism Disclaimer}

A potential misreading is that the observer ``creates'' geometry through survival.
We explicitly reject this.
The claim is structural: any subsystem maintaining persistence must encode its environment using a Clifford-compatible algebra.
Within HAFF, geometry exists as a stable organizational phase~\cite{Liu2026HAFF_B}---contingent on physical conditions but objective within them.
The present paper argues that subsystems embedded in such a phase must reflect that geometry in their internal algebra---not generate it.

\subsection{Scope}

This work does not claim to derive Clifford algebra from first principles.
It argues that, within the variational framework of persistence under Lindblad dynamics, Clifford algebra is the minimal algebraic structure compatible with stable feedback.
The argument proceeds by exclusion of alternatives, not by uniqueness proof.

% ============================================================
\section{Variational Bounds on Persistence}
\label{Q-B-sec:variational}

Consider $\mathcal{H}_{\mathrm{tot}} = \mathcal{H}_R \otimes \mathcal{H}_E$, with reduced dynamics:
\begin{equation}
\dot{\rho}_R = -i[H_{\mathrm{eff}}, \rho_R] + \mathcal{D}[\rho_R].
\end{equation}

\begin{definition}[Persistence Action]
$\mathcal{A}[Q] = \int_0^\tau dt\, D_{KL}(\rho(t) \| \rho_{\mathrm{NESS}})$.
\end{definition}

Minimizing $\delta\mathcal{A} = 0$ implies a control Hamiltonian $H_{\mathrm{ctrl}}(t)$ generated by an operator algebra $\mathcal{O}$.

\subsection{Why Lie Algebras Are Insufficient}

Standard quantum control theory uses Lie algebra generators~\cite{WisemanMilburn2009}: the control Hamiltonian $H_{\mathrm{ctrl}} = \sum_k u_k(t) G_k$ where $\{G_k\}$ generate a Lie algebra $\mathfrak{g}$ via commutators $[G_i, G_j] = i f_{ijk} G_k$.

Lie algebras encode \emph{infinitesimal symmetries}---they specify \emph{which directions} in state space are accessible via control.
However, they do not encode \emph{distances} between states.
The commutator $[G_i, G_j]$ determines the algebra's structure, but there is no built-in notion of ``how far'' a correction moves the state.

For error correction, the subsystem must quantify both the \emph{direction} and the \emph{magnitude} of environmental perturbations.
This requires a quadratic form $q(v) = \eta_{\mu\nu} v^\mu v^\nu$ on the space of perturbations---which is precisely the additional structure that Clifford algebras provide over Lie algebras.

% ============================================================
\section{Algebraic Constraints on Control Stability}
\label{Q-B-sec:stability}

\subsection{Constraint I: Associativity as Structural Boundary}
\label{Q-B-sec:assoc}

\begin{lemma}[Associativity Boundary]
\label{Q-B-lem:assoc}
Consistent composition of sequential control operations requires an associative algebra.
\end{lemma}

We acknowledge that this constraint is automatically satisfied by operator algebras on Hilbert spaces, where composition of linear maps is inherently associative~\cite{Breuer2002}.
Non-associative algebras (Jordan, octonion) are not realistic candidates for quantum dynamics.

Lemma~\ref{Q-B-lem:assoc} therefore functions as a \emph{structural boundary marker}: it delineates the minimal algebraic condition separating consistent from inconsistent dynamics, analogous to how the second law delineates irreversibility without claiming that reversible processes are a realistic threat.
For the mathematical structure of non-associative algebras and their dynamical instabilities, see~\cite{Schafer1966,Gunaydin1973}.

The substantive constraint is Constraint~II, which discriminates among \emph{associative} algebras.

\subsection{Constraint II: Indefinite Metric for Channel Discrimination}
\label{Q-B-sec:metric}

\begin{lemma}[Metric Constraint]
\label{Q-B-lem:metric}
For a persistent subsystem to distinguish qualitatively different environmental coupling channels and implement directed error correction, the control algebra must carry a non-degenerate bilinear form of indefinite signature.
\end{lemma}

\begin{proof}
Lyapunov stability requires $\dot{V} < 0$ for $V(\delta\rho) \geq 0$, implying gradient flow:
\begin{equation}
\dot{\lambda} = -\Gamma\, G^{-1} \nabla_\lambda V,
\label{Q-B-eq:gradient}
\end{equation}
where $G$ is a metric on the control parameter manifold.

\textbf{Important distinction}: $G$ here is an information-geometric metric on the space of control parameters, not the spacetime metric.
Standard quantum state metrics (Bures, Fisher--Rao~\cite{Petz1996}) are positive-definite and satisfy non-degeneracy.
However, they are \emph{isotropic}: they treat all perturbation directions equivalently.

In realistic open quantum systems, the environment couples to the subsystem through qualitatively different channels---dissipative (population decay), dephasing (coherence loss), and unitary (Hamiltonian shift).
Effective error correction requires distinguishing these channel types, which demands an \emph{anisotropic} metric that assigns different signs to different directions.

An indefinite quadratic form $q(v) = \eta_{\mu\nu} v^\mu v^\nu$ with $\mathrm{sig}(\eta) = (p,q)$, $p,q \geq 1$, encodes this distinction: positive-norm directions correspond to one class of perturbations, negative-norm directions to another.
This is precisely the structure built into Clifford algebras via $v^2 = q(v)\mathbf{1}$.

Algebras with only positive-definite metrics (generic von Neumann factors, $C^*$-algebras with Bures metric) cannot distinguish channel types at the algebraic level, requiring external structure to do so.
\end{proof}

\subsection{Exclusion of Alternative Algebras}
\label{Q-B-sec:exclusion}

\begin{table}[h]
\centering
\begin{tabular}{@{}lccl@{}}
\toprule
\textbf{Algebra} & \textbf{I: Assoc.} & \textbf{II: Indef.~$q$} & \textbf{Status} \\
\midrule
von Neumann (III$_1$) & \checkmark & $\times$ & No built-in $q$ \\
$C^*$-algebra & \checkmark & $\times$ & Positive-definite only \\
Lie algebra & \checkmark$^*$ & $\times$ & Killing form, no $q$ \\
Jordan algebra & $\times$ & --- & Non-associative \\
\textbf{Clifford} $Cl(V,q)$ & \checkmark & \checkmark & \textbf{Minimal} \\
\bottomrule
\end{tabular}
\caption{Systematic evaluation of candidate control algebras.
$^*$Via universal enveloping algebra.}
\label{Q-B-tab:exclusion}
\end{table}

The exclusion argument shifts the burden from ``why Clifford?'' to ``why not the alternatives?''---and the answer is that no other standard algebraic framework carries a built-in indefinite quadratic form encoding channel discrimination.

\subsection{Worked Example: Controlled Qubit Under Lindblad Dynamics}
\label{Q-B-sec:toymodel}

\paragraph{Setup.}
Consider a single qubit coupled to a thermal bath at inverse temperature $\beta$, with Lindblad dissipator:
\begin{equation}
\mathcal{D}[\rho] = \gamma_\downarrow \mathcal{L}[\sigma_-]\rho + \gamma_\uparrow \mathcal{L}[\sigma_+]\rho + \gamma_\phi \mathcal{L}[\sigma_z]\rho,
\end{equation}
where $\mathcal{L}[L]\rho = L\rho L^\dagger - \frac{1}{2}\{L^\dagger L, \rho\}$, and $\gamma_\downarrow$, $\gamma_\uparrow$, $\gamma_\phi$ are decay, excitation, and dephasing rates.

\paragraph{Control algebra.}
The control Hamiltonian is $H_{\mathrm{ctrl}} = \sum_i u_i(t)\, \sigma_i$ where $\{\sigma_x, \sigma_y, \sigma_z\}$ are Pauli operators.
These satisfy $\{\sigma_i, \sigma_j\} = 2\delta_{ij}\mathbf{1}$---the defining relation of $Cl(3,0)$.

\paragraph{Lyapunov function.}
Take $V = D_{KL}(\rho \| \rho_{\mathrm{NESS}})$ where $\rho_{\mathrm{NESS}}$ is the thermal state.
The gradient $\nabla_u V$ is well-defined because the Pauli algebra carries a natural inner product (the quadratic form $q(\sigma_i) = +1$).
The control protocol $u_i(t) = -\alpha\, \partial V / \partial u_i$ yields:
\begin{equation}
\dot{V} = -\alpha \sum_i \left(\frac{\partial V}{\partial u_i}\right)^2 \leq 0,
\end{equation}
which is strictly negative away from the NESS.

\paragraph{Failure mode without built-in metric.}
If the control algebra were an abstract Lie algebra $\mathfrak{su}(2)$ (same generators, but with only the commutator structure $[\sigma_i, \sigma_j] = 2i\epsilon_{ijk}\sigma_k$ and no anticommutator/metric), the control protocol could specify \emph{rotation directions} in Bloch sphere but could not canonically quantify \emph{how large} a correction to apply.
The gradient flow~\eqref{Q-B-eq:gradient} would require importing an external metric (e.g., the Killing form of $\mathfrak{su}(2)$, which happens to be proportional to $\delta_{ij}$).

In the Pauli/Clifford case, the metric is \emph{internal}: the same algebraic structure that generates rotations also defines distances.
This unification is what makes Clifford algebras uniquely suited for feedback control where both direction and magnitude matter.

\paragraph{Extension to indefinite signature.}
When the subsystem must distinguish dissipative from unitary perturbations---e.g., $\gamma_\downarrow \neq 0$ (dissipative) versus Hamiltonian noise (unitary)---the control space naturally splits into positive-norm (unitary) and negative-norm (dissipative) sectors.
Encoding this distinction algebraically requires an indefinite quadratic form, upgrading $Cl(3,0)$ to $Cl(p,q)$ with appropriate signature.

% ============================================================
\subsection{The Algebraic Compatibility Theorem}

\begin{theorem}[Persistence Compatibility]
\label{Q-B-thm:main}
Among associative algebras encoding $n$ orthogonal control channels with a built-in non-degenerate quadratic form, the Clifford algebra $Cl(V,q)$ is the universal minimal structure, by its universal property.
\end{theorem}

\begin{proof}
Constraint~I (associativity) is given.
Constraint~II requires a non-degenerate quadratic form $q$ on the generating space $V$, with indefinite signature when channel discrimination is required.
The universal property of Clifford algebras~\cite{Hestenes1966} identifies $Cl(V,q)$ as the unique associative algebra generated by $V$ subject to $v^2 = q(v)\mathbf{1}$.
\end{proof}

\begin{corollary}
Any subsystem maintaining NESS for $\tau \gg \tau_{\mathrm{relax}}$ while discriminating among environmental channels must encode its boundary using a Clifford-compatible algebra.
\end{corollary}

\begin{remark}[Natural Selection, Not Design]
The theorem establishes a selection principle.
Subsystems do not ``choose'' Clifford algebra; only Clifford-compatible structures persist when channel discrimination is required.
This is algebraic natural selection.
\end{remark}

% ============================================================
\section{Contextual Relations}
\label{Q-B-sec:context}

\subsection{Convergence with Paper A}

The companion paper~\cite{Liu2026QRAIF_A} argues that $Cl(1,3)$ is the minimal algebra compatible with emergent Lorentzian geometry in entropic gravity.

\begin{center}
\begin{tabular}{@{}lcc@{}}
\toprule
& \textbf{Paper A} & \textbf{This work} \\
\midrule
Starting point & Holographic boundary & Open subsystem \\
Method & Signature selection & Lyapunov stability \\
Key constraint & Causal ordering & Channel discrimination \\
Result & $Cl(1,3)$ & $Cl(V,q)$ \\
\bottomrule
\end{tabular}
\end{center}

We note explicitly that this convergence is \emph{heuristic rather than deductive}.
Two arguments pointing to the same algebraic structure from different directions is suggestive but does not constitute proof.
The convergence motivates further investigation through explicit models and connections to established frameworks, not a claim of mathematical necessity.

\subsection{Relation to Quantum Control Theory}

Standard quantum control operates within a Lie algebraic framework~\cite{WisemanMilburn2009}: controllability is characterized by the Lie algebra generated by the drift and control Hamiltonians.
This framework is complete for determining \emph{reachability} of target states.

However, Lie algebras encode symmetries (via commutators) without encoding distances (via quadratic forms).
When the control objective is not merely reachability but \emph{stabilization against stochastic perturbations}---as in NESS maintenance---both direction and magnitude of corrections must be specified.
Clifford algebras provide this additional structure through their built-in quadratic form, complementing rather than replacing the Lie algebraic framework.

\subsection{Relation to Decoherence-Free Subspaces}

Decoherence-free subspaces (DFS)~\cite{Zanardi2001,Lidar2003} represent subsystems that are passively protected from environmental noise by symmetry.
The present analysis addresses the \emph{active} counterpart: subsystems that maintain coherence through continuous feedback.
In both cases, the algebraic structure of the system-environment interaction determines which subsystems can persist.
The Clifford constraint identified here applies to the active case; DFS theory applies to the passive case.
A unified treatment remains an open problem.

% ============================================================
\section{Discussion}

\textbf{What this result does show:}
Clifford algebra is the minimal algebraic structure satisfying both associativity and built-in indefinite metric among standard algebraic candidates.
The exclusion of alternatives (Table~\ref{Q-B-tab:exclusion}) and the controlled qubit example (Section~\ref{Q-B-sec:toymodel}) provide concrete support.

\textbf{What this result does not show:}
That Clifford algebra is the \emph{unique} solution---larger structures are also compatible.
That non-Clifford feedback is impossible in all settings---it is possible when channel discrimination is not required.
A derivation from first principles independent of the variational framework assumed here.

\section{Conclusion}

We have argued that geometric (Clifford) algebra structure is a natural minimal requirement for persistent subsystems that must discriminate among environmental coupling channels:
(i)~associativity is a structural boundary condition;
(ii)~a built-in indefinite quadratic form is required for channel discrimination and directed error correction;
(iii)~no standard alternative algebra satisfies both with built-in structure.

Combined with the companion paper's holographic constraints (Chapter~\ref{Q-chap:paperA}), this suggests $Cl(V,q)$ occupies a distinguished position as the algebraic structure simultaneously compatible with geometric consistency and thermodynamic persistence.

% ============================================================


% ============================================================================
% PAPER C
% ============================================================================
\chapter{The Realizability Bridge: Algebraic Closure in the Q-RAIF Framework}
\label{Q-chap:paperC}

\begin{center}
\textit{Paper C --- ``The Bridge''}\\[0.5em]
Originally published: Zenodo, DOI: 10.5281/zenodo.18528935
\end{center}

\bigskip

% ============================================================
\section*{Abstract}
This addendum provides a minimal mathematical bridge between the two foundational papers of the \textbf{Q-RAIF (Quantum Reference Algebra for Information Flow)} framework.
Paper A (Chapter~\ref{Q-chap:paperA}) establishes that the observable algebra of a holographically consistent universe must contain $Cl(1,3)$ as its minimal Clifford-compatible structure.
Paper B (Chapter~\ref{Q-chap:paperB}) establishes that the control algebra of a persistent subsystem must be Cliffordian $Cl(V,q)$ to ensure Lyapunov stability under entropic constraints.

Here we prove the \textbf{Closure Theorem}: any \emph{physically realizable} control algebra must embed into the environmental algebra as a subalgebra.
We formalize the required feedback synchrony via a \emph{Same-Clock} co-indexing lemma, ensuring the feedback loop is thermodynamically potent.

This note does not modify Papers A or B; it supplies only the realizability bridge needed for algebraic closure.

\medskip
\noindent\textbf{Keywords}: Q-RAIF, realizability, representation, operator algebra, Clifford algebra, open quantum systems, Lyapunov stability, algebraic closure


% ============================================================
\section{Introduction}
\label{Q-C-sec:intro}

\subsection{Context: The Q-RAIF Program}

The Quantum Reference Algebra for Information Flow (Q-RAIF) framework investigates what algebraic structures are \emph{necessary}---as opposed to merely convenient---for the self-consistent description of physical reality and persistence within it.
The program builds on the Holographic Alaya-Field Framework (HAFF)~\cite{Liu2026HAFF_A,Liu2026HAFF_B}, which establishes that geometry emerges from coarse-graining of observable algebras.

\begin{center}
\begin{tabular}{@{}llll@{}}
\toprule
\textbf{Paper} & \textbf{Question} & \textbf{Analogy} & \textbf{Result} \\
\midrule
HAFF~\cite{Liu2026HAFF_A} & How does geometry emerge? & Ocean & Algebra $\to$ Geometry \\
Q-RAIF A~\cite{Liu2026QRAIF_A} & What algebra does geometry need? & Water & $Cl(1,3)$ \\
Q-RAIF B~\cite{Liu2026QRAIF_B} & What algebra does survival need? & Fish & $Cl(V,q)$ \\
This work & Must the fish fit the water? & Bridge & $Cl(V,q) \hookrightarrow Cl(1,3)$ \\
\bottomrule
\end{tabular}
\end{center}

\subsection{The Logical Gap}

Papers A and B independently arrive at Clifford algebra from opposite directions.
Both papers explicitly note that this convergence is \emph{heuristic rather than deductive}~\cite{Liu2026QRAIF_A,Liu2026QRAIF_B}.
The present note closes the gap by proving a realizability constraint: the internal control algebra of any persistent subsystem must be representable within the external observable algebra.

\subsection{Scope}

This addendum introduces no new physical assumptions.
It uses only the objects and results already established in Papers A and B, and derives their mutual constraint.
Papers A and B remain unmodified.

% ============================================================
\section{Setup and Prerequisites}
\label{Q-C-sec:setup}

Let $\mathcal{U}$ be a universe described by the Q-RAIF framework.
\begin{itemize}
    \item \textbf{Environment (``water'').} Let $\mathcal{A}_{\mathrm{ext}}$ denote the algebra of observables accessible at the holographic boundary.
    Paper A (Chapter~\ref{Q-chap:paperA}) argues that $\mathcal{A}_{\mathrm{ext}}$ must contain $Cl(1,3)$ as its minimal Clifford-compatible subalgebra (Theorem~1 of Paper A, ``Clifford Compatibility'').
    \item \textbf{Subsystem (``fish'').} Let $\mathcal{O}_{\mathrm{int}}$ denote the internal control algebra of a persistent subsystem $R\subset\mathcal{U}$.
    Paper B (Chapter~\ref{Q-chap:paperB}) argues that thermodynamic persistence requires $\mathcal{O}_{\mathrm{int}} \cong Cl(V,q)$ for some $(V,q)$ (Theorem~1 of Paper B, ``Persistence Compatibility'').
\end{itemize}

The remaining logical gap is the relationship between $\mathcal{O}_{\mathrm{int}}$ and $\mathcal{A}_{\mathrm{ext}}$: can a stable Clifford control algebra exist while being structurally disjoint from the available environmental observables?

% ============================================================
\section{Realizability and Same-Clock Co-Indexing}
\label{Q-C-sec:realizability}

\begin{definition}[Algebraic Realizability]
\label{Q-C-def:realizability}
A control algebra $\mathcal{O}_{\mathrm{int}}$ is \textbf{physically realizable} within an environment $\mathcal{A}_{\mathrm{ext}}$ if there exists a homomorphism
\begin{equation}
    \phi: \mathcal{O}_{\mathrm{int}} \to \mathcal{A}_{\mathrm{ext}}
\end{equation}
such that $\mathrm{Im}(\phi)$ has non-zero action on the interaction Hamiltonian $H_{\mathrm{int}}$, i.e., $[\mathrm{Im}(\phi), H_{\mathrm{int}}] \neq 0$.
This ensures that the controller can physically influence the system-environment boundary.
\end{definition}

Let $I$ be an operational/causal index set (e.g., proper-time frames or discretized event slices).
For a subset $J\subseteq I$, write $\mathcal{A}|_J$ for the restriction of an algebra $\mathcal{A}$ to the index set $J$.

\begin{lemma}[Same-Clock / Co-Indexing]
\label{Q-C-lem:clock}
For a feedback loop to be causally closed and thermodynamically potent (capable of entropy export~\cite{Seifert2012}), there must exist non-null index overlap between control and feedback windows: there exist $J_{\mathrm{ctrl}},J_{\mathrm{env}}\subseteq I$ such that
\begin{enumerate}
    \item \textbf{Non-null intersection:} $J_{\mathrm{ctrl}}\cap J_{\mathrm{env}}\neq\emptyset$.
    \item \textbf{Window integrity:} on any critical lookback window $W\subseteq J_{\mathrm{ctrl}}\cap J_{\mathrm{env}}$ used to define the controller, $\mathcal{A}_{\mathrm{ext}}|_W$ is well-defined (no holes on $W$).
\end{enumerate}
\end{lemma}

\begin{proof}
If $J_{\mathrm{ctrl}}\cap J_{\mathrm{env}}=\emptyset$, the control action is operationally decoupled from environmental feedback, so no entropy export channel exists; persistence (NESS~\cite{Seifert2012}) fails.
If window integrity fails on a critical lookback window $W$, the feedback map---and thus the Lyapunov descent condition (Eq.~(4) of Paper B (Chapter~\ref{Q-chap:paperB}))---is not definable on the operational window.
Therefore both conditions are necessary.
\end{proof}

% ============================================================
\section{The Closure Theorem}
\label{Q-C-sec:closure}

\begin{theorem}[Q-RAIF Algebraic Closure]
\label{Q-C-thm:closure}
Assume $\mathcal{A}_{\mathrm{ext}} \supseteq Cl(1,3)$ (Paper A (Chapter~\ref{Q-chap:paperA})).
Let $R$ be a persistent subsystem whose control algebra satisfies $\mathcal{O}_{\mathrm{int}}\cong Cl(V,q)$ (Paper B (Chapter~\ref{Q-chap:paperB})).
If $\mathcal{O}_{\mathrm{int}}$ is realizable in $\mathcal{A}_{\mathrm{ext}}$ (Definition~\ref{Q-C-def:realizability}) and the Same-Clock conditions of Lemma~\ref{Q-C-lem:clock} hold, then the effective control algebra
\begin{equation}
    \mathcal{O}_{\mathrm{eff}} := \mathrm{Im}(\phi) \subseteq \mathcal{A}_{\mathrm{ext}}
\end{equation}
is a Clifford subalgebra of the external geometry.
\end{theorem}

\begin{proof}
By realizability, there exists a homomorphism $\phi:\mathcal{O}_{\mathrm{int}} \to \mathcal{A}_{\mathrm{ext}}$ with non-trivial image.
The operational content of the controller is its image $\mathcal{O}_{\mathrm{eff}} = \mathrm{Im}(\phi)$.
Since $\mathcal{O}_{\mathrm{int}} \cong Cl(V,q)$ by the persistence requirement (Theorem~1 of Paper B), and $\phi$ is structure-preserving, $\mathcal{O}_{\mathrm{eff}}$ inherits the Clifford relations $v^2 = q(v)\mathbf{1}$~\cite{Hestenes1966}.
Since $\mathcal{O}_{\mathrm{eff}} \subseteq \mathcal{A}_{\mathrm{ext}}$, the internal geometry $(V,q)$ is induced by a restriction of the ambient algebraic structure.
\end{proof}

\begin{corollary}[No Ghost Algebra]
A control algebra that is mathematically stable (Cliffordian) but not representable in $\mathcal{A}_{\mathrm{ext}}$ is not physically realizable.
In particular, a control structure with signature incompatible with $(1,3)$ cannot underwrite persistent feedback in a universe whose observable algebra contains $Cl(1,3)$.
\end{corollary}

% ============================================================
\section{Discussion}
\label{Q-C-sec:discussion}

\subsection{What This Result Does and Does Not Show}

\textbf{Does show:}
Realizability forces the internal control algebra of a persistent subsystem to embed into the external observable algebra.
Combined with Papers A and B, this converts the previously heuristic convergence ($Cl(V,q)$ from stability, $Cl(1,3)$ from geometry) into a constrained embedding: $Cl(V,q) \hookrightarrow Cl(1,3)$.

\textbf{Does not show:}
That $\phi$ must be injective (faithful)---the theorem holds for any non-trivial homomorphism.
That the specific signature $(V,q)$ is uniquely determined---only that it must be compatible with $(1,3)$.
That this constitutes a derivation of physics from first principles---it is a consistency constraint within the Q-RAIF framework.

\subsection{The Bridge Statement}

\begin{remark}[Closing the Loop]
Paper A fixes the realizable operator content of the world ($\mathcal{A}_{\mathrm{ext}}$).
Paper B fixes the algebraic form required for persistence ($\mathcal{O}_{\mathrm{int}}$).
Theorem~\ref{Q-C-thm:closure} locks them together: realizable persistence forces the agent's control algebra to be built from the same algebraic atoms as its environment.
The fish's gills must be made of water's molecules.
\end{remark}

\subsection{Connection to HAFF}

Within the HAFF program~\cite{Liu2026HAFF_A,Liu2026HAFF_B}, geometry emerges from coarse-graining of observable algebras.
The Closure Theorem adds a further structural consequence: not only does the world's geometry emerge from its algebra, but any persistent subsystem's internal geometry is \emph{constrained to be a restriction} of that emergent geometry.
This is algebraic natural selection operating at the level of geometric structure.

% ============================================================


% ============================================================================
% UNIFIED BIBLIOGRAPHY
% ============================================================================

% ============================================================================
% PART III: T-DOME
% ============================================================================
\part{T-DOME: Thermodynamic Dynamics of Observer-Memory Entanglement}
\label{part:TDOME}

% ============================================================================
% PAPER I
% ============================================================================
\chapter{Non-Markovian Memory and the Thermodynamic Necessity of Temporal Accumulation}
\label{T-chap:paperI}

\begin{center}
\textit{Paper I --- ``The Seed''}\\[0.5em]
Originally published: Zenodo, DOI: 10.5281/zenodo.18574342
\end{center}

\bigskip

\section*{Abstract}
We investigate the thermodynamic constraints on open quantum systems
that must persist far from equilibrium in stochastic environments.
Working within the framework of stochastic thermodynamics and
information thermodynamics (Sagawa--Ueda), we define a
\emph{survival functional} $\mathcal{S} := \Delta F - W$
measuring the difference between the non-equilibrium free energy
gained and the work invested by an agent.

We prove a \textbf{Markovian Ceiling}: for any open-loop
Markovian (GKSL) dynamics with no measurement or feedback,
$\mathcal{S} \leq 0$---the agent cannot thermodynamically
``profit.''
We then derive an exact identity---valid for
\emph{arbitrary} (possibly correlated) initial states under
autonomous evolution in the weak-coupling limit---expressing
the survival functional in terms of the change in
system--environment mutual information and bath displacement:
$\beta\,\mathcal{S} = -\Delta I(S{:}E)
- \Delta D_{\mathrm{KL}}(\rho_E \| \rho_E^{\mathrm{th}})$.
Pre-existing correlations $I(S{:}E;\, 0) > 0$, built during
prior interaction epochs, serve as a consumable thermodynamic
resource; their consumption during non-Markovian backflow
intervals yields $\mathcal{S} > 0$, bounded by the initial
correlation budget.

This establishes \textbf{memory as a thermodynamic necessity}
for sustained far-from-equilibrium persistence.
The memory kernel induces a causal partial order on system
trajectories that, when restricted to the classical sector
selected by decoherence (quantum Darwinism), is consistent
with the accessibility ordering of the Holographic Alaya-Field
Framework (HAFF).
A worked example---a spin-boson model with Lorentz--Drude
spectral density---illustrates how non-Markovian backflow
enables free-energy extraction unavailable to memoryless systems.

Finally, using the entropy rate and predictive information from
computational mechanics, we quantify the intrinsic cost of memory
and identify the \textbf{Memory Catastrophe}: unbounded memory
under finite energy leads to thermodynamic collapse, motivating
the symmetry-breaking mechanism of Paper~II\@.

\medskip
\noindent\textbf{Keywords}: non-Markovian dynamics, open quantum systems,
Nakajima--Zwanzig equation, memory kernel, thermodynamic arrow of time,
information backflow, entropy production, stochastic thermodynamics


% ============================================================
\section{Introduction}
\label{T-I-sec:intro}

% ------------------------------------------------------------
\subsection{Context: The Problem of Persistence}

A quantum system coupled to a thermal environment generically
relaxes toward equilibrium. This is the content of the
\emph{zeroth crisis}: absent special structure, every open
subsystem is eventually erased by thermal noise~\cite{BreuerPetruccione2002}.

Yet the physical world contains persistent far-from-equilibrium
structures---from molecular machines to living organisms---that
maintain themselves against the entropic tide for timescales
vastly exceeding their intrinsic relaxation times. What
structural feature of their dynamics makes this possible?

The standard answer invokes free-energy input: a persistent system
is one that continuously imports low-entropy energy and exports
high-entropy waste~\cite{Schrodinger1944}. This is correct but
incomplete. Two systems receiving \emph{identical} free-energy
flux from \emph{identical} environments may exhibit vastly
different persistence characteristics. The distinguishing factor,
we argue, is \emph{memory}---the capacity to condition present
dynamics on past environmental states.

% ------------------------------------------------------------
\subsection{Position within the Series}

This paper is the first of three constituting the
\textbf{T-DOME} (Thermodynamic Dynamics of Observer-Memory
Entanglement) framework, the third pillar of a three-paper
program.

\begin{center}
\small
\setlength{\tabcolsep}{4pt}%
\begin{tabular}{@{}lp{3.2cm}cp{3.4cm}c@{}}
\toprule
\textbf{Framework} & \textbf{Question} & & \textbf{Result} & \textbf{Status} \\
\midrule
HAFF~\cite{Liu2026HAFF_A,Liu2026HAFF_B}
  & How does geometry emerge?
  & Ocean
  & Algebra $\to$ Geometry
  & Complete \\[3pt]
Q-RAIF~\cite{Liu2026QRAIF_A,Liu2026QRAIF_B}
  & What algebra must an observer have?
  & Fish
  & $Cl(V,q) \hookrightarrow Cl(1,3)$
  & Complete \\[3pt]
\textbf{T-DOME I} (this work)
  & Why must agents carry memory?
  & Seed
  & Markovian ceiling; memory as necessity
  & \textbf{This paper} \\[3pt]
T-DOME II
  & Why must agents break symmetry?
  & Ego
  & Reference-frame selection
  & Planned \\[3pt]
T-DOME III
  & How does self-calibration arise?
  & Loop
  & Fisher self-referential bound
  & Planned \\
\bottomrule
\end{tabular}
\end{center}

The three T-DOME papers form an irreversible logical chain.
Each resolves a survival crisis created by its predecessor:
\begin{enumerate}
\item \textbf{Paper I (The Seed):} Without memory, a system
  is trapped in the \emph{Markovian present}---no accumulation,
  no temporal arrow, inevitable thermal death.
  Memory breaks this trap but floods the system with unbounded
  historical data.
\item \textbf{Paper II (The Ego):} Unbounded memory under finite
  computational resources causes processing collapse.
  Spontaneous symmetry breaking of the reference frame
  (establishing a ``self'') resolves the overload but introduces
  systematic bias.
\item \textbf{Paper III (The Loop):} Uncorrected bias diverges from a
  changing environment. A self-referential calibration loop
  (monitoring one's own prediction error) resolves the bias
  but requires the system to ``observe its own observation''---closing
  the self-calibration loop.
\end{enumerate}

\noindent
The present paper addresses only the first link in this chain.

% ------------------------------------------------------------
\subsection{Relation to HAFF Paper F}

HAFF Paper F~\cite{Liu2026HAFF_F} establishes the arrow of time
as the direction of \emph{accessibility propagation}:
informational redundancy $\mathcal{R}(\hat{O})$ generically expands,
inducing a partial order $\prec$ on observable algebras.
That analysis is purely algebraic---it characterizes temporal
asymmetry without invoking dynamics.

The present paper complements Paper F by identifying the
\emph{dynamical} origin of temporal asymmetry: the non-Markovian
memory kernel $\mathcal{K}(t,s)$. We show (Section~\ref{T-I-sec:arrow})
that the partial order induced by the kernel's temporal support
embeds into the HAFF accessibility ordering as a sub-structure.
The two descriptions are dual faces of the same phenomenon:
Paper F provides the algebraic skeleton; Paper I provides the
dynamical muscle.

% ------------------------------------------------------------
\subsection{Scope and Disclaimers}

\begin{enumerate}
\item This work does \emph{not} claim that non-Markovian dynamics
  is sufficient for persistence. Memory is identified as
  \emph{necessary} under the conditions specified; sufficiency
  requires additional structure (Papers II and III).
\item We do \emph{not} claim that all non-Markovian systems
  outperform all Markovian systems. The theorem establishes that
  the supremum of survival efficiency over non-Markovian dynamics
  strictly exceeds the Markovian supremum.
\item We do \emph{not} derive the specific form of the memory
  kernel from first principles. The kernel is treated as a
  structural feature of the system-environment coupling.
\item The term ``agent'' is used in the control-theoretic sense
  (a subsystem that acts on its environment to maintain a target
  state) and carries no implication of consciousness, intention,
  or subjective experience.
\item A broader structural analogy with classical philosophical
  concepts of temporal persistence exists but is outside the
  scope of this paper.
\end{enumerate}

% ============================================================
\section{Mathematical Preliminaries}
\label{T-I-sec:prelim}

% ------------------------------------------------------------
\subsection{Open Quantum Systems: The Markovian Baseline}

Consider a bipartite Hilbert space
$\mathcal{H} = \mathcal{H}_R \otimes \mathcal{H}_E$,
where $R$ denotes the ``agent'' (reduced system) and $E$ the
environment. The total Hamiltonian is
\begin{equation}
\label{T-I-eq:H_total}
H = H_R \otimes \mathbb{1}_E
  + \mathbb{1}_R \otimes H_E
  + \lambda\, H_{\mathrm{int}},
\end{equation}
where $\lambda$ parametrizes the coupling strength.

Under the Born--Markov and secular approximations, the reduced
dynamics of $\rho_R(t) = \mathrm{Tr}_E[\rho(t)]$ is governed by
the Gorini--Kossakowski--Sudarshan--Lindblad (GKSL) master
equation~\cite{Lindblad1976,GKS1976}:
\begin{equation}
\label{T-I-eq:GKSL}
\dot{\rho}_R(t)
= -i[H_{\mathrm{eff}},\, \rho_R(t)]
  + \sum_k \gamma_k \left(
    L_k \rho_R(t) L_k^\dagger
    - \tfrac{1}{2}\{L_k^\dagger L_k,\, \rho_R(t)\}
  \right),
\end{equation}
with $\gamma_k \geq 0$ and Lindblad operators $\{L_k\}$.

\begin{remark}[Markovian = Memoryless]
\label{T-I-rem:markov}
The GKSL equation is \emph{time-local}: $\dot{\rho}_R(t)$ depends
only on $\rho_R(t)$, never on $\rho_R(s)$ for $s < t$.
Physically, this corresponds to an environment with vanishing
correlation time ($\tau_E \to 0$): the bath ``forgets'' its
interaction with the system instantaneously.
The semigroup property $\Lambda(t+s) = \Lambda(t)\Lambda(s)$
ensures complete positivity at all times but precludes any
information backflow from environment to system~\cite{RivasHuelgaPlenio2014}.
\end{remark}

% ------------------------------------------------------------
\subsection{Beyond Markov: The Nakajima--Zwanzig Equation}

When the environmental correlation time $\tau_E$ is non-negligible,
the Born--Markov approximation fails. The exact reduced dynamics
is captured by the Nakajima--Zwanzig (NZ) integro-differential
equation~\cite{Nakajima1958,Zwanzig1960}:
\begin{equation}
\label{T-I-eq:NZ}
\dot{\rho}_R(t)
= -i[H_{\mathrm{eff}},\, \rho_R(t)]
  + \int_0^t ds\; \mathcal{K}(t,s)\, \rho_R(s),
\end{equation}
where $\mathcal{K}(t,s)$ is the \textbf{memory kernel}---a
superoperator encoding the influence of the system's entire
history on its present dynamics.

\begin{definition}[Memory Kernel]
\label{T-I-def:kernel}
The memory kernel $\mathcal{K}: [0,\infty)^2 \to
\mathcal{L}(\mathcal{B}(\mathcal{H}_R))$ is the superoperator
satisfying~\eqref{T-I-eq:NZ}. It encodes two types of information:
\begin{enumerate}
\item \textbf{Environmental structure:} the spectral density,
  correlation functions, and non-equilibrium features of the bath;
\item \textbf{Temporal reach:} the effective support
  $\tau_{\mathrm{mem}} := \inf\{\tau : \|\mathcal{K}(t,s)\| < \epsilon
  \;\forall\; t - s > \tau\}$, the ``memory depth.''
\end{enumerate}
The Markovian limit corresponds to
$\mathcal{K}(t,s) \to \mathcal{K}_0\, \delta(t-s)$,
recovering the GKSL generator.
\end{definition}

\begin{remark}[Information Backflow]
\label{T-I-rem:backflow}
Non-Markovian dynamics admits \emph{information backflow}:
the distinguishability of two initial states, as measured by
trace distance $D(\rho_1(t), \rho_2(t))$, can temporarily
increase~\cite{BreuerLainePiilo2009}. This is the operational
signature of memory---the environment returns previously
absorbed information to the system.
\end{remark}

% ------------------------------------------------------------
\subsection{Thermodynamic Framework}
\label{T-I-subsec:thermo}

We adopt the framework of stochastic thermodynamics for open
quantum systems~\cite{EspositoLindenbergVandenBroeck2010}.
The following conventions are fixed throughout.

\begin{definition}[Thermodynamic Setup]
\label{T-I-def:thermo_setup}
\leavevmode
\begin{enumerate}
\item \textbf{Hamiltonian decomposition.}
  The system Hamiltonian is
  $H_S(t) = H_R + H_{\mathrm{ctrl}}(t)$,
  where $H_R$ is the \emph{fixed} bare Hamiltonian and
  $H_{\mathrm{ctrl}}(t)$ is the agent's time-dependent
  control protocol.
  The bath Hamiltonian $H_E$ and coupling $H_{\mathrm{int}}$
  are as in~\eqref{T-I-eq:H_total}.

\item \textbf{Reference state.}
  The thermal equilibrium state of the bare Hamiltonian is
  \begin{equation}
  \label{T-I-eq:rho_eq}
  \rho_{\mathrm{eq}} := \frac{e^{-\beta H_R}}{Z_R},
  \qquad Z_R := \tr(e^{-\beta H_R}),
  \qquad \beta := (k_B T)^{-1}.
  \end{equation}
  Since $H_R$ is time-independent, $\rho_{\mathrm{eq}}$ is a
  well-defined, fixed reference throughout the protocol.

\item \textbf{Non-equilibrium free energy.}
  For any state $\rho$ of the reduced system,
  \begin{equation}
  \label{T-I-eq:F_neq}
  F(\rho) := \tr(\rho\, H_R) + \beta^{-1}\tr(\rho\ln\rho)
  = \langle H_R \rangle_\rho - \beta^{-1} S(\rho),
  \end{equation}
  where $S(\rho) = -\tr(\rho\ln\rho)$ is the von~Neumann entropy.
  The equilibrium value is $F_{\mathrm{eq}} = -\beta^{-1}\ln Z_R$.

\item \textbf{Free energy--relative entropy identity.}
  \begin{equation}
  \label{T-I-eq:DKL_F}
  D_{\mathrm{KL}}(\rho \| \rho_{\mathrm{eq}})
  = \beta\bigl(F(\rho) - F_{\mathrm{eq}}\bigr) \geq 0.
  \end{equation}
  Thus $D_{\mathrm{KL}}$ measures the free-energy surplus in
  units of $k_B T$.

\item \textbf{Work.}
  The work performed on the system by the control protocol
  over $[0,\tau]$ is
  \begin{equation}
  \label{T-I-eq:work}
  W[0,\tau] := \int_0^\tau
  \tr\!\left(\rho(t)\,
  \frac{\partial H_{\mathrm{ctrl}}}{\partial t}\right) dt.
  \end{equation}

\item \textbf{Entropy-production functional.}
  The \emph{generalised entropy production} over $[0,\tau]$ is
  \begin{equation}
  \label{T-I-eq:Sigma}
  \Sigma[0,\tau] := \beta\bigl(W[0,\tau] - \Delta F\bigr),
  \end{equation}
  where $\Delta F = F(\rho(\tau)) - F(\rho(0))$.
  For uncorrelated (product) initial states,
  $\Sigma \geq 0$ recovers the standard second-law bound.
  For initially correlated states, $\Sigma$ can be
  \emph{negative}, reflecting the consumption of
  pre-existing correlations
  (see Remark~\ref{T-I-rem:battery}).
\end{enumerate}
\end{definition}

\begin{remark}[Why $H_R$ is fixed]
\label{T-I-rem:H_fixed}
The bare Hamiltonian $H_R$ defines the system's energy scale and
hence the reference state $\rho_{\mathrm{eq}}$.
The agent acts on the world through $H_{\mathrm{ctrl}}(t)$,
which may be time-dependent.
This separation ensures that $\rho_{\mathrm{eq}}$ is
well-defined and time-independent, avoiding the ambiguity
that arises when the full $H_S(t)$ is used to define the
thermal reference.
\end{remark}

\begin{definition}[Standing Assumptions]
\label{T-I-def:assumptions}
The following minimal assumptions are in force throughout
Sections~\ref{T-I-sec:advantage}--\ref{T-I-sec:example} unless
stated otherwise.
Every main result
(Lemma~\ref{T-I-lem:info_thermo},
Theorem~\ref{T-I-thm:advantage},
Corollary~\ref{T-I-cor:three_regimes})
relies \emph{only} on items
\textup{(A1)--(A5)} below.
\begin{enumerate}
\item[\textup{(A1)}]
  \textbf{Finite-dimensional bipartite system.}
  $\mathcal{H} = \mathcal{H}_S \otimes \mathcal{H}_E$,
  with total Hamiltonian~\eqref{T-I-eq:H_total}
  and global unitary evolution
  $U(t) = \mathcal{T}\exp(-i\int_0^t H(s)\,ds)$.

\item[\textup{(A2)}]
  \textbf{Weak coupling.}
  The system--environment interaction satisfies
  $\lambda \ll 1$ in~\eqref{T-I-eq:H_total}, so that
  $\Delta\langle H_{\mathrm{int}} \rangle
  = O(\lambda)$~\cite{BreuerPetruccione2002}.
  Energy conservation is then
  $\Delta\langle H_R\rangle
  + \Delta\langle H_{\mathrm{ctrl}}\rangle
  + \Delta\langle H_E\rangle \approx 0$
  up to controlled $O(\lambda)$ corrections.

\item[\textup{(A3)}]
  \textbf{Fixed environmental reference.}
  $\rho_E^{\mathrm{th}} := e^{-\beta H_E}/Z_E$
  is a fixed \emph{bookkeeping} Gibbs state at inverse
  temperature $\beta$.
  The \emph{actual} initial bath state $\rho_E(0)$
  need not coincide with $\rho_E^{\mathrm{th}}$;
  when $\rho_E(0) \neq \rho_E^{\mathrm{th}}$, the quantity
  $D_{\mathrm{KL}}(\rho_E(t)\|\rho_E^{\mathrm{th}})$
  tracks the nonequilibrium free energy stored in the bath
  relative to this reference.
  The bath Hamiltonian $H_E$ is time-independent.

\item[\textup{(A4)}]
  \textbf{Arbitrary initial state.}
  The total initial state $\rho_{SE}(0)$ is \emph{not}
  required to be a product state.
  In particular, initial system--environment correlations
  $I(S{:}E;\,0) > 0$ and initial bath displacement
  $D_{\mathrm{KL}}(\rho_E(0)\|\rho_E^{\mathrm{th}}) > 0$
  are both permitted.
\item[\textup{(A5)}]
  \textbf{Regularity.}
  All quantum states appearing in the thermodynamic
  identities are assumed to have full rank (or are
  restricted to their support), so that all relative
  entropies $D_{\mathrm{KL}}(\rho\|\sigma)$ are finite.
\end{enumerate}
\end{definition}

\begin{remark}[Bookkeeping conventions]
\label{T-I-rem:bookkeeping}
The heat absorbed by the environment is
$Q := \Delta\langle H_E \rangle
= \mathrm{Tr}[\rho_E(\tau) H_E]
  - \mathrm{Tr}[\rho_E(0) H_E]$
(matching
Esposito \emph{et al.}~\cite{EspositoLindenbergVandenBroeck2010}).
We define $\Sigma := \beta(W - \Delta F)$ as a
\emph{generalised entropy-balance functional};
for correlated initial conditions $\Sigma$ need not be
nonnegative
(see Remark~\ref{T-I-rem:battery}).
\end{remark}

% ------------------------------------------------------------
\subsection{The Survival Functional}
\label{T-I-subsec:survival}

We now define the central quantity of this paper.

\begin{definition}[Survival Functional]
\label{T-I-def:survival}
For a reduced system $R$ evolving under dynamics $\Lambda$
over $[0,\tau]$, the \textbf{survival functional} is
\begin{equation}
\label{T-I-eq:survival}
\mathcal{S}[\Lambda, \tau]
:= \Delta F - W[0,\tau]
= \bigl[F(\rho(\tau)) - F(\rho(0))\bigr] - W[0,\tau].
\end{equation}
Equivalently, using~\eqref{T-I-eq:Sigma},
\begin{equation}
\label{T-I-eq:survival_Sigma}
\beta\,\mathcal{S}[\Lambda,\tau] = -\Sigma[0,\tau].
\end{equation}
\end{definition}

\noindent\textit{Note on nomenclature.}
We retain the term ``survival functional'' to emphasize
the biological interpretation of persistence far from
equilibrium; mathematically, $\mathcal{S}$ is strictly a
\emph{generalized entropy-balance functional} derived from
the first and second laws.

\begin{remark}[Interpretation]
\label{T-I-rem:survival_interp}
The survival functional has a transparent physical meaning:
\begin{itemize}
\item $\mathcal{S} > 0$: the system gained more free energy than
  was invested by the external protocol---a \emph{thermodynamic
  profit}. The agent has extracted usable work from environmental
  correlations.
\item $\mathcal{S} = 0$: the agent breaks even (reversible limit,
  $\Sigma = 0$).
\item $\mathcal{S} < 0$: the agent paid more than it gained
  (the generic irreversible case).
\end{itemize}
Under the standard second law ($\Sigma \geq 0$),
$\mathcal{S} \leq 0$ always.
As we show in Sections~\ref{T-I-sec:ceiling} and~\ref{T-I-sec:advantage},
achieving $\mathcal{S} > 0$ requires \emph{information}---and
the memory kernel provides exactly this.
\end{remark}

\begin{remark}[Connection to Information Thermodynamics]
\label{T-I-rem:connection_SU}
In the Sagawa--Ueda framework~\cite{SagawaUeda2010,SagawaUeda2012},
a system under feedback control satisfies the generalized second law
\begin{equation}
\label{T-I-eq:sagawa_ueda}
\Sigma \geq -I_{\mathrm{feedback}},
\end{equation}
where $I_{\mathrm{feedback}} \geq 0$ is the mutual information
gained through measurement of the system.
This permits $\Sigma < 0$ (and hence $\mathcal{S} > 0$) at
the expense of information.
The core thesis of this paper is that a non-Markovian memory
kernel provides \emph{implicit} feedback: the system's history
encodes correlations with the environment that play the same
thermodynamic role as explicit measurement outcomes.
\end{remark}

% ============================================================
\section{The Markovian Ceiling}
\label{T-I-sec:ceiling}

We now establish the fundamental thermodynamic limitation
of memoryless agents.
The result is elementary given the framework of
Section~\ref{T-I-subsec:thermo}, but its consequences are far-reaching:
under \emph{open-loop} control---where the agent's protocol
$H_{\mathrm{ctrl}}(t)$ is fixed in advance and receives no
information from the bath---the survival functional can never
be positive.

\subsection{Spohn's Inequality}

Throughout this section we assume that the GKSL generator
$\mathcal{L}$ is a \emph{thermal Lindbladian}: it is obtained
from the weak-coupling (Davies) limit of a system coupled to a
single thermal bath at inverse temperature $\beta$, and satisfies
\textbf{quantum detailed balance} (the KMS
condition)~\cite{Spohn1978,BreuerPetruccione2002}.
Under this assumption, the unique stationary state is the Gibbs
state $\rho_{\mathrm{ss}} = \rho_{\mathrm{eq}}$
of~\eqref{T-I-eq:rho_eq}, and the generator is self-adjoint with
respect to the KMS inner product.
This ensures that the entropy production rate below is
well-defined and non-negative.

\begin{definition}[Markovian Semigroup]
\label{T-I-def:markov_semigroup}
Throughout this paper, ``Markovian'' dynamics refers
strictly to a \textbf{dynamical semigroup} generated by a
time-independent GKSL generator $\mathcal{L}$ with
non-negative rates.
While time-dependent CP-divisible
maps~\cite{RivasHuelgaPlenio2014} are often called
Markovian in broader contexts, the ceiling theorem
(Theorem~\ref{T-I-thm:ceiling}) targets the semigroup case
$\Lambda(t) = e^{\mathcal{L}t}$, where no memory effects
or temporal correlations can be exploited.
\end{definition}

\begin{lemma}[Spohn~\cite{Spohn1978}]
\label{T-I-lem:spohn}
For any GKSL dynamical semigroup $\Lambda_t = e^{\mathcal{L}t}$
satisfying quantum detailed balance with unique invariant state
$\rho_{\mathrm{eq}}$, the entropy production
rate
\begin{equation}
\label{T-I-eq:spohn_sigma}
\sigma(t) := -\tr\!\bigl(\mathcal{L}[\rho(t)]\,
(\ln\rho(t) - \ln\rho_{\mathrm{eq}})\bigr)
\end{equation}
satisfies $\sigma(t) \geq 0$, with equality if and only if
$\rho(t) = \rho_{\mathrm{eq}}$.
\end{lemma}

\begin{proof}
This follows from the contractivity of CPTP maps under quantum
relative entropy~\cite{Spohn1978,BreuerPetruccione2002}:
$D_{\mathrm{KL}}(\Lambda_t\rho \| \Lambda_t\rho_{\mathrm{eq}})
\leq D_{\mathrm{KL}}(\rho \| \rho_{\mathrm{eq}})$
for all $t \geq 0$.
Differentiating at $t = 0$ yields $\sigma(t) \geq 0$.
\end{proof}

\subsection{The Markovian Ceiling Theorem}

\begin{definition}[Open-loop Markovian control class
$\mathcal{C}_{\mathrm{M}}$]
\label{T-I-def:control_class}
A protocol $H_{\mathrm{ctrl}}(t)$ belongs to the
\textbf{open-loop Markovian control class}
$\mathcal{C}_{\mathrm{M}}$ if and only if:
\begin{enumerate}
\item[\textup{(C1)}] $H_{\mathrm{ctrl}}(t)$ is a
  \emph{predetermined} function of $t$ alone, fixed before the
  protocol begins.
\item[\textup{(C2)}] No measurement of the system or
  environment is performed during $[0,\tau]$, and
  $H_{\mathrm{ctrl}}(t)$ receives no feedback from measurement
  outcomes.
\item[\textup{(C3)}] $H_{\mathrm{ctrl}}(t)$ is statistically
  independent of the bath realization
  $\{\xi_E(s) : s \in [0,\tau]\}$.
\end{enumerate}
Protocols involving adaptive measurement-based feedback
(Sagawa--Ueda~\cite{SagawaUeda2010}) are \emph{excluded} from
$\mathcal{C}_{\mathrm{M}}$.
\end{definition}

\begin{theorem}[Markovian Ceiling]
\label{T-I-thm:ceiling}
Let $\Lambda^{\mathrm{M}}$ denote GKSL dynamics~\eqref{T-I-eq:GKSL}
satisfying quantum detailed balance
(Lemma~\ref{T-I-lem:spohn}), coupled to a stationary thermal bath at
inverse temperature $\beta$, under a control protocol
$H_{\mathrm{ctrl}}(t) \in \mathcal{C}_{\mathrm{M}}$
(Definition~\ref{T-I-def:control_class}).
Then the survival functional satisfies
\begin{equation}
\label{T-I-eq:ceiling}
\mathcal{S}[\Lambda^{\mathrm{M}}, \tau] \leq 0
\qquad\text{for all } \tau \geq 0.
\end{equation}
Equality holds in the quasi-static limit ($\Sigma \to 0$),
where the protocol varies slowly enough that the state
remains close to the instantaneous Gibbs state
$\rho_{\mathrm{eq}}(t)$ at all times.
\end{theorem}

\begin{proof}
The proof proceeds in two steps.

\noindent\textbf{Step 1: Free-energy balance.}
Differentiating~\eqref{T-I-eq:DKL_F}, the relative entropy
evolves as
\begin{equation}
\label{T-I-eq:balance}
\frac{d}{dt}\, D_{\mathrm{KL}}(\rho(t) \| \rho_{\mathrm{eq}})
= \beta\,\dot{W}(t) - \sigma(t),
\end{equation}
where $\dot{W}(t) = \tr(\rho(t)\,\partial_t H_{\mathrm{ctrl}})$
is the instantaneous power and $\sigma(t)$ is Spohn's entropy
production rate~\eqref{T-I-eq:spohn_sigma}.
Integrating over $[0,\tau]$:
\begin{equation}
\label{T-I-eq:balance_int}
\Delta D_{\mathrm{KL}} = \beta\, W[0,\tau]
  - \underbrace{\int_0^\tau \sigma(t)\, dt}_{\displaystyle
    = \Sigma \;\geq\; 0}.
\end{equation}

\noindent\textbf{Step 2: Applying Spohn.}
By Lemma~\ref{T-I-lem:spohn}, $\sigma(t) \geq 0$ for all $t$,
so $\Sigma \geq 0$.
From~\eqref{T-I-eq:balance_int}:
\begin{equation}
\Delta D_{\mathrm{KL}} \leq \beta\, W[0,\tau].
\end{equation}
Converting via~\eqref{T-I-eq:DKL_F}:
$\Delta F \leq W[0,\tau]$,
whence $\mathcal{S} = \Delta F - W \leq 0$.

The ceiling $\mathcal{S} = 0$ is achieved in the reversible
limit where the protocol is infinitely slow and $\sigma(t) \to 0$
pointwise.
\end{proof}

\begin{remark}[The ``Open-Loop'' Qualifier]
\label{T-I-rem:open_loop}
The restriction to the control class
$\mathcal{C}_{\mathrm{M}}$
(Definition~\ref{T-I-def:control_class}) is essential.
If the agent can perform \emph{measurements} on the bath and
condition its protocol on the outcomes---i.e., violate
condition~\textup{(C2)}---the Sagawa--Ueda
generalized second law~\eqref{T-I-eq:sagawa_ueda} permits
$\Sigma < 0$ (and hence $\mathcal{S} > 0$) at the expense
of mutual information.
The Markovian ceiling is therefore not a universal bound on
all Markovian agents, but on agents whose protocols satisfy
\textup{(C1)--(C3)}.

This qualifier is precisely the point:
the memory kernel of non-Markovian dynamics provides implicit
access to bath correlations, playing the role of implicit
measurement---the subject of Section~\ref{T-I-sec:advantage}.
\end{remark}

\begin{corollary}[Temporal Blindness]
\label{T-I-cor:blindness}
Under the Born--Markov approximation, the bath correlation
function is replaced by its white-noise limit
$C(t,s) \to C_0\,\delta(t-s)$, and the GKSL dissipator depends
only on the spectral density $J(\omega)$ evaluated at the
system's Bohr frequencies.
The agent interacts with the environment's
\emph{power spectrum} but is structurally blind to its
\emph{temporal correlations}---the off-diagonal elements
$C(t,s)$ for $t \neq s$.

Consequently, the spectral gap
$\lambda_{\min} \propto \sum_k J(\omega_k)$ of the Liouvillian
sets the rate of irreversible decay.
Maintaining $D_{\mathrm{KL}} > 0$ requires continuous work at
rate $\dot{W} \geq \beta^{-1}\sigma(t) > 0$, and the integrated
cost always meets or exceeds the integrated gain.
\end{corollary}

\begin{remark}[Dissipative vs.\ Self-Nourishing Structures]
\label{T-I-rem:ceiling_physics}
The Markovian ceiling partitions far-from-equilibrium structures
into two classes:
\begin{itemize}
\item \textbf{Dissipative structures} ($\mathcal{S} \leq 0$):
  sustained by continuous external free-energy input.
  Every unit of order is paid for in full.
  (Prigogine's sense~\cite{Schrodinger1944}.)
\item \textbf{Self-nourishing structures} ($\mathcal{S} > 0$):
  extract structured advantage from environmental correlations,
  gaining more free energy than they consume.
  These require information flow, and hence memory.
\end{itemize}
The ceiling is not a limitation of the agent's control
strategy but a \emph{structural consequence} of temporal
blindness: without memory, the environment's temporal
correlations are thermodynamically invisible.
\end{remark}

% ============================================================
\section{The Non-Markovian Advantage}
\label{T-I-sec:advantage}

Having established that open-loop Markovian agents are
thermodynamically capped at $\mathcal{S} \leq 0$, we now
demonstrate how non-Markovian dynamics breaks this ceiling.
The mechanism is grounded entirely in standard quantities:
the quantum mutual information $I(S{:}E)$ between system
and environment serves as a consumable thermodynamic resource.
Non-Markovian backflow intervals are precisely those during
which pre-existing correlations are consumed, enabling the
system to extract free energy beyond what open-loop work
provides.

\subsection{System--Environment Mutual Information}

We work with the total system--environment state
$\rho_{SE}(t)$, evolving unitarily under the total
Hamiltonian~\eqref{T-I-eq:H_total}.
The quantum mutual information
\begin{equation}
\label{T-I-eq:mutual_info}
I(S{:}E;\, t) := S(\rho_S(t)) + S(\rho_E(t))
  - S(\rho_{SE}(t))
= D_{\mathrm{KL}}\!\bigl(\rho_{SE}(t) \,\big\|\,
  \rho_S(t) \otimes \rho_E(t)\bigr)
\geq 0
\end{equation}
quantifies the total correlations (classical and quantum)
between the system $S$ and the environment $E$ at time $t$.

\begin{remark}[Role of Initial Correlations]
\label{T-I-rem:initial_corr}
Under the Born approximation, the initial state is taken as a
product $\rho_{SE}(0) = \rho_S(0) \otimes \rho_E^{\mathrm{th}}$,
so $I(S{:}E;\, 0) = 0$.
For a system that has already been interacting with its
environment (the physically generic situation for a
``persistent agent''), the effective initial state at any
restart time $t_0 > 0$ is \emph{not} a product state:
the preceding evolution has established correlations
$I(S{:}E;\, t_0) > 0$.
These pre-existing correlations---the system's ``memory''
of past interactions---are the thermodynamic resource
that the memory kernel can exploit.
\end{remark}

\subsection{The Information--Thermodynamic Identity}

The following identity is the central technical tool of this
section.
It holds for \textbf{any} initial state---product or
correlated---and relies only on unitarity and the definitions
of mutual information and relative entropy.

\begin{remark}[Relative-entropy chain rule]
\label{T-I-rem:chain_rule}
We repeatedly use the identity
\begin{equation}
\label{T-I-eq:chain_general}
D_{\mathrm{KL}}\!\bigl(\rho_{SE}\,\big\|\,
  \rho_S\otimes\sigma_E\bigr)
= I(S{:}E)_{\rho_{SE}}
  + D_{\mathrm{KL}}(\rho_E\|\sigma_E),
\end{equation}
valid for \emph{arbitrary} (possibly correlated)
$\rho_{SE}$ and any full-rank reference state
$\sigma_E$.\footnote{This follows from the definition of
quantum relative entropy and
$\ln(\rho_S\otimes\sigma_E)
= \ln\rho_S\otimes\mathbb{1}_E
  +\mathbb{1}_S\otimes\ln\sigma_E$.
See, e.g., M.~M.~Wilde, \emph{Quantum Information
Theory}, 2nd ed., Cambridge University Press (2017),
Sec.~11; and M.~A.~Nielsen and I.~L.~Chuang,
\emph{Quantum Computation and Quantum Information},
Cambridge University Press (2000), Ch.~11.}
Importantly, this is a \emph{pure algebraic identity} and
does not assume product initial conditions.
\end{remark}

\begin{lemma}[Information--Thermodynamic Identity]
\label{T-I-lem:info_thermo}
Let $\rho_{SE}(t)$ evolve unitarily under the total
Hamiltonian.
Then, for \textbf{any} initial state $\rho_{SE}(0)$
(product or correlated):
\begin{equation}
\label{T-I-eq:info_thermo}
\Delta I(S{:}E)
+ \Delta D_{\mathrm{KL}}\!\bigl(\rho_E \,\big\|\,
  \rho_E^{\mathrm{th}}\bigr)
= \Delta S_S + \beta\,\Delta\langle H_E \rangle,
\end{equation}
where $\Delta S_S = S(\rho_S(\tau)) - S(\rho_S(0))$ is the
change in the system's von~Neumann entropy and
$\Delta\langle H_E \rangle
= \mathrm{Tr}[\rho_E(\tau)\, H_E]
  - \mathrm{Tr}[\rho_E(0)\, H_E]$
is the energy absorbed by the environment.
\end{lemma}

\begin{proof}
Applying the chain rule~\eqref{T-I-eq:chain_general}
(Remark~\ref{T-I-rem:chain_rule}) with
$\sigma_E = \rho_E^{\mathrm{th}}$:
\begin{equation}
\label{T-I-eq:chain_step}
D_{\mathrm{KL}}\!\bigl(\rho_{SE}(t) \,\big\|\,
  \rho_S(t) \otimes \rho_E^{\mathrm{th}}\bigr)
= I(S{:}E;\, t)
  + D_{\mathrm{KL}}\!\bigl(\rho_E(t) \,\big\|\,
    \rho_E^{\mathrm{th}}\bigr).
\end{equation}
Expanding the left side using
$\ln\rho_E^{\mathrm{th}} = -\beta H_E - \ln Z_E$:
\begin{equation}
\label{T-I-eq:phi_expand}
D_{\mathrm{KL}}\!\bigl(\rho_{SE}(t) \,\big\|\,
  \rho_S(t) \otimes \rho_E^{\mathrm{th}}\bigr)
= -S(\rho_{SE}(t)) + S(\rho_S(t))
  + \beta\langle H_E \rangle_t + \ln Z_E.
\end{equation}
Since the total evolution is unitary,
$S(\rho_{SE}(t)) = S(\rho_{SE}(0))$ for all $t$.
Taking the difference between times $\tau$ and $0$ cancels
both $S(\rho_{SE})$ and $\ln Z_E$, yielding
\begin{equation}
\Delta\!\left[I(S{:}E)
  + D_{\mathrm{KL}}(\rho_E \| \rho_E^{\mathrm{th}})\right]
= \Delta S_S + \beta\,\Delta\langle H_E \rangle.
\end{equation}
\end{proof}

\begin{remark}[No assumption on the initial state]
\label{T-I-rem:no_product_lemma}
The proof of Lemma~\ref{T-I-lem:info_thermo} uses \emph{only}
unitarity ($\Delta S(\rho_{SE}) = 0$) and the algebraic
structure of the KL divergence.
No assumption is made about the initial state $\rho_{SE}(0)$,
the coupling strength, or the character (Markovian or
non-Markovian) of the reduced dynamics.
When the initial state is a product state with the environment
in thermal equilibrium, all initial-time terms vanish and the
identity reduces to the Esposito
decomposition~\cite{EspositoLindenbergVandenBroeck2010}:
$\Sigma = I(S{:}E;\,\tau)
+ D_{\mathrm{KL}}(\rho_E(\tau) \| \rho_E^{\mathrm{th}})$.
\end{remark}

\subsection{The Survival Identity}

We now connect the information--thermodynamic
identity~\eqref{T-I-eq:info_thermo} to the survival
functional $\mathcal{S}$ defined in
Section~\ref{T-I-subsec:survival}.

\begin{theorem}[Survival Functional: General Form]
\label{T-I-thm:advantage}
Under Assumptions \textup{(A1)--(A5)} of
Definition~\ref{T-I-def:assumptions},
let $\rho_{SE}(t)$ evolve unitarily from an \emph{arbitrary}
(possibly correlated) initial state $\rho_{SE}(0)$.
The survival functional
satisfies
\begin{equation}
\label{T-I-eq:advantage}
\boxed{\;
\beta\,\mathcal{S}[\Lambda,\tau]
= -\Delta I(S{:}E)
  - \Delta D_{\mathrm{KL}}\!\bigl(\rho_E \,\big\|\,
    \rho_E^{\mathrm{th}}\bigr)
  - \beta\,\Delta\langle H_{\mathrm{ctrl}} \rangle,
\;}
\end{equation}
where $\Delta\langle H_{\mathrm{ctrl}} \rangle
= \mathrm{Tr}[\rho_S(\tau)\, H_{\mathrm{ctrl}}(\tau)]
  - \mathrm{Tr}[\rho_S(0)\, H_{\mathrm{ctrl}}(0)]$
is the change in the control-field energy.

For \textbf{autonomous evolution}
($H_{\mathrm{ctrl}} = 0$ throughout $[0,\tau]$),
the control term vanishes:
\begin{equation}
\label{T-I-eq:advantage_auto}
\beta\,\mathcal{S}[\Lambda,\tau]
= -\Delta I(S{:}E)
  - \Delta D_{\mathrm{KL}}\!\bigl(\rho_E \,\big\|\,
    \rho_E^{\mathrm{th}}\bigr).
\end{equation}
\end{theorem}

\begin{proof}
The proof uses three ingredients: the definition of
$\mathcal{S}$, the first law, and
Lemma~\ref{T-I-lem:info_thermo}.

\noindent\textbf{Step 1 (First law in weak coupling).}
Since $H_{\mathrm{ctrl}}(t)$ is the only time-dependent
component of $H$, the work satisfies
$W = \Delta\langle H \rangle
\approx \Delta\langle H_R \rangle
  + \Delta\langle H_{\mathrm{ctrl}} \rangle
  + \Delta\langle H_E \rangle$
by Assumption~\textup{(A2)}.

\noindent\textbf{Step 2 (Connecting $\Sigma$ to the
identity).}
From Definition~\ref{T-I-def:survival} and~\eqref{T-I-eq:Sigma},
using $\Delta F = \Delta\langle H_R \rangle
- \beta^{-1}\Delta S_S$:
\begin{align}
\Sigma &= \beta(W - \Delta F)
= \beta\bigl(W - \Delta\langle H_R \rangle\bigr)
  + \Delta S_S \nonumber \\
&= \beta\bigl(\Delta\langle H_{\mathrm{ctrl}} \rangle
  + \Delta\langle H_E \rangle\bigr) + \Delta S_S
\nonumber \\
&= \bigl(\Delta S_S
  + \beta\,\Delta\langle H_E \rangle\bigr)
  + \beta\,\Delta\langle H_{\mathrm{ctrl}} \rangle.
\label{T-I-eq:Sigma_decomp}
\end{align}
By Lemma~\ref{T-I-lem:info_thermo}, the parenthesized term
equals
$\Delta I(S{:}E)
+ \Delta D_{\mathrm{KL}}(\rho_E \| \rho_E^{\mathrm{th}})$.
Hence
\begin{equation}
\label{T-I-eq:Sigma_general}
\Sigma = \Delta I(S{:}E)
  + \Delta D_{\mathrm{KL}}\!\bigl(\rho_E \,\big\|\,
    \rho_E^{\mathrm{th}}\bigr)
  + \beta\,\Delta\langle H_{\mathrm{ctrl}} \rangle.
\end{equation}

\noindent\textbf{Step 3 (Survival functional).}
$\beta\,\mathcal{S} = -\Sigma$ by~\eqref{T-I-eq:survival_Sigma},
yielding~\eqref{T-I-eq:advantage}.
For $H_{\mathrm{ctrl}} = 0$:
$\Delta\langle H_{\mathrm{ctrl}} \rangle = 0$,
recovering~\eqref{T-I-eq:advantage_auto}.
\end{proof}

\begin{remark}[Nature of the result]
\label{T-I-rem:identity_not_bound}
Equation~\eqref{T-I-eq:advantage} is an exact
\emph{accounting identity}, not an inequality or
optimality bound.
It establishes that any thermodynamic profit
($\mathcal{S} > 0$) in the autonomous regime must be
perfectly balanced by the consumption of
system--environment correlations ($\Delta I < 0$) or
the relaxation of the bath
($\Delta D_{\mathrm{KL}} < 0$).
The ``non-Markovian advantage'' arises because memory
kernels allow access to regimes where
$\Delta I(S{:}E)$ is negative and dominant---a channel
that memoryless (Born--Markov) dynamics resets to zero
at every time step
(Remark~\ref{T-I-rem:born_kills}).
\end{remark}

\begin{remark}[Scope of the theorem]
\label{T-I-rem:no_product}
Theorem~\ref{T-I-thm:advantage} holds for \emph{any} initial
state $\rho_{SE}(0)$---product or correlated.
The proof requires only
Assumptions~\textup{(A1)--(A5)} of
Definition~\ref{T-I-def:assumptions} and the definitions of
$\mathcal{S}$, $I(S{:}E)$, and $D_{\mathrm{KL}}$.
No assumption about the reduced dynamics (Markovian,
non-Markovian, or otherwise) is needed.
This generality is essential: a persistent agent that has
already been interacting with its environment necessarily
carries correlations ($I(S{:}E;\,0) > 0$), and it is
precisely these correlations that constitute the thermodynamic
resource for survival.
\end{remark}

\subsection{Three Regimes of Survival}

We specialize to the autonomous case
($H_{\mathrm{ctrl}} = 0$), which is the natural setting for
the ``memory as a resource'' argument: the agent benefits from
pre-existing correlations without external driving.

\begin{corollary}[Three Regimes]
\label{T-I-cor:three_regimes}
Under autonomous evolution, identity~\eqref{T-I-eq:advantage_auto}
identifies three regimes:
\begin{enumerate}
\item \textbf{Product initial state}
  ($I(S{:}E;\, 0) = 0$,
  $D_{\mathrm{KL}}(\rho_E(0) \| \rho_E^{\mathrm{th}}) = 0$):
  Both $\Delta I$ and $\Delta D_{\mathrm{KL}}$ are increases
  from zero to non-negative final values, so
  \[
  \beta\,\mathcal{S}
  = -\bigl(I(S{:}E;\,\tau)
  + D_{\mathrm{KL}}(\rho_E(\tau) \| \rho_E^{\mathrm{th}})\bigr)
  \leq 0.
  \]
  This recovers the Markovian ceiling
  (Theorem~\ref{T-I-thm:ceiling}), now with a precise accounting
  of \emph{where} the entropy goes: into system--environment
  correlations and bath displacement.

\item \textbf{Correlated initial state}
  ($I(S{:}E;\, 0) > 0$):
  If the dynamics \emph{consumes} pre-existing correlations
  ($\Delta I < 0$, i.e., $I(S{:}E;\, \tau) < I(S{:}E;\, 0)$),
  the first term contributes \emph{positively} to
  $\mathcal{S}$.
  Provided
  \begin{equation}
  \label{T-I-eq:ceiling_breach}
  |\Delta I(S{:}E)| > \Delta D_{\mathrm{KL}}\!\bigl(\rho_E
  \,\big\|\, \rho_E^{\mathrm{th}}\bigr),
  \end{equation}
  the survival functional is strictly positive:
  $\mathcal{S} > 0$.
  The agent has converted pre-existing correlations into
  usable free energy.

\item \textbf{Upper bound:}
  Since $I(S{:}E;\, \tau) \geq 0$ and
  $D_{\mathrm{KL}}(\rho_E(\tau) \| \rho_E^{\mathrm{th}})
  \geq 0$, the maximum survival gain is bounded by
  \begin{equation}
  \label{T-I-eq:S_upper}
  \beta\,\mathcal{S}
  \leq I(S{:}E;\, 0)
    + D_{\mathrm{KL}}\!\bigl(\rho_E(0) \,\big\|\,
      \rho_E^{\mathrm{th}}\bigr).
  \end{equation}
  The thermodynamic profit cannot exceed the total initial
  ``resource budget''---the pre-existing correlations plus
  the initial displacement of the bath from equilibrium.
\end{enumerate}
\end{corollary}

\subsection{The Correlation Battery}

The three regimes of Corollary~\ref{T-I-cor:three_regimes} raise a
natural question: \emph{where do the initial correlations
$I(S{:}E;\, 0) > 0$ come from?}

\begin{remark}[The Correlation Battery]
\label{T-I-rem:battery}
The answer is: from \textbf{prior interaction epochs}.
A persistent agent does not begin its existence in a product
state.
Over any interaction interval, unitary evolution generically
builds system--environment correlations ($\Delta I > 0$),
at a thermodynamic cost ($\mathcal{S} < 0$ during this
phase by Corollary~\ref{T-I-cor:three_regimes}(i)).
The non-Markovian agent's advantage is that these correlations
\emph{persist} and can be consumed during later intervals
($\Delta I < 0$, $\mathcal{S} > 0$).

The process is analogous to a \textbf{battery}:
\begin{itemize}
\item \textbf{Charging phase}
  (correlation building, $\Delta I > 0$):
  the agent ``pays'' free energy to build
  system--environment correlations.
  $\mathcal{S} < 0$.
\item \textbf{Discharging phase}
  (correlation consumption, $\Delta I < 0$):
  the agent extracts free energy from the stored
  correlations.
  $\mathcal{S} > 0$.
\end{itemize}
A Markovian agent cannot operate this battery.
The Born approximation resets $I(S{:}E) = 0$ at every
infinitesimal time step, destroying the stored correlations
before they can be used.
The semigroup property $\Lambda(t+s) = \Lambda(t)\Lambda(s)$
is precisely the statement that no inter-epoch correlations
survive.
The memory kernel $\mathcal{K}(t,s)$ is what allows the
non-Markovian agent to carry charge across epochs.

Crucially, global thermodynamics remains respected.
For any full cycle starting from an uncorrelated thermal
state ($I(S{:}E;\,0) = 0$,
$D_{\mathrm{KL}}(\rho_E(0)\|\rho_E^{\mathrm{th}}) = 0$),
the total survival functional satisfies
\begin{equation}
\label{T-I-eq:battery_closure}
\beta\,\mathcal{S}[0, t]
= -\Sigma[0, t] \;\leq\; 0
\qquad\text{(second law).}
\end{equation}
The local positivity $\mathcal{S}[t^*, t] > 0$ during the
discharging phase is strictly funded by the free energy
dissipated during the earlier charging phase
(see Proposition~\ref{T-I-prop:full_cycle} for the formal
decomposition).
\end{remark}

\begin{proposition}[Full-cycle closure]
\label{T-I-prop:full_cycle}
Under the conditions of
Theorem~\textup{\ref{T-I-thm:advantage}} with autonomous evolution
($H_{\mathrm{ctrl}} = 0$), partition $[0,\tau]$ at any
intermediate time $t^*$ into a charging phase $[0,t^*]$ and
a discharging phase $[t^*,\tau]$.
\begin{enumerate}
\item[\textup{(i)}]
  \textbf{Charging} (product initial state, $I(S{:}E;\,0) = 0$).
  By Corollary~\textup{\ref{T-I-cor:three_regimes}(i)},
  \begin{equation}
  \label{T-I-eq:charge}
  \beta\,\mathcal{S}[0,t^*]
  = -I(S{:}E;\,t^*)
    - D_{\mathrm{KL}}\!\bigl(\rho_E(t^*) \,\big\|\,
      \rho_E^{\mathrm{th}}\bigr)
  \;\leq\; 0.
  \end{equation}
\item[\textup{(ii)}]
  \textbf{Discharging} (correlated initial state at $t^*$).
  Applying~\eqref{T-I-eq:advantage_auto} to $[t^*,\tau]$:
  \begin{equation}
  \label{T-I-eq:discharge}
  \beta\,\mathcal{S}[t^*,\tau]
  = -\bigl(I(S{:}E;\,\tau) - I(S{:}E;\,t^*)\bigr)
    - \bigl(D_{\mathrm{KL}}(\rho_E(\tau)\|\rho_E^{\mathrm{th}})
      - D_{\mathrm{KL}}(\rho_E(t^*)\|\rho_E^{\mathrm{th}})\bigr),
  \end{equation}
  which is positive whenever the decrease in correlations
  dominates the change in bath displacement
  (Corollary~\textup{\ref{T-I-cor:three_regimes}(ii)}).
\item[\textup{(iii)}]
  \textbf{Full cycle.}
  Since $\mathcal{S}$ is additive over concatenated intervals,
  $\beta\,\mathcal{S}[0,\tau]
  = \beta\,\mathcal{S}[0,t^*]
    + \beta\,\mathcal{S}[t^*,\tau]$.
  Equivalently, applying~\eqref{T-I-eq:advantage_auto} directly to
  $[0,\tau]$ with $I(S{:}E;\,0) = 0$:
  \begin{equation}
  \label{T-I-eq:full_cycle}
  \beta\,\mathcal{S}[0,\tau]
  = -I(S{:}E;\,\tau)
    - D_{\mathrm{KL}}\!\bigl(\rho_E(\tau) \,\big\|\,
      \rho_E^{\mathrm{th}}\bigr)
  \;\leq\; 0.
  \end{equation}
\end{enumerate}
The net thermodynamic profit over the full cycle is
non-positive---the ``interest'' paid during charging
meets or exceeds the ``dividend'' collected during
discharging.
But the \emph{local} positivity of $\mathcal{S}$ during
discharge~\eqref{T-I-eq:discharge} is what enables the agent
to survive through intervals that would kill a memoryless
system.
\end{proposition}

\begin{proof}
The survival functional is additive over concatenated
intervals:
\[
\mathcal{S}[0,\tau]
= \underbrace{(\Delta F[0,t^*] - W[0,t^*])}_{\mathcal{S}[0,t^*]}
  +\; \underbrace{(\Delta F[t^*,\tau] - W[t^*,\tau])}_{\mathcal{S}[t^*,\tau]},
\]
since both $\Delta F$ and $W$ decompose additively.
Items (i) and (iii) then follow from
Theorem~\ref{T-I-thm:advantage} (autonomous case) applied to
$[0,t^*]$ and $[0,\tau]$ respectively, each starting from
a product state.
Item (ii) follows from Theorem~\ref{T-I-thm:advantage} applied
to $[t^*,\tau]$ with correlated initial state
$\rho_{SE}(t^*)$.
Inequality~\eqref{T-I-eq:full_cycle} holds because
$I(S{:}E;\,\tau) \geq 0$ and
$D_{\mathrm{KL}}(\rho_E(\tau)\|\rho_E^{\mathrm{th}}) \geq 0$.
\end{proof}

\subsection{Connection to Non-Markovianity Measures}

\begin{remark}[The Born Approximation Destroys the Resource]
\label{T-I-rem:born_kills}
Under the Born (product-state) approximation, every
infinitesimal time step begins from
$\rho_{SE} \approx \rho_S \otimes \rho_E^{\mathrm{th}}$,
enforcing $I(S{:}E) = 0$ at all times.
Corollary~\ref{T-I-cor:three_regimes}(i) then guarantees
$\mathcal{S} \leq 0$ for \emph{every} finite interval.
The Born approximation does not merely simplify the
dynamics---it \emph{eliminates the thermodynamic resource}
(system--environment correlations) that would otherwise be
available.
\end{remark}

\begin{remark}[Connection to BLP Non-Markovianity]
\label{T-I-rem:BLP}
The Breuer--Laine--Piilo (BLP) measure of
non-Markovianity~\cite{BreuerLainePiilo2009} is defined via
the temporary increase of trace distance between pairs of
initial states:
$\mathcal{N}_{\mathrm{BLP}} := \max_{\rho_{1,2}}
\int_{\dot{D}>0} \frac{d}{dt}
D(\rho_1(t),\rho_2(t))\, dt$.
The intervals where trace distance increases are precisely the
``discharging'' intervals of
Remark~\ref{T-I-rem:battery}~\cite{RivasHuelgaPlenio2014}:
correlations previously deposited in the bath flow back to the
system, restoring distinguishability.
The BLP measure thus witnesses the thermodynamic resource
that drives $\mathcal{S} > 0$ in
Corollary~\ref{T-I-cor:three_regimes}(ii).
\end{remark}

\begin{remark}[Consistency with the Sagawa--Ueda Framework]
\label{T-I-rem:SU_consistency}
In the Sagawa--Ueda framework~\cite{SagawaUeda2010,SagawaUeda2012},
measurement-based feedback permits
$\Sigma \geq -I_{\mathrm{feedback}}$, where
$I_{\mathrm{feedback}}$ is the mutual information gained
through measurement.
The memory kernel plays an analogous role:
the pre-existing correlations $I(S{:}E;\, 0)$ are the
non-Markovian analogue of $I_{\mathrm{feedback}}$.
The total system (agent + bath) still satisfies
$\Sigma_{\mathrm{total}} \geq 0$; the apparent ``profit'' for
the agent is paid for by the correlations consumed from the
system--environment entanglement.
The bound~\eqref{T-I-eq:S_upper} is the non-Markovian analogue of
the Sagawa--Ueda bound $\beta\,\mathcal{S} \leq
I_{\mathrm{feedback}}$.
\end{remark}

\subsection{Mechanism: The Surfer Analogy}

The physical mechanism admits an intuitive picture.

\begin{itemize}
\item \textbf{The Markovian Agent (The Stone):}
A stone thrown into the ocean sinks.
It interacts with the water only at the instant of contact,
dissipates its kinetic energy, and thermalizes
($\mathcal{S} \leq 0$).
Each collision builds system--environment correlations that are
immediately discarded (Born approximation), so
$I(S{:}E) = 0$ at all times.
The wave structure is invisible to it.

\item \textbf{The Non-Markovian Agent (The Surfer):}
A surfer carries \emph{memory} of past wave patterns---encoded
in the correlations $I(S{:}E;\, t_0) > 0$ built up over
previous interactions (the ``charging phase'' of
Remark~\ref{T-I-rem:battery}).
During backflow intervals ($\Delta I < 0$), the surfer
\emph{spends} these stored correlations to extract free energy
from the wave itself.
The surfer remains far from equilibrium not by fighting the
environment, but by converting temporal correlations into
thermodynamic profit.
\end{itemize}

\begin{remark}[Thermodynamic Rectification]
\label{T-I-rem:rectification}
The ``surfing'' mechanism is \textbf{thermodynamic
rectification}: the memory kernel $\mathcal{K}(t,s)$ functions
as a temporal filter that enables the system to accumulate
correlations during one phase and consume them during another.
Formally, the kernel enables access to the resource
$I(S{:}E;\, 0)$ accumulated during previous interaction
epochs---converting the environment's temporal correlations
into the system's structural persistence via the
$\Delta I$ term in Theorem~\ref{T-I-thm:advantage}.
\end{remark}

\begin{remark}[Memory as Implicit Maxwell's Demon]
\label{T-I-rem:demon}
The memory kernel functions as an \emph{implicit Maxwell's demon}.
A Markovian system interacts with each environmental fluctuation
exactly once, at the moment of contact; the Born approximation
resets $I(S{:}E) = 0$ after each step.
A non-Markovian system retains a trace of past fluctuations
(via $\mathcal{K}(t,s)$ with $s < t$) and can exploit
correlations between past and present environmental states.
This is not a violation of the second law but an instance of
the Sagawa--Ueda generalization: the demon's cost is paid in
the currency of memory maintenance (Landauer erasure), a point
we quantify in Section~\ref{T-I-sec:cost}.
The total budget for ``demonic profit'' is capped by the
bound~\eqref{T-I-eq:S_upper}.
\end{remark}

% ============================================================
\section{Emergent Temporal Arrow}
\label{T-I-sec:arrow}

We have shown that survival requires memory.
This requirement yields a corollary: the emergence of a
thermodynamic arrow of time.
In this framework, time is not an external parameter;
rather, \emph{the direction of time is the direction of memory
accumulation}.

We formalize this by defining a dynamical partial order induced
by the memory kernel and connecting it to the algebraic
accessibility structure of HAFF Paper~F~\cite{Liu2026HAFF_F}.

\subsection{The Causal Memory Order}

A non-Markovian memory kernel $\mathcal{K}(t,s)$ defines a
causal link between a past state at $s$ and the present dynamics
at $t$.
We define a partial order based on the effective support of this
influence.

\begin{definition}[Causal Memory Order]
\label{T-I-def:memory_order}
Let $\mathcal{T} = \{\rho(t) \mid t \in \mathbb{R}^+\}$ be
a state trajectory.
We define the binary relation $\prec_K$ on $\mathcal{T}$ by
\begin{equation}
\label{T-I-eq:memory_order}
\rho(s) \prec_K \rho(t) \quad \iff \quad
\exists\, \tau \in [s, t] \text{ such that }
\| \mathcal{K}(t, \tau)[\rho(s)] \| > \epsilon,
\end{equation}
where $\epsilon > 0$ is a physical distinguishability threshold
set by the thermal noise floor
$\epsilon \sim e^{-\beta\, \Delta E_{\min}}$.
Physically, $\rho(s) \prec_K \rho(t)$ means ``the dynamics at
$t$ retains operationally distinguishable information about the
state at $s$.''
\end{definition}

For a Markovian agent, $\mathcal{K}(t,s) \propto \delta(t-s)$,
so $\rho(s) \nprec_K \rho(t)$ for any $s < t$.
The Markovian agent has no dynamical past---it lives in an
eternal ``now.''
A non-Markovian agent carries its history within its dynamics;
the depth of the order $\prec_K$ is set by the memory time
$\tau_{\mathrm{mem}}$ (Definition~\ref{T-I-def:kernel}).

\subsection{Unidirectionality from Survival Optimization}

Why does the order $\prec_K$ point ``forward''?
While the microscopic laws are time-reversible, the
\emph{survival imperative} (maximizing $\mathcal{S}$) creates
a statistical irreversibility.

\begin{proposition}[Fisher Information Accretion]
\label{T-I-prop:fisher_accretion}
Let $\mathcal{I}_F(\theta;\, \rho(t))$ denote the Fisher
information contained in the system state $\rho(t)$ regarding
a parameter $\theta$ encoded in the environment at time $s < t$.
For an agent whose dynamics maximize the survival
functional~\eqref{T-I-eq:survival}, the time-averaged Fisher
information satisfies
\begin{equation}
\label{T-I-eq:fisher_accretion}
\overline{\frac{d}{dt}\,
\mathcal{I}_F(\theta;\, \rho(t))} \geq 0,
\end{equation}
where the overbar denotes a time average over scales larger
than the bath correlation time $\tau_B$.
\end{proposition}

\begin{proof}
By Theorem~\ref{T-I-thm:advantage}, the survival functional is
maximized when $I(S{:}E;\,0)$ is large and can be consumed
($\Delta I < 0$) during subsequent evolution.
Maintaining a large correlation budget $I(S{:}E)$ requires
the system state to retain correlations with environmental
degrees of freedom; this is precisely the content of
$\mathcal{I}_F(\theta;\, \rho(t)) > 0$.
An agent that discards useful correlations (decreasing
$\mathcal{I}_F$) without thermodynamic necessity depletes the
resource $I(S{:}E)$ and hence its survival functional.
Since the environment's correlations decay on a timescale
$\tau_B$, the agent must continuously build new correlations
to replace decaying ones.
The net effect is a time-averaged accretion of Fisher
information, whose gradient defines the dynamical arrow of time.
\end{proof}

\subsection{The Bridge to HAFF}

We now connect this dynamical picture to the algebraic picture of
HAFF Paper~F~\cite{Liu2026HAFF_F}, where the arrow of time was
defined by the expansion of the redundancy subalgebra
$\mathcal{R}$.

The connection requires care: quantum information cannot be
cloned (the no-cloning theorem), so the ``redundancy expansion''
of HAFF must be interpreted through the lens of
\emph{quantum Darwinism}~\cite{Zurek2009}.
In this framework, the environment acquires not copies of the
quantum state $\rho(s)$ itself, but rather \emph{coarse-grained
classical records} of pointer-state outcomes---precisely the
information that survives decoherence and can be redundantly
encoded in many environmental fragments.

\begin{proposition}[Dynamical--Algebraic Correspondence]
\label{T-I-prop:HAFF_bridge}
Let $\prec_K$ be the causal memory order
(Definition~\ref{T-I-def:memory_order}) and let
$\prec_{\mathrm{HAFF}}$ be the accessibility order of
HAFF Paper~F, defined by the inclusion of redundancy
subalgebras $\mathcal{R}$.
Under the additional assumption that the system--environment
interaction produces decoherence in a preferred pointer
basis~\cite{Zurek2009}, there exists a coarse-graining map
$\Phi: \rho(t) \mapsto \hat{p}(t)$ (projecting onto the
diagonal in the pointer basis) such that:
\begin{equation}
\label{T-I-eq:HAFF_bridge}
\rho(s) \prec_K \rho(t)
\quad\Longrightarrow\quad
\mathcal{R}(\Phi[\rho(s)])
\subseteq \mathcal{R}(\Phi[\rho(t)]).
\end{equation}
That is, the dynamical partial order maps into the algebraic
accessibility order when restricted to the classical sector
selected by decoherence.
\end{proposition}

\begin{proof}
The argument has three steps.

\noindent\textbf{Step 1 (Dynamical side):}
$\rho(s) \prec_K \rho(t)$ implies that the memory kernel
$\mathcal{K}$ transduces information about the state at $s$
into the dynamics at $t$, via system--environment correlations
built up over $[s,t]$.

\noindent\textbf{Step 2 (Quantum Darwinism):}
The system--environment interaction selects pointer states
$\{|i\rangle\}$ that are robust under
decoherence~\cite{Zurek2009}.
The diagonal populations
$p_i(t) = \langle i | \rho(t) | i \rangle$
constitute \emph{classical} information.
Quantum Darwinism~\cite{Zurek2009} establishes that this
classical information---and \emph{only} this information---is
redundantly imprinted in many environmental fragments $E_k$
through the decoherence interaction.
Each fragment that acquires a record of
$\hat{p}(t) = \{p_i(t)\}$ contributes to the growth of the
redundancy subalgebra $\mathcal{R}$.
Crucially, no quantum cloning is involved: the no-cloning
theorem forbids copying of arbitrary quantum states, but does
not constrain the classical pointer-state probabilities, which
are freely duplicable.
The expansion of $\mathcal{R}$ reflects the proliferation of
these classical records, not the copying of quantum coherences.

\noindent\textbf{Step 3 (Correspondence):}
The coarse-graining map $\Phi$ projects onto the
\emph{commuting} subalgebra generated by the pointer
observables $\{|i\rangle\langle i|\}$.
The resulting probability distributions $\hat{p}(t)$ are
classical and lie in a simplex.
If $\rho(s) \prec_K \rho(t)$, then the dynamics at $t$
retains information about the state at $s$
(Definition~\ref{T-I-def:memory_order}); in the pointer basis,
this means $\hat{p}(s)$ is statistically reconstructible
from the environmental records available at $t$.
Since each environmental fragment carrying a record of
$\hat{p}$ contributes to the HAFF redundancy subalgebra
$\mathcal{R}$, and the number of such fragments grows
monotonically with the accumulation of decoherence records,
the inclusion
$\mathcal{R}(\Phi[\rho(s)]) \subseteq
\mathcal{R}(\Phi[\rho(t)])$ follows.
\end{proof}

\begin{remark}[Scope of the Correspondence]
\label{T-I-rem:scope}
Proposition~\ref{T-I-prop:HAFF_bridge} is a \emph{consistency
result}, not a derivation of HAFF from T-DOME or vice versa.
It shows that the dynamical arrow (memory accumulation) and the
algebraic arrow (redundancy expansion) are compatible when
restricted to the decoherence-selected classical sector.
The quantum coherences---which are not redundantly
recorded---lie outside this correspondence and are handled by
the full non-Markovian dynamics.
\end{remark}

\begin{remark}[Dynamical and Algebraic Time]
\label{T-I-rem:dual_time}
The correspondence links two independently motivated notions of
temporal direction:
\begin{center}
\begin{tabular}{@{}lll@{}}
\toprule
& \textbf{Paper F (HAFF)} & \textbf{Paper I (T-DOME)} \\
\midrule
Nature & Algebraic & Dynamical \\
Mechanism & Redundancy expansion
  & Information backflow from memory \\
Formalism & Partial order on $\mathcal{A}_{\mathbf{c}}$
  & Partial order $\prec_K$ on $\rho_R(t)$ \\
Asymmetry source & Phase-space measure
  & Bath correlation structure \\
Domain & Classical (pointer) sector
  & Full quantum dynamics \\
\bottomrule
\end{tabular}
\end{center}
Paper~F provides the structural \emph{skeleton} of temporal
asymmetry; Paper~I provides the dynamical \emph{muscle}.
\end{remark}

\begin{remark}[The Seed and the Tree]
\label{T-I-rem:seed_tree}
The correspondence justifies the title of this paper.
In HAFF, the geometry of spacetime is the static ``tree.''
In T-DOME, the memory kernel is the ``seed'' containing the
generative algorithm for growth.
Time is not the space in which the tree grows;
time is the \emph{act of growing} itself.
\end{remark}

% ============================================================
\section{Worked Example: The Quantum Predictive Agent}
\label{T-I-sec:example}

To illustrate the Markovian ceiling and the memory advantage
\emph{quantitatively}, we employ the archetypal open quantum
system model: the spin-boson model with Lorentz--Drude spectral
density, which admits an exact analytic solution for the
decoherence dynamics~\cite{BreuerPetruccione2002}.

\subsection{Model Setup}

The total Hamiltonian is $H = H_S + H_B + H_I$.
The agent is a two-level system with energy gap $\omega_0$:
$H_S = \tfrac{\omega_0}{2}\sigma_z$.
The environment is a bosonic bath:
$H_B = \sum_k \omega_k b_k^\dagger b_k$.
The interaction is of the pure-dephasing form
$H_I = \sigma_z \otimes \sum_k (g_k\, b_k
+ g_k^*\, b_k^\dagger)$.

The spectral density
$J(\omega) = \sum_k |g_k|^2 \delta(\omega - \omega_k)$
characterizes the environment. We choose the Lorentz--Drude form:
\begin{equation}
\label{T-I-eq:lorentz_drude}
J(\omega) = \frac{2\lambda\, \gamma\, \omega}
  {\omega^2 + \gamma^2},
\end{equation}
where $\lambda$ is the reorganization energy and $\gamma$ is the
bath memory rate (inverse correlation time
$\tau_B = 1/\gamma$).
We place the system in the low-temperature regime
$\beta\omega_0 \gg 1$ (i.e., $k_BT \ll \omega_0$).
The bath correlation function in the $T \to 0$ limit is
$C(t) = \lambda\gamma\, e^{-\gamma|t|}$, so the parameter
$\gamma$ directly controls the bath memory depth.
For $\beta\omega_0 \geq 10$ the finite-temperature corrections
to all quantities below are of order
$O(e^{-\beta\omega_0}) \lesssim 5 \times 10^{-5}$ and
are neglected throughout.\footnote{All plots and numerical values
use the standard $T \to 0$ analytic expression for the
decoherence function~\eqref{T-I-eq:decoherence}
(see Breuer and Petruccione~\cite{BreuerPetruccione2002},
Sec.~12.3, for the Lorentz--Drude pure-dephasing solution),
which provides an accurate proxy in the low-temperature
regime;
$\beta$ is a well-defined bookkeeping parameter and
$\beta^{-1}$ a finite energy scale.}

\subsection{Exact Decoherence Function}

For the pure-dephasing spin-boson model in the
$T \to 0$ limit,
the off-diagonal element of the reduced density matrix
$\rho_{01}(t) = \rho_{01}(0)\, p(t)$ is governed by the
\textbf{decoherence function}~\cite{BreuerPetruccione2002}:
\begin{equation}
\label{T-I-eq:decoherence}
p(t) = e^{-\gamma t / 2}\left[
  \cos(\Omega t) + \frac{\gamma}{2\Omega}\,\sin(\Omega t)
\right],
\end{equation}
where $\Omega := \frac{1}{2}\sqrt{4\lambda\gamma - \gamma^2}$.
This solution is exact for the Lorentz--Drude spectral density.

\begin{remark}[Non-Markovian Regime]
\label{T-I-rem:NM_regime}
The character of the dynamics is controlled by the discriminant
$\Delta := 4\lambda\gamma - \gamma^2 = \gamma(4\lambda - \gamma)$:
\begin{itemize}
\item $\gamma > 4\lambda$ ($\Delta < 0$):
  $\Omega$ is imaginary, $p(t)$ decays monotonically.
  The dynamics is Markovian (no backflow).
\item $\gamma = 4\lambda$ ($\Delta = 0$):
  Critical damping. $p(t) = (1 + \gamma t/2)\, e^{-\gamma t/2}$.
\item $\gamma < 4\lambda$ ($\Delta > 0$):
  $\Omega$ is real and positive.
  $p(t)$ oscillates with envelope $e^{-\gamma t/2}$.
  The dynamics is \emph{non-Markovian}: intervals where
  $|p(t)|$ increases correspond to information
  backflow~\cite{BreuerLainePiilo2009}.
\end{itemize}
The non-Markovian regime $\gamma < 4\lambda$ is thus the regime
of structured, long-memory baths.
\end{remark}

\subsection{Quantitative Evaluation}

We now evaluate the survival functional explicitly.
For the pure-dephasing model, populations are conserved
($p_0(t) = p_0(0)$, $p_1(t) = p_1(0)$), and the non-equilibrium
free energy depends only on the coherence:
\begin{equation}
\label{T-I-eq:F_qubit}
F(\rho(t)) - F(\rho_{\mathrm{eq}})
= \beta^{-1}\, D_{\mathrm{KL}}(\rho(t) \| \rho_{\mathrm{eq}}).
\end{equation}
For a qubit with initial state
$\rho(0) = \tfrac{1}{2}(\mathbb{1} + \vec{r}\cdot\vec{\sigma})$
and $r_z = 0$ (maximal coherence in the $x$--$y$ plane),
the relative entropy reduces to
$D_{\mathrm{KL}}(\rho(t) \| \rho_{\mathrm{eq}})
\approx |p(t)|^2\, |\rho_{01}(0)|^2$
to leading order in the coherence (see,
e.g.,~\cite{BreuerPetruccione2002}).
Since there is no external driving ($H_{\mathrm{ctrl}} = 0$,
$W = 0$), the survival functional is simply
\begin{equation}
\label{T-I-eq:S_qubit}
\beta\,\mathcal{S}(t)
= D_{\mathrm{KL}}(\rho(t) \| \rho_{\mathrm{eq}})
  - D_{\mathrm{KL}}(\rho(0) \| \rho_{\mathrm{eq}})
\propto |p(t)|^2 - 1.
\end{equation}
The proportionality in~\eqref{T-I-eq:S_qubit} is specific to
the \textbf{pure-dephasing model} with the chosen maximally
coherent initial state ($r_z = 0$) and measurement in the
pointer basis ($\sigma_z$).
Under these conditions, the exact
solution~\cite{BreuerPetruccione2002} ensures that population
terms vanish from the free energy
($\Delta\langle H_S \rangle = 0$), leaving only the
coherence contribution:
$\beta\,\mathcal{S} = -\Delta S_S$ depends only on the
coherence trajectory $|p(t)|$.
The proxy $|p(t)|^2$ thus rigorously captures the sign and
monotone behaviour of $\beta\,\mathcal{S}$; the exact
numerical prefactor depends on the initial state and
on $\beta$, but the qualitative conclusion---$\mathcal{S} > 0$
during backflow intervals---is robust and does not depend on
the proxy normalization.

For a Markovian evolution, $|p(t)|$ decreases monotonically,
so $|p(t)|^2 - 1 \leq 0$ for all $t$: $\mathcal{S} \leq 0$
always (consistent with Theorem~\ref{T-I-thm:ceiling}).
For non-Markovian evolution with $\gamma < 4\lambda$, the
oscillations in $p(t)$ produce intervals where $|p(t)|$
\emph{increases after a previous decrease}, i.e., the system
\emph{re-coheres}.

\textbf{Concrete parameters.}
Set $\omega_0 = 1$ (energy units), $\lambda = 1$,
$\gamma = 0.5$ (deep non-Markovian regime: $\gamma / 4\lambda = 0.125 \ll 1$).
Then:
\begin{equation}
\Omega = \tfrac{1}{2}\sqrt{4 \cdot 1 \cdot 0.5 - 0.25}
= \tfrac{1}{2}\sqrt{1.75} \approx 0.661.
\end{equation}

The decoherence function~\eqref{T-I-eq:decoherence} first reaches
$p(t^*) = 0$ at $t^* \approx 2.00/\Omega \approx 3.03$
(in units of $\omega_0^{-1}$), where the system has fully
decohered.
Subsequently, the environment \emph{returns} coherence:
$|p(t)|$ increases, reaching a local maximum
$|p(t_1)| \approx 0.31$ at $t_1 \approx 4.75/\omega_0$.

Over the backflow interval $[t^*, t_1]$,
for the pure-dephasing qubit with the chosen initial state
($r_z = 0$, maximal coherence) and in the autonomous setting
($H_{\mathrm{ctrl}} = 0$, $W = 0$),
the survival proxy~\eqref{T-I-eq:S_qubit} gives
\begin{equation}
\label{T-I-eq:S_numeric}
\beta\,\mathcal{S}[t^*, t_1]
\propto |p(t_1)|^2 - |p(t^*)|^2
\approx 0.093 - 0 = 0.093 > 0.
\end{equation}
Equivalently,
$\mathcal{S} \approx 0.093\,\beta^{-1}$
in the bookkeeping units set by $\beta$.
The agent has gained a dimensionless survival advantage
$\beta\,\mathcal{S} \approx +0.093$
\emph{with zero work input}
(autonomous evolution, $H_{\mathrm{ctrl}} = 0$),
solely by exploiting the non-Markovian backflow.
Figure~\ref{T-I-fig:survival} illustrates the contrast between
Markovian and non-Markovian evolution.

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]{fig_survival.pdf}
\caption{%
Pure-dephasing spin-boson model
(Section~\ref{T-I-sec:example}) with Lorentz--Drude spectral
density~\eqref{T-I-eq:lorentz_drude}.
\textbf{Parameters:}
$\omega_0 = 1$ (energy unit),
$\lambda = 1$ (reorganization energy).
\textbf{Units:}
all times in $\omega_0^{-1}$;
energies in $\hbar\omega_0$.
\textbf{Regime:}
low temperature ($\beta\omega_0 \gg 1$);
the standard $T \to 0$ analytic
expression~\eqref{T-I-eq:decoherence}~\cite{BreuerPetruccione2002}
is used as an accurate proxy.
\textbf{(a)}~Decoherence amplitude $|p(t)|$
(eq.~\eqref{T-I-eq:decoherence}).
Blue: non-Markovian
($\gamma = 0.5$, $\gamma/4\lambda = 0.125$).
Orange: Markovian
($\gamma = 5.0$, $\gamma/4\lambda = 1.25$).
Dashed: exponential envelope $e^{-\gamma t/2}$.
Green bands indicate backflow
(Remark~\ref{T-I-rem:NM_regime}:
$d|p|/dt > 0$, $\Gamma(t) < 0$
per~\eqref{T-I-eq:Gamma_inst}).
\textbf{(b)}~Survival proxy
$|p(t)|^2 \propto \beta\,\mathcal{S}$
(eq.~\eqref{T-I-eq:S_qubit}).
At the first revival
($t_1 = \pi/\Omega \approx 4.75\,\omega_0^{-1}$),
the non-Markovian agent achieves
$\beta\,\mathcal{S}[t^*,t_1] \approx +0.093$
(eq.~\eqref{T-I-eq:S_numeric}), consistent with the
closed-form prediction~\eqref{T-I-eq:revival_exact},
funded by the consumption of pre-existing
correlations
(Proposition~\ref{T-I-prop:full_cycle}).
The Markovian agent decays monotonically:
$\mathcal{S} \leq 0$ always
(Theorem~\ref{T-I-thm:ceiling}).%
}
\label{T-I-fig:survival}
\end{figure}

\textbf{Consistency with
Theorem~\ref{T-I-thm:advantage} and
Proposition~\ref{T-I-prop:full_cycle}.}
Since this is autonomous evolution ($H_{\mathrm{ctrl}} = 0$),
identity~\eqref{T-I-eq:advantage_auto} applies exactly:
$\beta\,\mathcal{S} = -\Delta I(S{:}E)
- \Delta D_{\mathrm{KL}}(\rho_E \| \rho_E^{\mathrm{th}})$.
The example realizes the \emph{correlation battery}
of Remark~\ref{T-I-rem:battery}, with the charge--discharge
decomposition of
Proposition~\ref{T-I-prop:full_cycle}:
\begin{itemize}
\item \textbf{Charging} ($[0, t^*]$, eq.~\eqref{T-I-eq:charge}):
  the system decoheres, building correlations
  $I(S{:}E;\, t^*) > 0$ at the cost of
  $\mathcal{S} < 0$.
\item \textbf{Discharging} ($[t^*, t_1]$,
  eq.~\eqref{T-I-eq:discharge}):
  the correlations are consumed
  ($\Delta I < 0$ over this interval),
  returning $\beta\,\mathcal{S} \approx +0.093 > 0$.
\end{itemize}
The bound~\eqref{T-I-eq:S_upper} is satisfied:
$\beta\,\mathcal{S}[t^*, t_1] = 0.093
\leq I(S{:}E;\, t^*)$.
Full-cycle closure~\eqref{T-I-eq:full_cycle} is confirmed:
$\beta\,\mathcal{S}[0, t_1] < 0$.

\textbf{Instantaneous decoherence rate.}
The rate of coherence loss is
\begin{equation}
\label{T-I-eq:Gamma_inst}
\Gamma(t) := -\frac{d}{dt}\ln|p(t)|
= \frac{\gamma}{2}
  - \frac{\Omega\sin(\Omega t)
    + \tfrac{\gamma}{2}\cos(\Omega t)}
  {\cos(\Omega t)
    + \tfrac{\gamma}{2\Omega}\sin(\Omega t)}\,.
\end{equation}
In the Markovian limit $\gamma \gg 4\lambda$,
$\Gamma(t) \to \gamma/2 > 0$ for all $t$
(monotone decoherence).
In the non-Markovian regime $\gamma < 4\lambda$,
$\Gamma(t)$ oscillates and becomes \emph{negative}
during the backflow intervals where $|p(t)|$ increases.
These are precisely the intervals where
$\mathcal{S} > 0$.

\textbf{Closed-form revival amplitude.}
The decoherence function~\eqref{T-I-eq:decoherence} can be
written as $p(t) = R\, e^{-\gamma t/2}\cos(\Omega t - \phi)$,
where $R = \sqrt{1 + (\gamma/2\Omega)^2}$ and
$\phi = \arctan(\gamma/2\Omega)$, with $R\cos\phi = 1$.
The extrema of $|p(t)|$ occur at $t_n = n\pi/\Omega$
($n = 0, 1, 2, \ldots$), and the first revival peak
after the first zero is at $t_1 = \pi/\Omega$.
Its amplitude is \emph{exactly}
\begin{equation}
\label{T-I-eq:revival_exact}
|p(t_1)| = e^{-\gamma\pi/(2\Omega)},
\qquad
\beta\,\mathcal{S}[t^*, t_1]
\approx |p(t_1)|^2
= e^{-\gamma\pi/\Omega}.
\end{equation}
This is the paper's central computable prediction: the
survival gain at first backflow is determined by a single
dimensionless ratio $\gamma/\Omega$.

\begin{remark}[Parameter Survey]
\label{T-I-rem:parameter_survey}
Table~\ref{T-I-tab:survey} demonstrates the transition from
the Markovian regime ($\mathcal{S} \leq 0$) to the
non-Markovian regime ($\mathcal{S} > 0$) as the bath
memory rate $\gamma$ decreases below the critical value
$4\lambda$.
All entries use $\omega_0 = 1$, $\lambda = 1$,
$W = 0$ (autonomous evolution), with revival amplitudes
computed from~\eqref{T-I-eq:revival_exact}.
\begin{center}
\begin{tabular}{@{}cccccc@{}}
\toprule
$\gamma$ & $\gamma/4\lambda$ & Regime
& $|p(t_1)|$ & $\beta\,\mathcal{S}(t_1)$
& $\Gamma_{\min}$ \\
\midrule
$20.0$ & $5.0$ & Markov & --- & $\leq 0$ & $>0$ \\
$4.0$ & $1.0$ & Critical & --- & $\leq 0$ & $= 0$ \\
$2.0$ & $0.50$ & Non-Markov & $0.043$
  & $+0.002$ & $< 0$ \\
$1.0$ & $0.25$ & Non-Markov & $0.163$
  & $+0.027$ & $< 0$ \\
$0.5$ & $0.125$ & Deep NM & $0.305$
  & $+0.093$ & $< 0$ \\
$0.1$ & $0.025$ & Deep NM & $0.605$
  & $+0.37\phantom{0}$ & $< 0$ \\
\bottomrule
\end{tabular}
\end{center}
\captionsetup{hypcap=false}%
\captionof{table}{%
Survival functional at first backflow revival
as a function of the bath memory rate $\gamma$,
for the pure-dephasing spin-boson model
with Lorentz--Drude spectral density.
$|p(t_1)|$ is computed
from~\eqref{T-I-eq:revival_exact};
$\Gamma_{\min}$ is the sign of the minimum of the
instantaneous decoherence rate~\eqref{T-I-eq:Gamma_inst}.
The transition $\mathcal{S} \leq 0 \to \mathcal{S} > 0$
occurs precisely at the non-Markovian threshold
$\gamma = 4\lambda$.
For $\gamma = 0.1$ (deep non-Markovian),
the agent achieves $\beta\,\mathcal{S} \approx +0.37$
per backflow cycle in the autonomous setting
($H_{\mathrm{ctrl}} = 0$).%
}
\label{T-I-tab:survey}
\end{remark}

\begin{remark}[The Two Regimes: Summary]
\label{T-I-rem:two_regimes}
\begin{center}
\begin{tabular}{@{}lll@{}}
\toprule
& \textbf{Markovian ($\gamma = 20$)}
& \textbf{Non-Markovian ($\gamma = 0.5$)} \\
\midrule
$\gamma / 4\lambda$ & $5.0$ (overdamped)
  & $0.125$ (underdamped) \\
$\tau_B$ & $0.05\,\omega_0^{-1}$
  & $2.0\,\omega_0^{-1}$ \\
$p(t)$ & Monotone decay
  & Oscillatory with envelope \\
$|p(t_1)|$ at first revival & $0$ (no revival)
  & $\approx 0.31$ \\
$\beta\,\mathcal{S}$ at revival & $\leq 0$
  & $\approx +0.093$ \\
$\Gamma(t)$ & $> 0$ always
  & Oscillates, $< 0$ during backflow \\
Interpretation & Stone (sinks)
  & Surfer (rides backflow) \\
\bottomrule
\end{tabular}
\end{center}
The non-Markovian agent achieves
$\beta\,\mathcal{S} \approx +0.093$
per backflow cycle (autonomous, $H_{\mathrm{ctrl}} = 0$),
while the Markovian agent can only lose free energy.
As the coupling deepens ($\gamma/4\lambda \to 0$), the
revival amplitude grows and
$\mathcal{S}$ increases
(Table~\ref{T-I-tab:survey}), bounded above by
$\beta\,\mathcal{S} \leq I(S{:}E;\, t^*)$
(Corollary~\ref{T-I-cor:three_regimes}(iii)).
\end{remark}

% ============================================================
\section{The Cost of Memory}
\label{T-I-sec:cost}

We have shown that memory allows an agent to breach the
Markovian ceiling.
However, every advantage carries a thermodynamic shadow.
We now quantify the cost of memory and identify the survival
crisis that sets the stage for Paper~II\@.

\subsection{The Landauer Debt}

To exploit the memory kernel $\mathcal{K}(t,s)$, the physical
substrate of the agent must maintain correlations with its own
past.
This is equivalent to storing information.
By Landauer's principle, erasing or overwriting this information
dissipates heat; if the agent does not erase, it must pay an
entropic cost to store.

\begin{proposition}[Landauer Cost of Memory]
\label{T-I-prop:cost}
Let $\mathcal{I}_{\mathrm{stored}}(\tau_{\mathrm{mem}})$ be the
mutual information between the agent's state trajectory over
$[t - \tau_{\mathrm{mem}},\, t]$ and its current control
protocol $H_{\mathrm{ctrl}}(t)$.
The free-energy cost of maintaining this memory satisfies
\begin{equation}
\label{T-I-eq:landauer}
\Delta F_{\mathrm{mem}}
\geq k_B T \ln 2 \cdot
\mathcal{I}_{\mathrm{stored}}(\tau_{\mathrm{mem}}).
\end{equation}
\end{proposition}

\subsection{The Memory Catastrophe}

The crisis arises from the scaling of
$\mathcal{I}_{\mathrm{stored}}$ with time.
To quantify this, we borrow two quantities from computational
mechanics~\cite{CrutchfieldYoung1989,ShaliziCrutchfield2001}:

\begin{definition}[Entropy Rate and Predictive Information]
\label{T-I-def:entropy_rate}
Let $\{X_t\}$ be the stochastic process describing the
environment's influence on the agent (e.g., the sequence of
bath correlation values).
\begin{enumerate}
\item The \textbf{entropy rate} of the environment is
  \begin{equation}
  \label{T-I-eq:entropy_rate}
  h_\mu := \lim_{n \to \infty}
  H(X_n \mid X_{n-1}, \ldots, X_1),
  \end{equation}
  measuring the intrinsic unpredictability per time step.
\item The \textbf{predictive information} (excess entropy) is
  \begin{equation}
  \label{T-I-eq:pred_info}
  I_{\mathrm{pred}} := I(\overleftarrow{X};\,
  \overrightarrow{X})
  = \sum_{k=1}^{\infty}
  \bigl[H(X_k) - h_\mu\bigr],
  \end{equation}
  where $\overleftarrow{X}$ and $\overrightarrow{X}$ denote
  the past and future half-chains.
  This is the total amount of information about the future
  that is encoded in the past---the \emph{useful} memory.
\end{enumerate}
\end{definition}

For an environment with finite predictive information
($I_{\mathrm{pred}} < \infty$), an optimal agent needs only
finite memory to capture all exploitable correlations.
However, for environments with \emph{divergent} predictive
information (e.g., processes with long-range temporal
correlations, $1/f$ noise, or non-stationary statistics),
the required memory grows without bound.

\begin{proposition}[The Memory Catastrophe]
\label{T-I-thm:catastrophe}
\textbf{Assumptions.}
Let the environment be a \emph{stationary, mixing} stochastic
process with positive entropy rate $h_\mu > 0$
\cite{CrutchfieldYoung1989,ShaliziCrutchfield2001}.
Consider an agent that maintains a memory kernel
$\mathcal{K}(t,s)$ with support on $[t - \tau_{\mathrm{mem}},\, t]$.
Let $\dot{W}_{\mathrm{budget}}$ be the agent's available
free-energy flux (constant).
\begin{enumerate}
\item The minimum memory required to exploit correlations up
  to depth $\tau_{\mathrm{mem}}$ satisfies
  \begin{equation}
  \label{T-I-eq:mem_lower_bound}
  \mathcal{I}_{\mathrm{stored}}(\tau_{\mathrm{mem}})
  \geq \min\!\big(I_{\mathrm{pred}},\;
  h_\mu\, \tau_{\mathrm{mem}}\big).
  \end{equation}
\item The Landauer cost of maintaining this memory is
  \begin{equation}
  \label{T-I-eq:mem_cost_rate}
  \dot{W}_{\mathrm{mem}} \geq
  k_B T \ln 2 \cdot h_\mu,
  \end{equation}
  since the agent must erase (or overwrite) at least $h_\mu$
  bits per unit time to prevent memory overflow.
\item There exists a critical time
  $t_{\mathrm{crit}}$ beyond which the memory maintenance cost
  exceeds the survival gain:
  \begin{equation}
  \label{T-I-eq:catastrophe}
  t > t_{\mathrm{crit}}
  \quad\Longrightarrow\quad
  \dot{W}_{\mathrm{mem}}(t) > \dot{W}_{\mathrm{budget}},
  \end{equation}
  unless the agent compresses its memory.
\end{enumerate}
The agent dies not from entropy (disorder) but from
\emph{hypermnesia}: the thermodynamic cost of perfect memory
exceeds the benefit it provides.
\end{proposition}

\begin{proof}
Part~(1): an agent exploiting temporal correlations to depth
$\tau_{\mathrm{mem}}$ must store at least the mutual information
between the past $\tau_{\mathrm{mem}}$ time steps and the
present.
For a stationary ergodic process, this mutual information is
bounded below by $\min(I_{\mathrm{pred}},\,
h_\mu\, \tau_{\mathrm{mem}})$~\cite{CrutchfieldYoung1989,
BialekNemenmanTishby2001}.

Part~(2): each time step, the agent receives $\sim h_\mu$
bits of genuinely new information.
To maintain a fixed-capacity memory, it must erase at least
this many bits, incurring Landauer cost
$k_B T \ln 2 \cdot h_\mu$ per time step.

Part~(3): if $I_{\mathrm{pred}} = \infty$ (as for environments
with long-range correlations), the stored information grows
as $\mathcal{I}_{\mathrm{stored}} \sim h_\mu\,
\tau_{\mathrm{mem}}$.
Combined with part~(2), the memory cost grows linearly in the
effective memory depth.
For any finite budget $\dot{W}_{\mathrm{budget}}$, there exists
$t_{\mathrm{crit}}$ such that the cost exceeds the budget.
\end{proof}

\subsection{Resolution: The Necessity of Forgetting}

To survive beyond $t_{\mathrm{crit}}$, the agent must introduce
a \emph{lossy compression} scheme: it must discard the vast
majority of stored correlations and retain only the
thermodynamically salient features.

\begin{itemize}
\item \textbf{Compression requires a criterion.}
  To decide what to keep and what to erase, the agent needs a
  \emph{relevance function}---a mapping from stored correlations
  to survival value.
  This is a reference frame that ranks information by its
  contribution to $\mathcal{S}$.

\item \textbf{A reference frame requires symmetry breaking.}
  An ``unbiased'' agent that treats all correlations as equally
  valuable cannot compress: it must keep everything.
  The act of preferring one subset of information over another
  is a spontaneous breaking of the informational symmetry.
  This is the thermodynamic definition of a ``perspective''---or,
  more precisely, a \emph{privileged basis}.
\end{itemize}

\begin{remark}[The Origin of Paper II]
\label{T-I-rem:paper_II}
\emergencystretch=1em
Proposition~\ref{T-I-thm:catastrophe} reveals the \emph{poison} embedded
in Paper~I's medicine.
Memory enables survival beyond the Markovian ceiling, but
unbounded memory under finite energy resources leads to
\emph{computational explosion}: the agent must process an
ever-growing archive with bounded free energy.

This is the precise thermodynamic origin of the crisis
addressed in Paper~II\@.
The resolution---spontaneous symmetry breaking of the
agent's reference frame---is not an additional hypothesis
but a \emph{thermodynamic necessity}: the agent must
compress its infinite history into a finite, biased
representation.
The ``self'' (a privileged computational basis) emerges as
the minimal structure that makes memory computationally
tractable.

In the structural parallel noted in HAFF
Essay~C~\cite{Liu2026HAFF_C}: the accumulation mechanism of
Paper~I provides the raw material for survival, but without the
discriminative compression of Paper~II, the system collapses
under the weight of its own stored correlations.
\end{remark}

% ============================================================
\section{Numerical Demonstration}
\label{T-I-sec:numerical}

The preceding sections establish analytic bounds and a
worked example in the spin-boson model.  We now provide a numerical illustration showing that the
Markovian ceiling signature predicted by
Theorem~\ref{T-I-thm:ceiling} and the memory advantage of
Theorem~\ref{T-I-thm:advantage} are reproduced in a minimal
partially observed environment.
Full code and parameters are provided for reproducibility.

% ------------------------------------------------------------
\subsection{Model}
\label{T-I-subsec:demo_model}

\paragraph{Environment.}
A two-hidden-state HMM with aliased observations.
The hidden state $s_t \in \{0,1\}$ evolves as a persistent
Markov chain with $\Pr(s_{t+1} = s_t) = 1 - \varepsilon$;
the parameter $\varepsilon \in [10^{-3}, 10^{-1}]$ controls
the correlation length $\ell \sim 1/\varepsilon$.
Observations $o_t \in \{A, B\}$ are aliased:
$\Pr(o_t = A \mid s_t = 0) = 0.5 + \delta$,
$\Pr(o_t = A \mid s_t = 1) = 0.5 - \delta$,
with $\delta = 0.05$ (mutual information
$I(O; S) \approx 0.007$~bits).
Reward: $r_t = 1$ if $a_t = s_t$, $0$ otherwise.

\paragraph{Agents.}
All agents use the true model parameters and compute
exact Bayesian posteriors; the only difference is how many
observations each agent retains.
\begin{itemize}
\item \textbf{Markov-$k$} ($k \in \{1,2,4,8\}$): runs
  an exact Bayes filter over the most recent $k$
  observations (sliding window, uniform prior at each
  window start); acts by MAP.
\item \textbf{Memory (Bayes filter)}: maintains the full
  belief state $b_t = \Pr(s_t = 1 \mid o_{1:t})$ via the
  exact predict--update cycle over all past observations;
  acts by MAP.
\end{itemize}

\paragraph{Parameters.}
\begin{center}
\small
\begin{tabular}{@{}lcl@{}}
\toprule
\textbf{Quantity} & \textbf{Value} & \textbf{Role} \\
\midrule
$T$ & $100{,}000$ & horizon per trial \\
Seeds & 10 & independent replications \\
$\delta$ & 0.05 & observation asymmetry \\
$k$ & $\{1, 2, 4, 8\}$ & Markov window sizes \\
$\varepsilon$ & logspace($10^{-3}$, $10^{-1}$, 15)
  & transition noise grid \\
Burn-in & $5{,}000$ & discarded steps \\
\bottomrule
\end{tabular}
\end{center}

% ------------------------------------------------------------
\subsection{Results}
\label{T-I-subsec:demo_results}

Figure~\ref{T-I-fig:markov_ceiling} shows the two key signatures.

\paragraph{Result 1: Markov ceiling
(Figure~\ref{T-I-fig:markov_ceiling}a).}
The average reward $\bar{R}$ of the Bayes filter (memory
agent) increases monotonically with correlation length
$\ell = 1/\varepsilon$, while each Markov-$k$ agent
saturates at a distinct ceiling.  The ceilings are
ordered: $k = 1$ (lowest) through $k = 8$ (highest),
and all fall below the memory agent for
$\ell \gtrsim 20$.  This is consistent with the qualitative prediction of
Theorem~\ref{T-I-thm:ceiling}: finite-order Markov
representations have a performance upper bound that
the memory-carrying agent surpasses.

\paragraph{Result 2: Memory advantage
(Figure~\ref{T-I-fig:markov_ceiling}b).}
The gap $\Delta\bar{R} = \bar{R}_{\mathrm{mem}}
- \bar{R}_{\mathrm{Markov}\text{-}k}$ increases
monotonically with $\ell$, and is larger for smaller $k$.
Shaded bands show 95\% confidence intervals across
10 seeds.  The Markov-1 and Markov-2 curves nearly
overlap at small $\ell$, reflecting the fact that
short observation windows provide negligible additional
information in this aliasing regime---a consistency
check, not a deficiency.

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]%
  {fig_paper1_markov_ceiling.pdf}
\caption{%
\textbf{Markov ceiling and memory advantage.}
$T = 100{,}000$, 10 seeds, 95\% CI bands.
\textbf{(a)}~Average reward $\bar{R}$ vs correlation
length $\ell = 1/\varepsilon$.  The Bayes filter
(blue, bold) rises monotonically; Markov-$k$ agents
saturate at $k$-dependent ceilings.
\textbf{(b)}~Performance gap
$\Delta\bar{R} = \bar{R}_{\mathrm{mem}}
- \bar{R}_{\mathrm{Markov}\text{-}k}$
increases with $\ell$; smaller $k$ yields a larger gap.}
\label{T-I-fig:markov_ceiling}
\end{figure}

% ------------------------------------------------------------
\subsection{Scope of This Demonstration}
\label{T-I-subsec:demo_scope}

These simulations illustrate the ceiling phenomenon
predicted by Theorem~\ref{T-I-thm:ceiling} under the stated
model class; they do not constitute a proof beyond this
class.

\medskip
This demonstration \textbf{does} show:
\begin{enumerate}
\item A reproducible regime in which finite-order Markov
  agents exhibit a performance ceiling while a
  memory-carrying (Bayes filter) agent improves---the
  Markov ceiling signature predicted by
  Theorem~\ref{T-I-thm:ceiling}.
\item The memory advantage (Theorem~\ref{T-I-thm:advantage})
  manifests as a monotonically growing gap that widens
  with correlation length and tightens with window size.
\end{enumerate}

\noindent
This demonstration does \textbf{not} show:
\begin{enumerate}
\item Universality across environments, observation models,
  or agent architectures.  The model uses a two-state
  HMM with binary aliased observations.
\item Tight constants or the functional form of the
  ceiling boundary $\ell_c(k)$.
\item That the Bayes filter is optimal among all possible
  memory-carrying agents.
\end{enumerate}

\paragraph{Reproducibility.}
The complete simulation is a self-contained Python script
(\texttt{paper1\_markov\_ceiling\_demo.py}, ${\sim}\,560$
lines, requiring only NumPy and Matplotlib) with fixed
random seeds.  All figures in this section can be
reproduced by executing the script.  The following files
are included in the supplementary archive:
\begin{itemize}
\item \texttt{paper1\_markov\_ceiling\_demo.py} --- simulation script
\item \texttt{fig\_paper1\_markov\_ceiling.pdf} --- Figure~\ref{T-I-fig:markov_ceiling}
\item \texttt{markov\_ceiling\_data.csv} --- raw sweep data
\item \texttt{markov\_ceiling\_boundary.csv} --- extracted
  ceiling boundaries $\ell_c(k)$
\end{itemize}

% ============================================================
\section{Discussion}
\label{T-I-sec:discussion}

\subsection{Summary of Results}

\begin{center}
\small
\setlength{\tabcolsep}{4pt}%
\begin{tabular}{@{}lp{7.5cm}c@{}}
\toprule
\textbf{Result} & \textbf{Statement} & \textbf{Sec.} \\
\midrule
Markovian Ceiling &
  $\mathcal{S} \leq 0$ for open-loop GKSL (no feedback)
  & \ref{T-I-sec:ceiling} \\[3pt]
Memory Advantage &
  $\beta\mathcal{S} = -\Delta I
  - \Delta D_{\mathrm{KL}}
  - \beta\Delta\langle H_{\mathrm{ctrl}}\rangle$;\;
  $\mathcal{S} > 0$ when correlations consumed
  (any initial state)
  & \ref{T-I-sec:advantage} \\[3pt]
Quantitative demo &
  Spin-boson: $\beta\mathcal{S} \approx +0.093 > 0$
  at first backflow revival (Fig.~\ref{T-I-fig:survival},
  Table~\ref{T-I-tab:survey})
  & \ref{T-I-sec:example} \\[3pt]
Temporal Arrow &
  $\prec_K \to \prec_{\mathrm{HAFF}}$ via quantum
  Darwinism
  & \ref{T-I-sec:arrow} \\[3pt]
Memory Catastrophe &
  $\dot{W}_{\mathrm{mem}} \geq k_BT\ln 2 \cdot h_\mu$;\;
  exceeds budget at $t_{\mathrm{crit}}$
  & \ref{T-I-sec:cost} \\[3pt]
Numerical demo &
  Markov ceiling reproduced in HMM
  (Fig.~\ref{T-I-fig:markov_ceiling})
  & \ref{T-I-sec:numerical} \\
\bottomrule
\end{tabular}
\end{center}

\subsection{What This Paper Does and Does Not Show}

\textbf{This paper shows:}
\begin{enumerate}
\item Under open-loop GKSL dynamics (no measurement or feedback),
  the survival functional $\mathcal{S} \leq 0$
  (Theorem~\ref{T-I-thm:ceiling}).
\item For any initial state (product or correlated), the
  survival functional satisfies the exact identity
  $\beta\,\mathcal{S} = -\Delta I(S{:}E)
  - \Delta D_{\mathrm{KL}}(\rho_E \| \rho_E^{\mathrm{th}})
  - \beta\,\Delta\langle H_{\mathrm{ctrl}}\rangle$
  (Theorem~\ref{T-I-thm:advantage}).
  Under autonomous evolution, when pre-existing
  system--environment correlations are consumed
  ($\Delta I < 0$), $\mathcal{S} > 0$ is achievable,
  bounded by the initial correlation budget
  (Corollary~\ref{T-I-cor:three_regimes}).
\item A quantitative spin-boson example illustrates:
  $\beta\,\mathcal{S} \approx +0.093 > 0$ at the first
  non-Markovian revival (Section~\ref{T-I-sec:example}).
\item The causal memory order $\prec_K$ is consistent with the
  HAFF accessibility order when restricted to the classical
  (pointer-state) sector
  (Proposition~\ref{T-I-prop:HAFF_bridge}).
\item The thermodynamic cost of memory, quantified by the
  environment's entropy rate $h_\mu$, creates a survival
  crisis for agents with finite energy budgets
  (Proposition~\ref{T-I-thm:catastrophe}).
\item A minimal computational demonstration reproduces the
  Markov ceiling and memory advantage signatures in a
  two-state HMM with aliased observations
  (Section~\ref{T-I-sec:numerical},
  Figure~\ref{T-I-fig:markov_ceiling}).
\end{enumerate}

\textbf{This paper does not show:}
\begin{enumerate}
\item That non-Markovian dynamics is \emph{sufficient} for
  persistence (it is necessary but not sufficient;
  Paper~II addresses the additional requirements).
\item That \emph{all} non-Markovian systems outperform all
  Markovian systems (the comparison is between suprema under
  specified constraints).
\item That Markovian agents with explicit measurement-feedback
  are bounded by the ceiling (the Sagawa--Ueda framework shows
  they are not; Remark~\ref{T-I-rem:open_loop}).
\item That the specific form of the optimal memory kernel can be
  derived from first principles without specifying the
  environment.
\item That memory implies or requires consciousness.
\end{enumerate}

% ============================================================
% REFERENCES
% ============================================================

% ============================================================================
% PAPER II
% ============================================================================
\chapter{Spontaneous Symmetry Breaking of Reference Frames as a Computational Cost Minimization Strategy}
\label{T-chap:paperII}

\begin{center}
\textit{Paper II --- ``The Ego''}\\[0.5em]
Originally published: Zenodo, DOI: 10.5281/zenodo.18579703
\end{center}

\bigskip

\section*{Abstract}
We investigate the computational constraints on persistent
open quantum systems that carry non-Markovian memory
(Paper~I~\cite{Liu2026TDOME_I}).
Paper~I established that memory is a thermodynamic necessity
for survival beyond the Markovian ceiling, but revealed a
secondary crisis: the \emph{Memory Catastrophe}, in which
the Landauer cost of maintaining unbounded history exceeds
any finite free-energy budget.

We prove a \textbf{Computational Ceiling}: any agent that
processes its memory \emph{symmetrically}---treating all
components of its internal Clifford algebra $Cl(V,q)$ as
equally relevant---reaches computational paralysis at a
finite critical time $t_{\mathrm{par}}$.

We then show that the resolution requires
\textbf{spontaneous symmetry breaking} of the agent's
internal reference frame: the selection of a privileged basis
(a gauge fixing of the automorphism group
$G = \mathrm{Aut}(Cl(V,q))$) that compresses the memory
kernel into a tractable, low-dimensional representation.
The optimal compression is governed by a survival-weighted
rate-distortion bound; under generic conditions, the agent
retains $k^{*} = \mathcal{C}_{\mathrm{budget}}/h_\mu$
components and discards the rest.

This establishes \textbf{reference-frame selection as the
survival-optimal strategy under bounded rationality}:
the ``self'' (a privileged computational basis) is not an
additional hypothesis but the minimal structure that makes
memory computationally tractable.

The broken phase introduces four systematic bias terms---basis
selection, frame drag, objective centering, and model
incompleteness---that are generic consequences
of gauge fixing under assumptions~(B1)--(B5).
We show that under environmental drift, a fixed reference
frame leads to the \textbf{Delusion Trap}: an exponential
divergence of prediction error that the agent cannot detect
from within its own frame, establishing the crisis that
Paper~III must resolve.


% ============================================================
\section{Introduction}
\label{T-II-sec:intro}

% ------------------------------------------------------------
\subsection{Context: The Problem of Overload}
\label{T-II-subsec:overload}

Paper~I of this series~\cite{Liu2026TDOME_I} established that
non-Markovian memory is a thermodynamic necessity for
persistent far-from-equilibrium systems: under open-loop
Markovian (GKSL) dynamics, the survival functional satisfies
$\mathcal{S} \leq 0$ (the Markovian Ceiling), while agents
carrying memory kernels can achieve $\mathcal{S} > 0$ by
consuming stored system--environment correlations.

This result, however, carries a price.
The \emph{Memory Catastrophe} (Paper~I, Proposition~10)
shows that the Landauer cost of maintaining a memory archive
of depth $\tau_{\mathrm{mem}}$ grows at a rate
\begin{equation}
\label{T-II-eq:mem_cost_recall}
\dot{W}_{\mathrm{mem}}
\geq k_B T \ln 2 \cdot h_\mu,
\end{equation}
where $h_\mu$ is the entropy rate of the environmental
process~\cite{CrutchfieldYoung1989,ShaliziCrutchfield2001}.
For any finite free-energy budget $\dot{W}_{\mathrm{budget}}$,
there exists a critical time $t_{\mathrm{crit}}$ beyond which
$\dot{W}_{\mathrm{mem}} > \dot{W}_{\mathrm{budget}}$:
the agent's memory consumes more resources than are available.

But thermodynamic cost is only half the crisis.
Even if unlimited free energy were available for memory
maintenance, the agent must still \emph{process} the stored
correlations---evaluate the survival functional as a function
of its ever-growing archive---using finite computational
resources. This is the problem that the present paper
addresses.

% ------------------------------------------------------------
\subsection{Position within the Series}
\label{T-II-subsec:series_position}

This paper is the second of three constituting the
\textbf{T-DOME} (Thermodynamic Dynamics of Observer-Memory
Entanglement) framework, the third pillar of a three-paper
program.

\begin{center}
\small
\setlength{\tabcolsep}{4pt}%
\begin{tabular}{@{}lp{3.2cm}cp{3.4cm}c@{}}
\toprule
\textbf{Framework} & \textbf{Question} & & \textbf{Result}
  & \textbf{Status} \\
\midrule
HAFF~\cite{Liu2026HAFF_A,Liu2026HAFF_B}
  & How does geometry emerge?
  & Ocean
  & Algebra $\to$ Geometry
  & Complete \\[3pt]
Q-RAIF~\cite{Liu2026QRAIF_A,Liu2026QRAIF_B}
  & What algebra must an observer have?
  & Fish
  & $Cl(V,q) \hookrightarrow Cl(1,3)$
  & Complete \\[3pt]
T-DOME~I~\cite{Liu2026TDOME_I}
  & Why must agents carry memory?
  & Seed
  & Markovian ceiling; memory as necessity
  & Complete \\[3pt]
\textbf{T-DOME~II} (this work)
  & Why must agents break symmetry?
  & Ego
  & Reference-frame selection under bounded computation
  & \textbf{This paper} \\[3pt]
T-DOME~III
  & How does self-calibration arise?
  & Loop
  & Fisher self-referential bound
  & Planned \\
\bottomrule
\end{tabular}
\end{center}

The three T-DOME papers form an irreversible logical chain.
Each resolves a survival crisis created by its predecessor:
\begin{enumerate}
\item \textbf{Paper~I (The Seed):} Without memory, a system
  is trapped in the \emph{Markovian present}---no accumulation,
  no temporal arrow, inevitable thermal death.
  Memory breaks this trap but floods the system with unbounded
  historical data.
\item \textbf{Paper~II (The Ego, this work):} Unbounded memory
  under finite computational resources causes processing
  collapse. Spontaneous symmetry breaking of the reference
  frame (establishing a ``self'') resolves the overload but
  introduces systematic bias.
\item \textbf{Paper~III (The Loop):} Uncorrected bias diverges
  from a changing environment. A self-referential calibration
  loop (monitoring one's own prediction error) resolves the
  bias but requires the system to ``observe its own
  observation''---closing the self-calibration loop.
\end{enumerate}

% ------------------------------------------------------------
\subsection{Relation to Q-RAIF}
\label{T-II-subsec:qraif}

Q-RAIF Paper~B~\cite{Liu2026QRAIF_B} established that any
persistent open quantum subsystem maintaining a
non-equilibrium steady state (NESS) requires an internal
control algebra isomorphic to a Clifford algebra $Cl(V,q)$.
Paper~C~\cite{Liu2026QRAIF_C} showed that this algebra must
embed in the environmental observable algebra via a
realizability homomorphism
$\phi: Cl(V,q) \hookrightarrow Cl(1,3)$.

The Clifford algebra $Cl(V,q)$, however, admits a non-trivial
\emph{automorphism group} $G = \mathrm{Aut}(Cl(V,q))$.
In the absence of external constraints, all elements of $G$
yield physically equivalent representations---the choice of
basis within the algebra is a \emph{gauge freedom}.
This gauge freedom is the mathematical substrate of the
symmetry that the present paper breaks.

The ``ego'' is not a new algebraic structure imposed from
outside the Q-RAIF framework; it is a \emph{gauge fixing}
of the already-present internal symmetry, driven by
computational optimality under bounded resources.

% ------------------------------------------------------------
\subsection{Relation to HAFF Paper~G}
\label{T-II-subsec:haff_g}

HAFF Paper~G established \emph{architectural
incompleteness}: the observable-algebra framework cannot
self-ground~\cite{Liu2026HAFF_G}.
The present paper provides a partial operational resolution:
under bounded computation, an agent satisfying~(B1)--(B5)
is driven to choose a computational basis (break symmetry)
precisely \emph{because} the framework is incomplete.
The ego is an operational response to incompleteness, not a
metaphysical addition.

% ------------------------------------------------------------
\subsection{Scope and Disclaimers}
\label{T-II-subsec:scope}

To prevent interpretational overreach, we state at the
outset what this paper does \emph{not} claim:
\begin{enumerate}
\item We do not claim that symmetry breaking is
  \emph{sufficient} for persistence.
  Paper~III addresses the additional requirements.
\item We do not claim that the specific form of the
  privileged basis is unique---only that \emph{some} basis
  selection is necessary under bounded computation.
\item The term ``ego'' or ``self'' is used in the
  control-theoretic sense: a fixed reference frame within
  the agent's internal algebra. It carries no implication
  of consciousness or subjective experience.
\item A broader structural analogy with classical philosophical
  concepts of selfhood exists but is outside the scope of
  this paper.
\end{enumerate}

\paragraph{Related work.}
The idea that bounded agents must compress their
representations has roots in Simon's bounded
rationality~\cite{Simon1955}, Shannon's
rate-distortion theory~\cite{Shannon1959,CoverThomas2006},
and Sims's rational inattention~\cite{Sims2003}, which
models finite-capacity decision-makers as solving a
rate-distortion problem---precisely the economic
counterpart of our $\mathcal{C}_{\mathrm{budget}}$
formalism.
The information bottleneck~\cite{Tishby2000}
formalises relevance-weighted compression and has been
applied to neural coding and deep
learning.
The role of decoherence in selecting preferred bases
(pointer states) is well established via quantum
Darwinism~\cite{Zurek2009}; our contribution is to
show that the same selection arises as a \emph{computational}
necessity, independent of the decoherence mechanism.
Measures of non-Markovianity and their thermodynamic
consequences are reviewed
in~\cite{RivasHuelgaPlenio2014,BreuerPetruccione2002};
the connection to survival was established in Paper~I.

\paragraph{Summary of contributions.}
This paper establishes three main results:
\begin{enumerate}
\item \textbf{Computational Ceiling scaling law}
  (Theorem~\ref{T-II-thm:comp_ceiling}): symmetric processing
  of a $Cl(V,q)$ memory kernel requires rate
  $\mathcal{R} \geq h_\mu \cdot D$, leading to paralysis
  at a finite $\tau_{\mathrm{par}}$.
\item \textbf{Survival-weighted rate-distortion bound}
  (Theorem~\ref{T-II-thm:compression}): the optimal gauge-fixed
  representation retains
  $k^* = \lfloor\mathcal{C}_{\mathrm{budget}}/h_\mu\rfloor$
  components.
\item \textbf{Delusion dynamics}
  (Theorem~\ref{T-II-thm:delusion}): a fixed reference frame
  decouples from a drifting environment on the logarithmic
  timescale $t_{\mathrm{del}}
  = \Lambda^{-1}\ln(\pi/4\theta_0)$.
\end{enumerate}

% ============================================================
\section{Mathematical Preliminaries}
\label{T-II-sec:prelim}

% ------------------------------------------------------------
\subsection{Inherited Framework from Paper~I}
\label{T-II-subsec:inherited}

We briefly recall the key objects from
Paper~I~\cite{Liu2026TDOME_I} that the present work builds
upon.  The reader is referred to Paper~I for full definitions
and proofs.

\paragraph{Survival functional.}
For an open quantum system $S$ coupled to an environment $E$
at inverse temperature $\beta$, with dynamics $\Lambda$ and
external control protocol $H_{\mathrm{ctrl}}(t)$, the
survival functional is
\begin{equation}
\label{T-II-eq:survival_recall}
\mathcal{S}[\Lambda, \tau]
:= \Delta F - W[0,\tau],
\end{equation}
where $\Delta F = F(\rho(\tau)) - F(\rho(0))$ is the change
in non-equilibrium free energy and
$W = \int_0^\tau \tr(\rho(t)\,\dot{H}_{\mathrm{ctrl}}(t))\,dt$
is the work performed by the external protocol.

\paragraph{Markovian Ceiling.}
Under open-loop GKSL dynamics with no feedback
(control class $\mathcal{C}_{\mathrm{M}}$, Paper~I,
Definition~6):
\begin{equation}
\label{T-II-eq:ceiling_recall}
\mathcal{S}[\Lambda^{\mathrm{M}}, \tau] \leq 0
\qquad\text{for all } \tau \geq 0.
\end{equation}

\paragraph{Non-Markovian advantage identity.}
For arbitrary initial states:
\begin{equation}
\label{T-II-eq:advantage_recall}
\beta\,\mathcal{S}
= -\Delta I(S{:}E)
  - \Delta D_{\mathrm{KL}}(\rho_E \| \rho_E^{\mathrm{th}})
  - \beta\,\Delta\langle H_{\mathrm{ctrl}} \rangle.
\end{equation}

\paragraph{Memory Catastrophe.}
The Landauer cost of maintaining a memory archive of depth
$\tau_{\mathrm{mem}}$ satisfies
$\dot{W}_{\mathrm{mem}} \geq k_BT\ln 2 \cdot h_\mu$
(Paper~I, Proposition~10),
where $h_\mu$ is the \emph{per-component} entropy rate of the
environmental process~\cite{CrutchfieldYoung1989}, defined by
\begin{equation}
\label{T-II-eq:entropy_rate}
h_\mu
:= \lim_{T\to\infty}\frac{1}{T}\,H(X_{0:T}),
\end{equation}
measuring the asymptotic information (in bits per unit time)
generated by a single algebraic component of the memory
kernel (we work in units where the sampling interval equals
the environmental correlation time
$\tau_E$)\footnote{For a continuous-valued process sampled at
resolution $b$ bits, $h_\mu$ includes the quantisation cost:
$h_\mu = h_\mu^{(\mathrm{diff})} + b\,f_s$, where
$h_\mu^{(\mathrm{diff})}$ is the differential entropy rate
and $f_s$ the sampling frequency.  All budget inequalities in
this paper hold with $h_\mu$ so defined.}---and the stored
mutual
information grows as
$\mathfrak{i}_{\mathrm{stored}}(\tau_{\mathrm{mem}})
\geq \min(I_{\mathrm{pred}},\; h_\mu \,\tau_{\mathrm{mem}})$,
with $I_{\mathrm{pred}}$ the \emph{predictive information}
(excess entropy)~\cite{BialekNemenmanTishby2001,ShaliziCrutchfield2001},
defined as the mutual information between past and future
of the environmental process:
\begin{equation}
\label{T-II-eq:I_pred}
I_{\mathrm{pred}}
:= I\!\left(\overleftarrow{X};\, \overrightarrow{X}\right)
= H(\overrightarrow{X})
  - H(\overrightarrow{X} \mid \overleftarrow{X}),
\end{equation}
where $\overleftarrow{X}$ and $\overrightarrow{X}$ denote
the semi-infinite past and future, respectively.
For a stationary process,
$I_{\mathrm{pred}}$ relates to $h_\mu$ via the entropy-rate
decomposition
$H(X_{1:T}) = I_{\mathrm{pred}} + h_\mu\,T + o(1)$
as $T \to \infty$~\cite{CrutchfieldYoung1989}.

% ------------------------------------------------------------
\subsection{The Agent's Internal Algebra}
\label{T-II-subsec:algebra}

Following Q-RAIF~\cite{Liu2026QRAIF_B,Liu2026QRAIF_C},
the agent's internal control algebra is a Clifford algebra
$\mathcal{O}_{\mathrm{int}} = Cl(V,q)$
for a real vector space $V$ equipped with a non-degenerate
quadratic form $q$.
The algebra satisfies the fundamental relation
$v^2 = q(v)\,\mathbf{1}$ for all $v \in V$.

The \emph{automorphism group}
\begin{equation}
\label{T-II-eq:gauge_group}
G := \mathrm{Aut}(Cl(V,q))
\end{equation}
is the group of algebra automorphisms that preserve the
grading and quadratic form.\footnote{\label{T-II-fn:gauge_group}%
We use $G$ as an effective symmetry group acting
transitively on admissible frames.
The detailed Lie-algebraic structure of $G$ is not required
for our results; only the existence of a non-trivial
symmetry that must be broken (assumption~(B5)).
In concrete models, one may replace $G$ by its image
under the adjoint representation---typically
$O(V,q)$ or a pin/spin subgroup.}
For $Cl(1,3)$, $G$ contains the spin group
$\mathrm{Spin}(1,3) \cong SL(2,\mathbb{C})$
as a subgroup---a six-real-dimensional Lie group.

In the absence of computational constraints, all
$g \in G$ yield physically equivalent descriptions of
the agent's internal state.
The choice of basis within $Cl(V,q)$ is a \emph{gauge
freedom}---the symmetry that will be broken.

The realizability embedding
$\phi: Cl(V,q) \hookrightarrow Cl(1,3)$
(Q-RAIF Paper~C) constrains the physically accessible
reference frames: only gauge choices compatible with
$\mathrm{Im}(\phi) \subset Cl(1,3)$ are realizable.

\paragraph{Dimensional convention.}
Two distinct notions of dimension appear throughout:
\begin{center}
\small
\begin{tabular}{@{}lll@{}}
\toprule
Symbol & Meaning & Scaling \\
\midrule
$n := \dim V$ & number of generators
  (degrees of freedom) & --- \\
$D := \dim Cl(V,q) = 2^n$ & full multivector space
  (algebra basis size) & exponential in $n$ \\
\bottomrule
\end{tabular}
\end{center}
The Computational Ceiling (Section~\ref{T-II-sec:ceiling})
scales with~$D$, not~$n$; the distinction matters
whenever one compares generator-level and
algebra-level quantities.

% ------------------------------------------------------------
\subsection{Rate-Distortion Theory}
\label{T-II-subsec:RD}

We require the classical rate-distortion framework
of Shannon~\cite{Shannon1959}.

\begin{definition}[Rate-distortion function]
\label{T-II-def:RD}
Let $X$ be a random source with distribution $p(x)$,
$\hat{X}$ a reconstruction, and
$d: \mathcal{X} \times \hat{\mathcal{X}} \to [0,\infty)$
a distortion measure.
The \emph{rate-distortion function} is
\begin{equation}
\label{T-II-eq:RD}
R(D) := \min_{\substack{p(\hat{x}|x):\\
  \mathbb{E}[d(X,\hat{X})] \leq D}} I(X; \hat{X}),
\end{equation}
the minimum mutual information between source and
reconstruction that achieves average distortion at most $D$.
\end{definition}

$R(D)$ is a convex, non-increasing function of $D$ with
$R(0) = H(X)$ (lossless) and
$R(D_{\max}) = 0$ (maximum distortion).
It provides the fundamental limit on lossy
compression~\cite{CoverThomas2006}.
The \emph{information bottleneck} method of
Tishby et al.~\cite{Tishby2000} generalises this framework
to the case where the relevant variable is not the source
itself but a downstream prediction target---precisely the
situation in our survival-weighted compression problem
(Section~\ref{T-II-subsec:RD_bound}).

% ------------------------------------------------------------
\subsection{Bounded Rationality}
\label{T-II-subsec:bounded}

Following Simon~\cite{Simon1955}, we model computational
limitations as a hard constraint on the agent's information
processing rate.

\begin{definition}[Computational budget]
\label{T-II-def:budget}
The agent's \emph{computational budget}
$\mathcal{C}_{\mathrm{budget}}$ (measured in bits per unit
time) is the maximum rate at which the agent can evaluate
functions of its stored correlations.
We assume $\mathcal{C}_{\mathrm{budget}} < \infty$.
\end{definition}

Physically, finiteness of $\mathcal{C}_{\mathrm{budget}}$
reflects the finite number of degrees of freedom in the
agent's physical substrate: finite Hilbert space dimension,
finite memory register size, and finite energy available for
computation (Landauer's
principle~\cite{Landauer1961,Bennett1982}).

% ------------------------------------------------------------
\subsection{Fiber Bundle Formalism}
\label{T-II-subsec:fiber}

The geometric setting for reference-frame selection is a
principal fiber bundle.

\begin{definition}[Gauge bundle]
\label{T-II-def:bundle}
The \emph{gauge bundle} is the principal $G$-bundle
\begin{equation}
\label{T-II-eq:bundle}
\pi: P \to M, \qquad G = \mathrm{Aut}(Cl(V,q)),
\end{equation}
where:
\begin{itemize}
\item $M$ is the base space of \emph{effective memory
  kernels}---equivalently, the space of induced
  sufficient-statistic processes accessible to the agent
  (a finite-dimensional manifold that admits local
  parametrisation by the environmental spectral-density
  couplings);
\item $G$ is the structure group acting transitively on
  admissible frames (see
  footnote~\ref{T-II-fn:gauge_group} for the effective
  subgroup);
\item the fiber $\pi^{-1}(\kappa)$ over a kernel
  $\kappa \in M$ is the $G$-orbit of equivalent algebraic
  representations (frames) for describing~$\kappa$
  in $Cl(V,q)$;
\item a \emph{section} $\sigma: M \to P$ constitutes a
  global gauge-fixing policy---a systematic choice
  of reference frame for every kernel configuration.
\end{itemize}
\end{definition}

A \emph{connection} on $P$ specifies how the reference frame
is parallel-transported as the agent's state evolves.
The curvature of this connection measures the extent to
which the reference frame ``twists'' along different paths
through state space.

% ------------------------------------------------------------
\subsection{Standing Assumptions}
\label{T-II-subsec:standing}

\begin{definition}[Standing Assumptions]
\label{T-II-def:assumptions_B}
Throughout this paper, the following conditions are assumed:
\begin{enumerate}
\item[\textup{(B1)}] \textbf{Inherited framework.}
  All assumptions (A1)--(A5) of
  Paper~I~\cite{Liu2026TDOME_I} remain in force
  (open quantum system coupled to a thermal bath,
  well-defined free energy, non-equilibrium initial state,
  finite-dimensional system Hilbert space,
  and weak-coupling or controlled-coupling regime).
  Additionally, the agent possesses an internal control
  algebra $\mathcal{O}_{\mathrm{int}} = Cl(V,q)$
  with realizability embedding
  $\phi: Cl(V,q) \hookrightarrow Cl(1,3)$
  (Q-RAIF~\cite{Liu2026QRAIF_C}).
\item[\textup{(B2)}] \textbf{Finite computational budget.}
  The agent's information processing rate satisfies
  $\mathcal{C}_{\mathrm{budget}} < \infty$
  (Definition~\ref{T-II-def:budget}).
\item[\textup{(B3)}] \textbf{Non-trivial environment.}
  The entropy rate satisfies $h_\mu > 0$ and the
  memory depth satisfies $\tau_{\mathrm{mem}} > 0$.
  In Sections~\ref{T-II-sec:breaking}--\ref{T-II-sec:cost} we
  additionally require that the Computational Ceiling
  is binding:
  $\tau_{\mathrm{mem}} > \tau_{\mathrm{par}}$
  (Theorem~\ref{T-II-thm:comp_ceiling}), i.e., the symmetric
  phase is computationally intractable.
\item[\textup{(B4)}] \textbf{Survival imperative.}
  The agent's dynamics must maintain
  $\mathcal{S} \geq \mathcal{S}_{\min}$
  over survival horizons
  $T \gg \tau_{\mathrm{mem}}$.
  This is a persistence constraint, not an optimization
  objective.
\item[\textup{(B5)}] \textbf{Gauge symmetry of bare
  algebra.}
  The automorphism group $G = \mathrm{Aut}(Cl(V,q))$
  is non-trivial ($G \neq \{e\}$).
  In the absence of computational constraints, all
  $g \in G$ yield physically equivalent descriptions.
\end{enumerate}
\end{definition}

% ============================================================
\section{The Computational Ceiling}
\label{T-II-sec:ceiling}

We now establish the fundamental computational limitation of
symmetric agents---those that treat all components of their
internal algebra as equally relevant.
The result is the computational analogue of Paper~I's
Markovian Ceiling: where that theorem showed that
\emph{memoryless} dynamics cannot achieve
$\mathcal{S} > 0$, the present theorem shows that
\emph{unbiased processing} of memory leads to computational
paralysis.

% ------------------------------------------------------------
\subsection{The Information Processing Inequality
for Bounded Agents}
\label{T-II-subsec:processing}

\paragraph{Accounting convention.}
To ensure dimensional consistency throughout, we distinguish
two quantities:
\begin{itemize}
\item $\mathcal{C}_{\mathrm{budget}}$: the agent's processing
  \emph{rate} (bits per unit time).
\item $\mathcal{I}_{\mathrm{proc}}(\tau)$: the total
  information (bits) that must be processed per evaluation
  cycle when the memory archive has depth $\tau$.
\end{itemize}
The agent must complete one evaluation cycle per
environmental correlation time $\tau_E$.
The \emph{processing rate} required for a memory depth
$\tau$ is
\begin{equation}
\label{T-II-eq:rate_def}
\mathcal{R}_{\mathrm{proc}}(\tau)
:= \frac{\mathcal{I}_{\mathrm{proc}}(\tau)}
        {\tau_E}.
\end{equation}
Paralysis occurs when
$\mathcal{R}_{\mathrm{proc}}(\tau_{\mathrm{mem}})
> \mathcal{C}_{\mathrm{budget}}$.
Hereafter we measure time in units of $\tau_E$
(i.e., set $\tau_E = 1$), so that rates and per-cycle
information quantities are numerically equal.

\begin{definition}[Symmetric processing]
\label{T-II-def:symmetric}
An agent processes its memory \emph{symmetrically} if both
its cost functional $\mathcal{C}[\cdot]$ and its distortion
measure $D(\cdot)$ are $G$-invariant:
$\mathcal{C}[g \cdot \mathcal{K}]
= \mathcal{C}[\mathcal{K}]$ and
$D(g \cdot \mathcal{F}) = D(\mathcal{F})$
for every $g \in G = \mathrm{Aut}(Cl(V,q))$.
In operational terms: for every stored correlation $c_i$ in the
memory kernel $\mathcal{K}(t,s)$ and every $g \in G$, the
cost of evaluating $c_i$ equals the cost of evaluating
$g \cdot c_i$, and no basis direction is
\emph{a priori} preferred for survival evaluation.
\end{definition}

\begin{remark}[Operational meaning of processing rate]
\label{T-II-rem:proc_rate}
We define the processing rate
$\mathcal{R}_{\mathrm{proc}}$ as an
\emph{information-throughput} measure: the number of
algebraic components that must be updated per unit time,
multiplied by the innovation rate $h_\mu$ per component.
It captures the \emph{bandwidth} cost of maintaining an
internal representation, not the algorithmic gate
complexity of individual operations.
\end{remark}

\begin{theorem}[Computational Ceiling]
\label{T-II-thm:comp_ceiling}
Let an agent satisfy assumptions~\textup{(B1)--(B5)} with
memory depth $\tau_{\mathrm{mem}}$ and per-component entropy
rate $h_\mu > 0$.
Assume the environment is \textbf{unstructured} in the
following two senses:
\textup{(i)}~the effective activated dimension satisfies
$D_{\mathrm{eff}} \approx D$ (all grades of $Cl(V,q)$
carry non-negligible correlations), and
\textup{(ii)}~the predictive information is not concentrated
on a known sub-algebra (the agent possesses no
\emph{a priori} knowledge of the environmental symmetry
group and cannot exploit group-theoretic shortcuts such as
irreducible representations or Schur
decompositions).\footnote{%
If the agent knows the environmental symmetry group $H$,
symmetric processing can be restricted to the isotypic
components of $H$, reducing the effective dimension to
$D_{\mathrm{eff}} \leq D$.
The ceiling applies to the \emph{generic} (worst-case)
scenario.
All subsequent results hold \emph{a fortiori}
when $D$ is replaced by $D_{\mathrm{eff}}$.}
Within the class of \emph{symmetric representations}
that retain all $D$ components with equal fidelity
(permitting no privileged subspace)---thereby precluding
structured compression techniques such as sparse coding
or Johnson--Lindenstrauss
embeddings~\cite{JohnsonLindenstrauss1984}, as these
inherently implement a form of symmetry
breaking---the minimum processing rate satisfies
\begin{equation}
\label{T-II-eq:comp_ceiling}
\mathcal{R}_{\mathrm{proc}}^{\mathrm{sym}}
\;\geq\; h_\mu \cdot D,
\qquad D := \dim Cl(V,q) = 2^n,
\end{equation}
where $n = \dim V$ is the number of generators.
This rate scales \emph{linearly} in the algebra dimension
$D$ and \emph{exponentially} in~$n$.

For any finite $\mathcal{C}_{\mathrm{budget}}$, the maximum
memory depth that can be processed before correlations
expire is
\begin{equation}
\label{T-II-eq:t_par}
\tau_{\mathrm{par}}
:= \frac{\mathcal{C}_{\mathrm{budget}}}
        {h_\mu \cdot D}.
\end{equation}
Here $\tau_{\mathrm{par}}$ is measured in units of
$\tau_E$ (environmental correlation times), not seconds;
cf.\ the accounting convention at the start of this section.

For $\tau_{\mathrm{mem}} > \tau_{\mathrm{par}}$, the agent's
evaluation cycle cannot complete within one correlation time:
\begin{equation}
\label{T-II-eq:paralysis}
\mathcal{I}_{\mathrm{proc}}(\tau_{\mathrm{mem}})
= h_\mu \cdot \tau_{\mathrm{mem}} \cdot D
> \mathcal{C}_{\mathrm{budget}}.
\end{equation}
Stored correlations go stale before they can be used.
\end{theorem}

\begin{proof}
Under symmetric processing, the agent maintains $D$
parallel correlation channels---one for each independent
algebraic component of $Cl(V,q)$.
The environment generates innovations at rate $h_\mu$ bits
per unit time in each channel
(Remark~\ref{T-II-rem:proc_rate}).
Over a memory depth $\tau_{\mathrm{mem}}$, the total
information load is therefore
$\mathcal{I}_{\mathrm{proc}}(\tau_{\mathrm{mem}})
= D \cdot h_\mu \cdot \tau_{\mathrm{mem}}$
bits~\cite{CoverThomas2006}, and the required
\emph{rate} is
$\mathcal{R}_{\mathrm{proc}}^{\mathrm{sym}}
= D \cdot h_\mu$ bits per unit time.

The agent must complete one evaluation cycle within
$\tau_E$ (one environmental correlation time); otherwise
the oldest correlations expire before use.
Setting
$\mathcal{R}_{\mathrm{proc}}^{\mathrm{sym}}
= \mathcal{C}_{\mathrm{budget}}$
and solving for $\tau_{\mathrm{mem}}$ gives
$\tau_{\mathrm{par}}$~\eqref{T-II-eq:t_par}.
\end{proof}

\begin{corollary}[The Symmetry Tax]
\label{T-II-cor:symmetry_tax}
Maintaining full gauge invariance imposes a multiplicative
overhead of $D = 2^n$ on all computational operations
relative to a fixed-basis agent that processes only $k$
components.
The overhead ratio is $D/k$, which for
$Cl(1,3)$ ($D = 16$, $k = 2$) is $8\times$, and grows
exponentially with the number of generators $n$.
\end{corollary}

\begin{remark}[Effective vs.\ full dimension]
\label{T-II-rem:D_eff}
The ceiling uses $D = \dim Cl(V,q) = 2^n$, the full
multivector dimension.
In practice, the environment may couple to only a subset of
grades (e.g., grade-1 generators), yielding an effective
dimension $D_{\mathrm{eff}} \leq D$.
For a \emph{structured} environment where the agent knows
which grades are active, the ceiling can be tightened to
$\mathcal{R}_{\mathrm{proc}} \gtrsim h_\mu
\cdot D_{\mathrm{eff}}$.
The unstructured assumption~(B3) represents the worst case;
all subsequent results hold \emph{a fortiori} when
$D$ is replaced by $D_{\mathrm{eff}}$.
\end{remark}

% ------------------------------------------------------------
\subsection{Processing Collapse}
\label{T-II-subsec:collapse}

\begin{proposition}[Processing Collapse]
\label{T-II-prop:collapse}
Under~\textup{(B1)--(B5)}, an agent that maintains full
gauge symmetry reaches computational paralysis at time
$\tau_{\mathrm{par}}$~\eqref{T-II-eq:t_par}.
Beyond $\tau_{\mathrm{par}}$, the agent's processing latency
$\delta t_{\mathrm{proc}}$ exceeds the environmental
correlation time $\tau_E$:
\begin{equation}
\label{T-II-eq:latency}
\delta t_{\mathrm{proc}}(\tau_{\mathrm{mem}})
= \frac{D \cdot \tau_{\mathrm{mem}}}
       {\mathcal{C}_{\mathrm{budget}} / h_\mu}
> 1
\qquad\text{(in units of $\tau_E$)}.
\end{equation}
Every stored correlation becomes stale before it can be
evaluated, rendering the entire memory archive operationally
useless.
\end{proposition}

\begin{remark}[Comparison with Paper~I's Memory Catastrophe]
\label{T-II-rem:comparison}
Paper~I's Memory Catastrophe is \emph{thermodynamic}:
the \emph{cost of storing} memory exceeds the energy budget.
The Computational Ceiling is \emph{informational}: the
\emph{cost of processing} memory exceeds the computational
budget.
The two crises are complementary---an agent with unlimited
energy but finite computation is still paralyzed, and vice
versa.
The resolution of both crises is the same: compression
through symmetry breaking.
\end{remark}

% ============================================================
\section{The Symmetry Breaking Resolution}
\label{T-II-sec:breaking}

% ------------------------------------------------------------
\subsection{Reference Frame as Gauge Fixing}
\label{T-II-subsec:frame}

\begin{definition}[Reference frame]
\label{T-II-def:frame}
A \emph{reference frame} $\mathcal{F}$ is a section
$\sigma: M \to P$ of the gauge bundle
(Definition~\ref{T-II-def:bundle}).
Choosing $\sigma$ is equivalent to selecting a preferred
orthonormal basis $\{e_1, \ldots, e_n\}$ of the generating
vector space $V$ at each point in state space~$M$, thereby
fixing the gauge freedom of $Cl(V,q)$.
\end{definition}

\begin{definition}[Projected memory kernel]
\label{T-II-def:projected}
Given a reference frame $\mathcal{F}$, let
$V_{\mathrm{fg}}(\mathcal{F}) \subset Cl(V,q)$ be the
$k^*$-dimensional \emph{foreground subspace} selected by
the rate-distortion optimization
(Theorem~\ref{T-II-thm:compression}).
Let $\Pi_{\mathcal{F}}$ denote the orthogonal projection
onto $V_{\mathrm{fg}}(\mathcal{F})$ with respect to the
trace inner product
$\langle A, B \rangle := \tr(A^\dagger B)$.
The \emph{projected memory kernel} is
\begin{equation}
\label{T-II-eq:projected_kernel}
\mathcal{K}_{\mathcal{F}}(t,s)
:= \Pi_{\mathcal{F}}\,\mathcal{K}(t,s)\,
   \Pi_{\mathcal{F}}.
\end{equation}
The complementary projection
$\Pi_{\mathcal{F}}^{\perp}
= \mathbf{1} - \Pi_{\mathcal{F}}$ defines the
\emph{background subspace} $V_{\mathrm{bg}}(\mathcal{F})$.
The decomposition
$Cl(V,q) = V_{\mathrm{fg}} \oplus V_{\mathrm{bg}}$
is determined by $\mathcal{F}$, not by any \emph{a priori}
ordering of basis vectors.
\end{definition}

% ------------------------------------------------------------
\subsection{The Rate-Distortion Bound}
\label{T-II-subsec:RD_bound}

We now apply rate-distortion theory to the problem of
optimal memory compression under the survival constraint.

\paragraph{Processing rate of a frame.}
If the agent retains $k$ algebraic components (the foreground
subspace $V_{\mathrm{fg}}$), each generating $h_\mu$ bits
per unit time, the processing rate of frame $\mathcal{F}$ is
\begin{equation}
\label{T-II-eq:R_frame}
R_{\mathcal{F}}(k) \;=\; k \cdot h_\mu
\qquad\text{(bits per unit time)}.
\end{equation}
The budget constraint $R_{\mathcal{F}} \leq
\mathcal{C}_{\mathrm{budget}}$ thus bounds the number of
maintainable components.

\begin{definition}[Survival distortion]
\label{T-II-def:survival_distortion}
The \emph{survival distortion} of a reference frame
$\mathcal{F}$ is
\begin{equation}
\label{T-II-eq:distortion}
D(\mathcal{F})
:= \mathbb{E}_{\xi}\!\left[
  \ell\!\bigl(\mathcal{S}_{\mathrm{full}}(\xi)
  - \mathcal{S}_{\mathcal{F}}(\xi)\bigr)
\right],
\end{equation}
where $\xi$ denotes environmental realizations,
$\ell: \mathbb{R} \to [0,\infty)$ is a convex,
non-decreasing loss function (we use squared error
$\ell(x) = x^2$ throughout),
$\mathcal{S}_{\mathrm{full}}(\xi)$ is the survival
functional evaluated using the full memory kernel
$\mathcal{K}(t,s)$, and $\mathcal{S}_{\mathcal{F}}(\xi)$
is evaluated using the projected kernel
$\mathcal{K}_{\mathcal{F}}(t,s)$.
\end{definition}

\begin{remark}[Information-theoretic objects]
\label{T-II-rem:info_objects}
Strictly speaking, rate-distortion theory and mutual
information apply to stochastic processes, not to
superoperator kernels directly.
Throughout
Sections~\ref{T-II-sec:breaking}--\ref{T-II-sec:cost},
$I(\mathcal{K}_{\mathcal{F}};\,\mathcal{K})$ is shorthand
for $I(\hat{X};\,X)$, where
$X = \{c_i(t)\}_{i=1}^{D}$ is the sufficient-statistic
record process induced by the full kernel $\mathcal{K}$
acting on the agent's internal coordinates, and
$\hat{X} = \{c_i(t)\}_{i \in V_{\mathrm{fg}}}$ is the
projected record induced by
$\mathcal{K}_{\mathcal{F}}$.
The distortion measure~\eqref{T-II-eq:distortion} acts on the
survival functional $\mathcal{S}$ evaluated on these
records.
\end{remark}

\begin{theorem}[Optimal Compression under Survival Constraint]
\label{T-II-thm:compression}
Let an agent with computational budget
$\mathcal{C}_{\mathrm{budget}}$ and per-component entropy
rate $h_\mu$ choose a reference frame $\mathcal{F}$ that
minimizes the survival distortion~\eqref{T-II-eq:distortion}
subject to $R_{\mathcal{F}} \leq
\mathcal{C}_{\mathrm{budget}}$~\eqref{T-II-eq:R_frame}.
Then:
\begin{enumerate}
\item[\textup{(a)}] Assuming that $D(\mathcal{F})$ is
  non-increasing in the available rate $R_{\mathcal{F}}$
  (retaining more components cannot worsen survival
  distortion), the set of optimal reference frames
  $\mathfrak{F}^*
  := \operatorname*{arg\,min}_{\mathcal{F}}
  D(\mathcal{F})$
  subject to the budget constraint is non-empty, and
  any $\mathcal{F}^* \in \mathfrak{F}^*$ saturates the
  budget:
  $R_{\mathcal{F}^*} = \mathcal{C}_{\mathrm{budget}}$
  (the set $\mathfrak{F}^*$ may contain multiple
  elements; see Theorem~\ref{T-II-thm:SSB}(c)).
\item[\textup{(b)}] The compressed representation retains
  \begin{equation}
  \label{T-II-eq:k_star}
  k^* = \left\lfloor
    \frac{\mathcal{C}_{\mathrm{budget}}}{h_\mu}
  \right\rfloor
  \end{equation}
  effective algebraic components
  (the maximum integer number of components whose processing
  rate $k^* \cdot h_\mu$ fits within the budget;
  in practice the floor function ensures
  $k^* \in \mathbb{Z}_{\geq 1}$).
\item[\textup{(c)}] The fraction of algebraic structure
  discarded (in component count) is
  \begin{equation}
  \label{T-II-eq:discard_fraction}
  1 - \frac{k^*}{D},
  \end{equation}
  For $Cl(1,3)$ ($D = 16$) with a budget allowing
  $k^* = 2$, the discarded fraction is $1 - 2/16 = 87.5\%$.
  For $k^* = 1$, it exceeds $93\%$.
  In the regime $k^* \ll D$, the fraction approaches
  $1 - 1/D$ and grows with algebra dimension.
\end{enumerate}
\end{theorem}

\begin{proof}
The survival functional $\mathcal{S}$ is a function of the
full density operator $\rho(t)$, which in turn depends on
the full memory kernel $\mathcal{K}(t,s)$.
The agent's task is to evaluate $\mathcal{S}$ using only
$k$ components of $\mathcal{K}$, chosen to minimize the
mean-squared error in $\mathcal{S}$.

Strictly, rate-distortion theory applies to
\emph{random processes}, not to superoperator kernels
directly.
The bridge is the \emph{induced record process}: the
memory kernel $\mathcal{K}(t,s)$, acting on the agent's
internal coordinates, generates a $D$-component time series
of sufficient statistics $\{c_i(t)\}_{i=1}^{D}$ whose
entropy rate per component is~$h_\mu$.
Rate-distortion is applied to this record
stream~(Section~\ref{T-II-subsec:RD};
cf.\ Tishby et al.~\cite{Tishby2000}),
with source $X = \{c_i(t)\}$ (the full record),
reconstruction
$\hat{X} = \{c_i(t)\}_{i \in V_{\mathrm{fg}}}$
(the projected record), and distortion measure
$d = |\mathcal{S}_{\mathrm{full}}
- \mathcal{S}_{\mathcal{F}}|^2$.

By Shannon's rate-distortion theorem~\cite{Shannon1959},
the minimum rate required to achieve distortion $\delta$ is
$R(\delta)$, a convex non-increasing function.
The budget constraint~\eqref{T-II-eq:R_frame} limits the
processing rate to $R_{\mathcal{F}} = k \cdot h_\mu
\leq \mathcal{C}_{\mathrm{budget}}$.
The optimal frame $\mathcal{F}^*$ saturates this bound.

For part~(b): by~\eqref{T-II-eq:R_frame}, tracking $k$ components
costs $k \cdot h_\mu$ bits per unit time.
The maximum integer $k$ satisfying
$k \cdot h_\mu \leq \mathcal{C}_{\mathrm{budget}}$ is
$k^* = \lfloor \mathcal{C}_{\mathrm{budget}} / h_\mu
\rfloor$.

The discard fraction~(c) follows by counting:
$k^*$ of $D$ components are retained.
For $Cl(1,3)$ ($D = 16$, $k^* = 2$), the discarded fraction
is $87.5\%$; for higher-dimensional algebras it exceeds
$99\%$.
\end{proof}

% ------------------------------------------------------------
\subsection{Spontaneous Symmetry Breaking}
\label{T-II-subsec:SSB}

\begin{theorem}[Necessity of Symmetry Breaking]
\label{T-II-thm:SSB}
Under assumptions~\textup{(B1)--(B5)}, with the
Computational Ceiling binding
($\tau_{\mathrm{mem}} > \tau_{\mathrm{par}}$, both
measured in units of~$\tau_E$), and
assuming \emph{non-degeneracy}: the survival
distortion~\eqref{T-II-eq:distortion} satisfies
$D(\mathcal{F}) \neq D(\mathcal{F}')$ for almost all
pairs $\mathcal{F} \neq \mathcal{F}'$ in the space of
frames\footnote{%
Non-degeneracy is generically satisfied when the
environment's pointer basis~\cite{Zurek2009} assigns
different survival values to different algebraic
components, breaking the continuous symmetry of the
distortion landscape.
In degenerate cases, a finite set of local minima may
coexist---multiple ``ego attractors''---analogous to
the discrete magnetization directions in a
crystal-field anisotropic ferromagnet.},
the agent's survival-optimal strategy requires:
\begin{enumerate}
\item[\textup{(a)}] \textbf{Gauge fixing}: selection of a
  section $\sigma$ of the gauge bundle
  (Definition~\ref{T-II-def:bundle}), breaking the
  $G$-symmetry of the bare algebra.
\item[\textup{(b)}] \textbf{Privileged decomposition}:
  partition of the algebra into foreground and background
  subspaces,
  $Cl(V,q) = V_{\mathrm{fg}} \oplus V_{\mathrm{bg}}$,
  with
  $\dim V_{\mathrm{fg}} = k^* \ll \dim V_{\mathrm{bg}}$.
\item[\textup{(c)}] \textbf{Non-uniqueness}: the gauge
  fixing is generically \emph{not} unique.
  Different initial conditions, environmental histories,
  or stochastic fluctuations lead to different choices of
  $\sigma$, just as different initial conditions in a
  ferromagnet lead to different magnetization directions.
\end{enumerate}
The symmetry breaking is \emph{spontaneous} in the precise
physical sense: the underlying algebra $Cl(V,q)$ retains
its full $G$-symmetry, but the agent's operational
representation necessarily breaks it.
\end{theorem}

\begin{proof}
By Theorem~\ref{T-II-thm:comp_ceiling}, symmetric processing
leads to paralysis at $\tau_{\mathrm{par}}$.
By assumption~(B4) (survival imperative), the agent must
maintain $\mathcal{S} \geq \mathcal{S}_{\min}$ beyond
$\tau_{\mathrm{par}}$.
This requires evaluating $\mathcal{S}$ within the
computational budget $\mathcal{C}_{\mathrm{budget}}$, which
by Theorem~\ref{T-II-thm:compression} requires projecting onto
$k^* < \dim Cl(V,q)$ components.

Such a projection \emph{is} a gauge fixing: it selects
$k^*$ basis vectors $\{e_1, \ldots, e_{k^*}\}$ from the
generating space $V$, thereby breaking the
$G$-invariance that treats all bases equivalently.

Part~(b) follows from the definition of the projected kernel
(Definition~\ref{T-II-def:projected}).
Part~(c) follows from the non-degeneracy assumption:
the rate-distortion optimization
(Theorem~\ref{T-II-thm:compression}) generically admits
finitely many local minima.
Different initial conditions or environmental histories
select different minima, analogous to the
spontaneous magnetization of a ferromagnet below $T_c$.
The breaking is \emph{spontaneous}: the algebra retains
$G$-symmetry, but any operational solution breaks it.
\end{proof}

% ------------------------------------------------------------
\subsection{The Four Bias Terms}
\label{T-II-subsec:bias}

\begin{proposition}[Structure of the Broken Phase]
\label{T-II-prop:bias}
When gauge symmetry is broken by a reference frame
$\mathcal{F}$, the agent's operational representation
acquires four systematic deviations from the symmetric
phase:
\begin{enumerate}
\item[\textup{(i)}] \textbf{Basis selection bias}
  ($\mathcal{B}_{\mathrm{select}}$):
  The choice of $\{e_1, \ldots, e_{k^*}\}$ privileges
  certain algebraic components over others.
  Information aligned with the chosen basis is processed
  efficiently; misaligned information is discarded or
  distorted.
  \emph{Observable consequence:} systematic blindness to
  off-basis environmental perturbations (orthogonal
  masking).
\item[\textup{(ii)}] \textbf{Frame drag}
  ($\mathcal{B}_{\mathrm{frame}}$):
  The connection on the gauge bundle
  (Section~\ref{T-II-subsec:fiber}) induces a systematic
  preference for states near the current gauge choice.
  The agent's predictions are biased toward confirming
  its existing frame.
  \emph{Observable consequence:} hysteresis in belief
  updating; the agent's model lags behind rapid
  environmental shifts.
\item[\textup{(iii)}] \textbf{Objective centering}
  ($\mathcal{B}_{\mathrm{center}}$):
  The survival functional $\mathcal{S}$, when evaluated
  in the projected basis, becomes centered on the agent's
  own state rather than a global optimum.
  The agent optimizes \emph{locally} within its frame.
  \emph{Observable consequence:} inability to detect
  global survival optima located in the background
  subspace.
\item[\textup{(iv)}] \textbf{Model incompleteness}
  ($\mathcal{B}_{\mathrm{inc}}$):
  The compression from $Cl(V,q)$ to $V_{\mathrm{fg}}$
  is lossy.
  The discarded components $V_{\mathrm{bg}}$ contain
  correlations that are invisible to the agent but
  physically real.
  \emph{Observable consequence:} systematic
  underestimation of total thermodynamic uncertainty
  (overconfidence).
\end{enumerate}
\end{proposition}

\begin{proof}
(i)~follows directly from the definition of the projection
$\Pi_{\mathcal{F}}$: components orthogonal to the selected
basis are annihilated.

(ii)~The parallel transport of the gauge connection
preserves the agent's basis choice along its trajectory.
Under perturbation, the connection's holonomy creates a
restoring ``force'' toward the established frame---a
systematic confirmation bias.

(iii)~In the projected representation,
$\mathcal{S}_{\mathcal{F}}$ is a function of the
$k^*$-dimensional foreground state only.
The gradient $\nabla \mathcal{S}_{\mathcal{F}}$ lies
entirely in $V_{\mathrm{fg}}$, so the agent's
optimization is blind to directions in
$V_{\mathrm{bg}}$.
This is equivalent to centering the objective function
on the agent's own representational subspace.

(iv)~By Theorem~\ref{T-II-thm:compression}(c), a fraction
$\geq 1 - k^*/\dim Cl(V,q)$ of information is discarded.
The discarded components exist physically (they contribute
to $\mathcal{S}_{\mathrm{full}}$) but are invisible to the
agent's evaluation of $\mathcal{S}_{\mathcal{F}}$.
\end{proof}

\begin{table}[H]
\centering
\small
\setlength{\tabcolsep}{3pt}
\begin{tabular}{@{}lp{3.5cm}p{4.2cm}l@{}}
\toprule
\textbf{Bias} & \textbf{Origin}
  & \textbf{Observable consequence}
  & \textbf{Determines} \\
\midrule
$\mathcal{B}_{\mathrm{select}}$ (selection)
  & projection $\Pi_{\mathcal{F}}$
  & Systematic blindness to off-basis
    perturbations (orthogonal masking)
  & \emph{what} is seen \\[4pt]
$\mathcal{B}_{\mathrm{frame}}$ (frame drag)
  & bundle connection / holonomy
  & Hysteresis in belief updating;
    model lags behind rapid drift
  & \emph{duration} \\[4pt]
$\mathcal{B}_{\mathrm{center}}$ (centering)
  & $\nabla\mathcal{S} \in V_{\mathrm{fg}}$
  & Local frame-relative optima;
    global background optima invisible
  & \emph{target} \\[4pt]
$\mathcal{B}_{\mathrm{inc}}$ (incompleteness)
  & lossy compression $k^* \ll D$
  & Underestimation of thermodynamic
    uncertainty (structural overconfidence)
  & \emph{blind spot} \\
\bottomrule
\end{tabular}
\caption{The four bias terms of the broken phase.
  All four are generic consequences of gauge fixing
  under assumptions~(B1)--(B5).}
\label{T-II-tab:bias}
\end{table}

\begin{remark}[Nature of the bias terms]
\label{T-II-rem:bias_nature}
The four bias terms (Table~\ref{T-II-tab:bias}) are not
pathologies---they are \emph{generic} consequences of gauge
fixing under bounded computation.
Any agent satisfying~(B1)--(B5) acquires all four.
\end{remark}

% ============================================================
\section{Emergent Structure: The Architecture of Ego}
\label{T-II-sec:architecture}

We consolidate the gauge-fixed compressed representation
into a single mathematical object.
Throughout this section, ``ego'' is used purely as shorthand
for a gauge-fixed compressed representation; no claims about
phenomenal consciousness, subjective experience, or qualia
are intended or implied.

\begin{definition}[Ego]
\label{T-II-def:ego}
The \emph{ego} of an agent satisfying~\textup{(B1)--(B5)}
is the pair
\begin{equation}
\label{T-II-eq:ego}
\mathfrak{E}
:= \bigl(\mathcal{F}^*,\;
   V_{\mathrm{fg}}^*\bigr),
\end{equation}
where $\mathcal{F}^* \in \mathfrak{F}^*$
(Theorem~\ref{T-II-thm:compression}) is the chosen gauge
(providing the coordinate system) and
$V_{\mathrm{fg}}^*
:= V_{\mathrm{fg}}(\mathcal{F}^*)$ is the
$k^*$-dimensional foreground subspace selected by
the rate-distortion bound (providing the compression).
The projected memory kernel
$\mathcal{K}_{\mathfrak{E}}
:= \Pi_{V_{\mathrm{fg}}^*}\,\mathcal{K}\,
\Pi_{V_{\mathrm{fg}}^*}$
is induced by this pair.
All bias terms, distortion bounds, and delusion dynamics
are functions of~$\mathfrak{E}$.
\end{definition}

% ------------------------------------------------------------
\subsection{The Ego as a Fiber Bundle Section}
\label{T-II-subsec:section}

The reference frame $\mathcal{F}$, understood as a section
$\sigma: M \to P$, is the mathematical object we call the
\emph{ego}.
It has three key properties:

\paragraph{Smoothness.}
The section $\sigma$ varies continuously with the agent's
state $\rho \in M$.
Small changes in $\rho$ produce small changes in the
preferred basis---the ego is not a discrete switch but a
smooth deformation of perspective.

\paragraph{Holonomy.}
If the agent's state traces a closed loop
$\gamma: [0,1] \to M$ with $\gamma(0) = \gamma(1) = \rho_0$,
the parallel-transported frame need not return to its
initial value:
\begin{equation}
\label{T-II-eq:holonomy}
\sigma(\gamma(1))
= \mathrm{Hol}(\gamma) \cdot \sigma(\gamma(0)),
\end{equation}
where $\mathrm{Hol}(\gamma) \in G$ is the holonomy of the
connection around $\gamma$.
Non-trivial holonomy means the agent can ``learn''---its
reference frame shifts after a complete cycle of experience.

\paragraph{Topological obstruction.}
In general, a \emph{global} section $\sigma: M \to P$ may
not exist.
The obstruction is measured by the characteristic classes of
the bundle $P$.
When a global section does not exist, the ego must have
``singularities''---states where the preferred basis is
undefined or discontinuous.
This connects to the crisis of Paper~III: the delusion trap
can be understood as the agent approaching a topological
obstruction of its own reference frame.

% ------------------------------------------------------------
\subsection{The Effective Survival Functional}
\label{T-II-subsec:effective}

\begin{proposition}[Survival decomposition]
\label{T-II-prop:decomp}
In the broken phase, the survival functional decomposes as
\begin{equation}
\label{T-II-eq:decomp}
\mathcal{S}
= \mathcal{S}_{\mathrm{vis}}(\mathcal{F})
  + \mathcal{S}_{\mathrm{hid}}(\mathcal{F}),
\end{equation}
where:
\begin{itemize}
\item $\mathcal{S}_{\mathrm{vis}}(\mathcal{F})$
  is the contribution from the foreground subspace
  $V_{\mathrm{fg}}$, computable within the agent's
  reference frame;
\item $\mathcal{S}_{\mathrm{hid}}(\mathcal{F})$
  is the contribution from the background subspace
  $V_{\mathrm{bg}}$, invisible to the agent.
\end{itemize}
The agent maximizes $\mathcal{S}_{\mathrm{vis}}$ while
being structurally blind to
$\mathcal{S}_{\mathrm{hid}}$.
\end{proposition}

\begin{proof}
The survival functional $\mathcal{S} = \Delta F - W$ depends
on $\rho(t)$, which is a function of the full memory kernel
$\mathcal{K}(t,s)$.
Decomposing
$\mathcal{K} = \Pi_{\mathcal{F}}\,\mathcal{K}\,
\Pi_{\mathcal{F}}
+ \Pi_{\mathcal{F}}^{\perp}\,\mathcal{K}\,
\Pi_{\mathcal{F}}^{\perp}
+ \text{cross terms}$,
the leading contributions are
$\mathcal{S}_{\mathrm{vis}} := \mathcal{S}[
\Pi_{\mathcal{F}}\,\mathcal{K}\,\Pi_{\mathcal{F}}]$
and
$\mathcal{S}_{\mathrm{hid}} := \mathcal{S} -
\mathcal{S}_{\mathrm{vis}}$
(collecting background and cross terms).
The agent computes only
$\mathcal{S}_{\mathrm{vis}}$, as the projected kernel
$\mathcal{K}_{\mathcal{F}}$ discards all background
components.
\end{proof}

% ------------------------------------------------------------
\subsection{The Computational Speedup}
\label{T-II-subsec:speedup}

\begin{proposition}[Ego dividend]
\label{T-II-prop:speedup}
After symmetry breaking, the computational cost of
processing memory drops from
$\mathcal{C}_{\mathrm{proc}} \sim h_\mu \cdot
\tau_{\mathrm{mem}} \cdot D$
(symmetric case, $D = \dim Cl(V,q)$) to
\begin{equation}
\label{T-II-eq:speedup}
\mathcal{C}_{\mathrm{proc}}^{(\mathcal{F})}
\sim h_\mu \cdot \tau_{\mathrm{mem}}
     \cdot k^*.
\end{equation}
The speedup factor is
\begin{equation}
\label{T-II-eq:speedup_factor}
\frac{D}{k^*} = \frac{2^n}{k^*}.
\end{equation}
\end{proposition}

This is the computational advantage of reference-frame
selection.
For $Cl(1,3)$ ($D = 16$) with $k^* = 2$, the speedup is
$8\times$.
For higher-dimensional algebras, the speedup grows
exponentially in $n$.

% ------------------------------------------------------------
\subsection{The Ego-Entropy Trade-off}
\label{T-II-subsec:tradeoff}

\begin{theorem}[Ego-Entropy Trade-off]
\label{T-II-thm:tradeoff}
Let $X = \{c_i(t)\}_{i=1}^{D}$ denote the full stochastic
record process induced by the memory kernel $\mathcal{K}$
on the agent's internal coordinates, and let
$\hat{X} = \{c_i(t)\}_{i \in V_{\mathrm{fg}}}$ denote the
projected record retained by the ego.
The mutual information between compressed and full records,
denoted $I(\mathcal{K}_{\mathcal{F}};\,\mathcal{K})
\equiv I(\hat{X};\,X)$, satisfies
\begin{equation}
\label{T-II-eq:I_retained}
I(\hat{X};\,X) \;\leq\; H(\hat{X})
\;\leq\; k^* \cdot h_\mu \cdot \tau_{\mathrm{mem}}.
\end{equation}
Under the additional assumption that
$I_{\mathrm{pred}}$~\eqref{T-II-eq:I_pred} is approximately
uniformly distributed across the $D$ algebraic components
in the symmetric phase\footnote{%
This ``uniformity assumption'' is the information-theoretic
counterpart of the unstructured-environment condition in
Theorem~\ref{T-II-thm:comp_ceiling}.
When some components carry disproportionately more predictive
information, the bound tightens or loosens depending on the
alignment between $V_{\mathrm{fg}}$ and the high-information
subspace.},
the information discarded by the ego is bounded below
(up to $O(1)$ constants under uniformity):
\begin{equation}
\label{T-II-eq:I_discarded}
I_{\mathrm{discarded}}
:= H(X) - I(\hat{X};\,X)
\gtrsim \left(1 - \frac{k^*}{D}\right)
\cdot I_{\mathrm{pred}}.
\end{equation}
\end{theorem}

\begin{proof}
By the data processing inequality,
$I(\hat{X};\,X) \leq H(\hat{X})$.
The projected record $\hat{X}$ has $k^*$ components,
each carrying at most $h_\mu$ bits per unit time over a
window of $\tau_{\mathrm{mem}}$, giving
$H(\hat{X}) \leq k^* \cdot h_\mu \cdot
\tau_{\mathrm{mem}}$~\cite{CoverThomas2006}.
This yields~\eqref{T-II-eq:I_retained}.
The total predictive information in the full record is
$I_{\mathrm{pred}}$~\eqref{T-II-eq:I_pred}.
Under the uniformity assumption, each of the $D$ components
carries $\sim I_{\mathrm{pred}}/D$, so the $k^*$ retained
components account for $\sim (k^*/D)\,I_{\mathrm{pred}}$.
The discarded fraction follows by subtraction.
\end{proof}

\begin{remark}[The price of selfhood]
\label{T-II-rem:price}
Equation~\eqref{T-II-eq:I_discarded} quantifies the
\emph{information cost of having an ego}: the agent
sacrifices at least a fraction
$1 - k^*/\dim Cl(V,q)$ of all predictive information
about its environment in exchange for computational
tractability.
This is not a deficiency---it is a \emph{design
constraint} forced by bounded resources.
The ego is the optimal lossy compression under survival
weighting.
\end{remark}

% ============================================================
\section{Worked Example: Qubit in a Two-Channel Bath}
\label{T-II-sec:example}

% ------------------------------------------------------------
\subsection{Model Setup}
\label{T-II-subsec:model}

We extend Paper~I's spin-boson model to demonstrate
symmetry breaking explicitly.
Consider a qubit ($\dim \mathcal{H}_S = 2$) with internal
algebra $Cl(0,2) \cong \mathbb{H}$ (the quaternions,
$\dim = 4$).

\paragraph{Symbol mapping.}
The general framework of Sections~\ref{T-II-sec:ceiling}--\ref{T-II-sec:architecture}
specialises as follows:
\begin{center}
\small
\begin{tabular}{@{}lll@{}}
\toprule
General & This example & Value \\
\midrule
$Cl(V,q)$ & $Cl(0,2) \cong \mathbb{H}$
  & $D = 4$ \\
$G = \mathrm{Aut}(Cl(V,q))$ & $SO(3)$
  & acting on $\{\mathbf{i},\mathbf{j},\mathbf{k}\}$\\
$\mathcal{C}_{\mathrm{budget}}$ & $2\,h_\mu$
  & bits/time \\
$k^*$ (Thm.~\ref{T-II-thm:compression})
  & $\lfloor 2h_\mu / h_\mu \rfloor = 2$
  & components \\
$V_{\mathrm{fg}}$ & $\mathrm{span}\{1,\mathbf{k}\}$
  & dephasing subspace \\
$V_{\mathrm{bg}}$ & $\mathrm{span}\{\mathbf{i},\mathbf{j}\}$
  & dissipative subspace \\
$\tau_{\mathrm{par}}$ (Thm.~\ref{T-II-thm:comp_ceiling})
  & $2h_\mu / (4h_\mu) = 0.5$
  & $\omega_0^{-1}$ \\
\bottomrule
\end{tabular}
\end{center}
The qubit is coupled to a bosonic environment through
\emph{two} independent channels:
\begin{itemize}
\item A \emph{dephasing channel} via $\sigma_z$, with
  spectral density
  \begin{equation}
  \label{T-II-eq:J_z}
  J_z(\omega)
  = \frac{2\lambda_z\,\gamma_z\,\omega}
         {\omega^2 + \gamma_z^2}
  \qquad\text{(Lorentz--Drude)},
  \end{equation}
  producing a memory kernel $\mathcal{K}_z(t,s)$ with
  non-Markovian backflow.
\item A \emph{dissipative channel} via $\sigma_x$, with
  spectral density
  \begin{equation}
  \label{T-II-eq:J_x}
  J_x(\omega)
  = \frac{2\lambda_x\,\gamma_x\,\omega}
         {\omega^2 + \gamma_x^2}
  \qquad\text{(Lorentz--Drude)},
  \end{equation}
  producing a memory kernel $\mathcal{K}_x(t,s)$.
\end{itemize}

The full memory kernel is
$\mathcal{K}(t,s)
= \mathcal{K}_z(t,s) \oplus \mathcal{K}_x(t,s)$,
and the quaternionic algebra
$\mathbb{H} = \mathrm{span}\{1, \mathbf{i}, \mathbf{j},
\mathbf{k}\}$
has automorphism group
$G = \mathrm{Aut}(\mathbb{H}) \cong SO(3)$
(rotations of the pure quaternion subspace).

\paragraph{Parameters.}
We set $\omega_0 = 1$ (energy unit),
$\lambda_z = 1$, $\gamma_z = 0.5$ (underdamped, strong
non-Markovian effects in the dephasing channel),
$\lambda_x = 0.3$, $\gamma_x = 5.0$ (overdamped,
approximately Markovian in the dissipative channel),
and the low-temperature regime $\beta\omega_0 \gg 1$.

\paragraph{Computational budget.}
The agent has
$\mathcal{C}_{\mathrm{budget}} = 2\,h_\mu$
bits per unit time---sufficient to track two components
of $\mathbb{H}$ but not all four.

\paragraph{Parameter-to-theorem mapping.}
Table~\ref{T-II-tab:params} collects the example parameters and
confirms that the Computational Ceiling binds.

\begin{table}[t]
\centering
\small
\begin{tabular}{@{}lcll@{}}
\toprule
\textbf{Quantity} & \textbf{Symbol} & \textbf{Value}
  & \textbf{Theorem check} \\
\midrule
Full dimension & $D$ & $4$ &
  Thm.~\ref{T-II-thm:comp_ceiling} \\
Entropy rate & $h_\mu$ & $1.0$ (normalised) &
  per-component rate \\
Budget & $\mathcal{C}_{\mathrm{budget}}$ & $2\,h_\mu$
  & Def.~\ref{T-II-def:budget} \\
\midrule
Ceiling check & $h_\mu D$ vs $\mathcal{C}_{\rm budget}$
  & $4 > 2$ & \textbf{ceiling binds} \\
Optimal $k$ & $k^*$ & $\lfloor 2/1 \rfloor = 2$
  & Thm.~\ref{T-II-thm:compression}(b) \\
Discard fraction & $1 - k^*/D$ & $1/2 = 50\%$
  & Thm.~\ref{T-II-thm:tradeoff} \\
Paralysis time & $\tau_{\mathrm{par}}$ & $2/(4) = 0.5$
  & Eq.~\eqref{T-II-eq:t_par} \\
\bottomrule
\end{tabular}
\caption{Parameter mapping for the two-channel qubit
example.  The ceiling check confirms that symmetry
breaking is necessary; the budget is exactly saturated
after breaking ($R_{\mathcal{F}} = k^* h_\mu
= \mathcal{C}_{\mathrm{budget}}$).}
\label{T-II-tab:params}
\end{table}

% ------------------------------------------------------------
\subsection{The Unbroken Phase: Paralysis}
\label{T-II-subsec:unbroken}

In the symmetric phase, the agent tracks all four
quaternionic components
$\{1, \mathbf{i}, \mathbf{j}, \mathbf{k}\}$
simultaneously.
The computational cost is
\begin{equation}
\label{T-II-eq:cost_full}
\mathcal{C}_{\mathrm{proc}}
= h_\mu \cdot \tau_{\mathrm{mem}} \cdot D
= 4\,h_\mu \cdot \tau_{\mathrm{mem}},
\qquad D := \dim Cl(0,2) = 4.
\end{equation}
The paralysis time is
\begin{equation}
\label{T-II-eq:t_par_example}
\tau_{\mathrm{par}}
= \frac{\mathcal{C}_{\mathrm{budget}}}
       {h_\mu \cdot D}
= \frac{2\,h_\mu}{4\,h_\mu} = 0.5
\qquad\text{(in units of $\omega_0^{-1}$)}.
\end{equation}
Beyond $\tau_{\mathrm{mem}} = 0.5\,\omega_0^{-1}$,
the agent cannot process both channels
simultaneously---it is paralyzed.

% ------------------------------------------------------------
\subsection{Symmetry Breaking: Choosing $\sigma_z$}
\label{T-II-subsec:choosing}

The agent breaks the $SO(3)$ symmetry of $\mathbb{H}$
by selecting $\sigma_z$ as the privileged basis direction,
retaining the $\{1, \mathbf{k}\}$ subspace (the dephasing
channel) as foreground and discarding
$\{\mathbf{i}, \mathbf{j}\}$ (the dissipative channel)
as background:
\begin{equation}
\label{T-II-eq:decomp_example}
\mathbb{H}
= \underbrace{\mathrm{span}\{1, \mathbf{k}\}}_{%
  V_{\mathrm{fg}}\; (k^* = 2)}
\oplus
\underbrace{\mathrm{span}\{\mathbf{i}, \mathbf{j}\}}_{%
  V_{\mathrm{bg}}}.
\end{equation}

\paragraph{Why $\sigma_z$?}
The dephasing channel ($\lambda_z = 1$, $\gamma_z = 0.5$)
is strongly non-Markovian and carries the dominant
survival-relevant information (the backflow revivals that
enable $\mathcal{S} > 0$, as demonstrated in Paper~I).
The dissipative channel ($\lambda_x = 0.3$, $\gamma_x = 5.0$)
is approximately Markovian and contributes primarily to
decoherence---its survival value is negative.

This choice coincides with the \emph{pointer basis}
selected by environmental decoherence (quantum
Darwinism~\cite{Zurek2009}): the $\sigma_z$ eigenstates
are the states that survive decoherence and become
redundantly encoded in the environment.
The ego ``accepts the suggestion'' of decoherence,
aligning its computational resources with the
environmentally stable basis.

% ------------------------------------------------------------
\subsection{The Broken Phase: Effective Processing}
\label{T-II-subsec:broken}

In the broken phase, the projected memory kernel
$\mathcal{K}_{\mathcal{F}} = \mathcal{K}_z$ retains only
the dephasing-channel dynamics.
The computational cost drops to
\begin{equation}
\label{T-II-eq:cost_broken}
\mathcal{C}_{\mathrm{proc}}^{(\mathcal{F})}
= h_\mu \cdot \tau_{\mathrm{mem}} \cdot k^*
= 2\,h_\mu \cdot \tau_{\mathrm{mem}},
\end{equation}
exactly half the symmetric cost~\eqref{T-II-eq:cost_full}.
The agent can now process memory up to depth
$\tau_{\mathrm{mem}} = 1\,\omega_0^{-1}$ before reaching
its budget---twice the paralysis time.

The survival functional in the broken phase is
\begin{equation}
\label{T-II-eq:S_broken}
\mathcal{S}_{\mathrm{vis}}(\mathcal{F})
= \mathcal{S}[\mathcal{K}_z],
\end{equation}
which, as shown in Paper~I, achieves
$\beta\,\mathcal{S}_{\mathrm{vis}} \approx +0.093$ at
the first backflow revival.

The hidden component
$\mathcal{S}_{\mathrm{hid}} = \mathcal{S}[\mathcal{K}_x]$
is the survival contribution from the dissipative channel,
which the agent can no longer evaluate.
For the chosen parameters,
$|\mathcal{S}_{\mathrm{hid}}|
\ll |\mathcal{S}_{\mathrm{vis}}|$
(the dissipative channel contributes primarily negative
survival value), so the distortion is small.

% ------------------------------------------------------------
\subsection{Quantitative Evaluation}
\label{T-II-subsec:quantitative}

We now evaluate the ego dividend explicitly.
Each channel's decoherence function follows from the exact
$T \to 0$ solution of the Lorentz--Drude pure-dephasing
model~\cite{BreuerPetruccione2002,Liu2026TDOME_I}:
\begin{equation}
\label{T-II-eq:decoherence_II}
p_\alpha(t) = e^{-\gamma_\alpha t/2}\!\left[
  \cos(\Omega_\alpha t)
  + \frac{\gamma_\alpha}{2\Omega_\alpha}\,
    \sin(\Omega_\alpha t)
\right],
\quad
\Omega_\alpha
:= \tfrac{1}{2}\sqrt{4\lambda_\alpha\gamma_\alpha
   - \gamma_\alpha^2},
\end{equation}
for $\alpha \in \{z, x\}$.
When $4\lambda_\alpha\gamma_\alpha < \gamma_\alpha^2$
(the overdamped regime), $\Omega_\alpha$ becomes imaginary
and the trigonometric functions are replaced by hyperbolic
functions (monotonic decay, no backflow).

For our parameters:
\begin{itemize}
\item \textbf{$z$-channel} ($\lambda_z = 1$,
  $\gamma_z = 0.5$):
  $\Omega_z = \frac{1}{2}\sqrt{1.75} \approx 0.661$.
  Underdamped; $|p_z(t)|$ exhibits oscillatory backflow.
\item \textbf{$x$-channel} ($\lambda_x = 0.3$,
  $\gamma_x = 5.0$):
  Discriminant $4\lambda_x\gamma_x - \gamma_x^2
  = 6 - 25 = -19 < 0$.
  Overdamped; $|p_x(t)|$ decays monotonically with no
  backflow.
\end{itemize}

The survival proxy from Paper~I,
$\beta\,\mathcal{S} \propto |p(t)|^2 - 1$
(valid for the pure-dephasing model with maximally coherent
initial state and pointer-basis measurement), applies to
each channel independently.
Backflow intervals---where $d|p_\alpha|/dt > 0$---produce
$\mathcal{S} > 0$ over those subintervals (Paper~I,
Theorem~2).

\textbf{Key result.}
For the $z$-channel with $\gamma_z = 0.5$, the first
backflow interval begins at
$t^* \approx 2.9\,\omega_0^{-1}$---well after the
paralysis time $\tau_{\mathrm{par}} = 0.5\,\omega_0^{-1}$.
The symmetric agent, paralyzed at $\tau_{\mathrm{par}}$,
can harvest \emph{zero} backflow.
The ego agent, tracking only the $z$-channel, can process
memory to depth $1\,\omega_0^{-1}$ and exploits \emph{all
three} backflow revivals visible in
Figure~\ref{T-II-fig:ego}(a).

The cumulative backflow harvested by the ego agent
(Figure~\ref{T-II-fig:ego}(b)) totals approximately $0.10$
(in dimensionless $\beta\,\mathcal{S}$ units) over
$t \in [0, 15\,\omega_0^{-1}]$.
The symmetric agent harvests exactly zero.
This infinite ratio is the \emph{ego dividend}: the entire
non-Markovian survival advantage is accessible only to the
agent that has broken symmetry.

Crucially, visual inspection of Figure~\ref{T-II-fig:ego}(a)
reveals a timeline of tragedy for the symmetric agent.
The paralysis time $\tau_{\mathrm{par}} = 0.5$ occurs
\emph{before} the onset of the first backflow interval
($t^* \approx 2.9$).
The symmetric agent is computationally dead before the
environment offers its first gift.
The ratio of survival profit is not merely large; it is
singular.
In this framework, to remain symmetric is to starve in the
midst of plenty.

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]{fig_ego.pdf}
\caption{%
Two-channel qubit model (Section~\ref{T-II-sec:example}) with
Lorentz--Drude spectral density.
\textbf{Parameters:}
$\omega_0 = 1$ (energy unit);
$\lambda_z = 1$, $\gamma_z = 0.5$ (dephasing, non-Markovian);
$\lambda_x = 0.3$, $\gamma_x = 5.0$ (dissipative,
$\sim$Markovian);
$\mathcal{C}_{\mathrm{budget}} = 2\,h_\mu$.
\textbf{Units:} time in $\omega_0^{-1}$.
\textbf{Regime:} low temperature ($\beta\omega_0 \gg 1$);
using the standard $T \to 0$ analytic
expression~\eqref{T-II-eq:decoherence_II}~%
\cite{BreuerPetruccione2002}.
\textbf{(a)}~Decoherence amplitudes $|p_z(t)|$ (blue,
non-Markovian, with backflow in green bands) and
$|p_x(t)|$ (orange, monotonic decay).
Red dashed: paralysis time $\tau_{\mathrm{par}} = 0.5$.
\textbf{(b)}~Cumulative backflow harvested.
Blue: ego agent (broken $\to \sigma_z$) exploits all three
revival intervals.
Red dashed: symmetric agent, paralyzed at
$\tau_{\mathrm{par}}$, harvests zero---all backflow occurs
after paralysis onset.
The growing gap is the \emph{ego dividend}.}
\label{T-II-fig:ego}
\end{figure}

\paragraph{Consistency check.}
We verify the Computational Ceiling
(Theorem~\ref{T-II-thm:comp_ceiling}) directly:
$\mathcal{R}_{\mathrm{proc}}^{\mathrm{sym}}
= h_\mu \cdot D = 4\,h_\mu
> \mathcal{C}_{\mathrm{budget}} = 2\,h_\mu$,
confirming that the ceiling binds and symmetry breaking is
required.
After breaking ($k^* = 2$),
$R_{\mathcal{F}} = 2\,h_\mu
= \mathcal{C}_{\mathrm{budget}}$:
the budget is exactly saturated, as predicted by
Theorem~\ref{T-II-thm:compression}(a).

% ------------------------------------------------------------
\subsection{The Pointer-State Connection}
\label{T-II-subsec:pointer}

The optimal basis choice coincides with the einselection
(environment-induced superselection) basis of decoherence
theory~\cite{Zurek2009}.
This is not a coincidence: the pointer states are precisely
those that generate the most redundant records in the
environment---i.e., the most predictive correlations.
The rate-distortion optimization
(Theorem~\ref{T-II-thm:compression}) selects the components
with the highest survival value per bit, which are
generically the pointer-state components.

\begin{remark}[Decoherence as symmetry-breaking catalyst]
\label{T-II-rem:decoherence}
The environment does not \emph{force} a specific gauge
fixing; it merely breaks the degeneracy among possible
fixings by making some bases more informationally
efficient than others.
The agent's bounded computation does the rest: once
the degeneracy is broken, the survival imperative~(B4)
selects the pointer-aligned frame as optimal.
This is the precise sense in which decoherence ``catalyzes''
the spontaneous symmetry breaking of the ego.
\end{remark}

% ============================================================
\section{The Cost of Ego}
\label{T-II-sec:cost}

The ego resolves the computational crisis of
Section~\ref{T-II-sec:ceiling}, but it introduces a new
vulnerability. A fixed reference frame is a \emph{static}
gauge choice in a \emph{dynamic} environment.
If the environment changes, the ego becomes progressively
maladaptive.

\paragraph{Drift layer.}
Environmental change can occur at multiple levels:
parameter drift ($\lambda_\alpha(t)$, $\gamma_\alpha(t)$),
spectral-density deformation ($J(\omega, t)$), or
full process-distribution shift ($P_t(X)$).
For analytical tractability, we model drift at the
\emph{spectral-density parameter level} throughout this
section; the results generalise monotonically to deeper
levels (faster drift $\Rightarrow$ shorter
$t_{\mathrm{del}}$).

% ------------------------------------------------------------
\subsection{The Rigidity Trap}
\label{T-II-subsec:rigidity}

\begin{proposition}[Frame Rigidity under Drift]
\label{T-II-prop:rigidity}
Let the environment undergo slow drift: the spectral density
parameters change as
$\lambda_\alpha(t) = \lambda_\alpha^{(0)}
+ \varepsilon\,f_\alpha(t)$
for $\alpha \in \{z, x\}$, with drift rate
$\varepsilon > 0$.
The optimal reference frame $\mathcal{F}^*(t)$ (the
instantaneous minimizer of survival distortion)
rotates continuously in the gauge group~$G$.

If the agent's reference frame $\mathcal{F}$ is held fixed
(no recalibration), the mismatch between $\mathcal{F}$
and $\mathcal{F}^*(t)$ grows as
\begin{equation}
\label{T-II-eq:mismatch}
\delta(t)
:= d_G\bigl(\mathcal{F},\, \mathcal{F}^*(t)\bigr)
\sim \varepsilon \int_0^t \bigl|\dot{f}(s)\bigr|\,ds,
\end{equation}
where $d_G$ is the geodesic distance in the gauge group.
\end{proposition}

\begin{proof}
The instantaneous optimal frame $\mathcal{F}^*(t)$ is a
continuous function of the spectral density parameters
$\{\lambda_\alpha(t), \gamma_\alpha(t)\}$.
Under the drift $\lambda_\alpha(t)
= \lambda_\alpha^{(0)} + \varepsilon\,f_\alpha(t)$,
the chain rule gives
$\dot{\mathcal{F}}^*(t)
= \varepsilon\,\sum_\alpha
(\partial \mathcal{F}^*/\partial\lambda_\alpha)\,
\dot{f}_\alpha(t)$.
Integrating and taking the norm in $G$ gives
the bound~\eqref{T-II-eq:mismatch}.
\end{proof}

% ------------------------------------------------------------
\subsection{Stylized Drift Model}
\label{T-II-subsec:drift_model}

To quantify the collapse of a fixed frame, we introduce
a minimal drift model that makes the exponential divergence
and the logarithmic delusion time algebraically explicit.

\begin{definition}[Rotating optimal frame]
\label{T-II-def:drift}
Let the mismatch angle $\theta(t)$ between the agent's
fixed frame $\mathcal{F}$ and the instantaneous optimal
frame $\mathcal{F}^*(t)$ evolve as
\begin{equation}
\label{T-II-eq:theta}
\theta(t) = \theta_0\,e^{\Lambda t}
\qquad\text{(chaotic drift)},
\end{equation}
where $\theta_0 \in (0, \pi/4)$ is the initial misalignment
(so that $t_{\mathrm{del}} > 0$) and
$\Lambda > 0$ is the environmental Lyapunov exponent
(the rate at which nearby environmental trajectories
diverge in spectral-density space).
Operationally, $\Lambda$ is determined by the drift rate
$\varepsilon$ and the adaptation timescale
$\tau_{\mathrm{adapt}}$ of the spectral-density
parameters via the scaling
\begin{equation}
\label{T-II-eq:Lambda_scaling}
\Lambda \;\sim\; \frac{\varepsilon}
  {\tau_{\mathrm{adapt}}}\,;
\end{equation}
cf.~\eqref{T-II-eq:mismatch}.
For slow linear drift ($\theta(t) = \varepsilon\,t$,
$\Lambda \to 0$), the crossover time is
$t_{\mathrm{del}} = \pi/(4\varepsilon)$
(Remark~\ref{T-II-rem:linear_drift}).

The visible and hidden survival components decompose
geometrically:
\begin{equation}
\label{T-II-eq:vis_hid_theta}
\mathcal{S}_{\mathrm{vis}}(t)
= \mathcal{S}_{\mathrm{tot}}\,\cos^2\theta(t),
\qquad
\mathcal{S}_{\mathrm{hid}}(t)
= \mathcal{S}_{\mathrm{tot}}\,\sin^2\theta(t),
\end{equation}
where $\mathcal{S}_{\mathrm{tot}}$ is the full survival
functional (invariant under frame rotation).
\end{definition}

% ------------------------------------------------------------
\subsection{The Prediction Error Divergence}
\label{T-II-subsec:divergence}

\begin{proposition}[Divergence of Hidden Survival]
\label{T-II-prop:divergence}
Under the drift model~\eqref{T-II-eq:theta}--\eqref{T-II-eq:vis_hid_theta},
the hidden survival component grows as
\begin{equation}
\label{T-II-eq:divergence}
\bigl|\mathcal{S}_{\mathrm{hid}}(t)\bigr|
= |\mathcal{S}_{\mathrm{tot}}|\,\sin^2\!\bigl(\theta_0\,
  e^{\Lambda t}\bigr).
\end{equation}
For small angles ($\theta_0 e^{\Lambda t} \ll 1$):
$|\mathcal{S}_{\mathrm{hid}}| \approx
|\mathcal{S}_{\mathrm{tot}}|\,\theta_0^2\,e^{2\Lambda t}$
(exponential growth).
\end{proposition}

\begin{proof}
Direct substitution of~\eqref{T-II-eq:theta}
into~\eqref{T-II-eq:vis_hid_theta}.
The small-angle expansion
$\sin^2\theta \approx \theta^2$ gives the exponential
form.
\end{proof}

% ------------------------------------------------------------
\subsection{The Delusion Trap}
\label{T-II-subsec:delusion}

\begin{theorem}[The Delusion Trap]
\label{T-II-thm:delusion}
Under~\textup{(B1)--(B5)} with the drift
model~\eqref{T-II-eq:theta} and initial misalignment
$\theta_0 \in (0,\,\pi/4)$, an agent with a fixed
reference frame $\mathcal{F}$ reaches a critical
\textbf{delusion time}
\begin{equation}
\label{T-II-eq:t_delusion}
t_{\mathrm{del}}
= \frac{1}{\Lambda}\,
\ln\!\left(\frac{\pi/4}{\theta_0}\right),
\end{equation}
beyond which:
\begin{enumerate}
\item[\textup{(a)}]
  $|\mathcal{S}_{\mathrm{hid}}(t)|
  > |\mathcal{S}_{\mathrm{vis}}(t)|$:
  the invisible component dominates the survival functional.
\item[\textup{(b)}]
  The agent's update direction becomes
  \emph{anti-correlated} with the true optimal direction:
  the inner product of survival gradients
  (with respect to the agent's control variables
  $u \in V_{\mathrm{fg}}$) satisfies
  \begin{equation}
  \label{T-II-eq:anti_correlation}
  \bigl\langle \nabla_u\mathcal{S}_{\mathrm{vis}},\;
    \nabla_u\mathcal{S}_{\mathrm{full}}
  \bigr\rangle < 0.
  \end{equation}
  Updating $u$ to maximise $\mathcal{S}_{\mathrm{vis}}$
  actually \emph{decreases}
  $\mathcal{S}_{\mathrm{full}}$.
\item[\textup{(c)}]
  The agent cannot detect this failure from within its
  own reference frame, because all four bias terms
  ($\mathcal{B}_{\mathrm{select}}$,
  $\mathcal{B}_{\mathrm{frame}}$,
  $\mathcal{B}_{\mathrm{center}}$,
  $\mathcal{B}_{\mathrm{inc}}$)
  operate within $V_{\mathrm{fg}}$ and cannot register
  changes in $V_{\mathrm{bg}}$.
\end{enumerate}
\end{theorem}

\begin{proof}
Part~(a):
The crossover $|\mathcal{S}_{\mathrm{hid}}|
= |\mathcal{S}_{\mathrm{vis}}|$ occurs when
$\sin^2\theta = \cos^2\theta$, i.e.,
$\theta(t_{\mathrm{del}}) = \pi/4$.
Substituting~\eqref{T-II-eq:theta}:
$\theta_0\,e^{\Lambda\,t_{\mathrm{del}}} = \pi/4$,
which gives~\eqref{T-II-eq:t_delusion}.
The logarithmic dependence on $1/\theta_0$ means that
even a very small initial misalignment ($\theta_0 \sim 10^{-3}$)
delays the trap only by $\sim 7/\Lambda$---a modest
multiple of the environmental Lyapunov time.

Part~(b):
Beyond $t_{\mathrm{del}}$, the gradient
$\nabla\mathcal{S}_{\mathrm{full}}$ points primarily
into $V_{\mathrm{bg}}$ (the hidden sector now carrying
$> 50\%$ of survival weight), while
$\nabla\mathcal{S}_{\mathrm{vis}}$ remains confined to
$V_{\mathrm{fg}}$.
Since the foreground and background subspaces are
orthogonal by construction, the angle between the two
gradients exceeds $\pi/2$, yielding anti-correlation.

Part~(c):
The bias terms
$\mathcal{B}_{\mathrm{select}}$ through
$\mathcal{B}_{\mathrm{inc}}$
(Proposition~\ref{T-II-prop:bias}) are defined
\emph{within} $V_{\mathrm{fg}}$.
The agent's performance metric
$\mathcal{S}_{\mathrm{vis}} =
\mathcal{S}_{\mathrm{tot}}\cos^2\theta$
decreases only at second order in $\theta$,
so it remains positive and shows no anomaly until
$\theta$ is already $O(1)$.
The growing signal in $V_{\mathrm{bg}}$ maps to the null
space of $\Pi_{\mathcal{F}}$ and is strictly invisible.
\end{proof}

\begin{remark}[Linear drift limit]
\label{T-II-rem:linear_drift}
For slow linear drift ($\theta(t) = \varepsilon\,t$,
$\Lambda \to 0$), the crossover occurs at
$t_{\mathrm{del}} = \pi/(4\varepsilon)$.
With $\varepsilon = 0.01\,\omega_0$,
$t_{\mathrm{del}} \approx 79\,\omega_0^{-1}$---long
enough for the agent to accumulate a false sense of
security, yet short on environmental timescales.
\end{remark}

\begin{remark}[Why dithering does not help]
\label{T-II-rem:dithering}
One might ask whether the agent could escape the delusion
trap by randomly ``probing'' the background subspace
$V_{\mathrm{bg}}$---temporarily rotating its frame to
sample hidden components.
This fails for two reasons.
First, each probe costs
$\sim h_\mu \cdot D$ bits of
computation (the Symmetry Tax, Corollary~\ref{T-II-cor:symmetry_tax}),
directly competing with the budget allocated to foreground
processing.
Second---and more fundamentally---the agent has no
\emph{gradient signal} to indicate \emph{when} or
\emph{where} to probe.
As long as $|\mathcal{S}_{\mathrm{hid}}|
< |\mathcal{S}_{\mathrm{vis}}|$ (pre-delusion), the
in-frame performance metric $\mathcal{S}_{\mathrm{vis}}$
shows no anomaly.
The exponential divergence~\eqref{T-II-eq:divergence} is
invisible until it dominates---at which point it is too late.
Systematic correction requires monitoring the \emph{rate of
change} of prediction error, which is a second-order
operation: the subject of Paper~III.
\end{remark}

\begin{remark}[The ego as medicine and poison]
\label{T-II-rem:medicine_poison}
The ego cures computational paralysis
(Theorem~\ref{T-II-thm:comp_ceiling}) but creates the delusion
trap (Theorem~\ref{T-II-thm:delusion}).
It is simultaneously the \emph{medicine} for Paper~I's
crisis and the \emph{poison} that generates Paper~III's
crisis.
This duality is a structural consequence of the irreversible
logic chain: each resolution creates the conditions for the
next crisis.
\end{remark}

% ------------------------------------------------------------
\subsection{The Origin of Paper~III}
\label{T-II-subsec:paper3}

To escape the delusion trap, the agent needs a mechanism
to monitor the quality of its own reference frame---to
``observe its own observation.''
This requires a \emph{second-order control loop}: a
meta-controller that adjusts the gauge fixing $\sigma$ in
response to accumulated prediction errors.

The key difficulty is that the prediction errors the agent
can measure ($\mathcal{S}_{\mathrm{vis}} -
\mathcal{S}_{\mathrm{vis}}^{\mathrm{predicted}}$) all
lie within $V_{\mathrm{fg}}$.
To detect frame drift, the agent must compare these
in-frame errors to an estimate of out-of-frame
contributions---a self-referential operation that requires
\emph{Fisher information about the agent's own parameters}.

This is the subject of Paper~III: the Fisher information
geometry of self-referential calibration, and the
thermodynamic cost of the loop that closes the chain
\emph{Chaos $\to$ Time $\to$ Self $\to$ Calibration}.

% ============================================================
\section{Numerical Demonstration}
\label{T-II-sec:numerical}

The preceding sections establish analytic bounds and a
worked example with a qubit in a two-channel bath.
We now provide a numerical illustration showing that the
core symmetry-breaking signature---attention entropy collapse
under budget constraints---and the resulting selection
advantage are reproduced in a minimal multi-dimensional
system.
Full code and parameters are provided for reproducibility.

% ------------------------------------------------------------
\subsection{Model}
\label{T-II-subsec:demo_model}

\paragraph{Environment.}
A $D$-dimensional linear prediction task with sparse
rotating support:
$y(t) = \mathbf{w}^*(t)^\top \mathbf{x}(t) + \xi(t)$,
$\mathbf{x}(t) \sim \mathcal{N}(\mathbf{0}, \mathbf{I}_D)$,
$\xi \sim \mathcal{N}(0, \sigma^2)$.
Only $m \ll D$ dimensions carry nonzero weight at any time;
the active support rotates every $\tau_{\mathrm{switch}}$
steps, modelling environmental drift.

\paragraph{Hard budget constraint.}
Per step, the agent may update only $k$ coordinates of its
weight vector (a hard processing budget), mirroring the
bounded computation assumption~(B2).

\paragraph{Agents.}
\begin{itemize}
\item \textbf{Budgeted selector (SSB)}: selects the top-$k$
  dimensions by importance score---an exponential moving
  average of the signed per-coordinate gradient.  Signed
  accumulation ensures that noise dimensions (zero expected
  signal) cancel over time while signal dimensions persist,
  enabling reliable discrimination without access to the true
  support.
\item \textbf{Random-$k$ baseline}: selects $k$ dimensions
  uniformly at random each step.  This provides a
  budget-fair comparison: identical mechanism, no symmetry
  breaking.
\end{itemize}

\noindent
The choice of \emph{signed} gradient EMA (rather than
squared-gradient magnitude) is structurally motivated:
for noise dimensions $\mathbb{E}[r\,x_i] = 0$, so the
signed accumulation cancels over time; for signal
dimensions $\mathbb{E}[r\,x_i] \neq 0$, so a consistent
directional bias persists.  The signed EMA thus acts as a
\emph{directional coherence filter} that discriminates
signal from noise without access to the true support---a
minimal realisation of the ``reference-frame bias'' that
emerges from symmetry breaking.

\paragraph{Parameters.}
\begin{center}
\small
\begin{tabular}{@{}lcl@{}}
\toprule
\textbf{Quantity} & \textbf{Value} & \textbf{Role} \\
\midrule
$D$ & 64 & ambient dimension \\
$m$ & 8  & signal dimensions (sparse support) \\
$T$ & $10{,}000$ & horizon per trial \\
Seeds & 10 & independent replications \\
$\sigma$ & 0.3 & observation noise std \\
$\eta$ & 0.02 & SGD learning rate \\
$\lambda$ & 0.995 & weight decay per step \\
$k$ & 2, 4, 6, 8, 10, 12, 16, 20, 24, 32, 48, 64
  & budget grid \\
$\tau_{\mathrm{switch}}$ & $\{500, 1000, 2000\}$
  & support rotation period \\
\bottomrule
\end{tabular}
\end{center}

\paragraph{Attention entropy.}
Let $n_i$ be the number of updates coordinate $i$ receives
in a measurement window of the last $1{,}000$ steps.
The normalised update frequency
$p_i = n_i / \sum_j n_j$ defines the attention entropy:
\begin{equation}
\label{T-II-eq:H_attn}
H_{\mathrm{attn}} = -\sum_{i=1}^{D} p_i \ln p_i.
\end{equation}
Under symmetric processing (no SSB), $p_i = 1/D$ and
$H_{\mathrm{attn}} = \ln D$.  Under budget-constrained
selection, $H_{\mathrm{attn}}$ collapses away from $\ln D$,
serving as an order parameter for symmetry breaking.

\paragraph{Oracle metric.}
Neither agent has access to $\mathbf{w}^*(t)$.
Performance is evaluated externally using the
weight-space mean-squared error
$\mathrm{MSE} = \|\hat{\mathbf{w}} - \mathbf{w}^*\|^2$,
averaged over post-burn-in steps.

% ------------------------------------------------------------
\subsection{Results}
\label{T-II-subsec:demo_results}

Figure~\ref{T-II-fig:kstar_scaling} shows the two key signatures.

\paragraph{Result 1: Attention entropy collapse
(Figure~\ref{T-II-fig:kstar_scaling}a).}
Under fixed support (no rotation), the attention entropy
$H_{\mathrm{attn}}$ exhibits a sharp collapse away from
$\ln D = \ln 64 \approx 4.16$ and increases monotonically
with $k$, consistent with a budget-induced concentration
of update mass onto signal-carrying dimensions.
For budgets near and below the signal scale ($k \leq m$),
$H_{\mathrm{attn}}$ remains $O(\ln m)$, consistent with
confinement to the signal subspace.
We use the collapse of $H_{\mathrm{attn}}$ away from
$\ln D$ as the order parameter of symmetry breaking;
a strict plateau at $\ln m$ is not expected under the
present re-selection dynamics and finite-window estimator.

\paragraph{Result 2: Selection advantage
(Figure~\ref{T-II-fig:kstar_scaling}b).}
Under rotating support, the mean-squared error gap
$\Delta\mathrm{MSE} = \mathrm{MSE}_{\mathrm{rnd}}
- \mathrm{MSE}_{\mathrm{sel}}$ is positive for
$k \lesssim 3m$ and peaks at tight budgets ($k = 2$)
where the selection advantage is strongest.
For $k \gg m$ the gap turns slightly negative
(the selector's commitment to stale dimensions costs
more than the random baseline's diversification),
before returning to zero at $k = D$.
The three $\tau_{\mathrm{switch}}$ curves are ordered:
slower drift (larger $\tau$) yields a larger peak gap,
with the ordering most visible at small $k$.

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]%
  {fig_paper2_kstar_scaling.pdf}
\caption{%
\textbf{Budget-induced symmetry breaking.}
$D = 64$, $m = 8$, $T = 10{,}000$, 10 seeds, 95\% CI bands.
\textbf{(a)}~Attention entropy $H_{\mathrm{attn}}$ vs
budget $k$ (fixed support).  The empirical curve (blue)
collapses from $\ln D \approx 4.16$ toward an
$O(\ln m)$ floor as budget tightens.
For $k \leq m$, $H_{\mathrm{attn}}$ remains below
$\ln m \approx 2.08$ (green dashed), consistent with
confinement to the signal subspace.
\textbf{(b)}~Selection advantage
$\Delta\mathrm{MSE} = \mathrm{MSE}_{\mathrm{rnd}}
- \mathrm{MSE}_{\mathrm{sel}}$ vs budget $k$ under
rotating support.  The gap is positive for $k \lesssim 3m$
(selection helps), turns slightly negative at large $k$
(commitment cost exceeds diversification), and returns
to zero at $k = D$.  Slower drift ($\tau = 2000$)
yields a larger peak advantage.}
\label{T-II-fig:kstar_scaling}
\end{figure}

% ------------------------------------------------------------
\subsection{Scope of This Demonstration}
\label{T-II-subsec:demo_scope}

These simulations illustrate the symmetry-breaking
phenomenon predicted by Theorem~\ref{T-II-thm:SSB} under
the stated model class; they do not constitute a proof
beyond this class.

\medskip
This demonstration \textbf{does} show:
\begin{enumerate}
\item Under hard budget constraints, attention entropy
  collapses sharply away from $\ln D$ and remains
  $O(\ln m)$ for $k \leq m$---the agent confines its
  updates to the signal subspace.
  This is the computational analogue of spontaneous
  symmetry breaking (Theorem~\ref{T-II-thm:SSB}).
\item A budgeted selector that exploits importance-weighted
  selection systematically outperforms a budget-fair
  random baseline, consistent with a survival advantage
  in the broken phase
  (cf.~Proposition~\ref{T-II-prop:speedup}).
\item The advantage scales with both budget tightness
  (smaller $k$) and environmental stability (larger
  $\tau_{\mathrm{switch}}$).
\end{enumerate}

\noindent
In summary, this demonstration validates the
\emph{existence} and \emph{measurability} of
budget-induced symmetry breaking in a minimal linear
setting; it does not claim universality across
architectures or environment classes.

\medskip
This demonstration does \textbf{not} show:
\begin{enumerate}
\item That $H_{\mathrm{attn}}$ reaches a strict plateau
  at $\ln m$ for all $k \leq m$.  Under the adaptive
  re-selection dynamics used here, the selector cycles
  within the signal subspace, producing
  $H_{\mathrm{attn}}$ values near but not locked to
  $\ln m$.  The relevant signature is the collapse
  \emph{away from} $\ln D$, not convergence to a
  specific lower bound.
\item That the specific form of the importance score
  (signed gradient EMA) is optimal.  It is one
  realisation of the selection mechanism.
\item That the results generalise to all environment
  classes.  The model uses Gaussian features, linear
  regression, and sparse rotating support.
\item That the delusion--correction cycle is addressed.
  This is the subject of Paper~III.
\end{enumerate}

\paragraph{Reproducibility.}
The complete simulation is a self-contained Python script
(\texttt{paper2\_kstar\_scaling\_demo.py}, ${\sim}\,540$
lines, requiring only NumPy and Matplotlib) with fixed
random seeds.  All figures in this section can be
reproduced by executing the script.  The following files
are included in the supplementary archive:
\begin{itemize}
\item \texttt{paper2\_kstar\_scaling\_demo.py} --- simulation script
\item \texttt{fig\_paper2\_kstar\_scaling.pdf} --- Figure~\ref{T-II-fig:kstar_scaling}
\item \texttt{kstar\_scaling\_data.csv} --- raw performance gap data
\end{itemize}

% ============================================================
\section{Discussion}
\label{T-II-sec:discussion}

% ------------------------------------------------------------
\subsection{Summary of Results}
\label{T-II-subsec:summary}

\begin{center}
\small
\setlength{\tabcolsep}{4pt}%
\begin{tabular}{@{}lp{6cm}c@{}}
\toprule
\textbf{Result} & \textbf{Statement} & \textbf{Sec.} \\
\midrule
Computational Ceiling
  & Symmetric processing cost exceeds
    $\mathcal{C}_{\mathrm{budget}}$ at
    $\tau_{\mathrm{par}}$
  & \ref{T-II-sec:ceiling} \\[3pt]
Rate-Distortion Bound
  & Optimal compression retains
    $k^* = \mathcal{C}_{\mathrm{budget}}/h_\mu$
    components
  & \ref{T-II-subsec:RD_bound} \\[3pt]
Necessity of SSB
  & Under bounded computation, survival requires gauge fixing
  & \ref{T-II-subsec:SSB} \\[3pt]
Four Bias Terms
  & Broken phase acquires $\mathcal{B}_{\mathrm{select}}$,
    $\mathcal{B}_{\mathrm{frame}}$,
    $\mathcal{B}_{\mathrm{center}}$,
    $\mathcal{B}_{\mathrm{inc}}$
  & \ref{T-II-subsec:bias} \\[3pt]
Survival Decomposition
  & $\mathcal{S} = \mathcal{S}_{\mathrm{vis}} +
    \mathcal{S}_{\mathrm{hid}}$
  & \ref{T-II-subsec:effective} \\[3pt]
Ego-Entropy Trade-off
  & $\gtrsim 1 - k^*/\dim Cl(V,q)$ of
    $I_{\mathrm{pred}}$ discarded (uniformity assumption)
  & \ref{T-II-subsec:tradeoff} \\[3pt]
Delusion Trap
  & Fixed frame diverges from optimal under environmental
    drift; agent cannot self-detect
  & \ref{T-II-subsec:delusion} \\[3pt]
Numerical demo
  & Budget-induced SSB and selection advantage
    (Fig.~\ref{T-II-fig:kstar_scaling})
  & \ref{T-II-sec:numerical} \\
\bottomrule
\end{tabular}
\end{center}

% ------------------------------------------------------------
\subsection{What This Paper Does and Does Not Show}
\label{T-II-subsec:claims}

This paper \textbf{does} show:
\begin{enumerate}
\item Under bounded computation~(B2) and non-trivial
  environment~(B3), symmetric processing of memory leads
  to computational paralysis (Theorem~\ref{T-II-thm:comp_ceiling}).
\item The survival-optimal response is spontaneous symmetry
  breaking of the internal reference frame
  (Theorem~\ref{T-II-thm:SSB}), governed by a rate-distortion
  bound (Theorem~\ref{T-II-thm:compression}).
\item The broken phase acquires four generic bias
  terms under~(B1)--(B5) (Proposition~\ref{T-II-prop:bias}).
\item Under environmental drift, a fixed frame leads to
  exponential divergence of prediction error---the
  Delusion Trap (Theorem~\ref{T-II-thm:delusion}).
\item A minimal computational demonstration reproduces
  the budget-induced symmetry-breaking signature (attention
  entropy collapse away from $\ln D$) and selection
  advantage over a budget-fair random baseline
  (Section~\ref{T-II-sec:numerical},
  Figure~\ref{T-II-fig:kstar_scaling}).
\end{enumerate}

\medskip
This paper does \textbf{not} show:
\begin{enumerate}
\item That the privileged basis is uniquely determined by
  computational constraints. The basis is constrained but
  not unique---different histories lead to different gauge
  fixings, as in a ferromagnet.
\item That symmetry breaking is sufficient for persistence.
  It is the survival-optimal strategy under bounded computation;
  sufficiency
  requires the self-referential calibration of Paper~III.
\item That the ``ego'' implies or requires consciousness,
  subjective experience, or phenomenal awareness.
  The term is used strictly in the control-theoretic sense.
\item That this framework constitutes a theory of
  consciousness. It is a theory of computational optimality
  under thermodynamic constraints.
\item That the four bias terms exhaust the phenomenology of
  self-reference. They are the minimal structural
  consequences of gauge fixing in a Clifford algebra.
\item That the rate-distortion bound is achievable by any
  specific physical implementation. It is an
  information-theoretic lower bound.
\item That the Delusion Trap is inescapable. Paper~III will
  show it can be mitigated by self-referential calibration.
\item That the framework constitutes or implies a
  philosophical or metaphysical claim about the nature
  of selfhood.
\item That this framework applies to all possible physical
  systems. It applies to systems
  satisfying~(B1)--(B5)---persistent agents with finite
  computation in non-trivial environments.
\item That the Clifford algebra is the only possible
  algebraic setting. It is the minimal setting inherited
  from Q-RAIF. Other algebras may yield analogous results.
\end{enumerate}

% ============================================================
% REFERENCES
% ============================================================

% ============================================================================
% PAPER III
% ============================================================================
\chapter{Fisher Information Geometry and the Thermodynamic Cost of Self-Referential Calibration}
\label{T-chap:paperIII}

\begin{center}
\textit{Paper III --- ``The Loop''}\\[0.5em]
Originally published: Zenodo, DOI: 10.5281/zenodo.18591771
\end{center}

\bigskip

\section*{Abstract}
Papers~I and~II of the T-DOME
series~\cite{Liu2026TDOME_I,Liu2026TDOME_II} established
that persistent agents must carry non-Markovian memory
(Paper~I) and must spontaneously break the gauge symmetry of
their internal Clifford algebra $Cl(V,q)$ to form a
compressed reference frame---the ``ego''
$\mathfrak{E} = (\mathcal{F}^*,\,V_{\mathrm{fg}}^*)$
(Paper~II).
Paper~II concluded with the \textbf{Delusion Trap}: under
environmental drift, a fixed reference frame decouples from
the optimal gauge on the logarithmic timescale
$t_{\mathrm{del}}
= \Lambda^{-1}\ln(\pi/4\theta_0)$,
and the agent cannot detect this failure from within its own
foreground subspace $V_{\mathrm{fg}}$.

In this final work we derive the theory of
\textbf{self-referential calibration}.
We show that while the agent cannot observe the background
subspace $V_{\mathrm{bg}}$ directly, it can measure the
\textbf{Fisher information} of its own prediction-residual
stream with respect to its frame parameters~$\sigma$.
We prove three main results:
\begin{enumerate}
\item \textbf{Drift Detectability}
  (Theorem~\ref{T-III-thm:detectability}):
  environmental drift generates a quadratically growing
  signal in the self-referential Fisher information
  $\mathcal{I}_F(\sigma)$, detectable before the
  Delusion Trap closes.
\item \textbf{Self-Referential Cram\'{e}r--Rao Bound}
  (Theorem~\ref{T-III-thm:SRCR}):
  the agent's drift-estimation error is bounded below by
  $1/(n_{\mathrm{eff}}\,\mathcal{I}_F + \mathcal{I}_{\mathrm{ego}})$,
  where $\mathcal{I}_{\mathrm{ego}}$ quantifies the
  rigidity of the ego prior.
\item \textbf{Thermodynamic Cost of the Loop}
  (Theorem~\ref{T-III-thm:loop_cost}):
  the minimum dissipation rate for self-referential
  calibration is
  $\dot{W}_{\mathrm{loop}}
  \geq k_BT\,\ln 2\,[h_\mu\,k^*
  + \mathcal{C}_{\mathrm{meta}}]
  + \mathcal{L}^2/\tau_{\mathrm{recalib}}^2$,
  where $\mathcal{L}$ is the thermodynamic length of the
  frame update and $\tau_{\mathrm{recalib}}$ is the
  recalibration time.
\end{enumerate}
The calibration loop satisfies a Lyapunov tracking bound
(Theorem~\ref{T-III-thm:loop_stability}),
keeping the mismatch within a neighbourhood whose size is
set by the ratio of environmental drift speed to adaptation
rate.
We identify this loop as the minimal physical realisation of
\emph{reflexivity}---estimating drift from residual
statistics and correcting the frame via Lyapunov-monitored
natural gradient descent.
Combining with Papers~I and~II, we state a
\textbf{Four-Part Structure Proposition}
(Proposition~\ref{T-III-prop:four_part}):
within the class of agents satisfying~(C1)--(C5),
a sufficient architecture for persistence under drift
requires
(1)~an external observable geometry,
(2)~an internal control algebra,
(3)~a self-monitoring Lyapunov function, and
(4)~biased non-Markovian memory.


% ============================================================
\section{Introduction}
\label{T-III-sec:intro}

% ------------------------------------------------------------
\subsection{Context: The Delusion Trap}
\label{T-III-subsec:delusion_context}

Paper~II of this series~\cite{Liu2026TDOME_II} established
that persistent agents under bounded computation must
spontaneously break the gauge symmetry of their internal
algebra $Cl(V,q)$, selecting a privileged reference frame
$\mathcal{F}^*$ that compresses the memory kernel into a
tractable $k^*$-dimensional foreground subspace
$V_{\mathrm{fg}}$.
This gauge fixing---the ``ego''
$\mathfrak{E} := (\mathcal{F}^*,\,V_{\mathrm{fg}}^*)$---is
not an additional hypothesis but the survival-optimal strategy
under bounded rationality.

However, Paper~II's final theorem revealed a fatal
consequence.
Under environmental drift (spectral-density parameters
changing at rate~$\varepsilon$), the mismatch angle between
the agent's fixed frame and the instantaneous optimal frame
grows as
$\theta(t) = \theta_0\,e^{\Lambda t}$
(Paper~II, Definition~27),
where $\Lambda \sim \varepsilon/\tau_{\mathrm{adapt}}$
is the environmental Lyapunov exponent.
Beyond the \emph{delusion time}
\begin{equation}
\label{T-III-eq:t_del_recall}
t_{\mathrm{del}}
= \frac{1}{\Lambda}\,
\ln\!\left(\frac{\pi/4}{\theta_0}\right),
\end{equation}
three catastrophic failures occur simultaneously
(Paper~II, Theorem~29):
\begin{enumerate}
\item The hidden survival component dominates:
  $|\mathcal{S}_{\mathrm{hid}}|
  > |\mathcal{S}_{\mathrm{vis}}|$.
\item The agent's update direction anti-correlates with
  the true survival gradient:
  $\langle \nabla_u\mathcal{S}_{\mathrm{vis}},\,
  \nabla_u\mathcal{S}_{\mathrm{full}}\rangle
  < 0$.
\item All four bias terms
  ($\mathcal{B}_{\mathrm{select}}$,
  $\mathcal{B}_{\mathrm{frame}}$,
  $\mathcal{B}_{\mathrm{center}}$,
  $\mathcal{B}_{\mathrm{inc}}$)
  operate within $V_{\mathrm{fg}}$ and cannot register
  changes in the background $V_{\mathrm{bg}}$.
\end{enumerate}

Paper~II further showed
(Remark~31)
that ``dithering''---randomly probing the background
subspace---fails because the agent has no gradient signal to
indicate \emph{when} or \emph{where} to probe.
The exponential divergence in $V_{\mathrm{bg}}$ is invisible
until it dominates, at which point it is too late.

\emph{The present paper provides the escape.}

% ------------------------------------------------------------
\subsection{Position within Papers~I--III}
\label{T-III-subsec:sequence}

This paper is the third and final of the T-DOME framework,
closing the three-paper sequence.

\begin{center}
\small
\setlength{\tabcolsep}{4pt}%
\begin{tabular}{@{}lp{3.5cm}p{4.2cm}c@{}}
\toprule
\textbf{Framework} & \textbf{Question} & \textbf{Result}
  & \textbf{Status} \\
\midrule
HAFF~\cite{Liu2026HAFF_A,Liu2026HAFF_B}
  & How does geometry emerge?
  & Algebra $\to$ Geometry
  & Complete \\[3pt]
Q-RAIF~\cite{Liu2026QRAIF_A,Liu2026QRAIF_B}
  & What algebra must an observer have?
  & $Cl(V,q) \hookrightarrow Cl(1,3)$
  & Complete \\[3pt]
T-DOME~I~\cite{Liu2026TDOME_I}
  & Why must agents carry memory?
  & Markovian ceiling; memory as necessity
  & Complete \\[3pt]
T-DOME~II~\cite{Liu2026TDOME_II}
  & Why must agents break symmetry?
  & Reference-frame selection under bounded computation
  & Complete \\[3pt]
\textbf{T-DOME~III} (this work)
  & How does self-calibration arise?
  & Fisher self-referential bound;
    thermodynamic cost of reflexivity
  & \textbf{This paper} \\
\bottomrule
\end{tabular}
\end{center}

The three T-DOME papers form an irreversible logical chain:
\begin{enumerate}
\item \textbf{Paper~I:} Without memory, a system
  is trapped in the Markovian present.
  Memory breaks this trap but floods the system with
  unbounded historical data.
\item \textbf{Paper~II:} Unbounded memory under
  finite computational resources causes processing collapse.
  Spontaneous symmetry breaking resolves the overload but
  introduces systematic bias.
\item \textbf{Paper~III (this work):} Uncorrected
  bias diverges from a changing environment.
  A self-referential calibration loop---monitoring the
  Fisher information of one's own prediction stream---resolves
  the bias but requires a second-order control structure and
  an irreducible thermodynamic cost.
\end{enumerate}

Each resolution creates the precondition for the next
crisis: memory enables overload, compression enables bias,
and bias demands calibration.
Only the complete closure
\emph{Paper~I $+$ Paper~II $+$ Paper~III}
allows a system to persist under the Second Law in a
drifting environment.

% ------------------------------------------------------------
\subsection{The Information-Geometric Insight}
\label{T-III-subsec:insight}

The key observation that resolves the Delusion Trap is
subtle:
\emph{while the agent cannot observe $V_{\mathrm{bg}}$
directly, it can observe the statistical properties of its
own prediction residuals in $V_{\mathrm{fg}}$.}

The prediction residual
$e(t) := \mathcal{S}_{\mathrm{vis}}(t)
- \mathcal{S}_{\mathrm{vis}}^{(\mathrm{pred})}(t)$
lies in $V_{\mathrm{fg}}$ by construction.
Its \emph{value} carries no information about the background.
But its \emph{distribution}---the probability law
$p(e\,|\,\sigma)$, parametrised by the gauge-fixing
parameter~$\sigma$---does depend on~$\sigma$, because the
projection $\Pi_{\mathcal{F}}(\sigma)$ determines which
environmental correlations are captured and which are
discarded.

When the frame $\sigma$ drifts away from the optimal
$\sigma^*$, the residual distribution shifts.
The \emph{Fisher information metric}
\begin{equation}
\label{T-III-eq:fisher_preview}
g_{ij}(\sigma)
= \mathbb{E}_\sigma\!\left[
  \frac{\partial \log p(e\,|\,\sigma)}
       {\partial \sigma^i}\,
  \frac{\partial \log p(e\,|\,\sigma)}
       {\partial \sigma^j}
\right]
\end{equation}
measures the sensitivity of this distribution to changes
in~$\sigma$.
A spike in $g_{ij}$---a ``stress'' in the agent's
internal geometry---is the signal that the reference frame
is becoming stale.

This is the mathematical realisation of the
``second-order operation'' demanded by
Paper~II, Section~7.5: the agent does not need to see the
truth (the full $Cl(V,q)$), but only the \emph{rate of
change of its own prediction error} as a function of its
frame parameters.
Fisher information is precisely this quantity.

% ------------------------------------------------------------
\subsection{Relation to Architectural Incompleteness}
\label{T-III-subsec:haff_g}

The architectural incompleteness
result~\cite{Liu2026HAFF_G} established
\emph{architectural incompleteness}: the observable-algebra
framework cannot self-ground.
Paper~II provided a partial operational response (the ego as
gauge fixing under bounded computation).
The present paper provides the final operational response:
the self-referential calibration loop cannot \emph{eliminate}
architectural incompleteness, but it can \emph{track}
the consequences of incompleteness in real time.
The Lyapunov function $V(\sigma)$ monitors the distance
between the agent's frame and the optimal frame without
requiring access to the ``complete'' description---it
operates entirely within the agent's own predictive
statistics.

% ------------------------------------------------------------
\subsection{Scope and Disclaimers}
\label{T-III-subsec:scope}

\begin{enumerate}
\item \emph{Reflexivity} refers throughout to
  second-order control: the ability of a system to
  monitor and adjust its own monitoring process.
  It carries \emph{no} implication of phenomenal
  consciousness, subjective experience, or qualia.
\item The self-referential calibration loop does not
  \emph{eliminate} the ego's bias; it tracks and
  compensates for drift in the bias.
  The four bias terms of Paper~II persist in the
  calibrated phase.
\item The thermodynamic cost bounds are
  information-theoretic lower bounds, not claims about
  specific physical implementations.
\item The framework applies to systems
  satisfying~(C1)--(C5) (Section~\ref{T-III-subsec:standing_C}).
  It is not a universal theory of agency.
\end{enumerate}

\paragraph{Related work.}
The Fisher information metric on statistical manifolds was
introduced by Rao~\cite{Rao1945} and shown to be unique
by \v{C}encov~\cite{Cencov1982}.
The natural gradient and information geometry were developed
by Amari~\cite{Amari1998,AmariNagaoka2000}.
Thermodynamic length and optimal finite-time transformations
were established by
Crooks~\cite{Crooks2007} and
Sivak--Crooks~\cite{SivakCrooks2012}.
The connection between Fisher information and entropy
production was formalised by Ito~\cite{Ito2018} and
Barato--Seifert~\cite{BaratoSeifert2015}.
Second-order cybernetics originates with
Ashby~\cite{Ashby1956} and
von Foerster~\cite{vonFoerster2003}.
Adaptive control and self-tuning regulators are treated
in~\cite{AstromWittenmark1995}.
The Bayesian Cram\'{e}r--Rao bound (van Trees inequality)
is from~\cite{vanTrees1968}.

\paragraph{Summary of contributions.}
This paper establishes three main results:
\begin{enumerate}
\item \textbf{Drift Detectability}
  (Theorem~\ref{T-III-thm:detectability}):
  the self-referential Fisher information of the
  prediction-residual stream grows quadratically with
  accumulated drift, providing a detectable signal
  before the Delusion Trap closes.
\item \textbf{Self-Referential Cram\'{e}r--Rao Bound}
  (Theorem~\ref{T-III-thm:SRCR}):
  drift-estimation precision is bounded by the sum of
  data Fisher information and ego rigidity.
\item \textbf{Thermodynamic Cost}
  (Theorem~\ref{T-III-thm:loop_cost}):
  the self-calibration loop requires a minimum
  dissipation rate with three distinct components
  (sensing, computing, actuating).
\end{enumerate}

% ============================================================
\section{Mathematical Preliminaries}
\label{T-III-sec:prelim}

% ------------------------------------------------------------
\subsection{Inherited Framework from Papers~I and~II}
\label{T-III-subsec:inherited}

We briefly recall the key objects; the reader is referred to
Papers~I and~II for full definitions and proofs.

\paragraph{From Paper~I~\cite{Liu2026TDOME_I}.}
\begin{itemize}
\item \textbf{Survival functional.}
  $\mathcal{S}[\Lambda,\tau]
  := \Delta F - W[0,\tau]$~(Paper~I,
  Eq.~(9)).
\item \textbf{Markovian Ceiling.}
  $\mathcal{S}[\Lambda^{\mathrm{M}},\tau] \leq 0$ for all
  $\tau \geq 0$.
\item \textbf{Memory kernel.}
  $\mathcal{K}(t,s)$: the non-Markovian superoperator
  encoding system--environment correlations.
\item \textbf{Entropy rate.}
  $h_\mu := \lim_{T\to\infty}T^{-1}H(X_{0:T})$ (bits per
  unit time per algebraic component).
\item \textbf{Predictive information.}
  $I_{\mathrm{pred}}
  := I(\overleftarrow{X};\,\overrightarrow{X})$.
\end{itemize}

\paragraph{From Paper~II~\cite{Liu2026TDOME_II}.}
\begin{itemize}
\item \textbf{Internal algebra.}
  $\mathcal{O}_{\mathrm{int}} = Cl(V,q)$, $D = \dim Cl(V,q) = 2^n$,
  gauge group $G = \mathrm{Aut}(Cl(V,q))$.
\item \textbf{Gauge bundle.}
  $\pi: P \to M$, structure group $G$; a section
  $\sigma: M \to P$ is a reference frame.
\item \textbf{Ego.}
  $\mathfrak{E} := (\mathcal{F}^*,\,V_{\mathrm{fg}}^*)$
  with $k^* = \lfloor \mathcal{C}_{\mathrm{budget}}/
  h_\mu \rfloor$ foreground components.
\item \textbf{Projected kernel.}
  $\mathcal{K}_{\mathcal{F}}(t,s)
  = \Pi_{\mathcal{F}}\,\mathcal{K}(t,s)\,
  \Pi_{\mathcal{F}}$.
\item \textbf{Survival decomposition.}
  $\mathcal{S} = \mathcal{S}_{\mathrm{vis}}(\mathcal{F})
  + \mathcal{S}_{\mathrm{hid}}(\mathcal{F})$.
\item \textbf{Four bias terms.}
  $\mathcal{B}_{\mathrm{select}}$,
  $\mathcal{B}_{\mathrm{frame}}$,
  $\mathcal{B}_{\mathrm{center}}$,
  $\mathcal{B}_{\mathrm{inc}}$
  (Paper~II, Proposition~18, Table~2).
\item \textbf{Delusion Trap.}
  $t_{\mathrm{del}}
  = \Lambda^{-1}\ln(\pi/4\theta_0)$
  (Paper~II, Theorem~29).
\item \textbf{Information-objects convention.}
  $I(\mathcal{K}_{\mathcal{F}};\,\mathcal{K})
  \equiv I(\hat{X};\,X)$ on induced record processes
  (Paper~II, Remark~15).
\end{itemize}

% ------------------------------------------------------------
\subsection{Fisher Information Metric}
\label{T-III-subsec:fisher}

\begin{definition}[Fisher information matrix]
\label{T-III-def:fisher}
Let $\{p(x\,|\,\theta) : \theta \in \Theta
\subset \mathbb{R}^d\}$ be a parametric family of
probability densities satisfying standard regularity
conditions (interchange of differentiation and integration).
The \emph{Fisher information matrix} is
\begin{equation}
\label{T-III-eq:fisher_def}
g_{ij}(\theta)
:= \mathbb{E}_\theta\!\left[
  \frac{\partial \log p(x\,|\,\theta)}
       {\partial \theta^i}\,
  \frac{\partial \log p(x\,|\,\theta)}
       {\partial \theta^j}
\right]
= -\mathbb{E}_\theta\!\left[
  \frac{\partial^2 \log p(x\,|\,\theta)}
       {\partial \theta^i\,\partial \theta^j}
\right].
\end{equation}
The pair $(\Theta,\,g)$ is a Riemannian manifold called the
\emph{statistical manifold}.
\end{definition}

\begin{remark}[Uniqueness]
\label{T-III-rem:cencov}
By \v{C}encov's theorem~\cite{Cencov1982}, the Fisher--Rao
metric $g^{\mathrm{FR}}$ is, up to a positive scalar
multiple, the unique Riemannian metric on the space of
probability distributions that is invariant under all
Markov morphisms (sufficient-statistic embeddings).
This uniqueness guarantees that the Fisher metric is the
\emph{canonical} choice for measuring drift on the
statistical manifold of the agent's predictive model---it is
not a design choice but a mathematical necessity.
\end{remark}

\begin{proposition}[Cram\'{e}r--Rao bound]
\label{T-III-prop:CR}
For any unbiased estimator $\hat{\theta}$ of $\theta$ based
on $n$ independent observations:
\begin{equation}
\label{T-III-eq:CR}
\mathrm{Cov}(\hat{\theta})
\;\succeq\; \frac{1}{n}\,\bigl[g(\theta)\bigr]^{-1}
\end{equation}
in the L\"{o}wner order.
The scalar case reads
$\mathrm{Var}(\hat{\theta})
\geq 1/\bigl(n\,g(\theta)\bigr)$.
\end{proposition}

\begin{remark}[Effective independence]
\label{T-III-rem:effective_independence}
Throughout this paper, references to ``independent
observations'' in the context of continuous-time residual
streams should be read as \emph{effective independence}
after thinning by the environmental decorrelation
time~$\tau_E$, yielding an effective sample size
$n_{\mathrm{eff}} \approx T/\tau_E$.
In particular, the sample count $n$ in~\eqref{T-III-eq:CR}
becomes $n_{\mathrm{eff}}$ in the self-referential
setting of Section~\ref{T-III-subsec:SRCR}.
\end{remark}

\begin{remark}[Fisher metric and KL divergence]
\label{T-III-rem:fisher_KL}
The Fisher metric arises as the Hessian of the
Kullback--Leibler divergence~\cite{CoverThomas2006}:
\begin{equation}
\label{T-III-eq:fisher_KL}
D_{\mathrm{KL}}\bigl(p_\theta \,\|\, p_{\theta+d\theta}\bigr)
= \tfrac{1}{2}\,g_{ij}(\theta)\,d\theta^i\,d\theta^j
  + O\!\left(|d\theta|^3\right).
\end{equation}
This identifies the Fisher metric as the infinitesimal
measure of statistical distinguishability.
\end{remark}

% ------------------------------------------------------------
\subsection{Information Geometry}
\label{T-III-subsec:info_geom}

Following Amari~\cite{Amari1985,AmariNagaoka2000}, the
statistical manifold $(\Theta,\,g)$ carries additional
geometric structure beyond the Riemannian metric.

\paragraph{$\alpha$-connections.}
For each $\alpha \in [-1,\,1]$, Amari defines an affine
connection $\nabla^{(\alpha)}$ on $\Theta$.
The cases $\alpha = 1$ (exponential connection,
$\nabla^{(e)}$) and $\alpha = -1$ (mixture connection,
$\nabla^{(m)}$) are \emph{dual} with respect to $g$:
$\partial_k\,g(X,Y)
= g(\nabla_k^{(e)}X,\,Y)
+ g(X,\,\nabla_k^{(m)}Y)$.
For exponential families, $\nabla^{(e)}$ is flat in natural
parameters and $\nabla^{(m)}$ is flat in expectation
parameters---the \emph{dually flat structure}.
The case $\alpha = 0$ recovers the Levi-Civita connection of
the Fisher metric.

\paragraph{Natural gradient.}
Standard gradient descent in parameter space ignores the
curvature of the statistical manifold.
The \emph{natural gradient}~\cite{Amari1998}
\begin{equation}
\label{T-III-eq:natural_gradient}
\dot{\theta}
= -\eta\,g^{-1}(\theta)\,\nabla_\theta L(\theta),
\end{equation}
where $\eta > 0$ is the learning rate and $L(\theta)$ is a
loss function, provides the steepest descent direction in the
Fisher metric.
It is reparametrisation-invariant and Fisher-efficient
(achieves the Cram\'{e}r--Rao bound asymptotically).

\paragraph{Pythagorean theorem.}
In a dually flat space, the KL divergence satisfies
a generalised Pythagorean relation:
$D_{\mathrm{KL}}(p\,\|\,r)
= D_{\mathrm{KL}}(p\,\|\,q)
+ D_{\mathrm{KL}}(q\,\|\,r)$
when $q$ is the $m$-projection of $p$ onto a
submanifold containing $r$.
This decomposition will be applied to separate the
foreground-recoverable and background-irrecoverable
components of drift.

% ------------------------------------------------------------
\subsection{Thermodynamic Length}
\label{T-III-subsec:thermo_length}

\begin{definition}[Thermodynamic length]
\label{T-III-def:thermo_length}
Let $\lambda(t)$ for $t \in [0,\tau]$ be a path through
control parameter space, and let $\zeta_{ij}(\lambda)$ be the
\emph{friction tensor} (the time-integrated equilibrium
force--force correlation function at~$\lambda$).
The \emph{thermodynamic length} of the
path~\cite{Crooks2007} is
\begin{equation}
\label{T-III-eq:thermo_length}
\mathcal{L}
:= \int_0^\tau
\sqrt{\zeta_{ij}(\lambda)\,
  \dot{\lambda}^i\,\dot{\lambda}^j}\;dt.
\end{equation}
\end{definition}

\begin{proposition}[Sivak--Crooks bound]
\label{T-III-prop:sivak_crooks}
The excess (dissipated) work during a finite-time
transformation of duration $\tau$ satisfies~\cite{SivakCrooks2012}
\begin{equation}
\label{T-III-eq:sivak_crooks}
W_{\mathrm{ex}} \;\geq\; \frac{\mathcal{L}^2}{\tau}.
\end{equation}
The minimum is achieved by the geodesic of the friction
tensor $\zeta$.
In the linear-response regime, the friction tensor is
related to the Fisher metric of the equilibrium distribution
at $\lambda$ by
$\zeta_{ij}(\lambda)
\sim \tau_{\mathrm{relax}}\,g_{ij}^{\mathrm{Fisher}}(\lambda)$,
where $\tau_{\mathrm{relax}}$ is the relaxation time.
\end{proposition}

% ------------------------------------------------------------
\subsection{Second-Order Cybernetics}
\label{T-III-subsec:cybernetics}

Von Foerster~\cite{vonFoerster2003} distinguished two levels
of control:
\begin{itemize}
\item \textbf{First-order cybernetics}: feedback control of
  observed systems.
  The controller adjusts its actions based on the output of
  a sensor.
  Paper~II's ego is a first-order structure: it processes
  environmental data within a fixed frame.
\item \textbf{Second-order cybernetics}: feedback control of
  the \emph{observing} system itself.
  The controller adjusts the \emph{sensor}---or equivalently,
  the reference frame within which the sensor operates.
  This is what Paper~III provides.
\end{itemize}

Ashby's Law of Requisite Variety~\cite{Ashby1956} provides a
lower bound on the complexity of the meta-controller:
\begin{equation}
\label{T-III-eq:requisite_variety}
\dim\!\left(\text{meta-controller state space}\right)
\;\geq\; \dim\!\left(\text{environmental drift subspace}\right).
\end{equation}
The meta-observer must have at least as many adjustable
parameters as there are independent modes of environmental
drift.

In adaptive control
theory~\cite{AstromWittenmark1995}, the analogous result is
the \emph{persistent excitation} condition: parameter
estimates converge if and only if the input signal is
``rich enough'' to excite all modes of the system.
In our framework, persistent excitation corresponds to
$h_\mu > 0$---the environment must continue to generate
novelty for the self-calibration loop to function.

\begin{remark}[Operational content]
\label{T-III-rem:cybernetics_operational}
The second-order cybernetic structure in this paper is
\emph{not} a philosophical metaphor.
It has concrete operational content: the natural gradient
update~\eqref{T-III-eq:natural_gradient} is a specific algorithm
that takes as input the Fisher information of the residual
stream and produces as output an update to the frame
parameter~$\sigma$.
This algorithm can be implemented by any physical system
capable of accumulating second-moment statistics of its own
prediction errors over a window of length~$T \geq \tau_E$.
\end{remark}

% ------------------------------------------------------------
\subsection{Standing Assumptions}
\label{T-III-subsec:standing_C}

\begin{definition}[Standing Assumptions]
\label{T-III-def:assumptions_C}
Throughout this paper, the following conditions are assumed:
\begin{enumerate}
\item[\textup{(C1)}] \textbf{Inherited framework.}
  All assumptions (B1)--(B5) of
  Paper~II~\cite{Liu2026TDOME_II} remain in force.
  This transitively includes (A1)--(A5) of
  Paper~I~\cite{Liu2026TDOME_I}
  (open quantum system, thermal bath, well-defined free
  energy, finite Hilbert space, weak coupling) and the
  realizability embedding
  $\phi: Cl(V,q) \hookrightarrow Cl(1,3)$
  (Q-RAIF~\cite{Liu2026QRAIF_C}).
  We invoke this embedding strictly as a structural
  inheritance from the earlier papers; no new physical
  claims about $Cl(1,3)$ spacetime are introduced here.
  Additionally, the Delusion Trap is active:
  $\tau_{\mathrm{mem}} > \tau_{\mathrm{par}}$ and
  $\Lambda > 0$.
\item[\textup{(C2)}] \textbf{Environmental drift.}
  The instantaneous optimal frame
  $\mathcal{F}^*(t)$ rotates continuously in~$G$ at
  a rate characterised by the Lyapunov exponent
  $\Lambda > 0$~(Paper~II, Eq.~(37)).
\item[\textup{(C3)}] \textbf{Finite meta-observer budget.}
  The self-calibration loop has a computational budget
  $\mathcal{C}_{\mathrm{meta}} < \infty$ (bits per unit
  time), distinct from the ego's processing budget
  $\mathcal{C}_{\mathrm{budget}}$.
\item[\textup{(C4)}] \textbf{Regularity.}
  The agent's predictive family
  $\{p(e\,|\,\sigma)
  : \sigma \in G/H\}$ satisfies standard Fisher
  information regularity: full rank, finite Fisher matrix,
  and interchange of differentiation and integration.
  This extends (A5) from Paper~I.
\item[\textup{(C5)}] \textbf{Persistent excitation.}
  The environmental entropy rate satisfies
  $h_\mu > 0$ for all~$t$.
  The environment generates new information indefinitely;
  no ``frozen'' regimes occur.
\end{enumerate}
\end{definition}

% ============================================================
\section{The Drift Detection Problem}
\label{T-III-sec:detection}

% ------------------------------------------------------------
\subsection{Why First-Order Control Fails}
\label{T-III-subsec:first_order}

\begin{theorem}[First-Order Insufficiency]
\label{T-III-thm:first_order}
Under assumptions~\textup{(C1)--(C5)}, decompose the
prediction residual as
$e(t) = e_{\mathrm{drift}}(t) + \xi(t)$,
where $e_{\mathrm{drift}}$ is the deterministic
drift-induced component (second-order in $\theta$)
and $\xi(t)$ is the innovation noise, whose distribution
is symmetric on $V_{\mathrm{fg}}$ under~\textup{(C5)}.
No first-order controller---one that updates
$\dot{\sigma} = f(e(t))$ based on the instantaneous
residual without computing statistical properties of the
error stream---can uniformly reduce the drift.
Specifically: for any deterministic update function~$f$,
there exists a measurable event
$\mathcal{E} \subset V_{\mathrm{fg}}$ with
$\mathbb{P}(\mathcal{E})
\geq 1/2 - O(\mathrm{SNR})$
under the symmetric innovation distribution~$p(\xi)$,
such that for all $\xi \in \mathcal{E}$ the update
direction satisfies
$\langle \dot{\sigma},\,\dot{\sigma}^*\rangle \leq 0$,
where $\mathrm{SNR} \sim \theta^4/h_\mu$.
\end{theorem}

\begin{proof}
\emph{Probability space.}
The probability is taken over the innovation sequence
$\{\xi(t)\}_{t \geq 0}$ under the symmetric distribution
induced by the bath coupling~(C5).
All expectations below are over~$p(\xi)$.

\emph{Signal-to-noise separation.}
The prediction error $e(t)$ lies in $V_{\mathrm{fg}}$ by
construction.
Frame drift manifests as a rotation of the optimal frame
$\mathcal{F}^*(t)$ in the gauge group $G$, shifting
survival weight from $V_{\mathrm{fg}}$ to
$V_{\mathrm{bg}}$.
In $V_{\mathrm{fg}}$, the drift signal enters only at
second order in the mismatch angle~$\theta$
(Paper~II, proof of Theorem~29, part~(c)):
$\mathcal{S}_{\mathrm{vis}}
= \mathcal{S}_{\mathrm{tot}}\cos^2\theta$,
so
$e_{\mathrm{drift}}
\sim \theta^2\,\mathcal{S}_{\mathrm{tot}}$.
The noise $\xi(t)$ scales as $h_\mu^{1/2}$.
For $\theta \ll 1$, the single-sample signal-to-noise
ratio is
$\mathrm{SNR} \sim \theta^4/h_\mu \ll 1$.

\emph{Symmetry argument.}
Since $p(\xi)$ is symmetric on $V_{\mathrm{fg}}$,
for any deterministic $f$:
\begin{itemize}
\item If $f$ is odd (e.g., linear gain),
  $\mathbb{E}[f(e_{\mathrm{drift}} + \xi)]
  \approx f(e_{\mathrm{drift}})$,
  but the instantaneous sign of $f$ is determined by $\xi$
  with probability $\tfrac{1}{2} - O(\mathrm{SNR})$.
\item If $f$ is even,
  $f(e)$ carries no information about the
  \emph{sign} of $\dot{\sigma}^*$, so
  $\langle f(e),\,\dot{\sigma}^*\rangle$ vanishes in
  expectation.
\end{itemize}
In either case, the probability that the update direction
anti-correlates with the true drift direction is at
least~$1/2 - O(\mathrm{SNR})$.
Systematic drift detection requires accumulating
second-order statistics of the residual stream over
multiple samples---a second-order operation.
\end{proof}

% ------------------------------------------------------------
\subsection{The Agent's Statistical Manifold}
\label{T-III-subsec:stat_manifold}

The agent's prediction-residual stream
$\{e(t)\}_{t \geq 0}$ defines a stochastic process whose
distribution depends on the gauge-fixing
parameter~$\sigma$.
We model this dependence as a parametric family.

\begin{definition}[Predictive family]
\label{T-III-def:predictive_family}
The \emph{predictive family} of the agent is the set
\begin{equation}
\label{T-III-eq:predictive_family}
\mathcal{P}
:= \bigl\{p(e\,|\,\sigma)
  : \sigma \in \mathcal{M}_G\bigr\},
\end{equation}
where $\mathcal{M}_G := G/H$ is the space of gauge-fixing
orbits ($H$ is the stabiliser of the foreground subspace),
$e$ denotes the prediction-residual time series over a
window of length~$T$, and $p(e\,|\,\sigma)$ is the
likelihood of the observed residuals given the gauge
parameter~$\sigma$.
\end{definition}

The key insight is that $p(e\,|\,\sigma)$ depends
on~$\sigma$ even though $e(t) \in V_{\mathrm{fg}}$,
because the projection $\Pi_{\mathcal{F}}(\sigma)$
determines which environmental correlations are captured.
When $\sigma$ drifts from the optimal $\sigma^*$:
\begin{itemize}
\item The variance of the residuals increases (the
  discarded background components contribute unmodelled
  noise).
\item The temporal correlations of the residuals change
  (the projected kernel $\mathcal{K}_{\mathcal{F}}$ no
  longer captures the dominant environmental modes).
\item Higher-order statistics (kurtosis, spectral shape)
  shift systematically.
\end{itemize}
These distributional changes are invisible to the
raw error $e(t)$ but detectable by the Fisher metric
of $\mathcal{P}$.

% ------------------------------------------------------------
\subsection{Self-Referential Fisher Information}
\label{T-III-subsec:self_ref_fisher}

\begin{definition}[Self-referential Fisher information]
\label{T-III-def:self_ref_fisher}
The \emph{self-referential Fisher information} of the agent
at gauge parameter $\sigma$ is
\begin{equation}
\label{T-III-eq:self_ref_fisher}
\mathcal{I}_F(\sigma)
:= g_{ij}(\sigma)\,\delta\sigma^i\,\delta\sigma^j,
\end{equation}
where $g_{ij}(\sigma)$ is the Fisher information matrix of
the predictive family $\mathcal{P}$
(Definition~\ref{T-III-def:predictive_family}) evaluated at
$\sigma$, and $\delta\sigma$ is the frame perturbation
direction.
In the scalar case (single drift mode),
$\mathcal{I}_F(\sigma)
= \mathbb{E}_\sigma\!\bigl[
  (\partial_\sigma \log p(e\,|\,\sigma))^2\bigr]$.
\end{definition}

\begin{remark}[What the agent ``measures'']
\label{T-III-rem:what_measured}
Computing $\mathcal{I}_F(\sigma)$ does not require access
to $V_{\mathrm{bg}}$ or to the ``true'' environment.
It requires only: (i)~the agent's own prediction residuals
$\{e(t)\}$ (which lie in $V_{\mathrm{fg}}$), and
(ii)~the ability to evaluate the score function
$\partial_\sigma \log p(e\,|\,\sigma)$---the sensitivity of
its own predictive model to frame perturbations.
This is a computation entirely within the agent's internal
algebra, using only quantities already available from the
ego's processing pipeline.
\end{remark}

\begin{theorem}[Drift Detectability]
\label{T-III-thm:detectability}
Under assumptions~\textup{(C1)--(C5)}, suppose the frame
is freshly calibrated at time $t_0$
($\theta(t_0) = 0$).  Then the self-referential
Fisher information of the prediction-residual stream
satisfies, for small accumulated drift
($\Lambda\,\Delta t \ll 1$):
\begin{equation}
\label{T-III-eq:detectability}
\mathcal{I}_F(\sigma;\,\{e_t\}_{t_0}^{t_0+\Delta t})
\;\geq\; \kappa\,\Lambda^2\,(\Delta t)^2\,
\mathcal{I}_F^{\mathrm{env}},
\end{equation}
where:
\begin{itemize}
\item $\kappa := \inf_{\sigma \in \mathcal{N}}
  (\partial\theta / \partial\sigma)^2 > 0$ is the
  \emph{coupling efficiency}, where $\mathcal{N}$ is a
  compact neighbourhood of the calibrated point
  $\sigma^*$ on which the gauge chart is non-singular
  (existence guaranteed by~\textup{(C4)}; see proof);
\item $\Lambda$ is the environmental Lyapunov exponent
  \textup{(Paper~II, Eq.~(37))};
\item $\Delta t$ is the observation window;
\item $\mathcal{I}_F^{\mathrm{env}}
  := \mathbb{E}_{p(\cdot|\theta)}
  [(\partial_\theta \log p)^2]$ is the per-component
  environmental Fisher information, measuring the
  baseline sensitivity of the decoherence functions to the
  mismatch angle~$\theta$.
\end{itemize}

The self-referential Fisher information grows
\emph{quadratically} with accumulated drift time.
\end{theorem}

\begin{proof}
\emph{Step~1: chain rule.}
The frame parameter $\sigma$ determines the mismatch angle
$\theta = \theta(\sigma)$ via the gauge map
$G/H \to [0,\pi/2]$.
The chain rule for Fisher information gives
\begin{equation}
\label{T-III-eq:chain_rule_IF}
\mathcal{I}_F(\sigma)
\;=\; \left(\frac{\partial\theta}{\partial\sigma}\right)^2
\,\mathcal{I}_F(\theta),
\end{equation}
where $\mathcal{I}_F(\theta)
:= \mathbb{E}[(\partial_\theta \log p(e|\theta))^2]$
is the Fisher information of the residual stream with
respect to the mismatch angle.
By~(C4) (full-rank Fisher matrix), the Jacobian
$\partial\theta/\partial\sigma$ is bounded away from zero
on any compact neighbourhood $\mathcal{N}$ of the
calibrated point;
we define the coupling efficiency
$\kappa := \inf_{\sigma \in \mathcal{N}}
(\partial\theta/\partial\sigma)^2 > 0$.
This constant depends on the foreground
dimension~$k^*$, the Jacobian norms of the gauge-orbit
map $G/H \to [0,\pi/2]$, and the regularity constants
in~(C4); it is computable for any concrete model
(see Remark~\ref{T-III-rem:kappa_qubit} for the qubit case).

\emph{Step~2: small-drift expansion.}
Under freshly calibrated initial conditions
($\theta(t_0) = 0$),
the mismatch angle grows as
$\theta(\Delta t) = \Lambda\,\Delta t + O((\Delta t)^2)$
(Paper~II, Eq.~(35), linearised about $\theta = 0$).
The visible survival functional satisfies
$\mathcal{S}_{\mathrm{vis}}
= \mathcal{S}_{\mathrm{tot}}\cos^2\theta
\approx \mathcal{S}_{\mathrm{tot}}\,(1 - \theta^2)$
for $\theta \ll 1$.
Thus the residual distribution
$p(e\,|\,\theta)$ shifts from its baseline
$p(e\,|\,0)$ by a score proportional to $\theta^2$:
$\partial_\theta \log p \sim 2\theta
\cdot (\partial_\theta \log p)|_{\theta=\theta^*}$,
and consequently
\begin{equation}
\label{T-III-eq:IF_theta_lower}
\mathcal{I}_F(\theta)
\;\geq\; (\Lambda\,\Delta t)^2\,
\mathcal{I}_F^{\mathrm{env}},
\end{equation}
where the inequality retains only the leading $O(\theta^2)$
term and drops $O(\theta^4)$ corrections.

\emph{Step~3: assembly.}
Substituting~\eqref{T-III-eq:IF_theta_lower}
into~\eqref{T-III-eq:chain_rule_IF}:
\[
\mathcal{I}_F(\sigma)
\;\geq\; \kappa\,\Lambda^2\,(\Delta t)^2\,
\mathcal{I}_F^{\mathrm{env}}.
\qedhere
\]
\end{proof}

\begin{remark}[Coupling efficiency in the qubit example]
\label{T-III-rem:kappa_qubit}
For the single-qubit model of Section~\ref{T-III-sec:example},
the gauge orbit is parametrised directly by $\theta$
(rotation in the $xz$-plane of the Bloch sphere), so
$\partial\theta/\partial\sigma = 1$ and $\kappa = 1$.
More generally, $\kappa$ depends on the dimensionality
of the gauge group and the curvature of the orbit
$G/H$ at the current frame.
\end{remark}

\begin{corollary}[Detection before delusion]
\label{T-III-cor:detection_window}
Under~\textup{(C1)--(C5)}, there exists a detection
time $\Delta t_{\mathrm{detect}}$ satisfying
\begin{equation}
\label{T-III-eq:detection_window}
\Delta t_{\mathrm{detect}}
\;=\; \frac{1}{\Lambda}
\sqrt{\frac{\mathcal{I}_F^{\mathrm{min}}}
  {\kappa\,\mathcal{I}_F^{\mathrm{env}}}}
\;<\; t_{\mathrm{del}},
\end{equation}
where $\mathcal{I}_F^{\mathrm{min}}$ is the minimum Fisher
information required to exceed the noise floor
(determined by $h_\mu$ and the observation window length).
The detection window opens \emph{before} the Delusion Trap
closes, provided the meta-observer budget
$\mathcal{C}_{\mathrm{meta}}$ is sufficient to compute
$\mathcal{I}_F$.
\end{corollary}

\begin{proof}
The detection time
$\Delta t_{\mathrm{detect}} \propto \Lambda^{-1}$
(from~\eqref{T-III-eq:detectability}), while
$t_{\mathrm{del}} = \Lambda^{-1}\ln(\pi/4\theta_0)$
(from~\eqref{T-III-eq:t_del_recall}).
Since $\ln(\pi/4\theta_0) > 1$ for $\theta_0 < \pi/4e$
and the constant $\kappa\,\mathcal{I}_F^{\mathrm{env}}$
is finite under~(C4), the square root in
$\Delta t_{\mathrm{detect}}$ can be made smaller than
the logarithm in $t_{\mathrm{del}}$ for sufficiently
sensitive meta-observers (large
$\mathcal{I}_F^{\mathrm{env}}$).
\end{proof}

% ============================================================
\section{The Self-Referential Bound}
\label{T-III-sec:SRCR}

% ------------------------------------------------------------
\subsection{The Bayesian Framework}
\label{T-III-subsec:bayesian}

The agent's ego structure (Paper~II) provides a
\emph{prior belief} about the correct gauge parameter:
the current frame $\sigma_0$ is the ego's
``preferred'' value.
We encode this as a prior distribution
$\pi_{\mathrm{ego}}(\sigma)$, concentrated around
$\sigma_0$.

\begin{definition}[Ego rigidity]
\label{T-III-def:ego_rigidity}
The \emph{ego rigidity} is the prior Fisher information
\begin{equation}
\label{T-III-eq:ego_rigidity}
\mathcal{I}_{\mathrm{ego}}
:= \int_{\mathcal{M}_G}
\left(\frac{\partial \log \pi_{\mathrm{ego}}(\sigma)}
  {\partial \sigma}\right)^{\!2}
\pi_{\mathrm{ego}}(\sigma)\,d\sigma.
\end{equation}
High $\mathcal{I}_{\mathrm{ego}}$ corresponds to a
sharply peaked prior (rigid ego); low
$\mathcal{I}_{\mathrm{ego}}$ to a diffuse prior (flexible
ego).
The four bias terms of Paper~II contribute to
$\mathcal{I}_{\mathrm{ego}}$:
$\mathcal{B}_{\mathrm{select}}$ and
$\mathcal{B}_{\mathrm{frame}}$ sharpen the prior
around the current basis and connection,
while $\mathcal{B}_{\mathrm{center}}$ centres the prior
on the agent's own state.
\end{definition}

% ------------------------------------------------------------
\subsection{The Self-Referential Cram\'{e}r--Rao Bound}
\label{T-III-subsec:SRCR}

\begin{theorem}[Self-Referential Cram\'{e}r--Rao Bound]
\label{T-III-thm:SRCR}
Under assumptions~\textup{(C1)--(C5)}, let
$\delta\hat{\sigma}$ be any estimator of the frame drift
$\delta\sigma := \sigma^*(t) - \sigma$, based on a
residual record of duration~$T$.
Define the \emph{effective sample size}
$n_{\mathrm{eff}} := T/\tau_E$, where $\tau_E$ is the
decorrelation time of the residual process~$\{e(t)\}$
(the time beyond which consecutive residuals carry
approximately independent information about~$\sigma$).
Then the van Trees inequality~\cite{vanTrees1968} gives
\begin{equation}
\label{T-III-eq:SRCR}
\mathbb{E}\!\left[
  \bigl|\delta\hat{\sigma} - \delta\sigma\bigr|^2
\right]
\;\geq\; \frac{1}{n_{\mathrm{eff}}\,\mathcal{I}_F(\sigma)
  + \mathcal{I}_{\mathrm{ego}}}.
\end{equation}
\end{theorem}

\begin{proof}
This is a direct application of the van Trees
(Bayesian Cram\'{e}r--Rao)
inequality~\cite{vanTrees1968}.
The total information about the drift parameter $\delta\sigma$
consists of two contributions:
\begin{itemize}
\item $n_{\mathrm{eff}}\,\mathcal{I}_F(\sigma)$: the data
  Fisher information.  In continuous time, the residual
  process is correlated with decorrelation time $\tau_E$
  set by the bath memory kernel.
  Over a window of duration~$T$, the process yields
  $n_{\mathrm{eff}} \approx T/\tau_E$ effectively
  independent samples, each carrying
  $\mathcal{I}_F(\sigma)$ bits of information
  about $\delta\sigma$.
\item $\mathcal{I}_{\mathrm{ego}}$: the prior Fisher
  information from the ego's preference for $\sigma_0$
  (Definition~\ref{T-III-def:ego_rigidity}).
\end{itemize}
The van Trees inequality states that the Bayesian
mean-squared error is bounded below by the inverse of the
total information.
\end{proof}

\begin{remark}[The ego as help and hindrance]
\label{T-III-rem:ego_dual}
The ego rigidity $\mathcal{I}_{\mathrm{ego}}$ acts as
both help and hindrance:
\begin{itemize}
\item \textbf{Help}: when the ego is well-aligned
  ($\sigma_0 \approx \sigma^*$), the prior tightens the
  bound, reducing estimation variance.
\item \textbf{Hindrance}: when the ego is misaligned
  ($|\sigma_0 - \sigma^*|$ large), the prior pulls the
  estimate toward the wrong value, creating a
  \emph{confirmation bias} that resists recalibration.
\end{itemize}
The optimal Bayesian estimator balances data and prior:
\begin{equation}
\label{T-III-eq:optimal_estimator}
\hat{\sigma}_{\mathrm{opt}}
= \frac{n_{\mathrm{eff}}\,\mathcal{I}_F\,\hat{\sigma}_{\mathrm{MLE}}
  + \mathcal{I}_{\mathrm{ego}}\,\sigma_0}
  {n_{\mathrm{eff}}\,\mathcal{I}_F + \mathcal{I}_{\mathrm{ego}}},
\end{equation}
a weighted average of the maximum-likelihood estimate
$\hat{\sigma}_{\mathrm{MLE}}$ and the ego's prior belief
$\sigma_0$, with weights proportional to their respective
Fisher informations.
As $n_{\mathrm{eff}}\,\mathcal{I}_F \gg \mathcal{I}_{\mathrm{ego}}$
(enough data to overwhelm the ego), the estimator converges
to the MLE.
\end{remark}

% ------------------------------------------------------------
\subsection{The Rigidity-Sensitivity Trade-off}
\label{T-III-subsec:rigidity}

\begin{proposition}[Optimal ego rigidity]
\label{T-III-prop:optimal_rigidity}
Let the total expected loss be
$\mathcal{L}_{\mathrm{total}}
(\mathcal{I}_{\mathrm{ego}})
= \mathcal{L}_{\mathrm{estimation}}
+ \lambda\,\mathcal{L}_{\mathrm{calibration}}$,
where $\mathcal{L}_{\mathrm{estimation}}$ is the
mean-squared drift-estimation error
(bounded by~\eqref{T-III-eq:SRCR}) and
$\mathcal{L}_{\mathrm{calibration}}$ is the cost of
adjusting the frame (proportional to the frame rotation
distance, hence larger when the ego is rigid and must be
overcome).
Under~\textup{(C1)--(C5)}, there exists an optimal ego
rigidity $\mathcal{I}_{\mathrm{ego}}^*$ that minimises
$\mathcal{L}_{\mathrm{total}}$.

\emph{Too rigid}
($\mathcal{I}_{\mathrm{ego}} \gg n_{\mathrm{eff}}\,\mathcal{I}_F$):
the ego overwhelms the data; the agent is blind to drift.
\emph{Too soft}
($\mathcal{I}_{\mathrm{ego}} \ll n_{\mathrm{eff}}\,\mathcal{I}_F$):
the agent overreacts to noise; calibration cost is high.
The optimum balances sensitivity against stability.
\end{proposition}

\begin{proof}
The estimation loss decreases with
$\mathcal{I}_{\mathrm{ego}}$ (the prior sharpens the
bound~\eqref{T-III-eq:SRCR} when $\sigma_0 \approx \sigma^*$
but increases it when misaligned).
The calibration cost increases with
$\mathcal{I}_{\mathrm{ego}}$ (a rigid ego resists rotation).
The sum is a convex function of
$\mathcal{I}_{\mathrm{ego}}$ under standard regularity,
so a minimum exists.
\end{proof}

% ============================================================
\section{The Calibration Loop}
\label{T-III-sec:loop}

% ------------------------------------------------------------
\subsection{The Natural Gradient Update Law}
\label{T-III-subsec:update_law}

The meta-observer updates the gauge parameter $\sigma$
following the natural gradient on the statistical
manifold~$(\mathcal{M}_G,\,g)$:
\begin{equation}
\label{T-III-eq:update_law}
\dot{\sigma}
= -\eta\,g^{-1}(\sigma)\,
  \nabla_\sigma L_{\mathrm{frame}}(\sigma),
\end{equation}
where $\eta > 0$ is the adaptation rate and the
\emph{frame loss} is
\begin{equation}
\label{T-III-eq:frame_loss}
L_{\mathrm{frame}}(\sigma)
:= \mathbb{E}_\sigma\!\left[
  -\mathcal{S}_{\mathrm{vis}}(\sigma)\right].
\end{equation}
The frame loss is minimised at the optimal gauge
$\sigma^*$ that maximises visible survival.
The Fisher metric enters through the inverse $g^{-1}$
in the natural gradient, not as a penalty term:
it defines the \emph{geometry} of the update, ensuring
reparametrisation invariance.

\begin{remark}[Reparametrisation invariance]
\label{T-III-rem:reparam}
The natural gradient~\eqref{T-III-eq:update_law} is invariant
under reparametrisation of the gauge manifold
$\mathcal{M}_G$: the update direction does not depend on the
choice of coordinates for $\sigma$.
This is essential because the gauge manifold inherits its
geometry from the Clifford algebra, and no canonical
coordinate system is preferred.
\end{remark}

% ------------------------------------------------------------
\subsection{Lyapunov Stability of the Loop}
\label{T-III-subsec:lyapunov}

\paragraph{Drift velocity.}
Let $\sigma^*(t)$ denote the instantaneous optimal gauge
parameter (the minimiser of $L_{\mathrm{frame}}$ at
time~$t$; Paper~II, Definition~27).
Define the \emph{drift velocity}
$\dot{\sigma}^* := d\sigma^*/dt$, measured with respect to
the Fisher metric~$g$; its norm
$\|\dot{\sigma}^*\|_g
:= \sqrt{g_{ij}\,\dot{\sigma}^{*i}\,\dot{\sigma}^{*j}}$
is the instantaneous rate at which the environment's
optimal frame rotates on the gauge manifold.

\begin{definition}[Lyapunov monitoring function]
\label{T-III-def:lyapunov}
The \emph{Lyapunov monitoring function} is the squared
geodesic distance on the statistical manifold from the
current frame to the instantaneous optimal frame:
\begin{equation}
\label{T-III-eq:lyapunov}
V(\sigma)
:= d_{\mathrm{geo}}\!\left(\sigma,\,\sigma^*(t)\right)^2,
\end{equation}
where $d_{\mathrm{geo}}$ is the geodesic distance in the
Fisher metric~$g$.
\end{definition}

\begin{theorem}[Loop Tracking Bound]
\label{T-III-thm:loop_stability}
Under assumptions~\textup{(C1)--(C5)}, the natural gradient
update~\eqref{T-III-eq:update_law} applied to the Lyapunov
monitoring function~\eqref{T-III-eq:lyapunov} satisfies
\begin{equation}
\label{T-III-eq:lyapunov_decrease}
\frac{dV}{dt}
\;\leq\; -2\eta\,\alpha\,V
\;+\; 2\sqrt{V}\;\bigl\|\dot{\sigma}^*\bigr\|_g,
\end{equation}
where $\alpha > 0$ is the persistent excitation constant
(Definition~\ref{T-III-def:PE_constant} below)
and $\|\dot{\sigma}^*\|_g$ is the instantaneous drift speed
of the optimal frame.
Consequently:
\begin{enumerate}
\item[\textup{(a)}] \textbf{Tracking.}
  Whenever $\sqrt{V} >
  \|\dot{\sigma}^*\|_g / (\eta\,\alpha)$,
  we have $dV/dt < 0$: the loop actively reduces the
  mismatch.
\item[\textup{(b)}] \textbf{Tracking neighbourhood.}
  The mismatch converges to a neighbourhood of the set
  of stationary points of $L_{\mathrm{frame}}$.
  Assuming non-degeneracy (local strong convexity near
  $\sigma^*$, consistent with persistent
  excitation~(C5) in standard adaptive-control
  settings~\cite{AstromWittenmark1995}),
  this neighbourhood has size
  \begin{equation}
  \label{T-III-eq:tracking_neighbourhood}
  V_\infty
  \;:=\; \frac{\bigl\|\dot{\sigma}^*\bigr\|_g^2}
  {(\eta\,\alpha)^2}.
  \end{equation}
  For bounded drift
  ($\|\dot{\sigma}^*\|_g \leq \Lambda_{\max}$), the
  mismatch is bounded:
  $\limsup_{t\to\infty} V(t)
  \leq \Lambda_{\max}^2/(\eta\alpha)^2$.
\item[\textup{(c)}] \textbf{Static limit.}
  When $\sigma^* = \mathrm{const}$
  ($\dot{\sigma}^* = 0$), the bound reduces to
  $dV/dt \leq -2\eta\alpha\,V$,
  giving exponential convergence
  $V(t) \leq V(0)\,e^{-2\eta\alpha\,t}$.
\end{enumerate}
\end{theorem}

\begin{proof}
Since $V(\sigma) = d_{\mathrm{geo}}(\sigma,\,\sigma^*(t))^2$
and $\sigma^*(t)$ is time-varying, the total derivative
has two contributions:
\begin{equation*}
\frac{dV}{dt}
= \underbrace{\frac{\partial V}{\partial \sigma}
  \cdot \dot{\sigma}}_{\text{control}}
\;+\; \underbrace{\frac{\partial V}{\partial \sigma^*}
  \cdot \dot{\sigma}^*}_{\text{drift}}.
\end{equation*}

\paragraph{Control term.}
In normal coordinates centred at $\sigma^*$, let
$\delta\sigma := \sigma - \sigma^*$.
The control contribution is
$2\,g(\delta\sigma,\,\dot{\sigma})
= 2\,g(\delta\sigma,\,-\eta\,g^{-1}\nabla L_{\mathrm{frame}})
= -2\eta\,\langle \delta\sigma,\,
\nabla L_{\mathrm{frame}}\rangle$.
Since $\sigma^*$ minimises $L_{\mathrm{frame}}$ by
definition, $L_{\mathrm{frame}}$ is locally strongly
convex near $\sigma^*$ under persistent
excitation~(C5) (the Hessian of $L_{\mathrm{frame}}$
at $\sigma^*$ is bounded below by $\alpha\,g$,
where $\alpha$ is the persistent excitation constant).
Therefore
$\langle \delta\sigma,\,\nabla L_{\mathrm{frame}}\rangle
\geq \alpha\,|\delta\sigma|_g^2 = \alpha\,V$,
giving a control contribution $\leq -2\eta\,\alpha\,V$.

\paragraph{Drift term.}
The drift contribution is
$-2\,g(\delta\sigma,\,\dot{\sigma}^*)$.
By Cauchy--Schwarz:
$|g(\delta\sigma,\,\dot{\sigma}^*)|
\leq |\delta\sigma|_g\,\|\dot{\sigma}^*\|_g
= \sqrt{V}\,\|\dot{\sigma}^*\|_g$.
Hence the drift contribution is bounded by
$+2\sqrt{V}\,\|\dot{\sigma}^*\|_g$.

\paragraph{Combined.}
Adding both contributions
gives~\eqref{T-III-eq:lyapunov_decrease}.
Part~(a) follows by setting
$dV/dt < 0$; part~(b) by solving $dV/dt = 0$ for
the fixed point $\sqrt{V_\infty}
= \|\dot{\sigma}^*\|_g/(\eta\alpha)$;
part~(c) by setting $\dot{\sigma}^* = 0$.
\end{proof}

% ------------------------------------------------------------
\subsection{Convergence Rate under Persistent Excitation}
\label{T-III-subsec:convergence}

\begin{definition}[Persistent excitation constant]
\label{T-III-def:PE_constant}
The \emph{persistent excitation constant} $\alpha > 0$ is
the minimum eigenvalue of the time-averaged Fisher
information matrix:
\begin{equation}
\label{T-III-eq:PE_constant}
\bar{g}(t)
:= \frac{1}{T}\int_t^{t+T}
g(\sigma(s))\,ds
\;\succeq\; \alpha\,I
\qquad\text{for all } t,
\end{equation}
guaranteed to exist by~\textup{(C5)} and~\textup{(C4)}.
\end{definition}

\begin{remark}[Tracking vs convergence]
\label{T-III-rem:tracking}
In the static case ($\sigma^* = \mathrm{const}$),
Theorem~\ref{T-III-thm:loop_stability}(c) gives pure exponential
convergence:
$V(t) \leq V(0)\,e^{-2\eta\alpha\,t}$.
Under environmental drift, convergence to zero is
\emph{not} possible---instead the loop maintains the
mismatch within the tracking
neighbourhood~\eqref{T-III-eq:tracking_neighbourhood}.
The tracking error $V_\infty$ grows with drift speed
$\|\dot{\sigma}^*\|_g$ and decreases with loop parameters
$\eta$ and $\alpha$.
If the free-energy budget is insufficient to maintain
$\eta\,\alpha > \Lambda$ (the drift rate), the tracking
neighbourhood expands and the Delusion Trap re-emerges.
This connects the Lyapunov stability of the loop
directly to the thermodynamic budget
(Section~\ref{T-III-sec:cost}).
\end{remark}

\begin{remark}[The necessity of novelty]
\label{T-III-rem:novelty}
If $h_\mu \to 0$ (the environment ceases to generate new
information), the persistent excitation constant
$\alpha \to 0$ and the tracking neighbourhood
$V_\infty = \|\dot{\sigma}^*\|_g^2/(\eta\alpha)^2 \to \infty$:
the loop loses all ability to track.
\emph{Memory without novelty cannot sustain self-reference.}
This is the information-theoretic expression of a basic
physical principle: a system in thermodynamic equilibrium
cannot ``learn'' about itself.
\end{remark}

% ------------------------------------------------------------
\subsection{The Four-Part Structure Proposition}
\label{T-III-subsec:four_part}

We are now in a position to state the capstone result of
the T-DOME sequence.

\begin{proposition}[Sufficient Architecture for Persistent Agents]
\label{T-III-prop:four_part}
Within the class of agents satisfying~\textup{(C1)--(C5)},
a sufficient architecture for maintaining a
non-equilibrium steady state~\textup{(NESS)} in an open,
drifting environment under bounded computation comprises
the following four structural layers:
\begin{enumerate}
\item[\textup{(I)}] \textbf{External observable geometry.}
  The environmental observable algebra supports a
  metric structure; $Cl(1,3)$ serves as the running
  example throughout the programme, but the argument
  applies to any algebra satisfying~(C1).
  \emph{Assumption:}
  established
  in~\cite{Liu2026HAFF_A,Liu2026HAFF_B,Liu2026QRAIF_A};
  adopted here as a modelling premise.
\item[\textup{(II)}] \textbf{Internal control algebra.}
  The agent carries an internal algebra isomorphic to
  $Cl(V,q)$ with realizability embedding
  $\phi: Cl(V,q) \hookrightarrow Cl(1,3)$.
  \emph{Assumption:}
  established
  in~\cite{Liu2026QRAIF_B,Liu2026QRAIF_C};
  adopted here as a modelling premise.
\item[\textup{(III)}] \textbf{Self-monitoring function.}
  The agent maintains a Lyapunov function
  $V(\sigma)$~\eqref{T-III-eq:lyapunov} satisfying the
  tracking bound~\eqref{T-III-eq:lyapunov_decrease},
  implemented via a second-order control loop
  operating on the Fisher information of its own
  prediction stream.  The loop keeps the mismatch
  within the tracking
  neighbourhood~\eqref{T-III-eq:tracking_neighbourhood}.
  \emph{Source:} this paper,
  Theorem~\ref{T-III-thm:loop_stability}.
\item[\textup{(IV)}] \textbf{Biased, non-Markovian memory.}
  The agent carries path-dependent state
  (non-Markovian memory kernel $\mathcal{K}(t,s)$)
  compressed through a gauge-fixed reference frame
  (the ego $\mathfrak{E}$).
  \emph{Source:}
  Paper~I~\cite{Liu2026TDOME_I} (memory necessity)
  and Paper~II~\cite{Liu2026TDOME_II} (ego necessity).
\end{enumerate}
Without any one of the four layers, the agent fails:
\begin{itemize}
\item Without~(I): no physical embedding---the agent
  cannot interact with the Lorentzian environment.
\item Without~(II): no channel discrimination---the agent
  cannot distinguish survival-relevant from irrelevant
  information.
\item Without~(III): the Delusion Trap---the ego
  rigidifies and prediction error diverges exponentially.
\item Without~(IV): the Markovian Ceiling and
  computational paralysis---no temporal accumulation, no
  tractable processing.
\end{itemize}
\end{proposition}

\begin{proof}
Layers~(I) and~(II) are modelling
assumptions adopted
from~\cite{Liu2026HAFF_A,Liu2026HAFF_B,Liu2026QRAIF_A,Liu2026QRAIF_B,Liu2026QRAIF_C};
their sufficiency within those frameworks is established
therein.
The sufficiency of~(III) follows from the present paper:
Theorem~\ref{T-III-thm:first_order} shows that first-order
control is insufficient to escape the Delusion Trap, and
Theorem~\ref{T-III-thm:loop_stability} shows that the tracking
bound is sufficient.
The sufficiency of~(IV) follows from
Paper~I~\cite{Liu2026TDOME_I}
(Markovian Ceiling $\mathcal{S} \leq 0$)
and Paper~II~\cite{Liu2026TDOME_II}
(Computational Ceiling and necessity of SSB).

The ``without'' claims follow from the respective crisis
theorems: Paper~I's Theorem~14 (Markovian Ceiling),
Paper~II's Theorem~7 (Computational Ceiling)
and Theorem~29 (Delusion Trap), and the present
Theorem~\ref{T-III-thm:first_order}.
\end{proof}

% ============================================================
\section{Thermodynamic Cost}
\label{T-III-sec:cost}

% ------------------------------------------------------------
\subsection{The Three Cost Components}
\label{T-III-subsec:cost_components}

The self-referential calibration loop requires three
distinct operations, each carrying an irreducible
thermodynamic cost:

\paragraph{1.\ Sensing cost.}
The meta-observer must read the prediction residuals from
the ego's processing pipeline.
This requires monitoring $k^*$ foreground channels, each
producing $h_\mu$ bits per unit time:
\begin{equation}
\label{T-III-eq:W_sense}
\dot{W}_{\mathrm{sense}}
\;\geq\; k_BT\,\ln 2 \cdot h_\mu\,k^*.
\end{equation}
(Landauer cost of reading $h_\mu\,k^*$ bits per unit
time.)

\paragraph{2.\ Computing cost.}
Evaluating the Fisher information
$\mathcal{I}_F(\sigma)$ from the residual stream requires
the meta-observer to process
$\mathcal{C}_{\mathrm{meta}}$ bits per unit time:
\begin{equation}
\label{T-III-eq:W_compute}
\dot{W}_{\mathrm{compute}}
\;\geq\; k_BT\,\ln 2 \cdot \mathcal{C}_{\mathrm{meta}}.
\end{equation}

\paragraph{3.\ Actuating cost.}
Rotating the gauge parameter from the current frame
$\sigma$ to the estimated optimal frame
$\hat{\sigma}^*$ is a finite-time thermodynamic
transformation on the gauge manifold.
By the Sivak--Crooks bound
(Proposition~\ref{T-III-prop:sivak_crooks}):
\begin{equation}
\label{T-III-eq:W_actuate}
\dot{W}_{\mathrm{actuate}}
\;\geq\; \frac{\mathcal{L}^2(\sigma,\,\hat{\sigma}^*)}
  {\tau_{\mathrm{recalib}}^2},
\end{equation}
where $\mathcal{L}(\sigma,\,\hat{\sigma}^*)$ is the
thermodynamic length~\eqref{T-III-eq:thermo_length} of the
geodesic from $\sigma$ to $\hat{\sigma}^*$, and
$\tau_{\mathrm{recalib}}$ is the recalibration time.

% ------------------------------------------------------------
\subsection{The Thermodynamic Cost Theorem}
\label{T-III-subsec:cost_theorem}

\begin{theorem}[Thermodynamic Cost of Self-Referential
Calibration]
\label{T-III-thm:loop_cost}
Under assumptions~\textup{(C1)--(C5)}, the minimum
dissipation rate of the self-referential calibration loop
satisfies
\begin{equation}
\label{T-III-eq:loop_cost}
\dot{W}_{\mathrm{loop}}
\;\geq\; k_BT\,\ln 2\,\left[
  h_\mu\,k^*
  + \mathcal{C}_{\mathrm{meta}}
\right]
+ \frac{\mathcal{L}^2(\sigma,\,\sigma^*)}
  {\tau_{\mathrm{recalib}}^2}.
\end{equation}
The first bracketed term is the \emph{information tax}
(the Landauer cost of sensing and computing).
The second term is the \emph{geometric tax}
(the Sivak--Crooks cost of actuating the frame rotation).
\end{theorem}

\begin{proof}
We must establish that the three lower bounds can be
summed, i.e.\ that no single physical process can
simultaneously satisfy two or more of them.

The three operations act on \emph{disjoint physical
degrees of freedom}:
\begin{enumerate}
\item \emph{Sensing} reads the prediction residuals
  $\{e_t\}$ from the ego's foreground channels.
  The relevant degrees of freedom are the sensor
  registers that copy bits from the foreground subspace
  $V_{\mathrm{fg}}$.
  Each bit erased carries the Landauer
  cost $k_BT\ln 2$.
\item \emph{Computing} evaluates the Fisher information
  $\mathcal{I}_F(\sigma)$ from the copied residuals.
  The relevant degrees of freedom are the processor
  logic states of the meta-observer.
  These are distinct from the sensor registers: the
  processor manipulates the data \emph{after} it has
  been read, and its own state transitions carry an
  independent Landauer cost.
\item \emph{Actuating} rotates the gauge parameter from
  $\sigma$ to $\hat{\sigma}^*$.
  The relevant degrees of freedom are the control
  fields that implement the frame rotation on the
  agent's internal algebra $Cl(V,q)$.
  This is a physical transformation of the agent's
  hardware state, governed by the Sivak--Crooks bound
  on finite-time thermodynamic transformations.
  The $\tau_{\mathrm{recalib}}^{-2}$ scaling of the
  dissipation \emph{rate} follows from the
  Sivak--Crooks bound $W_{\mathrm{ex}} \geq
  \mathcal{L}^2/\tau$ (excess \emph{work}), divided by
  $\tau_{\mathrm{recalib}}$ to convert to a rate.
\end{enumerate}
Under the assumption that the three operations are
physically realised on separable degrees of freedom
(no shared erasure accounting),
the sets are disjoint
(sensor $\cap$ processor $= \emptyset$, processor
$\cap$ actuator $= \emptyset$, sensor $\cap$ actuator
$= \emptyset$), and the Landauer bound for each is independent.
Moreover, the actuating cost involves a different
\emph{type} of bound (thermodynamic length, not Landauer
erasure), reinforcing the independence.
The total lower bound is
therefore the sum of the three individual
bounds~\eqref{T-III-eq:W_sense}--\eqref{T-III-eq:W_actuate}.
\end{proof}

% ------------------------------------------------------------
\subsection{The Complete Persistence Budget}
\label{T-III-subsec:persistence}

\begin{corollary}[Persistence Budget]
\label{T-III-cor:persistence}
Combining the results of Papers~I, II, and~III, the minimum
free-energy dissipation rate for a persistent,
self-calibrating agent in a drifting environment is
\begin{equation}
\label{T-III-eq:persistence_budget}
\dot{W}_{\mathrm{total}}
\;\geq\; \underbrace{k_BT\,\ln 2 \cdot h_\mu}_{%
  \text{Paper~I: memory}}
+ \underbrace{k_BT\,\ln 2 \cdot h_\mu\,k^*}_{%
  \text{Paper~II: ego processing}}
+ \underbrace{k_BT\,\ln 2\,\left[
  h_\mu\,k^*
  + \mathcal{C}_{\mathrm{meta}}
\right]
+ \frac{\mathcal{L}^2}
  {\tau_{\mathrm{recalib}}^2}}_{%
  \text{Paper~III: self-calibration loop}}.
\end{equation}
Below this budget, the agent must sacrifice one or more of
the four structural layers
(Proposition~\ref{T-III-prop:four_part}):
losing memory (Paper~I crisis),
losing the ego (Paper~II crisis), or
losing self-calibration (Paper~III crisis, the Delusion Trap).
\end{corollary}

\begin{remark}[The cost of selfhood]
\label{T-III-rem:selfhood_cost}
Equation~\eqref{T-III-eq:persistence_budget} is the first
explicit, calculable lower bound on the thermodynamic cost
of maintaining a self-referential agent in a drifting
environment.
It shows that ``selfhood'' is not free: the ego
(Paper~II) and its calibration loop (Paper~III) each add
irreducible energy taxes on top of the memory cost
(Paper~I).
The total cost grows with the environmental complexity
($h_\mu$), the agent's representational capacity ($k^*$),
the meta-observer's computational power
($\mathcal{C}_{\mathrm{meta}}$), and the drift rate
(through $\mathcal{L}$ and $\tau_{\mathrm{recalib}}$).
\end{remark}

% ============================================================
\section{Worked Example: Qubit in a Drifting
Two-Channel Bath}
\label{T-III-sec:example}

% ------------------------------------------------------------
\subsection{Model Setup}
\label{T-III-subsec:model_III}

We extend the two-channel qubit model from
Paper~II~(Section~6) by introducing environmental drift.

\paragraph{Inherited setup.}
A qubit ($\dim\mathcal{H}_S = 2$) with internal algebra
$Cl(0,2) \cong \mathbb{H}$ ($D = 4$), coupled to two
bosonic channels:
\begin{itemize}
\item Dephasing channel ($\sigma_z$):
  $J_z(\omega) = 2\lambda_z\gamma_z\omega/
  (\omega^2 + \gamma_z^2)$.
\item Dissipative channel ($\sigma_x$):
  $J_x(\omega) = 2\lambda_x\gamma_x\omega/
  (\omega^2 + \gamma_x^2)$.
\end{itemize}
Paper~II's ego selects $V_{\mathrm{fg}}
= \mathrm{span}\{1,\mathbf{k}\}$ (the dephasing subspace),
discarding $V_{\mathrm{bg}}
= \mathrm{span}\{\mathbf{i},\mathbf{j}\}$.

\paragraph{Environmental drift.}
We now allow the dephasing coupling to drift exponentially
(matching Paper~II's Delusion Trap analysis):
\begin{equation}
\label{T-III-eq:drift_model}
\lambda_z(t)
= \lambda_z^{(0)}\bigl(1 + \theta_0\,e^{\Lambda t}\bigr),
\qquad
\theta_0 = 0.02,
\quad
\Lambda = 0.08\,\omega_0.
\end{equation}
The optimal frame $\mathcal{F}^*(t)$ rotates in
$SO(3)$ as the relative survival values of the two
channels change.  The Delusion Trap time
$t_{\mathrm{del}}
= \Lambda^{-1}\ln\!\bigl(\pi/(4\theta_0)\bigr)
\approx 45.9\,\omega_0^{-1}$.

\paragraph{Parameter mapping.}
\begin{center}
\small
\begin{tabular}{@{}lcl@{}}
\toprule
\textbf{Quantity} & \textbf{Value} & \textbf{Source} \\
\midrule
$D = \dim Cl(0,2)$ & 4 & Paper~II \\
$k^*$ & 2 & Paper~II, Theorem~17 \\
$\mathcal{C}_{\mathrm{budget}}$ & $2\,h_\mu$ & Paper~II \\
$\theta_0$ (initial misalignment) & 0.02 & this example \\
$\Lambda$ (drift rate) & $0.08\,\omega_0$
  & Eq.~\eqref{T-III-eq:drift_model} \\
$t_{\mathrm{del}}$ & $45.9\,\omega_0^{-1}$
  & Paper~II, Delusion Trap \\
$\eta$ (adaptation rate) & $0.5$ & meta-observer \\
\bottomrule
\end{tabular}
\end{center}

% ------------------------------------------------------------
\subsection{Fisher Information under Drift}
\label{T-III-subsec:fisher_drift}

As the coupling $\lambda_z(t)$ drifts, the decoherence
function $p_z(t)$ (Paper~II, Eq.~(34)) changes, shifting the
residual distribution.
The self-referential Fisher information
$\mathcal{I}_F(\sigma)$ measures this shift.

For the qubit model, the Fisher information with respect to
the frame angle $\phi$ (parametrising the $SO(3)$ rotation
between the current and optimal frames) is
\begin{equation}
\label{T-III-eq:fisher_qubit}
\mathcal{I}_F(\phi)
= \frac{(\partial_\phi\,\bar{e})^2}
  {\mathrm{Var}(e)}
\approx \frac{4\,\mathcal{S}_{\mathrm{tot}}^2\,
  \theta^2}
  {h_\mu / n_{\mathrm{eff}}},
\end{equation}
where $\bar{e} = \mathbb{E}[e\,|\,\phi]$ is the expected
residual,
$\theta = \theta(\phi)$ is the mismatch angle, and
$n_{\mathrm{eff}}$ is the effective sample size
(Remark~\ref{T-III-rem:effective_independence}).

When the frame is well-aligned ($\theta \approx 0$):
$\mathcal{I}_F \approx 0$.
As drift accumulates ($\theta$ grows):
$\mathcal{I}_F$ increases quadratically, producing a
detectable ``stress signal'' consistent with
Theorem~\ref{T-III-thm:detectability}.

% ------------------------------------------------------------
\subsection{Loop Dynamics: Self-Calibration in Action}
\label{T-III-subsec:loop_dynamics}

Under the natural gradient
update~\eqref{T-III-eq:update_law}, the frame angle
$\phi(t)$ tracks the drifting optimal frame
$\phi^*(t)$.
The Lyapunov function
$V(t) = (\phi(t) - \phi^*(t))^2$ is governed by the
tracking bound~\eqref{T-III-eq:lyapunov_decrease}:
the loop drives $V$ toward the tracking neighbourhood
$V_\infty = \|\dot{\sigma}^*\|_g^2/(\eta\alpha)^2$,
with the approach rate set by the persistent
excitation constant $\alpha$ and the adaptation
rate~$\eta$.

\paragraph{Comparison.}
\begin{itemize}
\item \textbf{Without loop} (Paper~II agent): the mismatch
  grows as $\theta(t) = \theta_0\,e^{\Lambda t}$,
  reaching $\pi/4$ at $t_{\mathrm{del}}$.
  The agent is delusional.
\item \textbf{With loop} (Paper~III agent): the mismatch
  oscillates around zero, bounded by the estimation
  noise floor
  $\theta_{\mathrm{min}}
  \sim 1/\sqrt{n_{\mathrm{eff}}\,\mathcal{I}_F^{\mathrm{env}}}$
  (the Cram\'{e}r--Rao limit).
  The agent remains calibrated.
\end{itemize}

A multi-dimensional numerical evaluation extending
this qubit illustration to continuous drift is presented
in Section~\ref{T-III-sec:numerical}.

% ------------------------------------------------------------
\subsection{Thermodynamic Cost Evaluation}
\label{T-III-subsec:cost_eval}

For the qubit example with $k^* = 2$, $h_\mu = 1$
(normalised), $\mathcal{C}_{\mathrm{meta}} = 1\,h_\mu$
(minimal meta-observer):
\begin{align}
\dot{W}_{\mathrm{sense}}
&\geq k_BT\,\ln 2 \cdot 1 \cdot 2
= 2\,k_BT\,\ln 2, \label{T-III-eq:cost_sense_ex} \\
\dot{W}_{\mathrm{compute}}
&\geq k_BT\,\ln 2 \cdot 1
= k_BT\,\ln 2, \label{T-III-eq:cost_compute_ex} \\
\dot{W}_{\mathrm{actuate}}
&\geq \frac{\mathcal{L}^2}{\tau_{\mathrm{recalib}}^2}
\approx \frac{\theta_0^2\,\tau_{\mathrm{relax}}}
  {\tau_{\mathrm{recalib}}^2}\,k_BT.
  \label{T-III-eq:cost_actuate_ex}
\end{align}
The total loop cost is dominated by the information tax
(sensing + computing) at $\sim 3\,k_BT\,\ln 2$ per unit
time, with the geometric tax (actuating) contributing a
smaller correction proportional to $\theta_0^2$.

For comparison, Paper~I's memory cost is
$\dot{W}_{\mathrm{mem}} \geq k_BT\,\ln 2$ and
Paper~II's ego processing cost is
$\dot{W}_{\mathrm{ego}} \sim 2\,k_BT\,\ln 2\cdot h_\mu$.
The self-calibration loop adds approximately $50\%$ to the
total energy budget---a significant but bounded cost for
escaping the Delusion Trap.

% ============================================================
\section{Numerical Demonstration}
\label{T-III-sec:numerical}

The preceding sections establish analytic bounds and a
low-dimensional worked example.  We now demonstrate
computationally that the three core phenomena---delusion
separation, detectable staleness, and an optimal calibration
budget---emerge in a minimal multi-dimensional system under
continuous drift.  Full code and parameters are provided for
reproducibility.

% ------------------------------------------------------------
\subsection{Model}
\label{T-III-subsec:demo_model}

\paragraph{Environment.}
A $d$-dimensional linear prediction task:
$y(t) = \mathbf{w}(t)^\top \mathbf{x}(t)
+ \sigma\,\epsilon(t)$,
$\mathbf{x}(t) \sim \mathcal{N}(\mathbf{0}, \mathbf{I}_d)$,
$\epsilon \sim \mathcal{N}(0,1)$.
The weight vector $\mathbf{w}(t) \in \mathbb{S}^{d-1}$
drifts by receiving random perturbations on
\emph{background} dimensions only (indices $k,\ldots,d{-}1$),
then renormalising.  Signal therefore migrates progressively
from the ego's foreground to its blind sector.

\paragraph{Agents.}
\begin{itemize}
\item \textbf{Fixed ego} (Paper~II analogue):
  learns a linear model on a \emph{fixed} foreground
  subspace of dimension~$k$ via stochastic gradient descent
  (SGD, rate~$\eta$, decay~$\lambda$).
  Embodies the ``frozen gauge'' of Paper~II.
\item \textbf{Calibrated loop} (Paper~III analogue):
  identical ego plus a staleness sentinel and recalibration
  mechanism.
  The sentinel tracks $g_i = \mathrm{EMA}(|e\,x_i|)$ for
  each dimension~$i$ (an absolute-gradient proxy),
  computes the fraction of top-$k$ gradient dimensions
  \emph{not} in the current foreground as a frame-staleness
  index $m \in [0,1]$, and triggers
  recalibration when
  $\mathrm{EMA}(m) > \theta$.
  After recalibration, a settling period
  of~$\tau$ steps elapses before the sentinel resumes
  monitoring.
\end{itemize}

\paragraph{Parameters.}
\begin{center}
\small
\begin{tabular}{@{}lcl@{}}
\toprule
\textbf{Quantity} & \textbf{Value} & \textbf{Role} \\
\midrule
$d$ & 20 & full ambient dimension \\
$k$ & 5  & ego foreground dimension ($k/d = 0.25$) \\
$\sigma$ & 0.1 & observation noise std \\
$\eta$ & 0.01 & SGD learning rate \\
$\lambda$ & 0.998 & SGD weight decay \\
$\theta$ & 0.25 & staleness threshold \\
$\Lambda$ & variable & drift rate per step \\
$\tau$ & variable & settling period (cooldown) \\
\bottomrule
\end{tabular}
\end{center}

\paragraph{Oracle metrics.}
Neither agent has access to $\mathbf{w}(t)$.
We evaluate performance externally using the \emph{oracle
full-space error}:
\begin{equation}
\label{T-III-eq:oracle_error}
\mathcal{E}_{\mathrm{full}}
= \bigl\|\mathbf{w}_{\mathrm{ego}}
  - \mathbf{w}^*_{\mathrm{fg}}\bigr\|^2
+ \bigl\|\mathbf{w}^*_{\mathrm{bg}}\bigr\|^2,
\end{equation}
where $\mathbf{w}^*_{\mathrm{fg}}$ and
$\mathbf{w}^*_{\mathrm{bg}}$ denote the true weight vector
restricted to foreground and background coordinates
respectively, and $\mathbf{w}_{\mathrm{ego}}$ is the ego's
foreground-supported estimator lifted to the full space.
The first term captures foreground tracking error (accessible
to the ego); the second captures hidden-sector signal
(invisible).

% ------------------------------------------------------------
\subsection{Results}
\label{T-III-subsec:demo_results}

\paragraph{Result 1: Delusion-correction separation
(Figure~\ref{T-III-fig:demo_trap}).}
At drift rate $\Lambda = 0.02$, settling period $\tau = 200$,
and $T = 5\,000$ steps, three phenomena are visible:

\begin{enumerate}
\item[(a)]
\emph{Delusion trap.}
The ego's foreground tracking error converges
to near zero, while the true full-space error rises
toward $\sim\!1$ and stabilises.
The growing gap between the two is the hidden sector,
confirming the prediction
of Theorem~\ref{T-III-thm:first_order}: first-order
monitoring cannot detect frame drift.

\item[(b)]
\emph{Detectability.}
The staleness sentinel produces a clean sawtooth:
rising from zero after each recalibration, crossing the
threshold $\theta = 0.25$, and triggering frame reset
(25~events over $T = 5\,000$).
This is consistent with the predicted growth trend of the
self-referential Fisher signal
(Theorem~\ref{T-III-thm:detectability}).

\item[(c)]
\emph{Net benefit.}
The calibrated loop achieves
$\mathcal{E}_{\mathrm{full}} \approx 0.74$
versus the fixed ego's $\approx 1.02$:
a $27\%$ reduction in true prediction error.
\end{enumerate}

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]{fig_delusion_trap.pdf}
\caption{%
\textbf{Delusion trap and calibration loop.}
$d = 20$, $k = 5$, $\Lambda = 0.02$, $\tau = 200$,
$T = 5\,000$.
\textbf{(a)}~Foreground tracking error (blue) decreases
toward zero while true full-space error (red) increases;
the shaded region is the hidden sector, invisible to the ego.
\textbf{(b)}~Frame-staleness sentinel (purple) rises
monotonically between recalibration events (orange),
producing a sawtooth with 25 threshold crossings.
\textbf{(c)}~The calibrated loop (green) maintains
lower true error than the fixed ego (red);
the grey dashed line shows the foreground energy fraction
decaying as signal migrates to the background.}
\label{T-III-fig:demo_trap}
\end{figure}

\paragraph{Result 2: Phase structure and optimal
calibration budget
(Figures~\ref{T-III-fig:demo_phase}--\ref{T-III-fig:demo_alpha}).}
We scan 16 drift rates $\Lambda \in [0.005, 0.08]$ and
16 settling periods $\tau \in [15, 800]$
(logarithmically spaced), running both agents for
$T = 4\,000$ steps across 6 random seeds per grid point.

Figure~\ref{T-III-fig:demo_phase}(a) shows the performance
gain $\Delta = \mathcal{E}_{\mathrm{ego}}
- \mathcal{E}_{\mathrm{loop}}$:
the loop improves over the ego (green) across most of
the parameter space, with a boundary at $\Delta = 0$
(dashed) below which recalibration is counterproductive
(very low drift, where the overhead of re-learning
exceeds the benefit of tracking).
The solid curve traces the \emph{optimal settling period}
$\tau_{\mathrm{opt}}(\Lambda)$---the recalibration
period minimising $\mathcal{E}_{\mathrm{loop}}$---which
decreases monotonically from $\sim\!370$ steps at
$\Lambda = 0.005$ to $\sim\!100$ at $\Lambda = 0.08$.
Figure~\ref{T-III-fig:demo_phase}(b) shows that calibration
frequency increases smoothly with drift and with shorter
settling period, exhibiting the cost--performance
trade-off of Theorem~\ref{T-III-thm:loop_cost}.

Extracting $\tau_{\mathrm{opt}}(\Lambda)$ yields the
\emph{optimal calibration frequency}
$\alpha_{\mathrm{opt}}(\Lambda)
= 1/\tau_{\mathrm{opt}}$
(Figure~\ref{T-III-fig:demo_alpha}).
The curve is smooth and monotonically increasing:
faster drift demands tighter calibration.
It saturates at high $\Lambda$ near
$\alpha_{\mathrm{opt}} \approx 0.01$ per step
($\tau_{\mathrm{opt}} \approx 100$), of the same
order as the learner's settling time.
This is consistent with the intuition that drift
estimation requires a minimum observation window;
the self-referential Cram\'{e}r--Rao bound
(Theorem~\ref{T-III-thm:SRCR}) provides the analytic
counterpart of this computational floor.

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]%
  {fig_phase_with_boundary.pdf}
\caption{%
\textbf{Phase structure and calibration cost.}
$16 \times 16$ grid, $T = 4\,000$, 6 seeds per point.
\textbf{(a)}~Performance gain $\Delta$; green = loop
improves on ego, red = counterproductive.
Solid curve: $\tau_{\mathrm{opt}}(\Lambda)$.
Dashed: $\Delta = 0$ boundary.
\textbf{(b)}~Calibration frequency (thermodynamic cost
proxy: recalibration events per step, proportional to
energy expenditure under a fixed per-recalibration cost
model); $\tau_{\mathrm{opt}}$ overlaid.}
\label{T-III-fig:demo_phase}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]{fig_alpha_opt.pdf}
\caption{%
\textbf{Optimal calibration frequency.}
\textbf{Left:}
$\tau_{\mathrm{opt}}(\Lambda)$ decreases monotonically
with drift rate.
\textbf{Right:}
$\alpha_{\mathrm{opt}}(\Lambda) = 1/\tau_{\mathrm{opt}}$
increases with drift rate and saturates at the learner's
settling timescale ($\sim\!100$ steps), consistent with
an observation-window floor.}
\label{T-III-fig:demo_alpha}
\end{figure}

% ------------------------------------------------------------
\subsection{Scope of This Demonstration}
\label{T-III-subsec:demo_scope}

This demonstration \textbf{does} show:
\begin{enumerate}
\item The delusion-correction separation predicted by
  Theorems~\ref{T-III-thm:first_order}
  and~\ref{T-III-thm:detectability} emerges in a minimal
  stochastic system with continuous drift.
\item A frame-staleness signal with clean threshold
  dynamics exists and triggers effective recalibration.
\item An optimal calibration frequency
  $\alpha_{\mathrm{opt}}(\Lambda)$ exists, increases
  monotonically with drift rate, and saturates at the
  learner's settling timescale.
\item The cost--performance trade-off of
  Theorem~\ref{T-III-thm:loop_cost} manifests as a structured
  phase diagram with an explicit
  $\tau_{\mathrm{opt}}$ boundary.
\end{enumerate}

\noindent
In summary, this demonstration validates the
\emph{existence} and \emph{detectability} of the
loop--cost trade-off in a minimal linear setting;
it does not claim universality across architectures
or environment classes.

\medskip
This demonstration does \textbf{not} show:
\begin{enumerate}
\item That the specific functional form of
  $\alpha_{\mathrm{opt}}(\Lambda)$ matches the analytic
  Cram\'{e}r--Rao prediction in the
  large-$d$ limit.  The demonstration confirms the
  monotonic trend and saturation; deriving the exact
  scaling exponent from Theorem~\ref{T-III-thm:SRCR}
  remains open.
\item That the results generalise to all environment
  classes.  The model uses Gaussian features, linear
  regression, and isotropic background drift; extensions
  to non-linear, non-Gaussian, or structured-drift
  settings require further investigation.
\item That the calibration loop is optimal among all
  possible adaptive strategies.  It implements one
  specific realisation of the calibration-loop
  architecture.
\end{enumerate}

\paragraph{Reproducibility.}
The complete simulation is a self-contained Python script
(\texttt{tdome\_demo.py}, $\sim\!550$ lines, requiring
only NumPy and Matplotlib) with fixed random seeds.
All figures in this section can be reproduced by
executing the script after setting the output directory
variable \texttt{BASE} to the desired path.

% ============================================================
\section{Discussion}
\label{T-III-sec:discussion}

% ------------------------------------------------------------
\subsection{Summary of Results}
\label{T-III-subsec:summary}

\begin{center}
\small
\setlength{\tabcolsep}{4pt}%
\begin{tabular}{@{}lp{6cm}c@{}}
\toprule
\textbf{Result} & \textbf{Statement} & \textbf{Sec.} \\
\midrule
First-Order Insufficiency
  & Raw prediction error cannot detect frame drift
  & \ref{T-III-subsec:first_order} \\[3pt]
Drift Detectability
  & Self-referential Fisher information grows
    quadratically with accumulated drift
  & \ref{T-III-subsec:self_ref_fisher} \\[3pt]
Self-Referential CR Bound
  & Drift estimation bounded by
    $1/(n_{\mathrm{eff}}\,\mathcal{I}_F + \mathcal{I}_{\mathrm{ego}})$
  & \ref{T-III-subsec:SRCR} \\[3pt]
Loop Tracking Bound
  & Lyapunov $V$ with tracking neighbourhood
    $V_\infty = \|\dot{\sigma}^*\|^2/(\eta\alpha)^2$
  & \ref{T-III-subsec:lyapunov} \\[3pt]
Four-Part Structure
  & Persistent agents require four structural layers
  & \ref{T-III-subsec:four_part} \\[3pt]
Loop Cost
  & $\dot{W}_{\mathrm{loop}} \geq k_BT\,\ln 2\,[h_\mu\,k^*
    + \mathcal{C}_{\mathrm{meta}}]
    + \mathcal{L}^2/\tau_{\mathrm{recalib}}^2$
  & \ref{T-III-subsec:cost_theorem} \\[3pt]
Persistence Budget
  & Total cost: memory + ego + loop
  & \ref{T-III-subsec:persistence} \\[3pt]
Numerical Demonstration
  & Delusion separation, sentinel detection,
    $\alpha_{\mathrm{opt}}(\Lambda)$ boundary
  & \ref{T-III-sec:numerical} \\
\bottomrule
\end{tabular}
\end{center}

% ------------------------------------------------------------
\subsection{The Complete Logic Chain}
\label{T-III-subsec:logic_chain}

Papers~I--III trace an irreversible
thermodynamic logic chain:

\begin{center}
\small
\setlength{\tabcolsep}{3pt}%
\begin{tabular}{@{}lp{3.2cm}p{3.8cm}l@{}}
\toprule
\textbf{Paper} & \textbf{Crisis} & \textbf{Resolution}
  & \textbf{What is born} \\
\midrule
Paper~I
  & Markovian trap: no history
  & Non-Markovian memory
  & \textbf{Temporal accumulation} \\[3pt]
Paper~II
  & Computation explosion: $\infty$~memory, finite budget
  & Gauge SSB: $Cl(V,q) \to V_{\mathrm{fg}}
    \oplus V_{\mathrm{bg}}$
  & \textbf{Compressed ref.\ frame} \\[3pt]
Paper~III
  & Delusion trap: fixed bias, drifting world
  & Fisher self-referential calibration; tracking bound
  & \textbf{Reflexivity} \\
\bottomrule
\end{tabular}
\end{center}

Each resolution creates the precondition for the next
crisis.
The chain terminates at Paper~III: the self-referential
calibration loop does not create a further crisis requiring a
``Paper~IV,'' because the loop is \emph{self-correcting}
by construction (Theorem~\ref{T-III-thm:loop_stability}).
Its only vulnerability is the thermodynamic budget
(Theorem~\ref{T-III-thm:loop_cost}): if the agent's free-energy
supply falls below the persistence
budget~\eqref{T-III-eq:persistence_budget}, the loop degrades
and the Delusion Trap re-emerges.
This is not a new crisis but the Second Law itself: all
order requires free-energy dissipation.

% ------------------------------------------------------------
\subsection{What This Paper Does and Does Not Show}
\label{T-III-subsec:claims}

This paper \textbf{does} show:
\begin{enumerate}
\item Under environmental drift~(C2) and bounded
  computation~(C1), first-order control fails to detect
  frame drift (Theorem~\ref{T-III-thm:first_order}).
\item Self-referential Fisher information provides a
  quadratically growing signal sufficient for drift
  detection before the Delusion Trap
  (Theorem~\ref{T-III-thm:detectability}).
\item Drift estimation precision is bounded by the
  Self-Referential Cram\'{e}r--Rao bound
  (Theorem~\ref{T-III-thm:SRCR}).
\item The calibration loop tracks the optimal frame
  within a bounded neighbourhood under a Lyapunov
  tracking bound
  (Theorem~\ref{T-III-thm:loop_stability}).
\item The thermodynamic cost of the loop is calculable
  (Theorem~\ref{T-III-thm:loop_cost}).
\end{enumerate}

\medskip
This paper does \textbf{not} show:
\begin{enumerate}
\item That self-referential calibration implies or requires
  phenomenal consciousness, subjective experience, or
  qualia. ``Reflexivity'' as used here denotes
  second-order control, nothing more.
\item That the Lyapunov function $V$ is a measure of
  ``awareness.'' It is a control-theoretic stability
  condition, not a consciousness metric.
\item That the Four-Part Structure Proposition is a complete
  characterisation of agency. It states sufficient
  conditions under~(C1)--(C5); other architectures may
  also suffice.
\item That Fisher information requires the agent to
  ``know'' it is computing Fisher information.
  The computation can be implemented implicitly by any
  physical system whose dynamics approximate the natural
  gradient.
\item That the calibration loop eliminates the ego's bias.
  It tracks and compensates for drift in the bias;
  the four bias terms of Paper~II persist.
\item That the thermodynamic cost bounds are achievable by
  any specific physical implementation.
  They are information-theoretic lower bounds.
\item That this framework applies to all possible systems.
  It applies to systems satisfying~(C1)--(C5).
\item That the structural parallel with philosophical
  concepts of self-awareness constitutes a philosophical
  or metaphysical claim.
\item That the Clifford algebra is the only possible
  algebraic setting. Other control algebras may yield
  analogous results with different quantitative bounds.
\end{enumerate}

\medskip
We have established a budgeted self-referential calibration
loop that detects drift via an intrinsic Fisher signal,
yields a falsifiable stability criterion, and incurs an
unavoidable thermodynamic cost.
In the context of Papers~I--III, this completes the
programme's third step by turning bias (Paper~II)
into a dynamically monitored and correctable quantity.

% ============================================================
% REFERENCES
% ============================================================


% ============================================================================
% BACK MATTER
% ============================================================================
\backmatter

\chapter*{Acknowledgments}
\addcontentsline{toc}{chapter}{Acknowledgments}

The author thanks the anonymous reviewers for their insightful comments and suggestions, which greatly improved the clarity and rigor of this work.

% ============================================================================
% Consolidated Bibliography
% ============================================================================

% ============================================================================
% UNIFIED BIBLIOGRAPHY
% ============================================================================
\begin{thebibliography}{99}

\bibitem{Amari1985}
S.-i.~Amari,
\emph{Differential-Geometrical Methods in Statistics},
Lecture Notes in Statistics \textbf{28}, Springer (1985).

\bibitem{Amari1998}
S.-i.~Amari,
\emph{Natural gradient works efficiently in learning},
Neural Computation \textbf{10}, 251 (1998).

\bibitem{AmariNagaoka2000}
S.-i.~Amari and H.~Nagaoka,
\emph{Methods of Information Geometry},
Translations of Mathematical Monographs \textbf{191},
AMS (2000).

\bibitem{Araki1999}
H. Araki, \emph{Mathematical Theory of Quantum Fields}, Oxford University Press (1999).

\bibitem{Asanga_Mahayana}
Asaá¹…ga, \emph{Mah\=ay\=anasaá¹ƒgraha (Summary of the Great Vehicle)}, trans.\ Ã‰. Lamotte, Peeters (1973).

\bibitem{Ashby1956}
W.~R.~Ashby,
\emph{An Introduction to Cybernetics},
Chapman \& Hall (1956).

\bibitem{AstromWittenmark1995}
K.~J.~\AA{}str\"{o}m and B.~Wittenmark,
\emph{Adaptive Control},
2nd ed., Addison-Wesley (1995).

\bibitem{BaratoSeifert2015}
A.~C.~Barato and U.~Seifert,
\emph{Thermodynamic uncertainty relation for biomolecular
processes},
Phys.\ Rev.\ Lett.\ \textbf{114}, 158101 (2015).

\bibitem{Bengtsson2006}
I. Bengtsson and K. \.Zyczkowski, \emph{Geometry of Quantum States: An Introduction to Quantum Entanglement}, Cambridge University Press (2006).

\bibitem{Bennett1982}
C.~H.~Bennett,
\emph{The thermodynamics of computation---a review},
Int.\ J.\ Theor.\ Phys.\ \textbf{21}, 905 (1982).

\bibitem{BialekNemenmanTishby2001}
W.~Bialek, I.~Nemenman, and N.~Tishby,
\emph{Predictability, complexity, and learning},
Neural Computation \textbf{13}, 2409 (2001).

\bibitem{Boltzmann1896}
L. Boltzmann, \emph{Vorlesungen \"uber Gastheorie}, J. A. Barth, Leipzig (1896).

\bibitem{Breuer2002}
H.-P.~Breuer and F.~Petruccione, \emph{The Theory of Open Quantum Systems}, Oxford University Press (2002).

\bibitem{BreuerLainePiilo2009}
H.-P.~Breuer, E.-M.~Laine, and J.~Piilo,
\emph{Measure for the Degree of Non-Markovian Behavior of Quantum Processes in Open Systems},
Phys.\ Rev.\ Lett.\ \textbf{103}, 210401 (2009).

\bibitem{BreuerPetruccione2002}
H.-P.~Breuer and F.~Petruccione,
\emph{The Theory of Open Quantum Systems},
Oxford University Press (2002).

\bibitem{Carroll2010}
S. Carroll, \emph{From Eternity to Here: The Quest for the Ultimate Theory of Time}, Dutton (2010).

\bibitem{Cencov1982}
N.~N.~\v{C}encov,
\emph{Statistical Decision Rules and Optimal Inference},
Translations of Mathematical Monographs \textbf{53},
AMS (1982).

\bibitem{Chalmers1996}
D. J. Chalmers, \emph{The Conscious Mind: In Search of a Fundamental Theory}, Oxford University Press (1996).

% Neuroscience

\bibitem{Connes1994}
A.~Connes, \emph{Noncommutative Geometry}, Academic Press (1994).

\bibitem{CoverThomas2006}
T.~M.~Cover and J.~A.~Thomas,
\emph{Elements of Information Theory},
2nd ed., Wiley (2006).

\bibitem{Crooks2007}
G.~E.~Crooks,
\emph{Measuring thermodynamic length},
Phys.\ Rev.\ Lett.\ \textbf{99}, 100602 (2007).

\bibitem{CrutchfieldYoung1989}
J.~P.~Crutchfield and K.~Young,
\emph{Inferring statistical complexity},
Phys.\ Rev.\ Lett.\ \textbf{63}, 105 (1989).

\bibitem{DeWitt1967}
B. S. DeWitt, \emph{Quantum Theory of Gravity. I. The Canonical Theory}, Phys. Rev. \textbf{160}, 1113 (1967).

\bibitem{Doran2003}
C.~Doran and A.~Lasenby, \emph{Geometric Algebra for Physicists}, Cambridge University Press (2003).

\bibitem{EspositoLindenbergVandenBroeck2010}
M.~Esposito, K.~Lindenberg, and C.~Van~den~Broeck,
\emph{Entropy production as correlation between system and reservoir},
New J.\ Phys.\ \textbf{12}, 013013 (2010).

\bibitem{Faulkner2014}
T. Faulkner, M. Guica, T. Hartman, R. C. Myers, and M. Van Raamsdonk, \emph{Gravitation from Entanglement in Holographic CFTs}, JHEP \textbf{03}, 051 (2014).

\bibitem{French2014}
S. French, \emph{The Structure of the World: Metaphysics and Representation}, Oxford University Press (2014).

% Buddhist Primary Texts (Yogacara)

\bibitem{Fuchs2014}
C. A. Fuchs, \emph{QBism, the Perimeter of Quantum Bayesianism}, arXiv:1003.5209 (2014).

\bibitem{FuchsMerminSchack2014}
C. A. Fuchs, N. D. Mermin, and R. Schack, \emph{An Introduction to QBism with an Application to the Locality of Quantum Mechanics}, Am. J. Phys. \textbf{82}, 749 (2014).

\bibitem{GKS1976}
V.~Gorini, A.~Kossakowski, and E.~C.~G.~Sudarshan,
\emph{Completely positive dynamical semigroups of $N$-level systems},
J.\ Math.\ Phys.\ \textbf{17}, 821 (1976).

\bibitem{Garfield2002}
J. L. Garfield, \emph{Empty Words: Buddhist Philosophy and Cross-Cultural Interpretation}, Oxford University Press (2002).

\bibitem{Gombrich1996}
R. F. Gombrich, \emph{How Buddhism Began: The Conditioned Genesis of the Early Teachings}, Athlone Press (1996).

\bibitem{Graybiel2008}
A. M. Graybiel, \emph{Habits, rituals, and the evaluative brain}, Annual Review of Neuroscience \textbf{31}, 359--387 (2008).

\bibitem{Gunaydin1973}
M.~G\"unaydin and F.~G\"ursey, \emph{Quark structure and octonions}, J.\ Math.\ Phys.\ \textbf{14}, 1651 (1973).

\bibitem{Haag1996}
R. Haag, \emph{Local Quantum Physics: Fields, Particles, Algebras}, Springer-Verlag (1996).

\bibitem{Haggard2005}
P. Haggard, \emph{Conscious intention and motor cognition}, Trends in Cognitive Sciences \textbf{9}(6), 290--295 (2005).

% Structural Realism

\bibitem{Harvey2000}
P. Harvey, \emph{An Introduction to Buddhist Ethics: Foundations, Values and Issues}, Cambridge University Press (2000).

% Early Buddhist Texts

\bibitem{Hayden2007}
P. Hayden and J. Preskill, \emph{Black holes as mirrors: quantum information in random subsystems}, JHEP \textbf{09}, 120 (2007).

\bibitem{Hestenes1966}
D.~Hestenes, \emph{Space-Time Algebra}, Gordon and Breach (1966).

\bibitem{Ito2018}
S.~Ito,
\emph{Stochastic thermodynamic interpretation of
information geometry},
Phys.\ Rev.\ Lett.\ \textbf{121}, 030605 (2018).

\bibitem{Jacobson1995}
T. Jacobson, \emph{Thermodynamics of Spacetime: The Einstein Equation of State}, Phys. Rev. Lett. \textbf{75}, 1260 (1995).

\bibitem{Jarzynski2011}
C.~Jarzynski, \emph{Equalities and inequalities: irreversibility and the second law at the nanoscale}, Annu.\ Rev.\ Condens.\ Matter Phys.\ \textbf{2}, 329 (2011).

\bibitem{JohnsonLindenstrauss1984}
W.~B.~Johnson and J.~Lindenstrauss,
\emph{Extensions of Lipschitz mappings into a Hilbert space},
Contemp.\ Math.\ \textbf{26}, 189 (1984).

\bibitem{Kiefer2012}
C. Kiefer, \emph{Quantum Gravity}, 3rd ed., Oxford University Press (2012).

\bibitem{Ladyman2007}
J. Ladyman and D. Ross, \emph{Every Thing Must Go: Metaphysics Naturalized}, Oxford University Press (2007).

\bibitem{Landauer1961}
R.~Landauer,
\emph{Irreversibility and heat generation in the
computing process},
IBM J.\ Res.\ Dev.\ \textbf{5}, 183 (1961).

\bibitem{Lashkari2014}
N. Lashkari, M. B. McDermott, and M. Van Raamsdonk, \emph{Gravitational dynamics from entanglement ``thermodynamics''}, JHEP \textbf{04}, 195 (2014).

\bibitem{LaudisaRovelli2021}
F. Laudisa and C. Rovelli, \emph{Relational Quantum Mechanics}, Stanford Encyclopedia of Philosophy (2021).

\bibitem{Levine1983}
J. Levine, \emph{Materialism and qualia: The explanatory gap}, Pacific Philosophical Quarterly \textbf{64}, 354 (1983).

\bibitem{Lidar2003}
D.~A.~Lidar and K.~B.~Whaley, \emph{Decoherence-free subspaces and subsystems}, in \emph{Irreversible Quantum Dynamics}, Springer, pp.~83--120 (2003).

\bibitem{Lindblad1976}
G.~Lindblad,
\emph{On the generators of quantum dynamical semigroups},
Commun.\ Math.\ Phys.\ \textbf{48}, 119 (1976).

\bibitem{Lusthaus2002}
D. Lusthaus, \emph{Buddhist Phenomenology: A Philosophical Investigation of Yog\=ac\=ara Buddhism and the Ch'eng Wei-shih lun}, Routledge (2002).

\bibitem{Maldacena1999}
J. M. Maldacena, \emph{The Large N limit of superconformal field theories and supergravity}, Int. J. Theor. Phys. \textbf{38}, 1113 (1999).

\bibitem{Nagarjuna_MMK_Garfield1995}
N\=ag\=arjuna, \emph{The Fundamental Wisdom of the Middle Way: N\=ag\=arjuna's M\=ulamadhyamakak\=arik\=a}, trans.\ J. L. Garfield, Oxford University Press (1995).

% Buddhist Secondary Sources

\bibitem{Nakajima1958}
S.~Nakajima,
\emph{On quantum theory of transport phenomena},
Prog.\ Theor.\ Phys.\ \textbf{20}, 948 (1958).

\bibitem{Page1993}
D. N. Page, \emph{Average entropy of a subsystem}, Phys. Rev. Lett. \textbf{71}, 1291 (1993).

\bibitem{PageWootters1983}
D. N. Page and W. K. Wootters, \emph{Evolution without evolution: Dynamics described by stationary observables}, Phys. Rev. D \textbf{27}, 2885 (1983).

\bibitem{Parrondo2015}
J.~M.~R.~Parrondo, J.~M.~Horowitz, and T.~Sagawa, \emph{Thermodynamics of information}, Nat.\ Phys.\ \textbf{11}, 131 (2015).

\bibitem{Pearl2009}
J. Pearl, \emph{Causality: Models, Reasoning, and Inference}, 2nd ed., Cambridge University Press (2009).

\bibitem{Penrose1989}
R. Penrose, \emph{The Emperor's New Mind}, Oxford University Press (1989).

\bibitem{Petz1996}
D. Petz, \emph{Monotone metrics on matrix spaces}, Linear Algebra Appl. \textbf{244}, 81 (1996).

\bibitem{Price2012}
H. Price, \emph{Does Time-Symmetry Imply Retrocausality?}, Found. Phys. \textbf{42}, 724 (2012).

\bibitem{Rao1945}
C.~R.~Rao,
\emph{Information and the accuracy attainable in the
estimation of statistical parameters},
Bull.\ Calcutta Math.\ Soc.\ \textbf{37}, 81 (1945).

\bibitem{RivasHuelgaPlenio2014}
\'{A}.~Rivas, S.~F.~Huelga, and M.~B.~Plenio,
\emph{Quantum non-Markovianity: characterization, quantification and detection},
Rep.\ Prog.\ Phys.\ \textbf{77}, 094001 (2014).

\bibitem{Rovelli1996}
C. Rovelli, \emph{Relational Quantum Mechanics}, Int. J. Theor. Phys. \textbf{35}, 1637 (1996).

\bibitem{Rovelli2004}
C. Rovelli, \emph{Quantum Gravity}, Cambridge University Press (2004).

\bibitem{RyuTakayanagi2006}
S. Ryu and T. Takayanagi, \emph{Holographic Derivation of Entanglement Entropy from AdS/CFT}, Phys. Rev. Lett. \textbf{96}, 181602 (2006).

\bibitem{Sagawa2012}
T.~Sagawa and M.~Ueda, \emph{Fluctuation theorem with information exchange}, Phys.\ Rev.\ E \textbf{85}, 021104 (2012).

\bibitem{SagawaUeda2010}
T.~Sagawa and M.~Ueda,
\emph{Generalized Jarzynski Equality under Nonequilibrium Feedback Control},
Phys.\ Rev.\ Lett.\ \textbf{104}, 090602 (2010).

\bibitem{SagawaUeda2012}
T.~Sagawa and M.~Ueda,
\emph{Fluctuation Theorem with Information Exchange},
Phys.\ Rev.\ Lett.\ \textbf{109}, 180602 (2012).

\bibitem{Schafer1966}
R.~D.~Schafer, \emph{An Introduction to Nonassociative Algebras}, Academic Press (1966).

\bibitem{Schrodinger1944}
E.~Schr\"odinger,
\emph{What is Life?},
Cambridge University Press (1944).

\bibitem{Seifert2012}
U.~Seifert, \emph{Stochastic thermodynamics, fluctuation theorems and molecular machines}, Rep.\ Prog.\ Phys.\ \textbf{75}, 126001 (2012).

\bibitem{ShaliziCrutchfield2001}
C.~R.~Shalizi and J.~P.~Crutchfield,
\emph{Computational mechanics: Pattern and prediction, structure and simplicity},
J.\ Stat.\ Phys.\ \textbf{104}, 817 (2001).

\bibitem{Shannon1959}
C.~E.~Shannon,
\emph{Coding theorems for a discrete source with a
fidelity criterion},
IRE Nat.\ Conv.\ Rec., Part~4, pp.~142--163 (1959).

\bibitem{Siderits2007}
M. Siderits, \emph{Buddhism as Philosophy: An Introduction}, Hackett Publishing (2007).

% Karma Studies

\bibitem{Simon1955}
H.~A.~Simon,
\emph{A behavioral model of rational choice},
Quarterly J.\ of Economics \textbf{69}, 99 (1955).

\bibitem{Sims2003}
C.~A.~Sims,
\emph{Implications of rational inattention},
J.\ Monetary Economics \textbf{50}, 665 (2003).

\bibitem{SivakCrooks2012}
D.~A.~Sivak and G.~E.~Crooks,
\emph{Thermodynamic metrics and optimal paths},
Phys.\ Rev.\ Lett.\ \textbf{108}, 190602 (2012).

\bibitem{Smolin2006}
L. Smolin, \emph{The case for background independence}, in \emph{The Structural Foundations of Quantum Gravity}, eds. D. Rickles, S. French, J. Saatsi, Oxford University Press (2006).

\bibitem{Spohn1978}
H.~Spohn,
\emph{Entropy production for quantum dynamical semigroups},
J.\ Math.\ Phys.\ \textbf{19}, 1227 (1978).

\bibitem{SuttaNipata}
\emph{Sutta Nip\=ata}, in \emph{The Group of Discourses (Sutta Nip\=ata)}, trans.\ K. R. Norman, Pali Text Society (2001).

\bibitem{Swingle2012}
B. Swingle, \emph{Entanglement Renormalization and Holography}, Phys. Rev. D \textbf{86}, 065007 (2012).

\bibitem{Thiemann2007}
T. Thiemann, \emph{Modern Canonical Quantum General Relativity}, Cambridge University Press (2007).

\bibitem{Tishby2000}
N.~Tishby, F.~C.~Pereira, and W.~Bialek,
\emph{The information bottleneck method},
in Proc.\ 37th Allerton Conf.\ on Communication, Control,
and Computing (1999); arXiv:physics/0004057 (2000).

\bibitem{VanRaamsdonk2010}
M. Van Raamsdonk, \emph{Building up spacetime with quantum entanglement}, Gen. Relativ. Gravit. \textbf{42}, 2323 (2010).

\bibitem{Vasubandhu_Trimsika}
Vasubandhu, \emph{Triá¹ƒÅ›ik\=a-vij\~naptim\=atrat\=a (Thirty Verses on Consciousness Only)}, trans.\ S. Anacker, in \emph{Seven Works of Vasubandhu}, Motilal Banarsidass (1984).

% Buddhist Primary Texts (Madhyamaka)

\bibitem{Verlinde2011}
E.~Verlinde, \emph{On the Origin of Gravity and the Laws of Newton}, JHEP \textbf{04}, 029 (2011).

\bibitem{Vidal2008}
G. Vidal, \emph{Class of quantum many-body states that can be efficiently simulated}, Phys. Rev. Lett. \textbf{101}, 110501 (2008).

\bibitem{Viola2004}
H. Barnum, E. Knill, G. Ortiz, R. Somma, and L. Viola, \emph{A Subsystem-Independent Generalization of Entanglement}, Phys. Rev. Lett. \textbf{92}, 107902 (2004).

\bibitem{Waldron2003}
W. S. Waldron, \emph{The Buddhist Unconscious: The Ä€laya-vij\~n\=ana in the Context of Indian Buddhist Thought}, Routledge (2003).

\bibitem{Wallace2012}
D. Wallace, \emph{The Emergent Multiverse}, Oxford University Press (2012).

\bibitem{Wallace2012Time}
D. Wallace, \emph{The Emergent Multiverse: Quantum Theory according to the Everett Interpretation}, Oxford University Press (2012), Chapter 8.

\bibitem{Weiss2012}
U.~Weiss, \emph{Quantum Dissipative Systems}, 4th ed., World Scientific (2012).

\bibitem{WisemanMilburn2009}
H.~M.~Wiseman and G.~J.~Milburn, \emph{Quantum Measurement and Control}, Cambridge University Press (2009).

\bibitem{Witten2018}
E.~Witten, \emph{APS Medal for Exceptional Achievement in Research: Invited article on entanglement properties of quantum field theory}, Rev.\ Mod.\ Phys.\ \textbf{90}, 045003 (2018).

\bibitem{Woodward2003}
J. Woodward, \emph{Making Things Happen: A Theory of Causal Explanation}, Oxford University Press (2003).

\bibitem{Yin2006}
H. H. Yin and B. J. Knowlton, \emph{The role of the basal ganglia in habit formation}, Nature Reviews Neuroscience \textbf{7}, 464--476 (2006).

\bibitem{Zanardi2001}
P. Zanardi, \emph{Virtual Quantum Subsystems}, Phys. Rev. Lett. \textbf{87}, 077901 (2001).

\bibitem{Zanardi2004}
P. Zanardi, D. A. Lidar, and S. Lloyd, \emph{Quantum Tensor Product Structures are Observable Induced}, Phys. Rev. Lett. \textbf{92}, 060402 (2004).

\bibitem{Zurek2003}
W. H. Zurek, \emph{Decoherence, einselection, and the quantum origins of the classical}, Rev. Mod. Phys. \textbf{75}, 715 (2003).

\bibitem{Zurek2009}
W. H. Zurek, \emph{Quantum Darwinism}, Nature Physics \textbf{5}, 181 (2009).

\bibitem{Zwanzig1960}
R.~Zwanzig,
\emph{Ensemble method in the theory of irreversibility},
J.\ Chem.\ Phys.\ \textbf{33}, 1338 (1960).

\bibitem{vanTrees1968}
H.~L.~van Trees,
\emph{Detection, Estimation, and Modulation Theory},
Part~I, Wiley (1968).

\bibitem{vonFoerster2003}
H.~von Foerster,
\emph{Understanding Understanding: Essays on Cybernetics
and Cognition},
Springer (2003).

\bibitem{Liu2026}
S. Liu, \emph{Emergent Geometry from Coarse-Grained Observable Algebras: The Holographic Alaya-Field Framework}, Zenodo (2026), DOI: 10.5281/zenodo.18361707.

\bibitem{Liu2026HAFF_A}
S.~Liu, \emph{Emergent Geometry from Coarse-Grained Observable Algebras: The Holographic Alaya-Field Framework}, Zenodo (2026), DOI: 10.5281/zenodo.18361707.

\bibitem{Liu2026HAFF_B}
S.~Liu, \emph{Accessibility, Stability, and Emergent Geometry: Conceptual Clarifications on the Holographic Alaya-Field Framework}, Zenodo (2026), DOI: 10.5281/zenodo.18367061.

\bibitem{Liu2026HAFF_C}
S.~Liu,
\emph{Causation, Agency, and Existence},
Zenodo (2026), DOI: 10.5281/zenodo.18391651.

\bibitem{Liu2026HAFF_F}
S.~Liu,
\emph{Temporal Asymmetry as Accessibility Propagation},
Zenodo (2026), DOI: 10.5281/zenodo.18417099.

\bibitem{Liu2026HAFF_G}
S.~Liu,
\emph{Structural Limits of Unification: Accessibility,
Incompleteness, and the Necessity of a Final Cut},
Zenodo (2026), DOI: 10.5281/zenodo.18402908.

\bibitem{Liu2026PaperG}
S. Liu, \emph{Structural Limits of Unification: Accessibility, Incompleteness, and the Necessity of a Final Cut}, Zenodo (2026), DOI: 10.5281/zenodo.18402908.

\bibitem{Penrose2010}
R.~Penrose, \emph{Cycles of Time: An Extraordinary New View of the Universe}, Bodley Head (2010).

\bibitem{Liu2026PaperA}
S. Liu, \emph{Emergent Geometry from Coarse-Grained Observable Algebras: The Holographic Alaya-Field Framework}, Zenodo (2026), DOI: 10.5281/zenodo.18361707.

\bibitem{Liu2026PaperB}
S. Liu, \emph{Accessibility, Stability, and Emergent Geometry: Conceptual Clarifications on the Holographic Alaya-Field Framework}, Zenodo (2026), DOI: 10.5281/zenodo.18367061.

% Causation and Philosophy of Science

\bibitem{Liu2026PaperC}
S. Liu, \emph{Causation, Agency, and Existence: Structural Constraints and Interpretive Bridges}, Zenodo (2026), DOI: 10.5281/zenodo.18374806.

\bibitem{Liu2026PaperD}
S. Liu, \emph{Gravitational Phenomena as Emergent Properties of Observable Algebra Selection: A Structural Analysis}, Zenodo (2026), DOI: 10.5281/zenodo.18388882.

\bibitem{Liu2026PaperE}
S. Liu, \emph{Measurement as Accessibility: A Structural Analysis of Observable Algebra Selection}, Zenodo (2026), DOI: 10.5281/zenodo.18400066.

\bibitem{Liu2026PaperF}
S. Liu, \emph{Temporal Asymmetry as Accessibility Propagation: A Structural Analysis of Causal Direction}, Zenodo (2026), DOI: 10.5281/zenodo.18400426.

\bibitem{Liu2026QRAIF_A}
S.~Liu, \emph{Algebraic Constraints on the Emergence of Lorentzian Metrics in Entropic Gravity Frameworks}, Zenodo (2026), DOI: 10.5281/zenodo.18525877.

\bibitem{Liu2026QRAIF_B}
S.~Liu, \emph{Thermodynamic Stability Constraints on the Operator Algebra of Persistent Open Quantum Subsystems}, Zenodo (2026), DOI: 10.5281/zenodo.18525891.

\bibitem{Liu2026QRAIF_C}
S.~Liu, \emph{The Realizability Bridge: Algebraic Closure in the Q-RAIF Framework}, Zenodo (2026), DOI: 10.5281/zenodo.18528935.

\bibitem{Liu2026TDOME_I}
S.~Liu,
\emph{Non-Markovian Memory and the Thermodynamic Necessity
of Temporal Accumulation},
Zenodo (2026), DOI: 10.5281/zenodo.18574342.

\bibitem{Liu2026TDOME_II}
S.~Liu,
\emph{Spontaneous Symmetry Breaking of Reference Frames
as a Computational Cost Minimization Strategy},
Zenodo (2026), DOI: 10.5281/zenodo.18579703.

\bibitem{Liu2026TDOME_III}
S.~Liu,
\emph{Fisher Information Geometry and the Thermodynamic Cost
of Self-Referential Calibration},
Zenodo (2026), DOI: 10.5281/zenodo.18591771.

\end{thebibliography}

\end{document}
